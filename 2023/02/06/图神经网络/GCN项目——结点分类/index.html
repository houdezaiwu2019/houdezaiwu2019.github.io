<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GCN项目——结点分类 - houdezaiwu&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="czt"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="czt"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="hljs.initHighlightingOnLoad();  本文主要介绍的是一个基于图卷积进行的节点分类问题，主要是图神经网络来进行半监督学习的一个案例，其中主要的基于PYG库进行，初学可以使用PYG进行快速的上手，之后还是做好基于pytorch自主实现。"><meta property="og:type" content="blog"><meta property="og:title" content="GCN项目——结点分类"><meta property="og:url" content="http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB/"><meta property="og:site_name" content="houdezaiwu&#039;s blog"><meta property="og:description" content="hljs.initHighlightingOnLoad();  本文主要介绍的是一个基于图卷积进行的节点分类问题，主要是图神经网络来进行半监督学习的一个案例，其中主要的基于PYG库进行，初学可以使用PYG进行快速的上手，之后还是做好基于pytorch自主实现。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"><meta property="article:published_time" content="2023-02-06T00:53:00.000Z"><meta property="article:modified_time" content="2023-02-06T03:25:32.773Z"><meta property="article:author" content="czt"><meta property="article:tag" content="图神经网络"><meta property="article:tag" content="Graph"><meta property="article:tag" content="Neural Networks"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB/"},"headline":"GCN项目——结点分类","image":["https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"],"datePublished":"2023-02-06T00:53:00.000Z","dateModified":"2023-02-06T03:25:32.773Z","author":{"@type":"Person","name":"czt"},"publisher":{"@type":"Organization","name":"houdezaiwu's blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"hljs.initHighlightingOnLoad();  本文主要介绍的是一个基于图卷积进行的节点分类问题，主要是图神经网络来进行半监督学习的一个案例，其中主要的基于PYG库进行，初学可以使用PYG进行快速的上手，之后还是做好基于pytorch自主实现。"}</script><link rel="canonical" href="http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="/css/prism-coy-without-shadows.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg" alt="GCN项目——结点分类"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-06T00:53:00.000Z" title="2023/2/6 上午8:53:00">2023-02-06</time>发表</span><span class="level-item"><time dateTime="2023-02-06T03:25:32.773Z" title="2023/2/6 上午11:25:32">2023-02-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a></span><span class="level-item">33 分钟读完 (大约4892个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">GCN项目——结点分类</h1><div class="content"><link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">

<!-- hexo-inject:begin --><!-- hexo-inject:end --><script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<p>本文主要介绍的是一个基于图卷积进行的节点分类问题，主要是图神经网络来进行半监督学习的一个案例，其中主要的基于PYG库进行，初学可以使用PYG进行快速的上手，之后还是做好基于pytorch自主实现。</p>
<span id="more"></span>
<h2 id="官方代码解读"><a href="#官方代码解读" class="headerlink" title="官方代码解读"></a><strong>官方代码解读</strong></h2><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a><strong>基本数据类型</strong></h3><p>A graph is used to model pairwise relations (edges) between objects (nodes). A single graph in PyG is described by an instance of <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>torch_geometric.data.Data</code></a>, which holds the following attributes by default:</p>
<ul>
<li><code>data.x</code>: Node feature matrix with shape <code>[num_nodes, num_node_features]</code></li>
<li><code>data.edge_index</code>: Graph connectivity in <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs">COO format</a> with shape <code>[2, num_edges]</code> and type <code>torch.long</code></li>
<li><code>data.edge_attr</code>: Edge feature matrix with shape <code>[num_edges, num_edge_features]</code> 相当于卷积核。</li>
<li><code>data.y</code>: Target to train against (may have arbitrary shape), <em>e.g.</em>, node-level targets of shape <code>[num_nodes, *]</code> or graph-level targets of shape <code>[1, *]</code> 输出节点的维度。</li>
<li><code>data.pos</code>: Node position matrix with shape <code>[num_nodes, num_dimensions]</code>这个是专门为点云准备的。</li>
</ul>
<p>None of these attributes are required. In fact, the <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> object is not even restricted to these attributes. We can, <em>e.g.</em>, extend it by <code>data.face</code> to save the connectivity of triangles from a 3D mesh in a tensor with shape <code>[3, num_faces]</code> and type <code>torch.long</code>.</p>
<p><code>data</code>里面的内容不是绝对的，可以根据自己的应用来字行调整。</p>
<p>We show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                           [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]], dtype=torch.long)</span><br><span class="line"><span class="comment"># 这里是个无向边，默认是双向连接的</span></span><br><span class="line">x = torch.tensor([[-<span class="number">1</span>], [<span class="number">0</span>], [<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">4</span>], x=[<span class="number">3</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://pytorch-geometric.readthedocs.io/en/latest/_images/graph.svg" alt=""></p>
<p>Note that <code>edge_index</code>, <em>i.e.</em> the tensor defining the source and target nodes of all edges, is <strong>not</strong> a list of index tuples. If you want to write your indices this way, you should transpose and call <code>contiguous</code> on it before passing them to the data constructor:</p>
<blockquote>
<p>就是转置之后需要将内存进行连续化操作。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                           [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                           [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                           [<span class="number">2</span>, <span class="number">1</span>]], dtype=torch.long)</span><br><span class="line">x = torch.tensor([[-<span class="number">1</span>], [<span class="number">0</span>], [<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index.t().contiguous())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">4</span>], x=[<span class="number">3</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>Although the graph has only two edges, we need to define four index tuples to account for both directions of a edge.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;x&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[-<span class="number">1.0</span>],</span><br><span class="line">            [<span class="number">0.0</span>],</span><br><span class="line">            [<span class="number">1.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key, item <span class="keyword">in</span> data:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span> found in data&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x found <span class="keyword">in</span> data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>edge_index found <span class="keyword">in</span> data</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;edge_attr&#x27;</span> <span class="keyword">in</span> data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.num_nodes</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">3</span></span><br><span class="line"></span><br><span class="line">data.num_edges</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">4</span></span><br><span class="line"></span><br><span class="line">data.num_node_features</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1</span></span><br><span class="line"></span><br><span class="line">data.has_isolated_nodes()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.has_self_loops()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.is_directed()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transfer data object to GPU.</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">data = data.to(device)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="常用数据集"><a href="#常用数据集" class="headerlink" title="常用数据集"></a><strong>常用数据集</strong></h3><p>PyG contains a large number of common benchmark datasets, <em>e.g.</em>, all Planetoid datasets (Cora, Citeseer, Pubmed), all graph classification datasets from <a target="_blank" rel="noopener" href="http://graphkernels.cs.tu-dortmund.de/">http://graphkernels.cs.tu-dortmund.de</a> and their <a target="_blank" rel="noopener" href="https://github.com/nd7141/graph_datasets">cleaned versions</a>, the QM7 and QM9 dataset, and a handful of 3D mesh/point cloud datasets like FAUST, ModelNet10/40 and ShapeNet.</p>
<p>Initializing a dataset is straightforward. An initialization of a dataset will automatically download its raw files and process them to the previously described <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> format. <em>E.g.</em>, to load the ENZYMES dataset (consisting of 600 graphs within 6 classes), type:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> TUDataset</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=<span class="string">&#x27;/tmp/ENZYMES&#x27;</span>, name=<span class="string">&#x27;ENZYMES&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ENZYMES(<span class="number">600</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(dataset)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">600</span></span><br><span class="line"></span><br><span class="line">dataset.num_classes</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">6</span></span><br><span class="line"></span><br><span class="line">dataset.num_node_features</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>We now have access to all 600 graphs in the dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">168</span>], x=[<span class="number">37</span>, <span class="number">3</span>], y=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">data.is_undirected()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机排序</span></span><br><span class="line">dataset = dataset.shuffle()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ENZYMES(<span class="number">600</span>)</span><br></pre></td></tr></table></figure>
<p>Let’s try another one! Let’s download Cora, the standard benchmark dataset for semi-supervised graph node classification:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">&#x27;/tmp/Cora&#x27;</span>, name=<span class="string">&#x27;Cora&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Cora()</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(dataset)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1</span></span><br><span class="line"></span><br><span class="line">dataset.num_classes</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">7</span></span><br><span class="line"></span><br><span class="line">dataset.num_node_features</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1433</span></span><br></pre></td></tr></table></figure>
<p>Here, the dataset contains only a single, undirected citation graph:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">10556</span>], test_mask=[<span class="number">2708</span>],</span><br><span class="line">         train_mask=[<span class="number">2708</span>], val_mask=[<span class="number">2708</span>], x=[<span class="number">2708</span>, <span class="number">1433</span>], y=[<span class="number">2708</span>])</span><br><span class="line"></span><br><span class="line">data.is_undirected()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">True</span></span><br><span class="line"><span class="comment"># 是无向图</span></span><br><span class="line"></span><br><span class="line">data.train_mask.<span class="built_in">sum</span>().item()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">140</span></span><br><span class="line"></span><br><span class="line">data.val_mask.<span class="built_in">sum</span>().item()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">500</span></span><br><span class="line"></span><br><span class="line">data.test_mask.<span class="built_in">sum</span>().item()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1000</span></span><br></pre></td></tr></table></figure>
<p>This time, the <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> objects holds a label for each node, and additional node-level attributes: <code>train_mask</code>, <code>val_mask</code> and <code>test_mask</code>, where</p>
<ul>
<li><code>train_mask</code> denotes against which nodes to train (140 nodes),</li>
<li><code>val_mask</code> denotes which nodes to use for validation, <em>e.g.</em>, to perform early stopping (500 nodes),</li>
<li><code>test_mask</code> denotes against which nodes to test (1000 nodes).</li>
</ul>
<blockquote>
<p>这里的mask是用来对数据进行标注，那些是训练集，那些是验证集合。其实现就是一个<code>one-hot</code>类型的0-1的向量。</p>
</blockquote>
<hr>
<h3 id="Mini-batches"><a href="#Mini-batches" class="headerlink" title="Mini-batches"></a><strong>Mini-batches</strong></h3><p>Neural networks are usually trained in a batch-wise fashion. PyG achieves parallelization over a mini-batch by creating sparse block diagonal adjacency matrices (defined by <code>edge_index</code>) and concatenating feature and target matrices in the node dimension. This composition allows differing number of nodes and edges over examples in one batch:</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201093721711.png" alt=""></p>
<blockquote>
<p>这里就是将一个batch里面的数据打包成矩阵，A是将mini-batches里面的元素进行对角化，输出输入直接拼成列向量，这样来保证图结构的顺序和一一对应的关系。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> TUDataset</span><br><span class="line"><span class="keyword">from</span> torch_geometric.loader <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=<span class="string">&#x27;/tmp/ENZYMES&#x27;</span>, name=<span class="string">&#x27;ENZYMES&#x27;</span>, use_node_attr=<span class="literal">True</span>)</span><br><span class="line">loader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; DataBatch(batch=[<span class="number">1082</span>], edge_index=[<span class="number">2</span>, <span class="number">4066</span>], x=[<span class="number">1082</span>, <span class="number">21</span>], y=[<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">    batch.num_graphs</span><br><span class="line">    &gt;&gt;&gt; <span class="number">32</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Data-Transforms"><a href="#Data-Transforms" class="headerlink" title="Data Transforms"></a><strong>Data Transforms</strong></h3><p>Transforms are a common way in <code>torchvision</code> to transform images and perform augmentation. PyG comes with its own transforms, which expect a <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> object as input and return a new transformed <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> object. Transforms can be chained together using <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.Compose.html#torch_geometric.transforms.Compose"><code>torch_geometric.transforms.Compose</code></a> and are applied before saving a processed dataset on disk (<code>pre_transform</code>) or before accessing a graph in a dataset (<code>transform</code>).</p>
<p>Let’s look at an example, where we apply transforms on the ShapeNet dataset (containing 17,000 3D shape point clouds and per point labels from 16 shape categories).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> ShapeNet</span><br><span class="line"></span><br><span class="line">dataset = ShapeNet(root=<span class="string">&#x27;/tmp/ShapeNet&#x27;</span>, categories=[<span class="string">&#x27;Airplane&#x27;</span>])</span><br><span class="line"></span><br><span class="line">dataset[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(pos=[<span class="number">2518</span>, <span class="number">3</span>], y=[<span class="number">2518</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里就是构造好基于KNN的边集</span></span><br><span class="line"><span class="keyword">import</span> torch_geometric.transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> ShapeNet</span><br><span class="line"></span><br><span class="line">dataset = ShapeNet(root=<span class="string">&#x27;/tmp/ShapeNet&#x27;</span>, categories=[<span class="string">&#x27;Airplane&#x27;</span>],</span><br><span class="line">                    pre_transform=T.KNNGraph(k=<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">dataset[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">15108</span>], pos=[<span class="number">2518</span>, <span class="number">3</span>], y=[<span class="number">2518</span>])</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="模型的构建过程"><a href="#模型的构建过程" class="headerlink" title="模型的构建过程"></a><strong>模型的构建过程</strong></h3><p>After learning about data handling, datasets, loader and transforms in PyG, it’s time to implement our first graph neural network!</p>
<p>We will use a simple GCN layer and replicate the experiments on the Cora citation dataset. For a high-level explanation on GCN, have a look at its <a target="_blank" rel="noopener" href="http://tkipf.github.io/graph-convolutional-networks/">blog post</a>.</p>
<p>We first need to load the Cora dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">&#x27;/tmp/Cora&#x27;</span>, name=<span class="string">&#x27;Cora&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Cora()</span><br></pre></td></tr></table></figure>
<p>Note that we do not need to use transforms or a dataloader. Now let’s implement a two-layer GCN:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCN</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = GCNConv(dataset.num_node_features, <span class="number">16</span>)</span><br><span class="line">        self.conv2 = GCNConv(<span class="number">16</span>, dataset.num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line"></span><br><span class="line">        x = self.conv1(x, edge_index)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = self.conv2(x, edge_index)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>The constructor defines two <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv"><code>GCNConv</code></a> layers which get called in the forward pass of our network. Note that the non-linearity is not integrated in the <code>conv</code> calls and hence needs to be applied afterwards (something which is consistent accross all operators in PyG). Here, we chose to use ReLU as our intermediate non-linearity and finally output a softmax distribution over the number of classes. Let’s train this model on the training nodes for 200 epochs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model = GCN().to(device)</span><br><span class="line">data = dataset[<span class="number">0</span>].to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.01</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = model(data)</span><br><span class="line">    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>Finally, we can evaluate our model on the test nodes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">pred = model(data).argmax(dim=<span class="number">1</span>)</span><br><span class="line">correct = (pred[data.test_mask] == data.y[data.test_mask]).<span class="built_in">sum</span>()</span><br><span class="line">acc = <span class="built_in">int</span>(correct) / <span class="built_in">int</span>(data.test_mask.<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Accuracy: <span class="number">0.8150</span></span><br></pre></td></tr></table></figure>
<p>This is all it takes to implement your first graph neural network. The easiest way to learn more about Graph Neural Networks is to study the examples in the <code>examples/</code> directory and to browse <code>torch_geometric.nn</code>. Happy hacking!</p>
<h2 id="节点分类任务的搭建"><a href="#节点分类任务的搭建" class="headerlink" title="节点分类任务的搭建"></a><strong>节点分类任务的搭建</strong></h2><h3 id="导入相关包"><a href="#导入相关包" class="headerlink" title="导入相关包"></a><strong>导入相关包</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch_geometric.nn <span class="keyword">as</span> pyg_nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="数据集的构建"><a href="#数据集的构建" class="headerlink" title="数据集的构建"></a><strong>数据集的构建</strong></h3><p>本项目利用官网上的数据集，导入<code>planetoid</code>类，需要的重要的参数是：</p>
<ul>
<li><code>root (string)</code>: Root directory where the dataset should be saved.</li>
<li><code>name (string)</code>: The name of the dataset (:obj:<code>&quot;Cora&quot;</code>, :obj:<code>&quot;CiteSeer&quot;</code>, :obj:<code>&quot;PubMed&quot;</code>).</li>
</ul>
<blockquote>
<p>在安装的出现相关依赖包的报错，这里需要自己根据相关的配置去离线安装。下载地址的连接如下：<a target="_blank" rel="noopener" href="https://pytorch-geometric.com/whl/">https://pytorch-geometric.com/whl/</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line"><span class="comment"># load cora dataset</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">folder=<span class="string">&quot;D:\\000learning\\2023winter\\GCN\\node_classification&quot;</span>,data_name=<span class="string">&quot;cora&quot;</span></span>):</span></span><br><span class="line">    dataset = Planetoid(root=folder,  name=data_name)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a><strong>模型搭建</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line"><span class="comment"># create the graph cnn model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraphCNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, hid_c, out_c</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GraphCNN, self).__init__()</span><br><span class="line">        self.conv1 = pyg_nn.GCNConv(in_channels=in_c, out_channels=hid_c)</span><br><span class="line">        self.conv2 = pyg_nn.GCNConv(in_channels=hid_c, out_channels=out_c)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data: Data</span>):</span></span><br><span class="line">        <span class="comment"># data.x data.edge_index</span></span><br><span class="line">        x = data.x                                    <span class="comment"># [N,C]</span></span><br><span class="line">        edge_index = data.edge_index                  <span class="comment"># [2,E]</span></span><br><span class="line">        hid = self.conv1(x=x, edge_index=edge_index)  <span class="comment"># [N,D] </span></span><br><span class="line">        hid = F.relu(hid)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(x=hid, edge_index=edge_index) <span class="comment"># [N,out_c]</span></span><br><span class="line">        out = F.log_softmax(out, dim=<span class="number">1</span>) </span><br><span class="line">        <span class="comment"># 默认是在dim=0上归一化的，就是在节点的方向进行的归一化</span></span><br><span class="line">        <span class="comment"># 于是修改成为在dim=1,本模型是做节点分类的，返回的是节点属于每个类的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>这里就是一个两层的GCN模型，其中中间隐层参数<code>hid=12</code>时的效果最好。</p>
<ul>
<li>大于12会出现过拟合，训练的效果很好但是测试的准确率不佳；</li>
<li>小于12就会出现欠拟合，训练和测试效果都不好。</li>
</ul>
<hr>
<h3 id="模型的训练和测试"><a href="#模型的训练和测试" class="headerlink" title="模型的训练和测试"></a><strong>模型的训练和测试</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 这里设置以下GPU</span></span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line">    cora_dataset = get_data()</span><br><span class="line">    in_channel = cora_dataset.num_node_features <span class="comment"># 节点的特征数</span></span><br><span class="line">    out_channel = cora_dataset.num_classes      <span class="comment"># 分类的类别数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 实例化模型</span></span><br><span class="line">    my_net = GraphCNN(in_c=in_channel, hid_c=<span class="number">12</span>, out_c=out_channel)</span><br><span class="line">    <span class="comment"># 导入gpu</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将模型和数据导入到gpu</span></span><br><span class="line">    my_net = my_net.to(device)</span><br><span class="line">    <span class="comment"># cora_dataset数据仅仅有一张图，所有的节点在一张图上面</span></span><br><span class="line">    cora_data = cora_dataset[<span class="number">0</span>].to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义优化器</span></span><br><span class="line">    optimizer = torch.optim.Adam(my_net.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model train </span></span><br><span class="line">    my_net.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">        output = my_net(cora_data)</span><br><span class="line">        <span class="comment"># 这个数据都在一张图上</span></span><br><span class="line">        loss = F.nll_loss(output[cora_data.train_mask], cora_data.y[cora_data.train_mask])</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch+<span class="number">1</span>, <span class="string">&quot;Loss&quot;</span>, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># modal test</span></span><br><span class="line">    my_net.<span class="built_in">eval</span>()</span><br><span class="line">    _, prediction = my_net(cora_data).<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    target = cora_data.y</span><br><span class="line"></span><br><span class="line">    test_correct = prediction[cora_data.test_mask].eq(target[cora_data.test_mask]).<span class="built_in">sum</span>().item()</span><br><span class="line">    test_num = cora_data.test_mask.<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accurary of Test Sample:&quot;</span>, test_correct/test_num)</span><br></pre></td></tr></table></figure>
<p>到这里项目基本实现，但是还有两个主要的问题：</p>
<ul>
<li>首先构建数据集时加载的内置数据集，需要我们自己去处理数据；</li>
<li>其次模型仅仅时单一的GCN，还需要尝试其他的模型。</li>
</ul>
<h2 id="项目模型的改进"><a href="#项目模型的改进" class="headerlink" title="项目模型的改进"></a><strong>项目模型的改进</strong></h2><h3 id="构建自己的数据集"><a href="#构建自己的数据集" class="headerlink" title="构建自己的数据集"></a><strong>构建自己的数据集</strong></h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h4><p>Although PyG already contains a lot of useful datasets, you may wish to create your own dataset with self-recorded or non-publicly available data.</p>
<p>Implementing datasets by yourself is straightforward and you may want to take a look at the source code to find out how the various datasets are implemented. However, we give a brief introduction on what is needed to setup your own dataset.</p>
<p>We provide two abstract classes for datasets: <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset"><code>torch_geometric.data.Dataset</code></a> and <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset"><code>torch_geometric.data.InMemoryDataset</code></a>. <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset"><code>torch_geometric.data.InMemoryDataset</code></a> inherits from <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset"><code>torch_geometric.data.Dataset</code></a> and <strong>should be used if the whole dataset fits into CPU memory.</strong></p>
<p>这里时将比较小的数据集直接存在缓存里面，这样的化可以加速运行。</p>
<p>Following the <code>torchvision</code> convention, each dataset gets passed a root folder which indicates where the dataset should be stored. We split up the root folder into two folders: the <code>raw_dir</code>, where the dataset gets downloaded to, and the <code>processed_dir</code>, where the processed dataset is being saved.</p>
<p>In addition, each dataset can be passed a <code>transform</code>, a <code>pre_transform</code> and a <code>pre_filter</code> function, which are <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/constants.html#None"><code>None</code></a> by default. The <code>transform</code> function dynamically transforms the data object before accessing (so it is best used for data augmentation). The <code>pre_transform</code> function applies the transformation before saving the data objects to disk (so it is best used for heavy precomputation which needs to be only done once). The <code>pre_filter</code> function can manually filter out data objects before saving. Use cases may involve the restriction of data objects being of a specific class.<em>**</em></p>
<hr>
<h4 id="Creating-“In-Memory-Datasets”"><a href="#Creating-“In-Memory-Datasets”" class="headerlink" title="Creating “In Memory Datasets”"></a>Creating “In Memory Datasets”</h4><p>In order to create a <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset"><code>torch_geometric.data.InMemoryDataset</code></a>, you need to implement four fundamental methods:</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.raw_file_names"><code>InMemoryDataset.raw_file_names()</code></a>: A list of files in the <code>raw_dir</code> which needs to be found in order to skip the download.</p>
<blockquote>
<p><code>raw_dir</code>就是存放源文件的文件夹；</p>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.processed_file_names"><code>InMemoryDataset.processed_file_names()</code></a>: A list of files in the <code>processed_dir</code> which needs to be found in order to skip the processing.</p>
<blockquote>
<p><code>proccessed_dir</code>就是存放已经处理好的文件的文件夹；</p>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.download"><code>InMemoryDataset.download()</code></a>: Downloads raw data into <code>raw_dir</code>.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.process"><code>InMemoryDataset.process()</code></a>: Processes raw data and saves it into the <code>processed_dir</code>.</p>
<blockquote>
<p>读取原始数据，存在处理好的数据的文件夹中</p>
</blockquote>
</li>
</ul>
<p>You can find helpful methods to download and extract data in <code>torch_geometric.data</code>.</p>
<p>The real magic happens in the body of <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.process"><code>process()</code></a>. Here, we need to read and create a list of <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> objects and save it into the <code>processed_dir</code>. </p>
<p><strong>一般情况就是将上面<code>Data</code>类型的数据，一起放入到一个<code>list</code>里面进行保存，但是实际情况下保存<code>list</code>是很花时间的。</strong></p>
<p><strong>于是需要在保存前进行一步<code>torch_geometric.data.InMemoryDataset.collate()</code></strong></p>
<p>Because saving a huge python list is rather slow, we collate the list into one huge <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data"><code>Data</code></a> object via <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset.collate"><code>torch_geometric.data.InMemoryDataset.collate()</code></a> before saving . The collated data object has concatenated all examples into one big data object and, in addition, returns a <code>slices</code> dictionary to reconstruct single examples from this object. Finally, we need to load these two objects in the constructor into the properties <code>self.data</code> and <code>self.slices</code>.</p>
<p>Let’s see this process in a simplified example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> InMemoryDataset, download_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyOwnDataset</span>(<span class="params">InMemoryDataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span>, pre_filter=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(root, transform, pre_transform, pre_filter)</span><br><span class="line">        self.data, self.slices = torch.load(self.processed_paths[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">raw_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;some_file_1&#x27;</span>, <span class="string">&#x27;some_file_2&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">processed_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;data.pt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Download to `self.raw_dir`.</span></span><br><span class="line">        download_url(url, self.raw_dir)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Read data into huge `Data` list.</span></span><br><span class="line">        data_list = [...]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_filter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list = [data <span class="keyword">for</span> data <span class="keyword">in</span> data_list <span class="keyword">if</span> self.pre_filter(data)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list = [self.pre_transform(data) <span class="keyword">for</span> data <span class="keyword">in</span> data_list]</span><br><span class="line">		<span class="comment"># 将list转换成为一个collate,方便保存</span></span><br><span class="line">        data, slices = self.collate(data_list)</span><br><span class="line">        torch.save((data, slices), self.processed_paths[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="Creating-“Larger”-Datasets"><a href="#Creating-“Larger”-Datasets" class="headerlink" title="Creating “Larger” Datasets"></a>Creating “Larger” Datasets</h4><p>For creating datasets which do not fit into memory, the <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset"><code>torch_geometric.data.Dataset</code></a> can be used, which closely follows the concepts of the <code>torchvision</code> datasets. It expects the following methods to be implemented in addition:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset.len"><code>Dataset.len()</code></a>: Returns the number of examples in your dataset.</li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset.get"><code>Dataset.get()</code></a>: Implements the logic to load a single graph.</li>
</ul>
<p>Internally, <code>torch_geometric.data.Dataset.__getitem__()</code> gets data objects from <a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset.get"><code>torch_geometric.data.Dataset.get()</code></a> and optionally transforms them according to <code>transform</code>.</p>
<p>Let’s see this process in a simplified example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Dataset, download_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyOwnDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span>, pre_filter=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(root, transform, pre_transform, pre_filter)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">raw_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;some_file_1&#x27;</span>, <span class="string">&#x27;some_file_2&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">processed_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;data_1.pt&#x27;</span>, <span class="string">&#x27;data_2.pt&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Download to `self.raw_dir`.</span></span><br><span class="line">        path = download_url(url, self.raw_dir)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span>(<span class="params">self</span>):</span></span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> raw_path <span class="keyword">in</span> self.raw_paths:</span><br><span class="line">            <span class="comment"># Read data from `raw_path`.</span></span><br><span class="line">            data = Data(...)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.pre_filter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> self.pre_filter(data):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.pre_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                data = self.pre_transform(data)</span><br><span class="line"></span><br><span class="line">            torch.save(data, osp.join(self.processed_dir, <span class="string">f&#x27;data_<span class="subst">&#123;idx&#125;</span>.pt&#x27;</span>))</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">len</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.processed_file_names)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        data = torch.load(osp.join(self.processed_dir, <span class="string">f&#x27;data_<span class="subst">&#123;idx&#125;</span>.pt&#x27;</span>))</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a><strong>代码实现</strong></h4><p>导入相关的包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch_geometric</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> InMemoryDataset</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"><span class="keyword">from</span> torch_geometric.loader <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure>
<hr>
<p>首先是创建一个数据集，这里用随机数随机一个数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a toy dataset</span></span><br><span class="line"><span class="comment"># 其实就是造一个数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toy_dataset</span>(<span class="params">num_nodes, num_node_features, num_edges</span>):</span></span><br><span class="line">    x = np.random.rand(num_nodes, num_node_features) <span class="comment"># node features</span></span><br><span class="line">    edge_index = np.random.randint(low=<span class="number">0</span>, high=num_nodes-<span class="number">1</span>, size=[<span class="number">2</span>, num_edges], dtype=np.long)</span><br><span class="line">    <span class="comment"># [2, num_edges]</span></span><br><span class="line">    data = Data(x=torch.from_numpy(x), edge_index=torch.from_numpy(edge_index))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>在主函数里面测试以下可得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    toy_sample = toy_dataset(num_nodes=<span class="number">32</span>, num_node_features=<span class="number">3</span>, num_edges=<span class="number">42</span>)</span><br><span class="line">    <span class="built_in">print</span>(toy_sample)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(x=[<span class="number">32</span>, <span class="number">3</span>], edge_index=[<span class="number">2</span>, <span class="number">42</span>])</span><br></pre></td></tr></table></figure>
<hr>
<p>然后是创建一个数据集类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In Memory Dataset</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyGtoyDataset</span>(<span class="params">InMemoryDataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span>, pre_filter=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(root, transform, pre_transform, pre_filter)</span><br><span class="line">        self.data, self.slices = torch.load(self.processed_file_names[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">raw_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&quot;raw_dir&quot;</span>] <span class="comment"># 因为没有于是随便写一个</span></span><br><span class="line">    <span class="comment">#     pass</span></span><br><span class="line">    <span class="comment"># 因为这里我们的数据时自己在程序里随手写的，因此没有源文件的路径</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">processed_file_names</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&quot;toy_dataset.pt&quot;</span>]</span><br><span class="line">        <span class="comment"># 这边时保存之后的文件名</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># 由于我们时自己随手写的数据集，因此这边不需要下载</span></span><br><span class="line">    <span class="comment"># 针对内置的数据集才需要下载</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 数据集处理函数</span></span><br><span class="line">        <span class="comment"># step1:将样本Data放入到一个list中</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建100个样本，每个样本有32个节点和42条边，每个节点的特征维数为3</span></span><br><span class="line">        data_list = [toy_dataset(num_nodes=<span class="number">32</span>, num_node_features=<span class="number">3</span>, num_edges=<span class="number">42</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># step2:将list转换成list再进行保存，这样就可以防止list的存储速度过慢</span></span><br><span class="line">        data_save, data_slice = self.collate(data_list)</span><br><span class="line">        torch.save((data_save, data_slice), self.processed_file_names[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>测试上面的类可得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    toy_data = PyGtoyDataset(root=<span class="string">&quot;toy&quot;</span>)</span><br><span class="line">    <span class="comment"># 100个样本，每个样本是一个图结构</span></span><br><span class="line">    <span class="built_in">print</span>(toy_data[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 取出第0个样本</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Processing...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Done!</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(x=[<span class="number">32</span>, <span class="number">3</span>], edge_index=[<span class="number">2</span>, <span class="number">42</span>])</span><br></pre></td></tr></table></figure>
<p>第一次构建会出现<code>Processing...</code>的字样。</p>
<p>于是就会在当前的文件夹里面出现我们调用的数据集文件</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201171940305.png" alt=""></p>
<hr>
<p>之后和<code>pytorch</code>一样，需要构建一个<code>dataloader</code>来对数据集里面的数据进行载入操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.loader <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">data_loader = DataLoader(toy_data, batch_size=<span class="number">5</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> data_loader:</span><br><span class="line">    <span class="built_in">print</span>(batch)</span><br><span class="line">    </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Processing...</span><br><span class="line">Done!</span><br><span class="line">DataBatch(x=[<span class="number">160</span>, <span class="number">3</span>], edge_index=[<span class="number">2</span>, <span class="number">210</span>], batch=[<span class="number">160</span>], ptr=[<span class="number">6</span>])</span><br><span class="line">DataBatch(x=[<span class="number">160</span>, <span class="number">3</span>], edge_index=[<span class="number">2</span>, <span class="number">210</span>], batch=[<span class="number">160</span>], ptr=[<span class="number">6</span>])</span><br><span class="line">DataBatch(x=[<span class="number">160</span>, <span class="number">3</span>], edge_index=[<span class="number">2</span>, <span class="number">210</span>], batch=[<span class="number">160</span>], ptr=[<span class="number">6</span>])</span><br></pre></td></tr></table></figure>
<p>前面讲解<strong><code>mini-batch</code>机制是通过空间的平行化</strong>，其实现是通过<strong>前面将节点按一定的顺序和对应关系来组合和拼接成一个大的矩阵</strong>，因此每个<code>batch</code>里面的节点数就直接相加。</p>
<p>例如，上面是<code>32*5=160,42*5=210</code>.</p>
<h3 id="查询GCN的其他用法"><a href="#查询GCN的其他用法" class="headerlink" title="查询GCN的其他用法"></a><strong>查询GCN的其他用法</strong></h3><p>这里参考<code>torch_geometric.nn</code>里的帮助文档。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201173433060.png" alt=""></p>
<p>下面是对应的帮助文档的链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers">Convolutional Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#aggregation-operators">Aggregation Operators</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#normalization-layers">Normalization Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers">Pooling Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#unpooling-layers">Unpooling Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models">Models</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#kge-models">KGE Models</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.encoding">Encodings</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#functional">Functional</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-convolutional-layers">Dense Convolutional Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-pooling-layers">Dense Pooling Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#model-transformations">Model Transformations</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.data_parallel">DataParallel Layers</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#model-summary">Model Summary</a></li>
</ul>
<p><strong>作业：调用其他的GCN卷积，来使得Cora数据测试的分类准确率可以达到82%以上。</strong></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>GCN项目——结点分类</p><p><a href="http://example.com/2023/02/06/图神经网络/GCN项目——结点分类/">http://example.com/2023/02/06/图神经网络/GCN项目——结点分类/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>czt</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-02-06</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-02-06</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a><a class="link-muted mr-2" rel="tag" href="/tags/Graph/">Graph</a><a class="link-muted mr-2" rel="tag" href="/tags/Neural-Networks/">Neural Networks</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">GCN项目——交通流量预测</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%BA%94%E7%94%A8/"><span class="level-item">图卷积的应用</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/hexoimg/202201222202112.jpg" alt="厚德载物"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">厚德载物</p><p class="is-size-6 is-block">实事求是，敢为人先</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 湖北 武汉</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">42</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://paperswithcode.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">paperwithcode</span></span><span class="level-right"><span class="level-item tag">paperswithcode.com</span></span></a></li><li><a class="level is-mobile" href="https://scholar.google.com.hk/?hl=zh-CN" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">google_scholar</span></span><span class="level-right"><span class="level-item tag">scholar.google.com.hk</span></span></a></li><li><a class="level is-mobile" href="https://arxiv.org/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">arxiv</span></span><span class="level-right"><span class="level-item tag">arxiv.org</span></span></a></li><li><a class="level is-mobile" href="https://leetcode-cn.com/problemset/algorithms/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leetcode</span></span><span class="level-right"><span class="level-item tag">leetcode-cn.com</span></span></a></li><li><a class="level is-mobile" href="https://mathf.itewqq.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">mathf</span></span><span class="level-right"><span class="level-item tag">mathf.itewqq.cn</span></span></a></li><li><a class="level is-mobile" href="https://qwerty.kaiyi.cool/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">qwerty</span></span><span class="level-right"><span class="level-item tag">qwerty.kaiyi.cool</span></span></a></li><li><a class="level is-mobile" href="https://www.overleaf.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">overleaf</span></span><span class="level-right"><span class="level-item tag">www.overleaf.com</span></span></a></li><li><a class="level is-mobile" href="http://www.pipioj.online/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">pipioj</span></span><span class="level-right"><span class="level-item tag">www.pipioj.online</span></span></a></li><li><a class="level is-mobile" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">hugocvofczt</span></span><span class="level-right"><span class="level-item tag">monumental-tarsier-a544f3.netlify.app</span></span></a></li><li><a class="level is-mobile" href="https://app.netlify.com/sites/monumental-tarsier-a544f3/overview" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">netlify</span></span><span class="level-right"><span class="level-item tag">app.netlify.com</span></span></a></li><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">一月 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">十二月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">八月 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">七月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">三月 2022</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">二月 2022</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">一月 2022</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ANSYS/"><span class="tag">ANSYS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-learning/"><span class="tag">Deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Finite-Element-Analysis/"><span class="tag">Finite Element Analysis</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%E5%AE%9E%E6%88%98/"><span class="tag">GAN实战</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-Adversarial-Networks/"><span class="tag">Generative Adversarial Networks</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IEEE%E6%8A%95%E7%A8%BF/"><span class="tag">IEEE投稿</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-learning/"><span class="tag">Machine learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Networks/"><span class="tag">Neural Networks</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SLAM/"><span class="tag">SLAM</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Typora/"><span class="tag">Typora</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/auto-encoder/"><span class="tag">auto-encoder</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/c/"><span class="tag">c++</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/control-theory/"><span class="tag">control theory</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/latex/"><span class="tag">latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/object-detection/"><span class="tag">object detection</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/opencv/"><span class="tag">opencv</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/point-cloud/"><span class="tag">point cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">29</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transformer/"><span class="tag">transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"><span class="tag">图像分类</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tag">图神经网络</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="tag">控制理论</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"><span class="tag">无监督学习</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90/"><span class="tag">有限元分析</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"><span class="tag">机械振动</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"><span class="tag">生成模型</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="tag">目标检测</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94/"><span class="tag">科研</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><span class="tag">自注意力机制</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"><span class="tag">论文写作</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"><span class="tag">语义分割</span><span class="tag">6</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#官方代码解读"><span class="level-left"><span class="level-item">1</span><span class="level-item">官方代码解读</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#基本数据类型"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">基本数据类型</span></span></a></li><li><a class="level is-mobile" href="#常用数据集"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">常用数据集</span></span></a></li><li><a class="level is-mobile" href="#Mini-batches"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Mini-batches</span></span></a></li><li><a class="level is-mobile" href="#Data-Transforms"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Data Transforms</span></span></a></li><li><a class="level is-mobile" href="#模型的构建过程"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">模型的构建过程</span></span></a></li></ul></li><li><a class="level is-mobile" href="#节点分类任务的搭建"><span class="level-left"><span class="level-item">2</span><span class="level-item">节点分类任务的搭建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#导入相关包"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">导入相关包</span></span></a></li><li><a class="level is-mobile" href="#数据集的构建"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">数据集的构建</span></span></a></li><li><a class="level is-mobile" href="#模型搭建"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">模型搭建</span></span></a></li><li><a class="level is-mobile" href="#模型的训练和测试"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">模型的训练和测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#项目模型的改进"><span class="level-left"><span class="level-item">3</span><span class="level-item">项目模型的改进</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#构建自己的数据集"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">构建自己的数据集</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#概述"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">概述</span></span></a></li><li><a class="level is-mobile" href="#Creating-“In-Memory-Datasets”"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">Creating “In Memory Datasets”</span></span></a></li><li><a class="level is-mobile" href="#Creating-“Larger”-Datasets"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">Creating “Larger” Datasets</span></span></a></li><li><a class="level is-mobile" href="#代码实现"><span class="level-left"><span class="level-item">3.1.4</span><span class="level-item">代码实现</span></span></a></li></ul></li><li><a class="level is-mobile" href="#查询GCN的其他用法"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">查询GCN的其他用法</span></span></a></li></ul></li></ul></div></div><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Finite-Element-Analysis/"><span class="level-start"><span class="level-item">Finite Element Analysis</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Generative-Adversarial-Networks/"><span class="level-start"><span class="level-item">Generative Adversarial Networks</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Latex/"><span class="level-start"><span class="level-item">Latex</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Point-Cloud/"><span class="level-start"><span class="level-item">Point Cloud</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"><span class="level-start"><span class="level-item">PyTorch教程与源码讲解</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/SLAM/"><span class="level-start"><span class="level-item">SLAM</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/Typora/"><span class="level-start"><span class="level-item">Typora</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/auto-encoder/"><span class="level-start"><span class="level-item">auto-encoder</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/opencv/"><span class="level-start"><span class="level-item">opencv</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">图像分类网络及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">图神经网络</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"><span class="level-start"><span class="level-item">振动力学</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/"><span class="level-start"><span class="level-item">机器学习基石</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="level-start"><span class="level-item">现代控制理论</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Epytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">目标检测与pytorch实现</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">科研入门笔记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/"><span class="level-start"><span class="level-item">自注意力机制和Transformer</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">语义分割及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">高级机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CPytorch%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="循环神经网络Pytorch代码实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:49:02.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CPytorch%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">循环神经网络Pytorch代码实现</a></p><p class="categories"><a href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">高级机器学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="循环神经网络基本理论"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:48:46.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/">循环神经网络基本理论</a></p><p class="categories"><a href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">高级机器学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/RepVGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="RepVGG网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:35:27.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/RepVGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">RepVGG网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/MoVIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="MoVIT网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:35:07.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/MoVIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">MoVIT网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Swin-transformer%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="Swin-transformer网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:34:53.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Swin-transformer%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">Swin-transformer网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 czt</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>