<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GCN项目——交通流量预测 - houdezaiwu&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="czt"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="czt"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="hljs.initHighlightingOnLoad();  本文基于pytorch进行的交通流量预测上的应用案例，其中主要包含数据集的构建、数据可视化、模型的搭建和训练测试。"><meta property="og:type" content="blog"><meta property="og:title" content="GCN项目——交通流量预测"><meta property="og:url" content="http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/"><meta property="og:site_name" content="houdezaiwu&#039;s blog"><meta property="og:description" content="hljs.initHighlightingOnLoad();  本文基于pytorch进行的交通流量预测上的应用案例，其中主要包含数据集的构建、数据可视化、模型的搭建和训练测试。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"><meta property="article:published_time" content="2023-02-06T00:53:20.000Z"><meta property="article:modified_time" content="2023-02-06T03:28:17.025Z"><meta property="article:author" content="czt"><meta property="article:tag" content="图神经网络"><meta property="article:tag" content="Graph"><meta property="article:tag" content="Neural Networks"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/"},"headline":"GCN项目——交通流量预测","image":["https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg"],"datePublished":"2023-02-06T00:53:20.000Z","dateModified":"2023-02-06T03:28:17.025Z","author":{"@type":"Person","name":"czt"},"publisher":{"@type":"Organization","name":"houdezaiwu's blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"hljs.initHighlightingOnLoad();  本文基于pytorch进行的交通流量预测上的应用案例，其中主要包含数据集的构建、数据可视化、模型的搭建和训练测试。"}</script><link rel="canonical" href="http://example.com/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="/css/prism-coy-without-shadows.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/pointnet/3394486.3403088.key.jpg" alt="GCN项目——交通流量预测"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-06T00:53:20.000Z" title="2023/2/6 上午8:53:20">2023-02-06</time>发表</span><span class="level-item"><time dateTime="2023-02-06T03:28:17.025Z" title="2023/2/6 上午11:28:17">2023-02-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a></span><span class="level-item">1 小时读完 (大约7148个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">GCN项目——交通流量预测</h1><div class="content"><link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">

<!-- hexo-inject:begin --><!-- hexo-inject:end --><script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<p>本文基于pytorch进行的交通流量预测上的应用案例，其中主要包含数据集的构建、数据可视化、模型的搭建和训练测试。</p>
<span id="more"></span>
<p>上节课通过我们基于<code>torch</code>和<code>pyG</code>来实现了cora数据集的节点分类项目。</p>
<p>本节课我们来进行交通流量预测的问题，其项目的主要难点是：</p>
<ul>
<li>数据处理上的，本项目是基于时序数据进行。</li>
<li>时序关系需要考虑到网络模型里。</li>
</ul>
<p>在具体实现上的困难就是，<code>PyG</code>在数据的加载以及后面模型的搭建上，其可扩展性比较的弱。</p>
<ul>
<li>比如我们需要对网络进行调整，就比较的麻烦，因为<code>GCNConv</code>是集成好的模块，修改起来很难。</li>
<li>其次对应时序数据的处理上，<code>pyG</code>还是很难实现的。</li>
</ul>
<p><code>pyG</code>在实际的初期时使用来便于理解和实现，到了后期最后自己写。</p>
<hr>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230202000545742.png" alt=""></p>
<h2 id="数据集可视化"><a href="#数据集可视化" class="headerlink" title="数据集可视化"></a><strong>数据集可视化</strong></h2><p>数据来自美国的加利福尼亚州的洛杉矶市，第一个CSV文件是关于节点的表示情况，一共有307个节点，第二个npz文件是交通流量的文件，时间范围是两个月（2018.1.1——2018.2.28），每5分钟测一次。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_flow</span>(<span class="params">file_name</span>):</span></span><br><span class="line">    flow_data = np.load(file_name)</span><br><span class="line">    flow_data = flow_data[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">    <span class="comment"># 字典就仅仅有一个key</span></span><br><span class="line">    <span class="keyword">return</span> flow_data</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    traffic_data = get_flow(<span class="string">&quot;PeMS04.npz&quot;</span>)</span><br><span class="line">    node_id = <span class="number">152</span></span><br><span class="line">    <span class="comment"># 这里可视化的时10号节点</span></span><br><span class="line">    <span class="built_in">print</span>(traffic_data.shape)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(traffic_data[:<span class="number">24</span>*<span class="number">12</span>, node_id, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 三个维度分别为交通流量，未知，车速</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>可视化的结果：</p>
<p><img src="https://img-blog.csdnimg.cn/20200730225126362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTkwMTUxOQ==,size_16,color_FFFFFF,t_70#pic_center" alt=""></p>
<p>在本问题仅仅考虑的是一维的交通流量特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_flow</span>(<span class="params">file_name</span>):</span></span><br><span class="line">    flow_data = np.load(file_name)</span><br><span class="line">     <span class="comment"># 字典就仅仅有一个key</span></span><br><span class="line">    flow_data = flow_data[<span class="string">&#x27;data&#x27;</span>].transpose([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">    flow_data = flow_data[:, :, <span class="number">0</span>] </span><br><span class="line">    <span class="comment"># 仅仅去取第一维的交通流量特征</span></span><br><span class="line">    flow_data = flow_data[:, :, np.newaxis] <span class="comment"># [N,T,D=1]</span></span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> flow_data</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="数据集的构建"><a href="#数据集的构建" class="headerlink" title="数据集的构建"></a><strong>数据集的构建</strong></h2><h3 id="首先是构建邻接矩阵的函数："><a href="#首先是构建邻接矩阵的函数：" class="headerlink" title="首先是构建邻接矩阵的函数："></a><strong>首先是构建邻接矩阵的函数：</strong></h3><ul>
<li><code>distance_file</code>：文件(csv)的路径；</li>
<li><code>num_nodes</code>：节点数；</li>
<li><code>id_file</code>：编号文件路径，不过此项目里面可能用不上这个文件。</li>
<li><code>graph_type</code>：节点的类型，一种是保存连接关系的，一种是保存距离的。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_adjacent_matrix</span>(<span class="params">distance_file: <span class="built_in">str</span>, num_nodes: <span class="built_in">int</span>, id_file: <span class="built_in">str</span> = <span class="literal">None</span>, graph_type=<span class="string">&quot;connect&quot;</span></span>) -&gt; np.array:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param distance_file: str, path of csv file to save the distances between nodes.</span></span><br><span class="line"><span class="string">    :param num_nodes: int, number of nodes in the graph</span></span><br><span class="line"><span class="string">    :param id_file: str, path of txt file to save the order of the nodes.</span></span><br><span class="line"><span class="string">    :param graph_type: str, [&quot;connect&quot;, &quot;distance&quot;]</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        np.array(N, N)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    A = np.zeros([<span class="built_in">int</span>(num_nodes), <span class="built_in">int</span>(num_nodes)])</span><br><span class="line">    <span class="comment"># 构建邻居矩阵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> id_file:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(id_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f_id:</span><br><span class="line">            node_id_dict = &#123;<span class="built_in">int</span>(node_id): idx <span class="keyword">for</span> idx, node_id <span class="keyword">in</span> <span class="built_in">enumerate</span>(f_id.read().strip().split(<span class="string">&quot;\n&quot;</span>))&#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(distance_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f_d:</span><br><span class="line">                f_d.readline()</span><br><span class="line">                reader = csv.reader(f_d)</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> reader:</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">len</span>(item) != <span class="number">3</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    i, j, distance = <span class="built_in">int</span>(item[<span class="number">0</span>]), <span class="built_in">int</span>(item[<span class="number">1</span>]), <span class="built_in">float</span>(item[<span class="number">2</span>])</span><br><span class="line">                    <span class="keyword">if</span> graph_type == <span class="string">&quot;connect&quot;</span>:</span><br><span class="line">                        A[node_id_dict[i], node_id_dict[j]] = <span class="number">1.</span></span><br><span class="line">                        A[node_id_dict[j], node_id_dict[i]] = <span class="number">1.</span></span><br><span class="line">                    <span class="keyword">elif</span> graph_type == <span class="string">&quot;distance&quot;</span>:</span><br><span class="line">                        A[node_id_dict[i], node_id_dict[j]] = <span class="number">1.</span> / distance</span><br><span class="line">                        A[node_id_dict[j], node_id_dict[i]] = <span class="number">1.</span> / distance</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">raise</span> ValueError(<span class="string">&quot;graph type is not correct (connect or distance)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(distance_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f_d:</span><br><span class="line">        <span class="comment"># 读取文件</span></span><br><span class="line">        f_d.readline()</span><br><span class="line">        <span class="comment"># 这里是用来将第一行的标题行去掉</span></span><br><span class="line">        reader = csv.reader(f_d)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> reader:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(item) != <span class="number">3</span>:</span><br><span class="line">                <span class="comment"># 对于长度不等于3的节点，这里将其抛弃处理</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            i, j, distance = <span class="built_in">int</span>(item[<span class="number">0</span>]), <span class="built_in">int</span>(item[<span class="number">1</span>]), <span class="built_in">float</span>(item[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据不同的类型来构建不同的邻接矩阵</span></span><br><span class="line">            <span class="keyword">if</span> graph_type == <span class="string">&quot;connect&quot;</span>:</span><br><span class="line">                A[i, j], A[j, i] = <span class="number">1.</span>, <span class="number">1.</span></span><br><span class="line">            <span class="keyword">elif</span> graph_type == <span class="string">&quot;distance&quot;</span>:</span><br><span class="line">                A[i, j] = <span class="number">1.</span> / distance</span><br><span class="line">                A[j, i] = <span class="number">1.</span> / distance</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;graph type is not correct (connect or distance)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="读取车流数据"><a href="#读取车流数据" class="headerlink" title="读取车流数据"></a><strong>读取车流数据</strong></h3><p>其实和之前可视化当中的数据很相似，主要的参数只有一个，就是读取流量文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_flow_data</span>(<span class="params">flow_file: <span class="built_in">str</span></span>) -&gt; np.array:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param flow_file: str, path of .npz file to save the traffic flow data</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        np.array(N, T, D)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 读取数据</span></span><br><span class="line">    data = np.load(flow_file)</span><br><span class="line">    <span class="comment"># 将流量数据单独选取出来，重新组织数据维度</span></span><br><span class="line">    flow_data = data[<span class="string">&#x27;data&#x27;</span>].transpose([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])[:, :, <span class="number">0</span>][:, :, np.newaxis]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> flow_data</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="构建数据集的类"><a href="#构建数据集的类" class="headerlink" title="构建数据集的类"></a><strong>构建数据集的类</strong></h3><p>其中里面有以下静态函数的修饰器，注释是网上给出的静态方法的注解：</p>
<blockquote>
<p>staticmethod用于修饰类中的方法,使其可以在不创建类实例的情况下调用方法，这样做的好处是执行效率比较高。当然，也可以像一般的方法一样用实例调用该方法。该方法一般被称为静态方法。静态方法不可以引用类中的属性或方法，其参数列表也不需要约定的默认参数self。我个人觉得，静态方法就是类对外部函数的封装，有助于优化代码结构和提高程序的可读性。当然了，被封装的方法应该尽可能的和封装它的类的功能相匹配。</p>
</blockquote>
<p>除了辅助我们处理数据的静态函数外，就是构建数据集必须的三大件：<code>__init__()</code>,<code>__len__()</code>,<code>__getitem__()</code>.</p>
<p>交通数据处理和普通的数据处理是不太一样的，比如说计算机视觉中，一般一张图片就是一个样本，每个图片有一个标签，那这个就已经组合成了模型的训练标签数据，而交通数据是一连串的时序数据，怎么找到训练样本和测试样本呢？下面看看对于时序数据是怎么划分训练和测试数据的。</p>
<ul>
<li><p>首先，对于时间序列，需要知道 <strong>滑动窗口</strong> 这个概念：比如，2019-2020年里的365天数据，如果我们单拿出来2019-6-3 这个点的数据，用这个点的数据来描绘当前情况是可以的，但是有更好的方案。</p>
<ul>
<li>分析：好像单拿出2019-6-3这个点的数据来描绘当前情况有点太绝对，它会不会有或多或少的误差，如果我想看一下2019-6-3的大致情况，我是不是可以取它的一个范围，比如2019-6-1、2019-6-2、···、2019-6-5，取这个区间的平均值来大概当做2019-6-3这天的情况，这是不是更科学些，尤其是当我们要进行预测的时候，单独拿出来一个或多或少会有些离群会有些差异，会影响我们的结果，所以我们可以基于这样一个窗口，通过窗口取平均，使得我们的数据是更平稳些。</li>
<li>滑动窗口就是窗口向一端滑行，比如从左往右，每次滑动并不是窗口区间整块的滑行，而是一个单位一个单位的滑动。例如窗口2019-6-1到2019-6-5，下一个窗口并不是2019-6-5到2019-6-10，而是2019-6-2到2019-6-6（假设数据的截取是以天为单位），整体向右移动一个单位，而不是一个窗口。</li>
<li>窗口中的值从覆盖整个窗口的位置开始产生，在此之前即为NaN，举例如下：窗口大小为10，前9个都不足够为一个一个窗口的长度，因此都无法取值。</li>
</ul>
</li>
<li><p>现在知道了滑动窗口，所以我们开始划分数据集，首先对于从0~T的时间序列划一刀，分为train_data 和 test_data，如下图所示：</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201221836858.png" alt="">    </p>
</li>
<li><p>然后我们以训练集为例来取一个一个的样本。具体而言，人为定义一个滑动窗口的大小，因为我要预测下一时刻的交通流量，所以这里我定义滑动窗口的大小为7。这个7就是一个样本，包含了输入样本 $x $和 标签 $y$，具体如下图所示。</p>
<p>我把 $x$ 的数据叫做历史数据$ H$，现在要做的是预测$ H + 1$  时刻的交通流量（当然别的问题可能是要预测多个时刻，这个同理），也就是标签 $ \hat y$ ，所以正如下图所示，这就组成了一个训练的样本。最后就是把这个窗口按一个时间单位的一次移动，就得到了所有的训练样本。<br><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201222215572.png" alt=""></p>
</li>
<li><p>假设训练集的程度为$L_1$，测试集的长度为$L_2$。于是就可以得出两个集合的索引$idx$的范围。</p>
<ul>
<li><code>train</code>：$idx \to [0, L_1-1] \to [H,L_1-1+H]$，长度为 $H+L_1$。</li>
<li><code>test</code>：$idx \to [0, L_2-1]$，长度为 $H+L_2$。</li>
</ul>
<p>但是考虑到窗口的问题，<code>idx</code>遍历的时候要在前面空出一定的长度。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201223107447.png" alt=""></p>
<p>此时就可以得出数据集的总长是$T=L_1+L_2+H$。</p>
</li>
</ul>
<p>下面将进行具体的代码实现：</p>
<ul>
<li><p><code>data_path</code>: <code>list</code>, [“graph file name” , “flow data file name”], path to save the data file names.<strong>数据的列表</strong></p>
</li>
<li><p><code>num_nodes</code>: <code>int</code>, number of nodes. <strong>节点的数量</strong></p>
</li>
<li><p><code>divide_days</code>: <code>list</code>, [ days of train data, days of test data], list to divide the original data. <strong>天数划分，列表的第一个参数为训练集的天数，第二个参数为测试集的天数</strong></p>
</li>
<li><code>time_interval</code>: <code>int</code>, time interval between two traffic data records (mins).<strong>两个交通数据采集的时间间隔</strong></li>
<li><p><code>history_length</code>: <code>int</code>, length of history data to be used.<strong>历史数据长度，就上图里面的H</strong></p>
</li>
<li><p><code>train_mode</code>: <code>list</code>, [“train”, “test”].</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoadData</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_path, num_nodes, divide_days, time_interval, history_length, train_mode</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data_path: list, [&quot;graph file name&quot; , &quot;flow data file name&quot;], path to save the data file names.</span></span><br><span class="line"><span class="string">        :param num_nodes: int, number of nodes.</span></span><br><span class="line"><span class="string">        :param divide_days: list, [ days of train data, days of test data], list to divide the original data.</span></span><br><span class="line"><span class="string">        :param time_interval: int, time interval between two traffic data records (mins).</span></span><br><span class="line"><span class="string">        :param history_length: int, length of history data to be used.</span></span><br><span class="line"><span class="string">        :param train_mode: list, [&quot;train&quot;, &quot;test&quot;].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.data_path = data_path</span><br><span class="line">        self.num_nodes = num_nodes</span><br><span class="line">        self.train_mode = train_mode</span><br><span class="line">        self.train_days = divide_days[<span class="number">0</span>]  <span class="comment"># 45</span></span><br><span class="line">        self.test_days = divide_days[<span class="number">1</span>]  <span class="comment"># 14 = 7 * 2</span></span><br><span class="line">        self.history_length = history_length  <span class="comment"># 6</span></span><br><span class="line">        self.time_interval = time_interval  <span class="comment"># 5 min</span></span><br><span class="line">        <span class="comment"># 这里取样的长度是5 min，于是历史长度是6，即是用历史30min取预测后面5分钟的数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.one_day_length = <span class="built_in">int</span>(<span class="number">24</span> * <span class="number">60</span> / self.time_interval) </span><br><span class="line">        <span class="comment"># 一整天的数据量</span></span><br><span class="line"></span><br><span class="line">        self.graph = get_adjacent_matrix(distance_file=data_path[<span class="number">0</span>], num_nodes=num_nodes)</span><br><span class="line">        <span class="comment"># 构建邻接矩阵</span></span><br><span class="line"></span><br><span class="line">        self.flow_norm, self.flow_data = self.pre_process_data(data=get_flow_data(data_path[<span class="number">1</span>]), norm_dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 对流量数据进行预处理操作，一般就是归一化</span></span><br><span class="line">        <span class="comment"># 返回交通流量预测的基和归一化之后的参数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :return: length of dataset (number of samples).</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 数据的长度等于天数乘以一天的长度</span></span><br><span class="line">        <span class="keyword">if</span> self.train_mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> self.train_days * self.one_day_length - self.history_length</span><br><span class="line">        <span class="keyword">elif</span> self.train_mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> self.test_days * self.one_day_length</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;train mode: [&#123;&#125;] is not defined&quot;</span>.<span class="built_in">format</span>(self.train_mode))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span>  <span class="comment"># (x, y), index = [0, L1 - 1]</span></span><br><span class="line">        <span class="comment"># 获取数据的索引</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param index: int, range between [0, length - 1].</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            graph: torch.tensor, [N, N].</span></span><br><span class="line"><span class="string">            data_x: torch.tensor, [N, H, D].</span></span><br><span class="line"><span class="string">            data_y: torch.tensor, [N, 1, D].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.train_mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            index = index</span><br><span class="line">            <span class="comment"># 训练集是从0开始起步的</span></span><br><span class="line">        <span class="keyword">elif</span> self.train_mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">            index += self.train_days * self.one_day_length</span><br><span class="line">            <span class="comment"># 测试集需要考虑在前面增加一个偏移量</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;train mode: [&#123;&#125;] is not defined&quot;</span>.<span class="built_in">format</span>(self.train_mode))</span><br><span class="line"></span><br><span class="line">        data_x, data_y = LoadData.slice_data(self.flow_data, self.history_length, index, self.train_mode)</span><br><span class="line">        <span class="comment"># 将数据根据索引进行切片</span></span><br><span class="line"></span><br><span class="line">        data_x = LoadData.to_tensor(data_x)  <span class="comment"># [N, H, D]</span></span><br><span class="line">        data_y = LoadData.to_tensor(data_y).unsqueeze(<span class="number">1</span>)  <span class="comment"># [N, 1, D]</span></span><br><span class="line">        <span class="comment"># 在中间增加一维</span></span><br><span class="line">         </span><br><span class="line">        <span class="comment"># 最后返回的结果是一个字典</span></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;graph&quot;</span>: LoadData.to_tensor(self.graph), <span class="string">&quot;flow_x&quot;</span>: data_x, <span class="string">&quot;flow_y&quot;</span>: data_y&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">slice_data</span>(<span class="params">data, history_length, index, train_mode</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        :param history_length: int, length of history data to be used.</span></span><br><span class="line"><span class="string">        :param index: int, index on temporal axis.</span></span><br><span class="line"><span class="string">        :param train_mode: str, [&quot;train&quot;, &quot;test&quot;].</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            data_x: np.array, [N, H, D].</span></span><br><span class="line"><span class="string">            data_y: np.array [N, D].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> train_mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            start_index = index</span><br><span class="line">            end_index = index + history_length</span><br><span class="line">            <span class="comment"># [idx,idx+h]</span></span><br><span class="line">        <span class="keyword">elif</span> train_mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">            start_index = index - history_length</span><br><span class="line">            end_index = index</span><br><span class="line">            <span class="comment"># [idx-h,idx]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;train model &#123;&#125; is not defined&quot;</span>.<span class="built_in">format</span>(train_mode))</span><br><span class="line"></span><br><span class="line">        data_x = data[:, start_index: end_index]</span><br><span class="line">        data_y = data[:, end_index]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data_x, data_y</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span>(<span class="params">data, norm_dim</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :param norm_dim: int, normalization dimension.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            norm_base: list, [max_data, min_data], data of normalization base.</span></span><br><span class="line"><span class="string">            norm_data: np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        norm_base = LoadData.normalize_base(data, norm_dim)  <span class="comment"># find the normalize base</span></span><br><span class="line">        norm_data = LoadData.normalize_data(norm_base[<span class="number">0</span>], norm_base[<span class="number">1</span>], data)  <span class="comment"># normalize data</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> norm_base, norm_data</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize_base</span>(<span class="params">data, norm_dim</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :param norm_dim: int, normalization dimension.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            max_data: np.array</span></span><br><span class="line"><span class="string">            min_data: np.array</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        max_data = np.<span class="built_in">max</span>(data, norm_dim, keepdims=<span class="literal">True</span>)  <span class="comment"># [N, T, D] , norm_dim=1, [N, 1, D]</span></span><br><span class="line">        <span class="comment"># 这里如果keepdims=False,norm_dim=1  则[N,T,D]-&gt;[N,D]</span></span><br><span class="line">        min_data = np.<span class="built_in">min</span>(data, norm_dim, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> max_data, min_data</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize_data</span>(<span class="params">max_data, min_data, data</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param max_data: np.array, max data.</span></span><br><span class="line"><span class="string">        :param min_data: np.array, min data.</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        mid = min_data</span><br><span class="line">        base = max_data - min_data</span><br><span class="line">        normalized_data = (data - mid) / base</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> normalized_data</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recover_data</span>(<span class="params">max_data, min_data, data</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param max_data: np.array, max data.</span></span><br><span class="line"><span class="string">        :param min_data: np.array, min data.</span></span><br><span class="line"><span class="string">        :param data: np.array, normalized data.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            recovered_data: np.array, recovered data.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        mid = min_data</span><br><span class="line">        base = max_data - min_data</span><br><span class="line"></span><br><span class="line">        recovered_data = data * base + mid</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> recovered_data</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_tensor</span>(<span class="params">data</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(data, dtype=torch.<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="几个静态函数的介绍"><a href="#几个静态函数的介绍" class="headerlink" title="几个静态函数的介绍"></a><strong>几个静态函数的介绍</strong></h3><p>首先是预处理函数，其实就是完成了一步归一化的操作。</p>
<p>主要的参数是：<code>data</code>为原始数据；<code>norm_dim</code>为归一化的交通流量数据。</p>
<p>其返回的是归一化的基和已经归一化好的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span>(<span class="params">data, norm_dim</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :param norm_dim: int, normalization dimension.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            norm_base: list, [max_data, min_data], data of normalization base.</span></span><br><span class="line"><span class="string">            norm_data: np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    norm_base = LoadData.normalize_base(data, norm_dim)  <span class="comment"># find the normalize base</span></span><br><span class="line">    norm_data = LoadData.normalize_data(norm_base[<span class="number">0</span>], norm_base[<span class="number">1</span>], data)  <span class="comment"># normalize data</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> norm_base, norm_data</span><br></pre></td></tr></table></figure>
<p>其中调用了计算归归一化极值的函数，即返回计算归一化函数的基：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_base</span>(<span class="params">data, norm_dim</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :param norm_dim: int, normalization dimension.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            max_data: np.array</span></span><br><span class="line"><span class="string">            min_data: np.array</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    max_data = np.<span class="built_in">max</span>(data, norm_dim, keepdims=<span class="literal">True</span>)  <span class="comment"># [N, T, D] , norm_dim=1, [N, 1, D]</span></span><br><span class="line">    <span class="comment"># 这里如果keepdims=False,norm_dim=1  则[N,T,D]-&gt;[N,D]</span></span><br><span class="line">    min_data = np.<span class="built_in">min</span>(data, norm_dim, keepdims=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> max_data, min_data</span><br></pre></td></tr></table></figure>
<p>接下来调用的是计算归一化的函数：</p>
<p>主要的参数是：原始数据和归一化基。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_data</span>(<span class="params">max_data, min_data, data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param max_data: np.array, max data.</span></span><br><span class="line"><span class="string">        :param min_data: np.array, min data.</span></span><br><span class="line"><span class="string">        :param data: np.array, original traffic data without normalization.</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    mid = min_data</span><br><span class="line">    base = max_data - min_data</span><br><span class="line">    normalized_data = (data - mid) / base</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> normalized_data</span><br></pre></td></tr></table></figure>
<p>最后是根据归一化基和归一化之后的数据来恢复之前原始数据的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recover_data</span>(<span class="params">max_data, min_data, data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param max_data: np.array, max data.</span></span><br><span class="line"><span class="string">    :param min_data: np.array, min data.</span></span><br><span class="line"><span class="string">    :param data: np.array, normalized data.</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        recovered_data: np.array, recovered data.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    mid = min_data</span><br><span class="line">    base = max_data - min_data</span><br><span class="line"></span><br><span class="line">    recovered_data = data * base + mid</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> recovered_data</span><br></pre></td></tr></table></figure>
<p>下面针对数据的索引的获取问题，这里需要一个数据切片的函数：</p>
<p>主要参数：交通流量数据、历史长度、当前索引值以及所处的训练的模式。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230201235527093.png" alt=""></p>
<ul>
<li><code>train</code>：其<code>x</code>对应的是$[s,e)$，<code>y</code>对应的数据是$[e]$，对于训练集$e=s+h=index+h$，并且$index=s$</li>
<li><code>test</code>： 其<code>x</code>对应的是$[s,e)$，<code>y</code>对应的数据是$[e]$，对于测试集$s=e-h=index-h$，其中$index=e$ </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slice_data</span>(<span class="params">data, history_length, index, train_mode</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: np.array, normalized traffic data.</span></span><br><span class="line"><span class="string">        :param history_length: int, length of history data to be used.</span></span><br><span class="line"><span class="string">        :param index: int, index on temporal axis.</span></span><br><span class="line"><span class="string">        :param train_mode: str, [&quot;train&quot;, &quot;test&quot;].</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            data_x: np.array, [N, H, D].</span></span><br><span class="line"><span class="string">            data_y: np.array [N, D].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> train_mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            start_index = index</span><br><span class="line">            end_index = index + history_length</span><br><span class="line">            <span class="comment"># [idx,idx+h]</span></span><br><span class="line">        <span class="keyword">elif</span> train_mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">            start_index = index - history_length</span><br><span class="line">            end_index = index</span><br><span class="line">            <span class="comment"># [idx-h,idx]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;train model &#123;&#125; is not defined&quot;</span>.<span class="built_in">format</span>(train_mode))</span><br><span class="line"></span><br><span class="line">        data_x = data[:, start_index: end_index]</span><br><span class="line">        data_y = data[:, end_index]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data_x, data_y</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="测试数据集"><a href="#测试数据集" class="headerlink" title="测试数据集"></a><strong>测试数据集</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    train_data = LoadData(data_path=[<span class="string">&quot;PeMS_04/PeMS04.csv&quot;</span>, <span class="string">&quot;PeMS_04/PeMS04.npz&quot;</span>], num_nodes=<span class="number">307</span>, divide_days=[<span class="number">45</span>, <span class="number">14</span>],</span><br><span class="line">                          time_interval=<span class="number">5</span>, history_length=<span class="number">6</span>,</span><br><span class="line">                          train_mode=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_data))</span><br><span class="line">    <span class="built_in">print</span>(train_data[<span class="number">0</span>][<span class="string">&quot;flow_x&quot;</span>].size())</span><br><span class="line">    <span class="built_in">print</span>(train_data[<span class="number">0</span>][<span class="string">&quot;flow_y&quot;</span>].size())</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="模型搭建和训练测试"><a href="#模型搭建和训练测试" class="headerlink" title="模型搭建和训练测试"></a><strong>模型搭建和训练测试</strong></h2><p>在加载完数据之后，我们就需要来自己搭建模型来实现对交通流的预测。</p>
<h3 id="导入相关包"><a href="#导入相关包" class="headerlink" title="导入相关包"></a><strong>导入相关包</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> traffic_dataset <span class="keyword">import</span> LoadData</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> Evaluation</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> visualize_result</span><br><span class="line"><span class="keyword">from</span> chebnet <span class="keyword">import</span> ChebNet</span><br><span class="line"><span class="keyword">from</span> gat <span class="keyword">import</span> GATNet</span><br></pre></td></tr></table></figure>
<h3 id="搭建整体的框架"><a href="#搭建整体的框架" class="headerlink" title="搭建整体的框架"></a><strong>搭建整体的框架</strong></h3><h4 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a><strong>整体框架</strong></h4><p>本项目基于之前的类似的训练和测试过程，先将整个的框架完成，模型上使用一个单层的神经网路作为一个简单的BaseLine，来看模型是否可以跑通，如可以跑通之后，在取尝试搭建所需要的的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loading Dataset</span></span><br><span class="line">    train_data = LoadData(data_path=[<span class="string">&quot;PeMS_04/PeMS04.csv&quot;</span>, <span class="string">&quot;PeMS_04/PeMS04.npz&quot;</span>], num_nodes=<span class="number">307</span>, divide_days=[<span class="number">45</span>, <span class="number">14</span>],</span><br><span class="line">                          time_interval=<span class="number">5</span>, history_length=<span class="number">6</span>,</span><br><span class="line">                          train_mode=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">    test_data = LoadData(data_path=[<span class="string">&quot;PeMS_04/PeMS04.csv&quot;</span>, <span class="string">&quot;PeMS_04/PeMS04.npz&quot;</span>], num_nodes=<span class="number">307</span>, divide_days=[<span class="number">45</span>, <span class="number">14</span>],</span><br><span class="line">                         time_interval=<span class="number">5</span>, history_length=<span class="number">6</span>,</span><br><span class="line">                         train_mode=<span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    test_loader = DataLoader(test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loading Model</span></span><br><span class="line">    <span class="comment"># my_net = GATNet(in_c=6 * 1, hid_c=6, out_c=1, n_heads=2)</span></span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    my_net = my_net.to(device)</span><br><span class="line"></span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">    optimizer = optim.Adam(params=my_net.parameters())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train model</span></span><br><span class="line">    Epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    my_net.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(Epoch):</span><br><span class="line">        epoch_loss = <span class="number">0.0</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:  <span class="comment"># [&quot;graph&quot;: [B, N, N] , &quot;flow_x&quot;: [B, N, H, D], &quot;flow_y&quot;: [B, N, 1, D]]</span></span><br><span class="line">            my_net.zero_grad()</span><br><span class="line"></span><br><span class="line">            predict_value = my_net(data, device).to(torch.device(<span class="string">&quot;cpu&quot;</span>))  <span class="comment"># [0, 1] -&gt; recover</span></span><br><span class="line">            <span class="comment"># 这里在模型的内部进行所需数据导入GPU的操作</span></span><br><span class="line">            <span class="comment"># 这里将标签数据导入到cpu进行计算和测试</span></span><br><span class="line">            loss = criterion(predict_value, data[<span class="string">&quot;flow_y&quot;</span>])</span><br><span class="line"></span><br><span class="line">            epoch_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line"></span><br><span class="line">            optimizer.step()</span><br><span class="line">        end_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch: &#123;:04d&#125;, Loss: &#123;:02.4f&#125;, Time: &#123;:02.2f&#125; mins&quot;</span>.<span class="built_in">format</span>(epoch, <span class="number">1000</span> * epoch_loss / <span class="built_in">len</span>(train_data),</span><br><span class="line">                                                                          (end_time-start_time)/<span class="number">60</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test Model</span></span><br><span class="line">    my_net.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        MAE, MAPE, RMSE = [], [], []</span><br><span class="line">        Target = np.zeros([<span class="number">307</span>, <span class="number">1</span>, <span class="number">1</span>]) <span class="comment"># [N, 1, D]</span></span><br><span class="line">        Predict = np.zeros_like(Target)  <span class="comment">#[N, T, D]</span></span><br><span class="line"></span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line"></span><br><span class="line">            predict_value = my_net(data, device).to(torch.device(<span class="string">&quot;cpu&quot;</span>))  <span class="comment"># [B, N, 1, D]  -&gt; [1, N, B(T), D]</span></span><br><span class="line"></span><br><span class="line">            loss = criterion(predict_value, data[<span class="string">&quot;flow_y&quot;</span>])</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            predict_value = predict_value.transpose(<span class="number">0</span>, <span class="number">2</span>).squeeze(<span class="number">0</span>)  <span class="comment"># [1, N, B(T), D] -&gt; [N, B(T), D] -&gt; [N, T, D]</span></span><br><span class="line">            target_value = data[<span class="string">&quot;flow_y&quot;</span>].transpose(<span class="number">0</span>, <span class="number">2</span>).squeeze(<span class="number">0</span>)  <span class="comment"># [1, N, B(T), D] -&gt; [N, B(T), D] -&gt; [N, T, D]</span></span><br><span class="line"></span><br><span class="line">            performance, data_to_save = compute_performance(predict_value, target_value, test_loader)</span><br><span class="line"></span><br><span class="line">            Predict = np.concatenate([Predict, data_to_save[<span class="number">0</span>]], axis=<span class="number">1</span>)</span><br><span class="line">            Target = np.concatenate([Target, data_to_save[<span class="number">1</span>]], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            MAE.append(performance[<span class="number">0</span>])</span><br><span class="line">            MAPE.append(performance[<span class="number">1</span>])</span><br><span class="line">            RMSE.append(performance[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Test Loss: &#123;:02.4f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">1000</span> * total_loss / <span class="built_in">len</span>(test_data)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Performance:  MAE &#123;:2.2f&#125;    &#123;:2.2f&#125;%    &#123;:2.2f&#125;&quot;</span>.<span class="built_in">format</span>(np.mean(MAE), np.mean(MAPE * <span class="number">100</span>), np.mean(RMSE)))</span><br><span class="line"></span><br><span class="line">    Predict = np.delete(Predict, <span class="number">0</span>, axis=<span class="number">1</span>)</span><br><span class="line">    Target = np.delete(Target, <span class="number">0</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    result_file = <span class="string">&quot;GAT_result.h5&quot;</span></span><br><span class="line">    file_obj = h5py.File(result_file, <span class="string">&quot;w&quot;</span>)</span><br><span class="line"></span><br><span class="line">    file_obj[<span class="string">&quot;predict&quot;</span>] = Predict</span><br><span class="line">    file_obj[<span class="string">&quot;target&quot;</span>] = Target</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a><strong>模型评估</strong></h4><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230202105747923.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Evaluation</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae_</span>(<span class="params">target, output</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>(target - output))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mape_</span>(<span class="params">target, output</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>(target - output) / (target + <span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_</span>(<span class="params">target, output</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.sqrt(np.mean(np.power(target - output, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">total</span>(<span class="params">target, output</span>):</span></span><br><span class="line">        mae = Evaluation.mae_(target, output)</span><br><span class="line">        mape = Evaluation.mape_(target, output)</span><br><span class="line">        rmse = Evaluation.rmse_(target, output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mae, mape, rmse</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a><strong>可视化</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_result</span>(<span class="params">h5_file, nodes_id, time_se, visualize_file</span>):</span></span><br><span class="line">    file_obj = h5py.File(h5_file, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    prediction = file_obj[<span class="string">&quot;predict&quot;</span>][:][:, :, <span class="number">0</span>]  <span class="comment"># [N, T]</span></span><br><span class="line">    target = file_obj[<span class="string">&quot;target&quot;</span>][:][:, :, <span class="number">0</span>]  <span class="comment"># [N, T]</span></span><br><span class="line">    file_obj.close()</span><br><span class="line"></span><br><span class="line">    plot_prediction = prediction[nodes_id][time_se[<span class="number">0</span>]: time_se[<span class="number">1</span>]]  <span class="comment"># [T1]</span></span><br><span class="line">    plot_target = target[nodes_id][time_se[<span class="number">0</span>]: time_se[<span class="number">1</span>]]  <span class="comment"># [T1]</span></span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;-.&quot;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">    plt.plot(np.array([t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(time_se[<span class="number">1</span>] - time_se[<span class="number">0</span>])]), plot_prediction, ls=<span class="string">&quot;-&quot;</span>, marker=<span class="string">&quot; &quot;</span>, color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.plot(np.array([t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(time_se[<span class="number">1</span>] - time_se[<span class="number">0</span>])]), plot_target, ls=<span class="string">&quot;-&quot;</span>, marker=<span class="string">&quot; &quot;</span>, color=<span class="string">&quot;b&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend([<span class="string">&quot;prediction&quot;</span>, <span class="string">&quot;target&quot;</span>], loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.axis([<span class="number">0</span>, time_se[<span class="number">1</span>] - time_se[<span class="number">0</span>],</span><br><span class="line">              np.<span class="built_in">min</span>(np.array([np.<span class="built_in">min</span>(plot_prediction), np.<span class="built_in">min</span>(plot_target)])),</span><br><span class="line">              np.<span class="built_in">max</span>(np.array([np.<span class="built_in">max</span>(plot_prediction), np.<span class="built_in">max</span>(plot_target)]))])</span><br><span class="line"></span><br><span class="line">    plt.savefig(visualize_file + <span class="string">&quot;.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="模型的构建"><a href="#模型的构建" class="headerlink" title="模型的构建"></a><strong>模型的构建</strong></h3><h4 id="BaseLine模型"><a href="#BaseLine模型" class="headerlink" title="BaseLine模型"></a><strong>BaseLine模型</strong></h4><p>首先构建一个十分简答的神经网路来作为BaseLine测试模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Baseline</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, out_c</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Baseline, self).__init__()</span><br><span class="line">        self.layer = nn.Linear(in_c, out_c)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data, device</span>):</span></span><br><span class="line">        flow_x = data[<span class="string">&quot;flow_x&quot;</span>].to(device)  <span class="comment"># [B, N, H, D]</span></span><br><span class="line"></span><br><span class="line">        B, N = flow_x.size(<span class="number">0</span>), flow_x.size(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        flow_x = flow_x.view(B, N, -<span class="number">1</span>)  <span class="comment"># [B, N, H*D]  H = 6, D = 1</span></span><br><span class="line"></span><br><span class="line">        output = self.layer(flow_x)  <span class="comment"># [B, N, Out_C=1], Out_C = D = 1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output.unsqueeze(<span class="number">2</span>)  <span class="comment"># [B, N, 1, D=Out_C=1]</span></span><br></pre></td></tr></table></figure>
<hr>
<h4 id="GCN的搭建"><a href="#GCN的搭建" class="headerlink" title="GCN的搭建"></a><strong>GCN的搭建</strong></h4><p>之后整体的框架可以跑通之后，我们将使用一个简单GCN模型。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230202093238683.png" alt=""></p>
<p>GCN模型其实就是在以原来的线性连接的基础上增加图结构的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, hid_c, out_c</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GCN, self).__init__()</span><br><span class="line">        self.linear_1 = nn.Linear(in_c, hid_c)</span><br><span class="line">        self.linear_2 = nn.Linear(hid_c, out_c)</span><br><span class="line">        self.act = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data, device</span>):</span></span><br><span class="line">        graph_data = data[<span class="string">&quot;graph&quot;</span>].to(device)[<span class="number">0</span>]  <span class="comment"># [N, N]</span></span><br><span class="line">        graph_data = GCN.process_graph(graph_data)</span><br><span class="line"></span><br><span class="line">        flow_x = data[<span class="string">&quot;flow_x&quot;</span>].to(device)  <span class="comment"># [B, N, H, D]</span></span><br><span class="line"></span><br><span class="line">        B, N = flow_x.size(<span class="number">0</span>), flow_x.size(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        flow_x = flow_x.view(B, N, -<span class="number">1</span>)  <span class="comment"># [B, N, H*D]  H = 6, D = 1</span></span><br><span class="line"></span><br><span class="line">        output_1 = self.linear_1(flow_x)  <span class="comment"># [B, N, hid_C]</span></span><br><span class="line">        output_1 = self.act(torch.matmul(graph_data, output_1))  <span class="comment"># [N, N], [B, N, Hid_C]</span></span><br><span class="line"></span><br><span class="line">        output_2 = self.linear_2(output_1)</span><br><span class="line">        output_2 = self.act(torch.matmul(graph_data, output_2))  <span class="comment"># [B, N, 1, Out_C]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_2.unsqueeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_graph</span>(<span class="params">graph_data</span>):</span></span><br><span class="line">        <span class="comment"># 主要是用来处理图结构</span></span><br><span class="line">        N = graph_data.size(<span class="number">0</span>)</span><br><span class="line">        matrix_i = torch.eye(N, dtype=graph_data.dtype, device=graph_data.device)</span><br><span class="line">        graph_data += matrix_i  <span class="comment"># A~=A+I [N, N] </span></span><br><span class="line">        <span class="comment"># 增加自连接边</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 度矩阵的生成</span></span><br><span class="line">        degree_matrix = torch.<span class="built_in">sum</span>(graph_data, dim=-<span class="number">1</span>, keepdim=<span class="literal">False</span>)  <span class="comment"># [N]</span></span><br><span class="line">        <span class="comment"># keepdim=False的意思其实就是不保持原来矩阵的维度</span></span><br><span class="line">        degree_matrix = degree_matrix.<span class="built_in">pow</span>(-<span class="number">1</span>)</span><br><span class="line">        degree_matrix[degree_matrix == <span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] = <span class="number">0.</span>  <span class="comment"># [N]</span></span><br><span class="line"></span><br><span class="line">        degree_matrix = torch.diag(degree_matrix)  <span class="comment"># [N, N]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里torch.mm是矩阵乘法的意思</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(degree_matrix, graph_data)  <span class="comment"># D^(-1) * A = \hat(A)</span></span><br></pre></td></tr></table></figure>
<p>训练之后的结果，此处为节约时间就训练10个回合：</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/gat_node_120.png" alt=""></p>
<p>可以看出其低频的特征基本学到了，但是高频的特征还没有学习的很好，训练集和测试集的误差还是比较的大，还有很大的提上空间。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0000, Loss: 0.8328, Time: 0.53 mins</span><br><span class="line">Epoch: 0001, Loss: 0.1393, Time: 0.09 mins</span><br><span class="line">Epoch: 0002, Loss: 0.1389, Time: 0.09 mins</span><br><span class="line">Epoch: 0003, Loss: 0.1385, Time: 0.09 mins</span><br><span class="line">Epoch: 0004, Loss: 0.1378, Time: 0.09 mins</span><br><span class="line">Epoch: 0005, Loss: 0.1372, Time: 0.09 mins</span><br><span class="line">Epoch: 0006, Loss: 0.1365, Time: 0.09 mins</span><br><span class="line">Epoch: 0007, Loss: 0.1358, Time: 0.09 mins</span><br><span class="line">Epoch: 0008, Loss: 0.1350, Time: 0.10 mins</span><br><span class="line">Epoch: 0009, Loss: 0.1342, Time: 0.10 mins</span><br><span class="line">Test Loss: 0.1328</span><br><span class="line">Performance:  MAE 33.51    1.67%    47.52</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="ChebNet的搭建"><a href="#ChebNet的搭建" class="headerlink" title="ChebNet的搭建"></a><strong>ChebNet的搭建</strong></h4><p>可以看到这里的GCN的效果还有很大的提升空间，于是这边将模型增加一些基函数得到ChebNet网络。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230202105533832.png" alt=""></p>
<p>首先将忽略具体模块的细节，将整体的大的框架搭建出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChebNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, hid_c, out_c, K</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param in_c: int, number of input channels.</span></span><br><span class="line"><span class="string">        :param hid_c: int, number of hidden channels.</span></span><br><span class="line"><span class="string">        :param out_c: int, number of output channels.</span></span><br><span class="line"><span class="string">        :param K:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ChebNet, self).__init__()</span><br><span class="line">        self.conv1 = ChebConv(in_c=in_c, out_c=hid_c, K=K)</span><br><span class="line">        self.conv2 = ChebConv(in_c=hid_c, out_c=out_c, K=K)</span><br><span class="line">        self.act = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data, device</span>):</span></span><br><span class="line">        graph_data = data[<span class="string">&quot;graph&quot;</span>].to(device)[<span class="number">0</span>]  <span class="comment"># [N, N]</span></span><br><span class="line">        flow_x = data[<span class="string">&quot;flow_x&quot;</span>].to(device)  <span class="comment"># [B, N, H, D]</span></span><br><span class="line"></span><br><span class="line">        B, N = flow_x.size(<span class="number">0</span>), flow_x.size(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        flow_x = flow_x.view(B, N, -<span class="number">1</span>)  <span class="comment"># [B, N, H*D]</span></span><br><span class="line"></span><br><span class="line">        output_1 = self.act(self.conv1(flow_x, graph_data))</span><br><span class="line">        output_2 = self.act(self.conv2(output_1, graph_data))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_2.unsqueeze(<span class="number">2</span>) <span class="comment"># [B, N, 1]</span></span><br></pre></td></tr></table></figure>
<p>下面我们就开始构架具体细节ChenConv类，其中也定义了一些辅助的静态函数，首先是计算拉普拉斯矩阵的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_laplacian</span>(<span class="params">graph, normalize</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        return the laplacian of the graph.</span></span><br><span class="line"><span class="string">        :param graph: the graph structure without self loop, [N, N]. 不可以有自连接边</span></span><br><span class="line"><span class="string">        :param normalize: whether to used the normalized laplacian.</span></span><br><span class="line"><span class="string">        :return: graph laplacian.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        D = torch.diag(torch.<span class="built_in">sum</span>(graph, dim=-<span class="number">1</span>) ** (-<span class="number">1</span> / <span class="number">2</span>))</span><br><span class="line">        L = torch.eye(graph.size(<span class="number">0</span>), device=graph.device, dtype=graph.dtype) - torch.mm(torch.mm(D, graph), D) <span class="comment"># 度矩阵归一化</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            D = torch.diag(torch.<span class="built_in">sum</span>(graph, dim=-<span class="number">1</span>))</span><br><span class="line">            L = D - graph</span><br><span class="line">            <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>
<p>有了拉普拉斯矩阵，就可以计算我们的切比雪夫多项式函数，这里使用的是迭代求解的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cheb_polynomial</span>(<span class="params">self, laplacian</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the Chebyshev Polynomial, according to the graph laplacian.</span></span><br><span class="line"><span class="string">    :param laplacian: the graph laplacian, [N, N].</span></span><br><span class="line"><span class="string">    :return: the multi order Chebyshev laplacian, [K, N, N].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N = laplacian.size(<span class="number">0</span>)  <span class="comment"># [N, N]</span></span><br><span class="line">    multi_order_laplacian = torch.zeros([self.K, N, N], device=laplacian.device, dtype=torch.<span class="built_in">float</span>)  <span class="comment"># [K, N, N]</span></span><br><span class="line">    multi_order_laplacian[<span class="number">0</span>] = torch.eye(N, device=laplacian.device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.K == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> multi_order_laplacian</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        multi_order_laplacian[<span class="number">1</span>] = laplacian</span><br><span class="line">        <span class="keyword">if</span> self.K == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> multi_order_laplacian</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, self.K):</span><br><span class="line">                multi_order_laplacian[k] = <span class="number">2</span> * torch.mm(laplacian, multi_order_laplacian[k-<span class="number">1</span>]) - \</span><br><span class="line">                                           multi_order_laplacian[k-<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> multi_order_laplacian</span><br></pre></td></tr></table></figure>
<p>有了上述两个关键的函数，这里就开始搭建chebConv的实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChebConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    The ChebNet convolution operation.</span></span><br><span class="line"><span class="string">    :param in_c: int, number of input channels.</span></span><br><span class="line"><span class="string">    :param out_c: int, number of output channels.</span></span><br><span class="line"><span class="string">    :param K: int, the order of Chebyshev Polynomial.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, out_c, K, bias=<span class="literal">True</span>, normalize=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChebConv, self).__init__()</span><br><span class="line">        self.normalize = normalize</span><br><span class="line"></span><br><span class="line">        self.weight = nn.Parameter(torch.Tensor(K + <span class="number">1</span>, <span class="number">1</span>, in_c, out_c))  <span class="comment"># [K+1, 1, in_c, out_c]</span></span><br><span class="line">        init.xavier_normal_(self.weight)</span><br><span class="line">        <span class="comment"># 基于特殊的高斯分布进行的初始化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> bias:</span><br><span class="line">            self.bias = nn.Parameter(torch.Tensor(<span class="number">1</span>, <span class="number">1</span>, out_c))</span><br><span class="line">            init.zeros_(self.bias)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.register_parameter(<span class="string">&quot;bias&quot;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        self.K = K + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, graph</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param inputs: the input data, [B, N, C]</span></span><br><span class="line"><span class="string">        :param graph: the graph structure, [N, N]</span></span><br><span class="line"><span class="string">        :return: convolution result, [B, N, D]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        L = ChebConv.get_laplacian(graph, self.normalize)  <span class="comment"># [N, N]</span></span><br><span class="line">        <span class="comment"># 计算K个chebyshev多项式的结果</span></span><br><span class="line">        mul_L = self.cheb_polynomial(L).unsqueeze(<span class="number">1</span>)   <span class="comment"># [K, 1, N, N]</span></span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 这里张量的计算有一点难以理解需要查阅相关资料</span></span><br><span class="line">        result = torch.matmul(mul_L, inputs)  <span class="comment"># [K, B, N, C]</span></span><br><span class="line">        result = torch.matmul(result, self.weight)  <span class="comment"># [K, B, N, D]</span></span><br><span class="line">        result = torch.<span class="built_in">sum</span>(result, dim=<span class="number">0</span>) + self.bias  <span class="comment"># [B, N, D]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cheb_polynomial</span>(<span class="params">self, laplacian</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Compute the Chebyshev Polynomial, according to the graph laplacian.</span></span><br><span class="line"><span class="string">        :param laplacian: the graph laplacian, [N, N].</span></span><br><span class="line"><span class="string">        :return: the multi order Chebyshev laplacian, [K, N, N].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        N = laplacian.size(<span class="number">0</span>)  <span class="comment"># [N, N]</span></span><br><span class="line">        multi_order_laplacian = torch.zeros([self.K, N, N], device=laplacian.device, dtype=torch.<span class="built_in">float</span>)  <span class="comment"># [K, N, N]</span></span><br><span class="line">        multi_order_laplacian[<span class="number">0</span>] = torch.eye(N, device=laplacian.device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.K == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> multi_order_laplacian</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            multi_order_laplacian[<span class="number">1</span>] = laplacian</span><br><span class="line">            <span class="keyword">if</span> self.K == <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> multi_order_laplacian</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, self.K):</span><br><span class="line">                    multi_order_laplacian[k] = <span class="number">2</span> * torch.mm(laplacian, multi_order_laplacian[k-<span class="number">1</span>]) - \</span><br><span class="line">                                               multi_order_laplacian[k-<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> multi_order_laplacian</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_laplacian</span>(<span class="params">graph, normalize</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        return the laplacian of the graph.</span></span><br><span class="line"><span class="string">        :param graph: the graph structure without self loop, [N, N]. 不可以有自连接边</span></span><br><span class="line"><span class="string">        :param normalize: whether to used the normalized laplacian.</span></span><br><span class="line"><span class="string">        :return: graph laplacian.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> normalize:</span><br><span class="line">            D = torch.diag(torch.<span class="built_in">sum</span>(graph, dim=-<span class="number">1</span>) ** (-<span class="number">1</span> / <span class="number">2</span>))</span><br><span class="line">            L = torch.eye(graph.size(<span class="number">0</span>), device=graph.device, dtype=graph.dtype) - torch.mm(torch.mm(D, graph), D) <span class="comment"># 度矩阵归一化</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            D = torch.diag(torch.<span class="built_in">sum</span>(graph, dim=-<span class="number">1</span>))</span><br><span class="line">            L = D - graph</span><br><span class="line">        <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>
<p>这里<code>torch.matmul()</code>的计算的规则可以参考以下的文章：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qsmx666/article/details/105783610">https://blog.csdn.net/qsmx666/article/details/105783610</a></p>
<p>对ChebNet网络进行训练可得，此处为了节省时间就训练10个回合：</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/chebnet_node_120.png" alt=""></p>
<p>这里可以看出chebNet对高频的特征也学习到很多的信息，高频的特性变好。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0000, Loss: 0.8416, Time: 0.39 mins</span><br><span class="line">Epoch: 0001, Loss: 0.0860, Time: 0.12 mins</span><br><span class="line">Epoch: 0002, Loss: 0.0649, Time: 0.12 mins</span><br><span class="line">Epoch: 0003, Loss: 0.0556, Time: 0.12 mins</span><br><span class="line">Epoch: 0004, Loss: 0.0518, Time: 0.12 mins</span><br><span class="line">Epoch: 0005, Loss: 0.0500, Time: 0.12 mins</span><br><span class="line">Epoch: 0006, Loss: 0.0489, Time: 0.12 mins</span><br><span class="line">Epoch: 0007, Loss: 0.0481, Time: 0.13 mins</span><br><span class="line">Epoch: 0008, Loss: 0.0474, Time: 0.15 mins</span><br><span class="line">Epoch: 0009, Loss: 0.0469, Time: 0.19 mins</span><br><span class="line">Test Loss: 0.0472</span><br><span class="line">Performance:  MAE 18.96    0.43%    28.40</span><br></pre></td></tr></table></figure>
<h4 id="GAT的搭建"><a href="#GAT的搭建" class="headerlink" title="GAT的搭建"></a><strong>GAT的搭建</strong></h4><p>最后我们尝试GAT模型，看其模型的预测效果。</p>
<p>首先实现的是Attention的layer。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraphAttentionLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, out_c</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GraphAttentionLayer, self).__init__()</span><br><span class="line">        self.in_c = in_c</span><br><span class="line">        self.out_c = out_c</span><br><span class="line"></span><br><span class="line">        self.F = F.softmax</span><br><span class="line"></span><br><span class="line">        self.W = nn.Linear(in_c, out_c, bias=<span class="literal">False</span>)  <span class="comment"># y = W * x</span></span><br><span class="line">        self.b = nn.Parameter(torch.Tensor(out_c))</span><br><span class="line"></span><br><span class="line">        nn.init.normal_(self.W.weight)</span><br><span class="line">        nn.init.normal_(self.b)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, graph</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param inputs: input features, [B, N, C].</span></span><br><span class="line"><span class="string">        :param graph: graph structure, [N, N].</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            output features, [B, N, D].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        h = self.W(inputs)  <span class="comment"># [B, N, D]</span></span><br><span class="line">        outputs = torch.bmm(h, h.transpose(<span class="number">1</span>, <span class="number">2</span>)) * graph.unsqueeze(<span class="number">0</span>)  <span class="comment"># [B, N, D]*[B, D, N]-&gt;[B, N, N]      x(i)^T * x(j)</span></span><br><span class="line"></span><br><span class="line">        outputs.data.masked_fill_(torch.eq(outputs, <span class="number">0</span>), -<span class="built_in">float</span>(<span class="number">1e16</span>))</span><br><span class="line"></span><br><span class="line">        attention = self.F(outputs, dim=<span class="number">2</span>)   <span class="comment"># [B, N, N]</span></span><br><span class="line">        <span class="keyword">return</span> torch.bmm(attention, h) + self.b  <span class="comment"># [B, N, N] * [B, N, D]</span></span><br></pre></td></tr></table></figure>
<p>下面实现的是子模块的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GATSubNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, hid_c, out_c, n_heads</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GATSubNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.attention_module = nn.ModuleList([GraphAttentionLayer(in_c, hid_c) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_heads)])</span><br><span class="line">        self.out_att = GraphAttentionLayer(hid_c * n_heads, out_c)</span><br><span class="line"></span><br><span class="line">        self.act = nn.LeakyReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, graph</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param inputs: [B, N, C]</span></span><br><span class="line"><span class="string">        :param graph: [N, N]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        outputs = torch.cat([attn(inputs, graph) <span class="keyword">for</span> attn <span class="keyword">in</span> self.attention_module], dim=-<span class="number">1</span>)  <span class="comment"># [B, N, hid_c * h_head]</span></span><br><span class="line">        outputs = self.act(outputs)</span><br><span class="line"></span><br><span class="line">        outputs = self.out_att(outputs, graph)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.act(outputs)</span><br></pre></td></tr></table></figure>
<p>GAT模型的搭建如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GATNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_c, hid_c, out_c, n_heads</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GATNet, self).__init__()</span><br><span class="line">        self.subnet = GATSubNet(in_c, hid_c, out_c, n_heads)</span><br><span class="line">        <span class="comment"># self.subnet = [GATSubNet(...) for _ in range(T)]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data, device</span>):</span></span><br><span class="line">        graph = data[<span class="string">&quot;graph&quot;</span>][<span class="number">0</span>].to(device)  <span class="comment"># [N, N]</span></span><br><span class="line">        flow = data[<span class="string">&quot;flow_x&quot;</span>]  <span class="comment"># [B, N, T, C]</span></span><br><span class="line">        flow = flow.to(device)</span><br><span class="line"></span><br><span class="line">        B, N = flow.size(<span class="number">0</span>), flow.size(<span class="number">1</span>)</span><br><span class="line">        flow = flow.view(B, N, -<span class="number">1</span>)  <span class="comment"># [B, N, T * C]</span></span><br><span class="line"></span><br><span class="line">        prediction = self.subnet(flow, graph).unsqueeze(<span class="number">2</span>)  <span class="comment"># [B, N, 1, C]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure>
<p>模型的训练测试效果如下，此处为了节省时间，就训练20个回合：</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/gat_node_120-16753072900321.png" alt=""></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0000, Loss: 0.5048, Time: 0.15 mins</span><br><span class="line">Epoch: 0001, Loss: 0.2916, Time: 0.09 mins</span><br><span class="line">Epoch: 0002, Loss: 0.2162, Time: 0.10 mins</span><br><span class="line">Epoch: 0003, Loss: 0.1865, Time: 0.10 mins</span><br><span class="line">Epoch: 0005, Loss: 0.1566, Time: 0.09 mins</span><br><span class="line">Epoch: 0006, Loss: 0.1468, Time: 0.09 mins</span><br><span class="line">Epoch: 0007, Loss: 0.1376, Time: 0.10 mins</span><br><span class="line">Epoch: 0008, Loss: 0.1258, Time: 0.10 mins</span><br><span class="line">Epoch: 0009, Loss: 0.1194, Time: 0.10 mins</span><br><span class="line">Test Loss: 0.1191</span><br><span class="line">Performance:  MAE 30.92    1.94%    44.89</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/GNN/image-20230202111003269.png" alt=""></p>
<p>有时间改进以下GAT，并且自己搭建以下DCRNN模型。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>GCN项目——交通流量预测</p><p><a href="http://example.com/2023/02/06/图神经网络/GCN项目——交通流量预测/">http://example.com/2023/02/06/图神经网络/GCN项目——交通流量预测/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>czt</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-02-06</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-02-06</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a><a class="link-muted mr-2" rel="tag" href="/tags/Graph/">Graph</a><a class="link-muted mr-2" rel="tag" href="/tags/Neural-Networks/">Neural Networks</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Swin-transformer%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Swin-transformer网络详解与Pytorch实现</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/02/06/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GCN%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB/"><span class="level-item">GCN项目——结点分类</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/hexoimg/202201222202112.jpg" alt="厚德载物"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">厚德载物</p><p class="is-size-6 is-block">实事求是，敢为人先</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 湖北 武汉</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">121</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">44</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://paperswithcode.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">paperwithcode</span></span><span class="level-right"><span class="level-item tag">paperswithcode.com</span></span></a></li><li><a class="level is-mobile" href="https://scholar.google.com.hk/?hl=zh-CN" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">google_scholar</span></span><span class="level-right"><span class="level-item tag">scholar.google.com.hk</span></span></a></li><li><a class="level is-mobile" href="https://arxiv.org/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">arxiv</span></span><span class="level-right"><span class="level-item tag">arxiv.org</span></span></a></li><li><a class="level is-mobile" href="https://leetcode-cn.com/problemset/algorithms/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leetcode</span></span><span class="level-right"><span class="level-item tag">leetcode-cn.com</span></span></a></li><li><a class="level is-mobile" href="https://mathf.itewqq.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">mathf</span></span><span class="level-right"><span class="level-item tag">mathf.itewqq.cn</span></span></a></li><li><a class="level is-mobile" href="https://qwerty.kaiyi.cool/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">qwerty</span></span><span class="level-right"><span class="level-item tag">qwerty.kaiyi.cool</span></span></a></li><li><a class="level is-mobile" href="https://www.overleaf.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">overleaf</span></span><span class="level-right"><span class="level-item tag">www.overleaf.com</span></span></a></li><li><a class="level is-mobile" href="http://www.pipioj.online/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">pipioj</span></span><span class="level-right"><span class="level-item tag">www.pipioj.online</span></span></a></li><li><a class="level is-mobile" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">hugocvofczt</span></span><span class="level-right"><span class="level-item tag">monumental-tarsier-a544f3.netlify.app</span></span></a></li><li><a class="level is-mobile" href="https://app.netlify.com/sites/monumental-tarsier-a544f3/overview" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">netlify</span></span><span class="level-right"><span class="level-item tag">app.netlify.com</span></span></a></li><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">四月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">一月 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">十二月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">八月 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">七月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">三月 2022</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">二月 2022</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">一月 2022</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ANSYS/"><span class="tag">ANSYS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-learning/"><span class="tag">Deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion-Modal/"><span class="tag">Diffusion Modal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Finite-Element-Analysis/"><span class="tag">Finite Element Analysis</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%E5%AE%9E%E6%88%98/"><span class="tag">GAN实战</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-Adversarial-Networks/"><span class="tag">Generative Adversarial Networks</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-model/"><span class="tag">Generative model</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IEEE%E6%8A%95%E7%A8%BF/"><span class="tag">IEEE投稿</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-learning/"><span class="tag">Machine learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Networks/"><span class="tag">Neural Networks</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SLAM/"><span class="tag">SLAM</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Typora/"><span class="tag">Typora</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/auto-encoder/"><span class="tag">auto-encoder</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/c/"><span class="tag">c++</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/control-theory/"><span class="tag">control theory</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/latex/"><span class="tag">latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/object-detection/"><span class="tag">object detection</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/opencv/"><span class="tag">opencv</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/point-cloud/"><span class="tag">point cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transformer/"><span class="tag">transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"><span class="tag">图像分类</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tag">图神经网络</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="tag">控制理论</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"><span class="tag">无监督学习</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90/"><span class="tag">有限元分析</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"><span class="tag">机械振动</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"><span class="tag">生成模型</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="tag">目标检测</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94/"><span class="tag">科研</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><span class="tag">自注意力机制</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"><span class="tag">论文写作</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"><span class="tag">语义分割</span><span class="tag">6</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#数据集可视化"><span class="level-left"><span class="level-item">1</span><span class="level-item">数据集可视化</span></span></a></li><li><a class="level is-mobile" href="#数据集的构建"><span class="level-left"><span class="level-item">2</span><span class="level-item">数据集的构建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#首先是构建邻接矩阵的函数："><span class="level-left"><span class="level-item">2.1</span><span class="level-item">首先是构建邻接矩阵的函数：</span></span></a></li><li><a class="level is-mobile" href="#读取车流数据"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">读取车流数据</span></span></a></li><li><a class="level is-mobile" href="#构建数据集的类"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">构建数据集的类</span></span></a></li><li><a class="level is-mobile" href="#几个静态函数的介绍"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">几个静态函数的介绍</span></span></a></li><li><a class="level is-mobile" href="#测试数据集"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">测试数据集</span></span></a></li></ul></li><li><a class="level is-mobile" href="#模型搭建和训练测试"><span class="level-left"><span class="level-item">3</span><span class="level-item">模型搭建和训练测试</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#导入相关包"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">导入相关包</span></span></a></li><li><a class="level is-mobile" href="#搭建整体的框架"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">搭建整体的框架</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#整体框架"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">整体框架</span></span></a></li><li><a class="level is-mobile" href="#模型评估"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">模型评估</span></span></a></li><li><a class="level is-mobile" href="#可视化"><span class="level-left"><span class="level-item">3.2.3</span><span class="level-item">可视化</span></span></a></li></ul></li><li><a class="level is-mobile" href="#模型的构建"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">模型的构建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#BaseLine模型"><span class="level-left"><span class="level-item">3.3.1</span><span class="level-item">BaseLine模型</span></span></a></li><li><a class="level is-mobile" href="#GCN的搭建"><span class="level-left"><span class="level-item">3.3.2</span><span class="level-item">GCN的搭建</span></span></a></li><li><a class="level is-mobile" href="#ChebNet的搭建"><span class="level-left"><span class="level-item">3.3.3</span><span class="level-item">ChebNet的搭建</span></span></a></li><li><a class="level is-mobile" href="#GAT的搭建"><span class="level-left"><span class="level-item">3.3.4</span><span class="level-item">GAT的搭建</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#小结"><span class="level-left"><span class="level-item">4</span><span class="level-item">小结</span></span></a></li></ul></div></div><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Diffusion/"><span class="level-start"><span class="level-item">Diffusion</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Finite-Element-Analysis/"><span class="level-start"><span class="level-item">Finite Element Analysis</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Generative-Adversarial-Networks/"><span class="level-start"><span class="level-item">Generative Adversarial Networks</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Latex/"><span class="level-start"><span class="level-item">Latex</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Point-Cloud/"><span class="level-start"><span class="level-item">Point Cloud</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"><span class="level-start"><span class="level-item">PyTorch教程与源码讲解</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/SLAM/"><span class="level-start"><span class="level-item">SLAM</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/Typora/"><span class="level-start"><span class="level-item">Typora</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/auto-encoder/"><span class="level-start"><span class="level-item">auto-encoder</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/opencv/"><span class="level-start"><span class="level-item">opencv</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">图像分类网络及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">图神经网络</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"><span class="level-start"><span class="level-item">振动力学</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/"><span class="level-start"><span class="level-item">机器学习基石</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="level-start"><span class="level-item">现代控制理论</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Epytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">目标检测与pytorch实现</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">科研入门笔记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/"><span class="level-start"><span class="level-item">自注意力机制和Transformer</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">语义分割及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">高级机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2023/04/03/Diffusion/%E5%88%9D%E5%A7%8BDiffusion-Model/"><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/diffusion/GANs_Diffusion_Autoencoders.png" alt="初始Diffusion Model"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-04-03T07:51:54.000Z">2023-04-03</time></p><p class="title"><a href="/2023/04/03/Diffusion/%E5%88%9D%E5%A7%8BDiffusion-Model/">初始Diffusion Model</a></p><p class="categories"><a href="/categories/Diffusion/">Diffusion</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CPytorch%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="循环神经网络Pytorch代码实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:49:02.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CPytorch%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">循环神经网络Pytorch代码实现</a></p><p class="categories"><a href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">高级机器学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="循环神经网络基本理论"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:48:46.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/">循环神经网络基本理论</a></p><p class="categories"><a href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">高级机器学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/RepVGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="RepVGG网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:35:27.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/RepVGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">RepVGG网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/MoVIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="MoVIT网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-02-06T03:35:07.000Z">2023-02-06</time></p><p class="title"><a href="/2023/02/06/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/MoVIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">MoVIT网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 czt</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>