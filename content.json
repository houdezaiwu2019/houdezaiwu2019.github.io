{"pages":[],"posts":[{"title":"Typora入门","text":"本文主要从目录设置、标题设置、特殊的标记符号、导入公式和列表以及图片图床的设置与排版来进行整理。 目录篇代码：[TOC] 标题篇对于Typora来说，主要分为快捷键方法和一般的直接写代码的方法，这里我比较推荐的还是直接写代码的方法，但是新手入门还是比较推荐先使用快捷键来进行入门。 标题的代码：==#+空格+内容== 这里有几个#就是几级标题 123# 一级标题## 二级标题### 三级标题 标题的快捷键：Ctrl+(数字) Ctrl+0 &lt;=&gt; 一般段落 Ctrl+1 &lt;=&gt; 一级标题 Ctrl+2 &lt;=&gt; 二级标题 连续两次Ctrl+同一个数字：取消标题操作 Ctrl+ +/-：代表标题的升级和降级 标记符号篇标记符号这里主要讲的是加粗、斜体、下滑线、高亮和内置公式与代码。 加粗：快捷键==Ctrl+B==，代码**text** 斜体：快捷键==Ctrl+I==，代码*text* 下滑线：快捷键==Ctrl+U==，代码**&lt;u&gt;text&lt;/u&gt;** 高亮：代码==text== 内置代码：快捷键==Ctrl+Shift+`==，代码`` 代码块：快捷键==Ctrl+Shift+K==， 代码: “```”+语言(c++/python/java) “```” 内置公式：代码\\aplha，这里使用的是latex代码进行标记的。 公式块：快捷键==Ctrl+Shift+M==，代码$$$ $$$ 1234$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}引用：快捷键==Ctrl+Shift+Q，代码&gt;+空格+text 书籍是人类进步的阶梯。——高尔基 超级链接：代码[blibli](https://www.bilibili.com) [text](#name) eg1. blibli 的链接 eg2.目录 的链接 脚注：代码text[^name],之后在后面[^name]:text 1,这里添加成功后，后面会出现回车 ↩符号。 上标：代码X^2 下标：代码H~2~o 注意这里需要的一些额外的设置： 列表篇有序列表：快捷键==Ctrl+Shift+[==，代码1.+空格+text 无序列表：快捷键==Ctrl+Shift+]==，代码-+空格+text 注意：无序列表如果想切换到下一级时可以直接按==tab== 表格：快捷键==Ctrl+T==，之后弹出对话框，自己来选择需要的行数和列数。 今天 明天 早饭 午饭 晚饭 上述表格的源代码： 12345| | 今天 | 明天 || :--: | :--- | :--: || 早饭 | | || 午饭 | | || 晚饭 | | | 这里还是用快捷键吧，使用代码太麻烦了。 图片篇本地路径导入图片 一般来说，图片使用的是绝对路径，如下图所示为直接截图并粘贴等到的图片的路径。但这种语言不是md的语言。 &lt;img src=&quot;C:\\Users\\dell\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220118215115730.png&quot; alt=&quot;image-20220118215115730&quot; style=&quot;zoom:50%;&quot; /&gt;。 这里的路径是Typora自行生成的，但实际输入的时候要输入代码![]()。 也可以用相对路径，代码是![](./+name.png/jpg) ./代表的是当前的文件夹。 ../代表的是上一级文件夹。 ![](./pic01.png) 对于.md来说，保存图片一般使用的是保存图片的链接，这样可以减小文件的空间（相比Word）。但这样会造成修改了文件或者图片的路径以及清除的C盘的缓存文件时会造成无法显示的问题。 利用图床导入图片这里有个比较矛盾的问题，使用GitHub的图床的话会造成国内没有VPN的用户无法访问，但是使用一般的七牛云的话要花钱，因此再三考虑我们使用码云gitee来作图床（弊端是图片的大小不能超过1M）。 将插入图片的无任何操作-&gt;上传图片 根据picgo的位置来配置路径。并且这里还要下载一个node.js，下载过程这里省略。 到picgo中下载gitee的插件，这里我们使用的是第三个，当然其他的两个也是可以的，但以下将围绕第三个gitee-uploader来配置。 在gitee里面创建仓库，注意创建时一定要点击初始化，只有这样才可以上传图片。如果没有点，那么创建好仓库时也可以点初始化。 要生成一个token，打开gitee的设置，点击生成令牌。点击设置-&gt;安全设置-&gt;私人令牌 设置权限，起个名字点击生成。注意令牌只弹出一次，最好找个记事本记录下来，防止自己忘记。 配置picgo，打开图床设置-&gt;gitee。 注意，这里自己仓库命名repo格式：用户名/仓库名。 但是之前遇到了问题，上传的图片在本地无法显示，其中的原因是gitee设置的是私有的，可以在仓库的管理界面更改。 github的操作同上，但是2022年3月26日，gitee单方面禁用了图床功能。 Typora图片排版这里图片排版需要我们掌握一点点HTML(Hyper Text Markup Language)的语法知识。 图注 12345678# 这里为上面图片的HTML代码&lt;center&gt; &lt;img src='https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; // 这里&lt;br&gt;的意思是回车，如果没有br会和图片是并排的 图注&lt;/center&gt; 因此，要实现下面两个图片并排的效果，就可以直接将图片的放一起即可，如果实现连个图片的上下排列，这是需要在之间加一个&lt;br&gt;即可 这里的&lt;center&gt;是默认图片居中的意思。导入图片默认的情况就是都是居中的，如果要改成左对齐则将&lt;center&gt;--&gt;&gt;&lt;left&gt;即可实现，同理右对齐就用&lt;right&gt;。 图 晚安 123456789&lt;center&gt; &lt;img src='https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;img src='https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; 图 晚安 &lt;img src=&quot;http://latex.codecogs.com/gif.latex? a^2&quot;&gt;&lt;/center&gt; 这里使用的是latex代码的形式来显示图注，虽然不是很好看，但是只是可以显示。","link":"/2022/01/21/Typora%E5%85%A5%E9%97%A8/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/01/18/hello-world/"},{"title":"Auto-Encoder (2021)","text":"hljs.initHighlightingOnLoad(); 本文主要从auto-encoder的Basic Idea of Auto-encoder、Feature Disentanglement、Discrete Latent Representation以及More Applications四个方面进行叙述。这里主要参考的时李宏毅2021年的新课。这里auto-encoder和 CycleGAN 和transformers机制有一定的相似之处，后续还要深入了解。 Self supervised Learning Framework 自监督学习：使用大量的资料，进行不用标注的学习任务，主要有填空题和预测下一句话。 将自监督模型做一点调整，用在下游的任务里。 BERT和GPT是主流的自监督学习的框架，但是之前的Auto-Encoder其实也可以算作是自监督学习的一种(因为其可以不要label)。 Basic Idea of Auto-encoder Auto-encoder的思想和Cycle GAN相当的类似，就是将输入的图片进行两次转换得到解码后的图片和原来的图片之间的差距越小越好。 中间编码的向量可以见Embedding、也可以叫Representation或者叫Code。 下游任务：将图片压缩后进行相关的处理。如More Dimension Reduction 技术上可以使用Auto-encoder。 为什么使用Auto-encoder这里举了神雕侠侣的例子，就是想说明3x3的图片其实受到图片自身的限制，内部是由一定规律的，可以将其进行压缩。抑或是武器是受到手臂活动范围的约束，不可能变化很多。 由于图片的自身的约束，可以简化为低维的状态。 auto-encoder is not a new ideas.assets/image-20220209095443614.png) 之前训练是使用受限玻尔兹曼机RBM来训练深度模型。 主要是利用RBM将每一层都训练好，之后拼接起来进行微调，继而完成深度模型的预训练。 但是2012年，Hinton发表文章，说明其实RBM技术没有太大的必要，于是进年来没有人再去使用RBM了。 De-noising Auto encoder 通过encoder和decoder来去掉噪声。 BERT模型其实思想上和De-noising Auto encoder相似。 Feature DisentanglementRepresentation includes information of different aspects 但是，这些信息是纠缠在一个向量里面的，我们不知道那些维里包含有上述信息的主要内容。 Feature Disentanglement：训练出来的auto-encoder,可以将信息按照维度进行分类，不同的维度代表则不同的信息。 主要的应用是 Application: Voice Conversion 之前是需要成对的声音讯号，就是让两个人读相同的句子(监督学习)。 现在A和B不需要将同样的句子和语言，就可以实现声音的转换。 提取出我自己的内容讯号和新垣结衣的声音讯号，结合起来完成Voice Conversion。 Discrete Latent RepresentationDiscrete Representation one-hot可以实现手写数据集Mnist 的分类，一共10维，每一维代表的是一维数据的。 Codebook里面是一系列的向量，Codebook里的系列也是NN从字典（大量训练集）中学到的。 得出的code vector 和Codebook里面的所有向量进行相似度的计算，取相似度最高的向量，进行decoder。 decoder的输入必须是Codebook里面的向量，这样来来实现离散化。 这里相似度的计算和attention机制相似。 在语音上面，codebook可以学习到最基本的发音。 Text as Representation将Embedding变成一段文字，这样一段文字有可能就成为文章摘要。 encoder和decoder要是transformer机制。 但是，实际train以后，encoder生成的code是人看不懂的，但是decoder就可以看懂。 因此，要增加一个判别器，来判别是不是人话。 主要的思想几就是CycleGAN的思想。 Tree as Embedding More ApplicationsGenerator With some modification, we have variational auto encoder (VAE). 这里在得到encoder的同时，也收获到一个生成器模型(decoder)。 Compression 做图片压缩，但是会有一定得失真。 Anomaly Detection(异常检测机制) 就是给了一些列的训练资料 ${x^1, x^2,x^3,\\cdots,x^N}$。 检测输入的$x$，是否和训练数据相类似。 相似的内涵是训练数据来定的。 信用卡消费检测 Fraud DetectionTraining data: credit card transactions, 𝑥: fraud or notRef: https://www.kaggle.com/ntnu-testimon/paysim1/homeRef: https://www.kaggle.com/mlg-ulb/creditcardfraud/home 网络的侵入检测 Network Intrusion DetectionTraining data: connection, 𝑥: attack or notRef: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 癌症检测 Cancer DetectionTraining data: normal cells, 𝑥: cancer or notRef: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/home 异常检测的难点在于异常的资料相当少，因此不能看作二元分类器，相当于使用一元数据进行分类。 对于相似的数据，decoder可以顺利的还原图片数据。 对于异常的图片，decoder就很难还原，因为训练的时候根本没见过这样的情况，通过这种机制来实现检测。 根据重构的误差的损失来看是否异常。 More about Anomaly DetectionPart 1: https://youtu.be/gDp2LXGnVLQPart 2: https://youtu.be/cYrNjLxkoXsPart 3: https://youtu.be/ueDlm2FkCnwPart 4: https://youtu.be/XwkHOUPbc0QPart 5: https://youtu.be/Fh1xFBktRLQPart 6: https://youtu.be/LmFWzmn2rFYPart 7: https://youtu.be/6W8FqUGYyDo","link":"/2022/02/09/Auto-encoder/Auto-encoder-2021/"},{"title":"Deep Auto-Encoder基本理论","text":"hljs.initHighlightingOnLoad(); 本文主要从PCA进行进行类比得出auto-encoder，通过增加深度来提高auto-encoder的特性，以及其在文字处理、预训练参数和图片相似度比较上的应用。 Auto-encoder 编码器：将图片的信息压缩称为一个code，代表原图的一个精简的表示。 解码器：根据code来将原来的图片进行重构。 单个encoder，只有input没有output，是没有办法学习的。 因此实际了一个解码器来得到输出。 然后将encoder和decoder连接到一起，一起来学习。 Starting from PCA $W$为变换矩阵，PCA一种Linear method。 目标是使得输出的重构图片和输入的原图片之间的差距越小越好。 可以将$W$看成是一个encoder，将$W^T$看成是一个decoder，中间的code相当于是一个hidden layer。 encoder可以是一个NN，因此可以增加中间的层数。 Deep Auto-encoder 之前，Deep Auto-encoder很难训练，需要RBM进行layer的初始化才能训练的好一点。 Symmetric is not necessary，就是可以将encoder和decoder对应起来训练，但是这样其实是不必要的，直接训练两个NN即可。 相比PCA来说，通过增加深度可以很好的提高结果的清晰度。 下图为一个效果上的对比，将数据降维成2维 PCA得出的code很难讲这个数据的特征提取出来。 Deep Auto-encoder则可以明显的将这几个特征分开。 Text Retrieval(文字处理) Vector Space Model：将文章编码成高维的向量，对比cos上的相似度。 Bag-of-word：通过0和1的形式，来完成句子的取词和构建。还有一种是用[0,1]来表示重要性。但是无法学习到单词的语义。 通过deep auto-encoder学到的文档的信息有清晰的分类。 LSA则很难将不同的文档中的特征进行区分。 Auto-encoder-similar Image Search 将图片之间直接计算相似度，得出的结果和预期相差较大。 因此使用自编码器将每张图片进行编码，直接对编码计算相似度如图所示。 Auto-encoder - Pre-training DNN使用auto-encoder进行神经网络的初始化操作。 先用auto-encoder进行预训练，这里如左图所示，先将784维转换1000维再784维，看训练的重构的情况。(将低位转换成为高维需要很强的正则化[如L1使得但部分为0只有个别几维不为0]，否则会出现一个分块的单位矩阵那样) W= \\begin{pmatrix} 1 & 0 & \\cdots & 0 & 0 & \\cdots & 0 \\\\ 0 & 1 & \\cdots & 0 & 0 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 & 0 & \\cdots & 0 \\\\ 0 & 0 & \\cdots & 0 & 0 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 0 & 0 & \\cdots & 0 \\\\ \\end{pmatrix} 之后就将第1层进行固定，再次进行auto-encoder操作。 然后，重复上面的操作如图，再向下学习得到下一层。 最后一层直接随机初始化即可。 在大量数据进行训练的时候，上述的技术还是十分的重要的。 其他类型的auto-encoder 加入噪声后的auto-encoder，decode是跟原来没有噪声的数据进行对比的，不是最原始的结果。 Auto-encoder for CNN 目标是相同的，减小解码前和重构以后的差别。 相比于编码器的卷积和池化操作，解码器的操作为反卷积和反池化。 CNN-Unpooling Maxpooling是将一个kernel里去最大的一个。 Unpooling是保留原来卷积的位置信息，其他地方用0来补齐。但是keras是直接将值复制四份。 CNN-Deconvolution其实，deconvolution也是一种卷积。 一般的卷积是将多个值变为一个值，反卷积是将一个值通过乘以不同的权重变成多个值。 反卷积也可以等价为多个值转换为一个值，其实是等价的。 NEXT 将编码值进行解码，即可以得出如图二维code的分布，没有分布点的的地方解码以后的结果不是很好，有点分布的地方可以看到大概的数字。 通过二维的分布来判断那边是有值存在的，那边取样才可能出现结果。 在code上面加L2的正则化，保证在0的附近都是有值的。","link":"/2022/02/08/Auto-encoder/Deep-Auto-encoder%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/"},{"title":"Auto-Encoder的补充内容","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是auto-encoder的补充内容，包括除了重构误差以外评估编码器效果的判别器模型，以及离散化表示学习的方法来进行嵌入。 More than minimizing reconstruction error 什么是好的embedding，好的embedding可以很好的表示其编码的对象的主要特征（如五等分花嫁中三玖的特点是带耳机）。 除了Reconstruction，如何评估encoder的效果？(下图为 一个编码的例子) 使用一个判别器discriminator——binary classifer 如果编码正确输出1，错误输出0。此时分类器可以很容易判断输出编码的争取与否，即编码具有很强的代表性。 如果编码不具有代表性，分类器很难判断正确和错误，此时编码器的代表很差。 于是，训练的目标函数变成最小化$\\theta$ 使得损失函数$L_D^*$最小。 \\begin{align} \\theta^*&=arg\\ \\min_\\limits{\\theta} \\ L_D^*\\\\ &=arg\\ \\min_\\limits{\\theta}\\ \\min_\\limits{\\phi}L_D^*\\\\ \\end{align}Train the encoder 𝜃and discriminator 𝜙 to minimize $L_D^*$ $\\Rightarrow$ (c.f. training encoder and decodert o minimize reconstruction error) 经典的auto-encoder形式其实是一个特例。 一般的设计如下图所示： 训练的时候给定图片和编码向量，输出的为重构的误差，这里没有了positive example和negative example的影响，只是positive example的score(重构的错误率)越小越好。 More interpretable embeddingDiscrete Representation一般方法 要得到的编码是一个一维向量，每个向量都有很好的可解释性。 non differentiable : https://arxiv.org/pdf/1611.01144.pdf 处理不能微分的论文。 Binary vector相比one hot 更好，因为其参数相对更少，而且可以产生训练参数里没有的东西（泛化性能更强）。 Vector Quantized Variational Auto encoder (VQVAE) Codebook里面是一系列的向量，Codebook里的系列也是NN学习出来的。 得出的code vector 和Codebook里面的所有向量进行相似度的计算，取相似度最高的向量，进行decoder。(通过这样来实现离散化) 离散化的作用是保留声音里文字的部分，过滤掉背景噪声的因素。","link":"/2022/02/08/Auto-encoder/Auto-encoder%E7%9A%84%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9/"},{"title":"Variational Autoencoder(2013)","text":"hljs.initHighlightingOnLoad(); 关于生成模型的综述： https://openai.com/blog/generative-models/ 相比PixelRNN(2016)和Generative Adversarial Network(2014)， VAE其实是最旧的模型。 本文主要介绍VAE的一些理论和直观和正式的解释以及一些问题和局限。 Basic introduction 但是实际使用的过程中，auto-encoder的效果并不是很好。 VAE的encoder生成的是两个向量，然后让其中一个和一组正态分布的向量做内积，然后和另一组相加之后作为编码进行decoder。 损失函数也不仅仅是直接使用最小化reconstruction error，而是增加了一个损失项 -\\sum_{i=1}^{3}(\\exp(\\sigma_i)-(1+\\sigma_i)+m_i^2) 在生成的结果上也是比较一般的。 这里主要做的是将VAE训练好之后，使用将decoder单独提取出来，然后将code的10-dim中去固定8个，将剩下的两个进行测试看其可以生成什么样的图片。 通过分析上述的结果来发觉每个维度的代表的大概含义。 Why VAE为什么使用VAE？ 直观解释 VAE增加了噪声项，这样的话我们在一定的范围内等可以得出满月和新月的图片； 而且VAE生成新的code的过程效果比传统地AE要好。 这里面几个参数地含义： $\\sigma_i$ ：代表主要地噪声项，表示造成的方差大小，这里加一个$\\exp()$的作用是保证输出一定要为正的，因为只有为正才可以保证其可以作为方差variance来参与计算。 $e_i$：代表了方差的放大倍数，是随机产生的数。如果没有$e_i$的话，那么方差都是由encoder自己来决定，encoder可能会自己直接将其train为0，这样的话就和AE是一样的了。因此要保证$e_i$不为0. Loss function：要加入限制$\\sigma_i$为0的项，因为如果这样就是成为一个AE了，所以就有了上面的第二损失函数。 如图可得，绿线在最低点的时候，此时的$\\sigma_i=1$，防止其为0。 第二项为正则化项。 正规解释就是生成一些数据点来估计概率分布。 这里用高斯混合模型来解释 GMN Gaussian Mixture Model. 如何从高斯分部中进行取样： 首先，从一个简单随机分布中进行取样，来判断是从那个高斯分布中取样。$m \\sim P(m)$ 之后，选择第一次得到的m，从第m个Gaussian Model 中取样。 $x|m \\sim N(\\mu^m,\\sum^m)$ 这样相当于有无穷个Gaussian 同时，在这个分布中有每一个z都会对应一个Gaussian分布。 p(x)=\\int_zP(z)p(x|z)\\ dz 其实 $z$ 这个分布可以是任何分布，不一定非要是高斯。但是NN的逼近能力很强，因此其实不用太在意z的分布。 模型估计——MAE 我们极大似然主要是用来估计$\\mu(z),\\sigma(z)$的表达式。通过极大似然来调节NN的参数。 我们还需要另一个分布$q(z|x)$，其可以是任何的分布。 这一步主要是用来凑KL散度的，KL div主要是来计算两个分布的距离，即相似程度。 因此问题转换为找一项$q(z|x) \\rightarrow P(z|x)$； 如果直接调$P(x|z)$ 会使$L,L_b,KL$ 三个同时变化，不太好控制，因此但是$q(z|x)$是和$L$无关的，仅仅影响散度和 lower bound. $L_b$ 上升，也就会驱使L的上升，从而达到最大化L的目的。同时也得到$P(x|z)$的一个估计值。 注意这里的$q(z|x)$是一个NN，因此极大似然就是调整NN参数，使其接近$P(z)$ ，著其实就是与AE的不要不同之处。 因此就变成从$z \\sim q(z|x)$ 得到z，之后利用这个z去产生x，使得期望越大越好，$x \\sim P(x|z)$ 。 这里就是让$\\mu(x)\\rightarrow x$ 其实就是AE。 条件VAE，链接：https://arxiv.org/pdf/1406_5298v2.pdf Problems of VAEVAE其实就是努力进行逼近和相似，并没有很强的生成新的能力。 仅仅是在模仿，没有生成创新能力，生成新的模型要看GAN。","link":"/2022/03/21/Auto-encoder/Variational-Autoencoder-2013/"},{"title":"Condition_WGAN_GP的搭建","text":"hljs.initHighlightingOnLoad(); 这个模型和ACGAN有相似之处，都增加了标签的embedding层，用来辅助训练。这样可以实现训练的结果和原来标签实现一一对应。 本文主要是在WGAN-GP的基础上修改，主要增加了和label与embedding相关的参数，并修改了模型。但是训练的效果不是很满意，收敛的速度不如WGAN-GP。 模型搭建 在模型搭建上，该模型主要增加了label的embedding层，并将embedding层和原来的输入层进行堆叠。 判别器 增加了embedding层： 增加了与labels和embedding层相关的参数： 前向传播函数增加了embedding的内容： 完整代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Discriminator(nn.Module): def __init__(self, channel_img, features_d, num_classes, img_size): super(Discriminator, self).__init__() self.img_size = img_size self.disc = nn.Sequential( # Input: N x channels_img x 64 x 64 nn.Conv2d( in_channels=channel_img+1, # 由于增加了一个编码层 因此要加1 out_channels=features_d, kernel_size=4, stride=2, padding=1 ), # 32 x 32 nn.LeakyReLU(0.2), self._block(features_d, features_d * 2, 4, 2, 1), # 16 x 16 self._block(features_d * 2, features_d * 4, 4, 2, 1), # 8 x 8 self._block(features_d * 4, features_d * 8, 4, 2, 1), # 4 x 4 nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0), # 1x1 nn.Sigmoid(), ) # 增加一个编码器 将一个label编码为一个图片 self.embed = nn.Embedding( num_embeddings=num_classes, embedding_dim=img_size*img_size ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.LeakyReLU(0.2), nn.BatchNorm2d(out_channels), ) def forward(self, x, labels): # label -&gt; [batch_size, 1] -&gt; N x 1 embedding = self.embed(labels).view([labels.shape[0], 1, self.img_size, self.img_size]) # embedding -&gt; N x 1 x img_size(64) x img_size x = torch.cat([x, embedding], dim=1) # x -&gt; N x channel_img x img_size(64) x img_size # dim=1 代表在第二维上进行堆叠 就是在channel上堆叠 return self.disc(x) 生成器 embed_size：编码器将num_classes维转换为embed_size。 新增embedding层： 修改前向传播函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Generator(nn.Module): def __init__(self, z_dim, channels_img, features_g, num_classes, img_size, embed_size): # z_dim 生成噪声的维度 # channels_img 图片的维度 super(Generator, self).__init__() self.img_size = img_size self.gen = nn.Sequential( # Input: N x (z_dim + embed_size) x 1 x 1 self._block(z_dim + embed_size, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4 self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8 self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16 self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32 nn.ConvTranspose2d( features_g*2, channels_img, kernel_size=4, stride=2, padding=1 ), # 64 x 64 nn.Tanh(), # [-1, 1] # 由于mnist数据集的特点，我们输入标准化后的数据是[-1,1] # 最后的输出要在[-1,1]之间 ) # 编码的维度要跟噪声的维度相同 self.embed = nn.Embedding(num_embeddings=num_classes, embedding_dim=embed_size) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.ConvTranspose2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.BatchNorm2d(out_channels), nn.ReLU(), ) def forward(self, x, labels): embedding = self.embed(labels).unsqueeze(2).unsqueeze(3) # unsqueeze()的作用是增加维度，这里增加了第3，4维 # embedding -&gt; N x embed_size x 1 x 1 # x -&gt; N x z_dim x 1 x 1 x = torch.cat([x, embedding], dim=1) return self.gen(x) 梯度惩罚项增加了和label相关的参数即可。 12345678910111213141516171819202122def gradient_penalty(critic, real, labels, fake, device=&quot;cpu&quot;): batch_size, channels, H, W = real.shape epsilon = torch.rand((batch_size, 1, 1, 1)).repeat(1, channels, H, W).to(device) interpolated_images = real * epsilon + fake * (1 - epsilon) # 计算判别器输出 mix_scores = critic(interpolated_images, labels) # 求导 gradient = torch.autograd.grad( inputs=interpolated_images, outputs=mix_scores, grad_outputs=torch.ones_like(mix_scores), create_graph=True, retain_graph=True, )[0] gradient = gradient.view(gradient.shape[0], -1) gradient_norm = gradient.norm(2, dim=1) # 求2-范数 gradient_penalty_value = torch.mean((gradient_norm - 1) ** 2) return gradient_penalty_value 参数设置123# 新增编码参数num_classes = 10gen_embedding = 100 其他参数和原来相似，完整代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Hyperparameters etc (超参数)device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;lr = 5e-5# 也可以使用两组学习率，一个是生成器的、一个是判别器的。z_dim = 64# 同样的可以尝试 128, 256image_size = 64# gan对于超参数相当的敏感，# 换一个其他的参数可能就not work了batch_size = 64num_epoch = 3channels_img = 1features_disc = 64features_gen = 64# WGAN特有的参数critic_iteration = 5# weight_clip = 0.01LAMBEDA_GP = 10# 新增编码参数num_classes = 10gen_embedding = 100transforms = transforms.Compose([ transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize( [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)] ) # 自适应我们的通道数，几个通道都为0.5 # transforms.Normalize((0.1307,), (0.3081,)) # 参数谷歌的参数，计算mnist的偏差值 # 但是这组参数可能会导致不收敛，因此我们换用原来的参数])dataset = datasets.MNIST(root=&quot;./dataset&quot;, transform=transforms, download=True)loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)disc_critic = Discriminator(channels_img, features_disc, num_classes, image_size).to(device)gen = Generator(z_dim, channels_img, features_gen, num_classes, image_size, gen_embedding).to(device)# 初始化模型initialize_weights(disc_critic)initialize_weights(gen)# 设置优化器opt_disc = optim.Adam(disc_critic.parameters(), lr=lr, betas=(0.0, 0.9))opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.0, 0.9))fixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)# 损失函数# criterion = nn.BCELoss()# Binary Cross Entropywriter_fake = SummaryWriter(f&quot;runs/CWGAN_MNIST/fake&quot;)writer_real = SummaryWriter(f&quot;runs/CWGAN_MNIST/real&quot;) 模型训练 主要的变化是在增加了和label相关的参数，其他部分不变。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778step = 0gen.train()disc_critic.train()# trainfor epoch in range(num_epoch): for batch_idx, (real, labels) in enumerate(loader): real = real.to(device) labels = labels.to(device) # 将图片后两维展平 第一维为batch_size # batch_size = real.shape[0] for _ in range(critic_iteration): # ------------------------------------------------------------ # Train Discriminator: # max {log(D(real)) + log(1 - D(G(Z))} # 等价于 min{-log(D(real)) - log(1 - D(G(Z))} noise = torch.randn((batch_size, z_dim, 1, 1)).to(device) fake = gen(noise, labels) # G(z) critic_real = disc_critic(real, labels).reshape(-1) critic_fake = disc_critic(fake, labels).reshape(-1) gp = gradient_penalty(disc_critic, real, labels, fake, device=device) # 这里自定义了损失函数 # (f-GAN论文讲了，其实损失函数的设置对结果的影响不大) loss_critic = ( -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBEDA_GP*gp ) # 初始化梯度 disc_critic.zero_grad() # 反向传播 loss_critic.backward(retain_graph=True) # 优化器优化 opt_disc.step() # ------------------------------------------------------------ # Train Generator # min log(1 - D(G(z)) -&gt; min -log(D(G(z)) # -&gt; max D(G(z)) # 开始的时候会因为梯度饱和训练不动 # 因此换了损失函数 # 我们在训练生成器时还想用之前判别器的梯度和参数 # 这里有两种办法 # lossD.backward(retain_grap=True) # disc_fake = disc(fake.detach()).view(-1) output = disc_critic(fake, labels).reshape(-1) # 由于上面retain_graph=True, 因此相当于此时的判别器时固定的 loss_gen = - torch.mean(output) gen.zero_grad() loss_gen.backward() opt_gen.step() if batch_idx % 100 == 0: print( f&quot;Epoch [{epoch}/{num_epoch}] Batch {batch_idx}/{len(loader)} &quot; f&quot;loss_critic: {loss_critic:.4f}, loss_gen: {loss_gen:.4f}&quot; ) gen.eval() disc_critic.eval() with torch.no_grad(): fake = gen(noise, labels) # 每次测试的噪声是不变的，都是将一组固定的噪声转换的fake 假的图片 img_grid_fake = torchvision.utils.make_grid( fake, normalize=True) img_grid_real = torchvision.utils.make_grid( real, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist real Images&quot;, img_grid_real, global_step=step ) step = step + 1 gen.train() disc_critic.train()","link":"/2022/02/12/Generative%20Adversarial%20Networks/Condition-WGAN-GP%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"DCGAN 的搭建","text":"hljs.initHighlightingOnLoad(); 本文主要根据视频教程来搭建的一个卷积对抗网路DCGAN模型，相比之前的网络是将线性层换成卷积层和反卷积层，数据集只要需用的是Mnist手写数据集，主要从模型搭建、参数设置和模型训练三个方面进行讲解。 原论文要点 为了保证网络的稳定性，DCGAN去掉了最大池化层和平均池化层。 再判别器和生成器中使用了BatchNorm。 去掉的全连接隐藏层。 在生成器中使用ReLU激活函数，除了最后一个输出层。 在判别器中使用LeakyReLU激活函数。 导入相关包12345678import torchimport torch.nn as nnimport torch.optim as optimimport torchvisionimport torchvision.datasets as datasetsfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterimport torchvision.transforms as transforms 模型搭建判别器1234567891011121314151617181920212223242526272829303132333435363738class Discriminator(nn.Module): def __init__(self, channel_img, features_d): super(Discriminator, self).__init__() self.disc = nn.Sequential( # Input: N x channels_img x 64 x 64 nn.Conv2d( in_channels=channel_img, out_channels=features_d, kernel_size=4, stride=2, padding=1 ), # 32 x 32 nn.LeakyReLU(0.2), self._block(features_d, features_d * 2, 4, 2, 1), # 16 x 16 self._block(features_d * 2, features_d * 4, 4, 2, 1), # 8 x 8 self._block(features_d * 4, features_d * 8, 4, 2, 1), # 4 x 4 nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0), # 1x1 nn.Sigmoid(), ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.LeakyReLU(0.2), nn.BatchNorm2d(out_channels), ) def forward(self, x): return self.disc(x) 主要的区别是将线性连接换成了卷积，其他不变。 生成器123456789101112131415161718192021222324252627282930313233343536class Generator(nn.Module): def __init__(self, z_dim, channels_img, features_g): # z_dim 生成噪声的维度 # channels_img 图片的维度 super(Generator, self).__init__() self.gen = nn.Sequential( # Input: N x z_dim x 1 x 1 self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4 self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8 self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16 self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32 nn.ConvTranspose2d( features_g*2, channels_img, kernel_size=4, stride=2, padding=1 ), # 64 x 64 nn.Tanh(), # [-1, 1] # 由于mnist数据集的特点，我们输入标准化后的数据是[-1,1] # 最后的输出要在[-1,1]之间 ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.ConvTranspose2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.BatchNorm2d(out_channels), nn.ReLU(), ) def forward(self, x): return self.gen(x) 这里生成器主要使用的是反卷积操作。 初始化和测试1234567891011121314151617181920def initialize_weights(model): for m in model.modules(): if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)): nn.init.normal_(m.weight.data, mean=0.0, std=.02)def test(): N, in_channels, H, W = 8, 3, 64, 64 z_dim = 100 x = torch.randn((N, in_channels, H, W)) disc = Discriminator(in_channels, 8) initialize_weights(disc) tmp = disc(x).shape == (N, 1, 1, 1) assert tmp gen = Generator(z_dim, in_channels, 8) z = torch.randn((N, z_dim, 1, 1)) tmp = gen(z).shape == (N, in_channels, H, W) assert tmp print(&quot;Success&quot;) 参数设置超参数设计1234567891011121314# Hyperparameters etc (超参数)device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;lr = 2e-4# 3e-4 是对于Adam 来说最好的学习率z_dim = 64# 同样的可以尝试 128, 256image_size = 64# gan对于超参数相当的敏感，# 换一个其他的参数可能就not work了batch_size = 128num_epoch = 50channels_img = 1features_disc = 64features_gen = 64 features_disc、features_gen分别为判别器和生成器卷积层中的特征通道数。 channels_img = 1数据的通道数。 数据初始化123456789101112131415161718transforms = transforms.Compose([ transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize( [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)] ) # 自适应我们的通道数，几个通道都为0.5 # transforms.Normalize((0.1307,), (0.3081,)) # 参数谷歌的参数，计算mnist的偏差值 # 但是这组参数可能会导致不收敛，因此我们换用原来的参数])dataset = datasets.MNIST(root=&quot;./dataset&quot;, transform=transforms, download=True)loader = DataLoader(dataset, batch_size=batch_size, shuffle=True) 初始化模型123disc = Discriminator(channels_img, features_disc).to(device)gen = Generator(z_dim, channels_img, features_gen).to(device)fixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device) 损失函数与与优化器的初始化123456789# 设置优化器opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))# 可以考虑设置betas=的参数opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))fixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)# 损失函数criterion = nn.BCELoss() 模型训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869writer_fake = SummaryWriter(f&quot;runs/DCGAN_MNIST/fake&quot;)writer_real = SummaryWriter(f&quot;runs/DCGAN_MNIST/real&quot;)step = 0# trainfor epoch in range(num_epoch): for batch_idx, (real, _) in enumerate(loader): real = real.to(device) # 将图片后两维展平 第一维为batch_size batch_size = real.shape[0] # ------------------------------------------------------------ # Train Discriminator: # max {log(D(real)) + log(1 - D(G(Z))} # 等价于 min{-log(D(real)) - log(1 - D(G(Z))} noise = torch.randn((batch_size, z_dim, 1, 1)).to(device) fake = gen(noise) # G(z) disc_real = disc(real).reshape(-1) # view()也可以 lossD_real = criterion(disc_real, torch.ones_like(disc_real)) disc_fake = disc(fake).reshape(-1) # view()也可以 lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) lossD = (lossD_fake + lossD_real) / 2 # 初始化梯度 disc.zero_grad() # 反向传播 lossD.backward(retain_graph=True) # 优化器优化 opt_disc.step() # ------------------------------------------------------------ # Train Generator # min log(1 - D(G(z)) -&gt; min -log(D(G(z)) # -&gt; max D(G(z)) # 开始的时候会因为梯度饱和训练不动 # 因此换了损失函数 # 我们在训练生成器时还想用之前判别器的梯度和参数 # 这里有两种办法 # lossD.backward(retain_grap=True) # disc_fake = disc(fake.detach()).view(-1) output = disc(fake).view(-1) # 由于上面retain_graph=True, 因此相当于此时的判别器时固定的 lossG = criterion(output, torch.ones_like(output)) gen.zero_grad() lossG.backward() opt_gen.step() if batch_idx % 100 == 0: print( f&quot;Epoch [{epoch}/{num_epoch}] Batch {batch_idx}/{len(loader)}\\ &quot; f&quot;Loss D: {lossD:.4f}, Loss G: {lossG:.4f}&quot; ) with torch.no_grad(): fake = gen(fixed_noise) # 每次测试的噪声是不变的，都是将一组固定的噪声转换的fake 假的图片 img_grid_fake = torchvision.utils.make_grid( fake, normalize=True) img_grid_real = torchvision.utils.make_grid( real, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist real Images&quot;, img_grid_real, global_step=step ) step = step + 1 这里主要和Simple GAN的区别是，数据的维度上的处理，之前是将图片展成一组向量，而且batch_size也有一定的改变。","link":"/2022/02/11/Generative%20Adversarial%20Networks/DCGAN-%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"Simple NN-GAN的搭建","text":"hljs.initHighlightingOnLoad(); 本文主要根据视频教程来搭建的一个只有线性层的简单神经网络，数据集只要需用的是Mnist手写数据集，主要从模型搭建、参数设置和模型训练三个方面进行讲解。 导入相关包12345678import torchimport torch.nn as nnimport torch.optim as optimimport torchvisionimport torchvision.datasets as datasetsfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterimport torchvision.transforms as transforms 模型搭建判别器12345678910111213141516class Discriminator(nn.Module): def __init__(self, img_dim): super().__init__() self.disc = nn.Sequential( nn.Linear(in_features=img_dim, out_features=128), nn.LeakyReLU(0.1), # 在GAN里面LeakyReLU的效果比ReLU好 nn.Linear(128, 1), nn.Sigmoid(), # 因为输出是0和1的布尔值 # 因此这里的激活函数选用Sigmoid ) def forward(self, x): return self.disc(x) 这里使用的是最简单的现象模型来搭建的，基本的框架就是这样。 在GAN里面激活函数LeakyReLU的效果比ReLU好。 因为输出是0和1的布尔值， 因此这里的激活函数选用Sigmoid。 生成器1234567891011121314151617class Generator(nn.Module): def __init__(self, z_dim, img_dim): # z_dim 生成噪声的维度 # img_dim 图片的维度 super().__init__() self.gen = nn.Sequential( nn.Linear(z_dim, 256), nn.LeakyReLU(0.1), nn.Linear(256, img_dim), # 28x28x1 -&gt; 784 nn.Tanh() # 由于mnist数据集的特点，我们输入标准化后的数据是[-1,1] # 最后的输出要在[-1,1]之间 ) def forward(self, x): return self.gen(x) 参数设置超参数设计1234567891011121314151617181920# Hyperparameters etc (超参数)device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;lr = 3e-4# lr=1e-4# 3e-4 是对于Adam 来说最好的学习率z_dim = 64# 同样的可以尝试 128, 256image_dim = 28 * 28 * 1 # 784# gan对于超参数相当的敏感，# 换一个其他的参数可能就not work了batch_size = 32num_epoch = 50transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) # transforms.Normalize((0.1307,), (0.3081,)) # 参数谷歌的参数，计算mnist的偏差值 # 但是这组参数可能会导致不收敛，因此我们换用原来的参数]) 超参数里最基本有敏感度的是学习率，lr=3e-4 是对于Adam 来说最好的学习率，有时候也会用lr=1e-4。 其次就是标准化参数的影响是最大的。 然后再考虑生成噪声数据的维度、每一批次的数据量batch_size(根据自己的内存来考虑，量力而行) 最后考虑总的循环数，一般是迭代次数越多越好。 实例化模型123disc = Discriminator(image_dim).to(device)gen = Generator(z_dim, image_dim).to(device)fixed_noise = torch.randn((batch_size, z_dim)).to(device) 数据预处理、损失函数和优化器123456789101112131415161718dataset = datasets.MNIST(root=&quot;/dataset&quot;, transform=transforms, download=True)loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)# 设置优化器opt_disc = optim.Adam(disc.parameters(), lr=lr)# 可以考虑设置betas=的参数opt_gen = optim.Adam(gen.parameters(), lr=lr)# 损失函数criterion = nn.BCELoss()# Binary Cross Entropywriter_fake = SummaryWriter(f&quot;runs/GAN_MNIST/fake&quot;)writer_real = SummaryWriter(f&quot;runs/GAN_MNIST/real&quot;) GAN的优化器选择的是带有动量的Adam优化器。 损失函数选择的是二元交叉熵函数。 Parameters weight (Tensor, optional) – a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size nbatch.权重参数。 size_average (bool, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string**, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' 模型训练1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465step = 0# trainfor epoch in range(num_epoch): for batch_idx, (real, _) in enumerate(loader): real = real.view(-1, 784).to(device) # 将图片后两维展平 第一维为batch_size batch_size = real.shape[0] # ------------------------------------------------------------ # Train Discriminator: # max {log(D(real)) + log(1 - D(G(Z))} # 等价于 min{-log(D(real)) - log(1 - D(G(Z))} noise = torch.randn(batch_size, z_dim).to(device) fake = gen(noise) # G(z) disc_real = disc(real).view(-1) lossD_real = criterion(disc_real, torch.ones_like(disc_real)) disc_fake = disc(fake).view(-1) lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) lossD = (lossD_fake + lossD_real) / 2 # 初始化梯度 disc.zero_grad() # 反向传播 lossD.backward(retain_graph=True) # 优化器优化 opt_disc.step() # ------------------------------------------------------------ # Train Generator # min log(1 - D(G(z)) -&gt; min -log(D(G(z)) # -&gt; max log(D(G(z)) # 开始的时候会因为梯度饱和训练不动 # 因此换了损失函数 # 我们在训练生成器时还想用之前判别器的梯度和参数 # 这里有两种办法 # lossD.backward(retain_grap=True) # disc_fake = disc(fake.detach()).view(-1) output = disc(fake).view(-1) # 由于上面retain_graph=True, 因此相当于此时的判别器时固定的 lossG = criterion(output, torch.ones_like(output)) gen.zero_grad() lossG.backward() opt_gen.step() if batch_idx == 0: print( f&quot;Epoch [{epoch}/{num_epoch}] \\ &quot; f&quot;Loss D: {lossD:.4f} ,Loss G: {lossG:.4f}&quot; ) with torch.no_grad(): fake = gen(fixed_noise).reshape(-1, 1, 28, 28) data = real.reshape(-1, 1, 28, 28) img_grid_fake = torchvision.utils.make_grid( fake, normalize=True) img_grid_real = torchvision.utils.make_grid( data, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist real Images&quot;, img_grid_real, global_step=step ) step = step + 1 对于判别器来说，其目标函数为： \\max \\{\\log(D(x_{real})) + \\log(1-D(G(z))\\}\\\\ \\Leftrightarrow \\min \\{ -\\log(D(x_{real})) - \\log(1-D(G(z))\\} 这里我们选择的损失函数是BCLoss： L(x,y) = -[y\\log(x) + (1-y)\\log(1-x)]\\\\ L(x,y)= \\begin{cases} -\\log(x), & if\\quad y=1 \\\\ -\\log(1-x), & if\\quad y=0 \\end{cases}因此这里选择torch.ones_like()和torch.zeros_like()来作为y参数。 对于生成器来说，其目标函数为： \\min \\log(1-D(G(z)))由于训练开始时的梯度较小，可能会导致生成器训练不动，生成器过早收敛。于是将目标函数转换为： \\min -\\log(D(G(z))) 同时生成器中的D时固定的，利用的是上一轮中D的参数，因此这里要将其固定： 12345# 方法1:保持动态图不变lossD.backward(retain_grap=True)# 方法2:保持计算出来的fake&lt;-&gt;G(z)保留fake = gen(noise)disc_fake = disc(fake.detach()).view(-1) detach()返回一个新的tensor，是从当前计算图中分离下来的，但是仍指向原变量的存放位置，其grad_fn=None且requires_grad=False，得到的这个tensor永远不需要计算其梯度，不具有梯度grad，即使之后重新将它的requires_grad置为true,它也不会具有梯度grad。 注意：返回的tensor和原始的tensor共享同一内存数据。in-place函数修改会在两个tensor上同时体现(因为它们共享内存数据)，此时当要对其调用backward()时可能会导致错误。 测试是将生成器作用到一个固定的噪声数据中。 1fake = gen(fixed_noise).reshape(-1, 1, 28, 28) 这里是将数据拼接成为网格形状 1img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)","link":"/2022/02/11/Generative%20Adversarial%20Networks/Simple-NN-GAN%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"WGAN的搭建","text":"hljs.initHighlightingOnLoad(); 本文主要介绍了WGAN的理论和pytorch实现，主要的相比之前DCGAN修改了模型搭建部分的激活函数、新加入了一些超参数、去掉了原来的损失函数并在模型训练中定义了损失函数。 WGAN理论简介这里有时间去复习李宏毅的WGAN相关理论，这里直接从代码部分讲起。 参考公式如图所示： 学习率$\\alpha$=5e-5, 截断系数c=0.01, 每一批的数据batch_size=64, 以及每个循环里生成器训练一次对应的判别器训练的次数$n_{critic} = 5$ 这里的 $\\theta$ 代表生成器的参数，$\\omega$ 代表判别器的参数。循环结束的条件是生成器的参数 $\\theta$ 是否收敛。 为了保证数学上的具有$1-Lipschitz$ 连续性(保证函数是光滑的)， 于是增加了截断误差，就是将判别器的参数 $\\omega$ 裁剪到一个小的范围之内，[-0.01, 0.01]。 优化器使用的是RMSProp优化器，替代了原来的Adma优化器。 模型搭建模型的结构是基本不变的，判别器的最后一层去掉了Sigmoid()函数。 其他的地方均和DCGAN相同。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import torchimport torch.nn as nnclass Discriminator(nn.Module): def __init__(self, channel_img, features_d): super(Discriminator, self).__init__() self.disc = nn.Sequential( # Input: N x channels_img x 64 x 64 nn.Conv2d( in_channels=channel_img, out_channels=features_d, kernel_size=4, stride=2, padding=1 ), # 32 x 32 nn.LeakyReLU(0.2), self._block(features_d, features_d * 2, 4, 2, 1), # 16 x 16 self._block(features_d * 2, features_d * 4, 4, 2, 1), # 8 x 8 self._block(features_d * 4, features_d * 8, 4, 2, 1), # 4 x 4 nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0), # 1x1 # nn.Sigmoid(), 判别器取消了Sigmoid() ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.LeakyReLU(0.2), nn.BatchNorm2d(out_channels), ) def forward(self, x): return self.disc(x)class Generator(nn.Module): def __init__(self, z_dim, channels_img, features_g): # z_dim 生成噪声的维度 # channels_img 图片的维度 super(Generator, self).__init__() self.gen = nn.Sequential( # Input: N x z_dim x 1 x 1 self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4 self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8 self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16 self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32 nn.ConvTranspose2d( features_g*2, channels_img, kernel_size=4, stride=2, padding=1 ), # 64 x 64 nn.Tanh(), # [-1, 1] # 由于mnist数据集的特点，我们输入标准化后的数据是[-1,1] # 最后的输出要在[-1,1]之间 ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.ConvTranspose2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.BatchNorm2d(out_channels), nn.ReLU(), ) def forward(self, x): return self.gen(x)def initialize_weights(model): for m in model.modules(): if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)): nn.init.normal_(m.weight.data, mean=0.0, std=.02) 参数设置超参数的设置这里参数选择参考理论简介部分。以下为具体的代码： 1234567891011121314151617# Hyperparameters etc (超参数)device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;lr = 5e-5# 也可以使用两组学习率，一个是生成器的、一个是判别器的。z_dim = 64# 同样的可以尝试 128, 256image_size = 64# gan对于超参数相当的敏感，# 换一个其他的参数可能就not work了batch_size = 64num_epoch = 6channels_img = 1features_disc = 64features_gen = 64# WGAN特有的参数critic_iteration = 5weight_clip = 0.05 优化器和损失函数的设置注意WGAN的损失函数都是自己写的，因此不设置损失函数了。 123456789101112# 设置优化器opt_disc = optim.RMSprop(disc_critic.parameters(), lr=lr)opt_gen = optim.RMSprop(gen.parameters(), lr=lr)fixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)# 损失函数# criterion = nn.BCELoss()# Binary Cross Entropywriter_fake = SummaryWriter(f&quot;runs/WGAN_MNIST/fake&quot;)writer_real = SummaryWriter(f&quot;runs/WGAN_MNIST/real&quot;) 模型初始化和数据预处理这边也保持不变。 12345678910111213141516171819202122232425transforms = transforms.Compose([ transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize( [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)] ) # 自适应我们的通道数，几个通道都为0.5 # transforms.Normalize((0.1307,), (0.3081,)) # 参数谷歌的参数，计算mnist的偏差值 # 但是这组参数可能会导致不收敛，因此我们换用原来的参数])dataset = datasets.MNIST(root=&quot;./dataset&quot;, transform=transforms, download=True)loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)disc_critic = Discriminator(channels_img, features_disc).to(device)gen = Generator(z_dim, channels_img, features_gen).to(device)# 初始化模型initialize_weights(disc_critic)initialize_weights(gen) 模型训练 这边也不变，注意这里有BN层，需要加model.train() 函数。 损失函数： 判别器： g_{w} \\leftarrow \\nabla_{w}\\left[\\frac{1}{m} \\sum_{i=1}^{m} f_{w}\\left(x^{(i)}\\right)-\\frac{1}{m} \\sum_{i=1}^{m} f_{w}\\left(g_{\\theta}\\left(z^{(i)}\\right)\\right)\\right]\\\\ w \\leftarrow w+\\alpha \\cdot \\mathrm{RMSProp}\\left(w, g_{w}\\right)​ 生成器： g_{\\theta} \\leftarrow \\nabla_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} f_{w}\\left(g_{\\theta}\\left(z^{(i)}\\right)\\right)12345678noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)fake = gen(noise) # G(z)critic_real = disc_critic(real).reshape(-1)critic_fake = disc_critic(fake).reshape(-1)# 这里自定义了损失函数# (f-GAN论文讲了，其实损失函数的设置对结果的影响不大)loss_critic = - (torch.mean(critic_real) - torch.mean(critic_fake))# - 负号为了保证最小化 这里损失函数为判别器计算出来的数值取平均，即可。 训练的顺序是每次先训练$n_{critic}$次判别器，之后再训练1次生成器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778step = 0gen.train()disc_critic.train()# trainfor epoch in range(num_epoch): for batch_idx, (real, _) in enumerate(loader): real = real.to(device) # 将图片后两维展平 第一维为batch_size # batch_size = real.shape[0] for _ in range(critic_iteration): # ------------------------------------------------------------ # Train Discriminator: # max {log(D(real)) + log(1 - D(G(Z))} # 等价于 min{-log(D(real)) - log(1 - D(G(Z))} noise = torch.randn((batch_size, z_dim, 1, 1)).to(device) fake = gen(noise) # G(z) critic_real = disc_critic(real).reshape(-1) critic_fake = disc_critic(fake).reshape(-1) # 这里自定义了损失函数 # (f-GAN论文讲了，其实损失函数的设置对结果的影响不大) loss_critic = - (torch.mean(critic_real) - torch.mean(critic_fake)) # - 负号为了保证最小化 # 初始化梯度 disc_critic.zero_grad() # 反向传播 loss_critic.backward(retain_graph=True) # 优化器优化 opt_disc.step() # 参数进行截断 for p in disc_critic.parameters(): p.data.clamp_(-weight_clip, weight_clip) # ------------------------------------------------------------ # Train Generator # min log(1 - D(G(z)) -&gt; min -log(D(G(z)) # -&gt; max D(G(z)) # 开始的时候会因为梯度饱和训练不动 # 因此换了损失函数 # 我们在训练生成器时还想用之前判别器的梯度和参数 # 这里有两种办法 # lossD.backward(retain_grap=True) # disc_fake = disc(fake.detach()).view(-1) output = disc_critic(fake).reshape(-1) # 由于上面retain_graph=True, 因此相当于此时的判别器时固定的 loss_gen = - torch.mean(output) gen.zero_grad() loss_gen.backward() opt_gen.step() if batch_idx % 100 == 0: print( f&quot;Epoch [{epoch}/{num_epoch}] Batch {batch_idx}/{len(loader)} &quot; f&quot;loss_critic: {loss_critic:.4f}, loss_gen: {loss_gen:.4f}&quot; ) gen.eval() disc_critic.eval() with torch.no_grad(): fake = gen(noise) # 每次测试的噪声是不变的，都是将一组固定的噪声转换的fake 假的图片 img_grid_fake = torchvision.utils.make_grid( fake, normalize=True) img_grid_real = torchvision.utils.make_grid( real, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist real Images&quot;, img_grid_real, global_step=step ) step = step + 1 gen.train() disc_critic.train() 总结： 其实WGAN的效果在一般的Mnist数据集上的效果不是很好，因此尽管数学上的效果很好，但是试验证实的效果还是不理想。","link":"/2022/02/12/Generative%20Adversarial%20Networks/WGAN%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"WGAN-GP的搭建","text":"hljs.initHighlightingOnLoad(); 本文主要介绍了WGAN-GP的理论和pytorch实现，主要的相比之前WGAN修改了生成器的归一化层、新加入了一些超参数、增加了新的计算梯度惩罚项的函数、去掉了原来的损失函数并在模型训练中定义了新的损失函数。 WGAN-GP理论简介WGAN-GP是WGAN的改进版，因为截断操作一方面浪费时间，其次效果实在一般，还不如DCGAN，因此这里带有梯度惩罚项的函数来进行优化操作。 这里的主要参数如下： $\\lambda=10$ 是惩罚项的系数，其代表的是梯度惩罚项前面的权重。 $\\alpha=1e-4$ 是学习率，$\\beta_1=0 \\ ,\\beta_2=0.9$ 是Adam优化器的动量参数。 每个循环里生成器训练一次对应的判别器训练的次数$n_{critic} = 5$ $\\hat{\\boldsymbol{x}} \\leftarrow \\epsilon \\boldsymbol{x}+(1-\\epsilon) \\tilde{\\boldsymbol{x}}$ 代表的是计算真实图片和生成图片的加权值。 $\\lambda\\left(\\left|\\nabla_{\\hat{\\boldsymbol{x}}} D_{w}(\\hat{\\boldsymbol{x}})\\right|_{2}-1\\right)^{2}$ 之后将加权值求范数，如果范数值为1，则此时满足$1-Lipschitz$ 稳定性。否则，作为惩罚项加入到损失函数中。 生长器也是使用Adam优化器，其他的地方不变。 模型搭建生成器和判别器这里使用的是将生成器的BatchNorm2d换成了InstanceNorm2d，关于InstanceNorm2d的参考CSDN博文 。 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import torchimport torch.nn as nnclass Discriminator(nn.Module): def __init__(self, channel_img, features_d): super(Discriminator, self).__init__() self.disc = nn.Sequential( # Input: N x channels_img x 64 x 64 nn.Conv2d( in_channels=channel_img, out_channels=features_d, kernel_size=4, stride=2, padding=1 ), # 32 x 32 nn.LeakyReLU(0.2), self._block(features_d, features_d * 2, 4, 2, 1), # 16 x 16 self._block(features_d * 2, features_d * 4, 4, 2, 1), # 8 x 8 self._block(features_d * 4, features_d * 8, 4, 2, 1), # 4 x 4 nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0), # 1x1 # nn.Sigmoid(), 判别器取消了Sigmoid() ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), # 整理修改为InstanceNorm2d # LayerNorm &lt;-&gt; InstanceNorm nn.InstanceNorm2d(out_channels, affine=True), nn.LeakyReLU(0.2), ) def forward(self, x): return self.disc(x)class Generator(nn.Module): def __init__(self, z_dim, channels_img, features_g): # z_dim 生成噪声的维度 # channels_img 图片的维度 super(Generator, self).__init__() self.gen = nn.Sequential( # Input: N x z_dim x 1 x 1 self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4 self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8 self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16 self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32 nn.ConvTranspose2d( features_g*2, channels_img, kernel_size=4, stride=2, padding=1 ), # 64 x 64 nn.Tanh(), # [-1, 1] # 由于mnist数据集的特点，我们输入标准化后的数据是[-1,1] # 最后的输出要在[-1,1]之间 ) def _block(self, in_channels, out_channels, kernel_size, stride, padding): return nn.Sequential( nn.ConvTranspose2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False ), nn.BatchNorm2d(out_channels), nn.ReLU(), ) def forward(self, x): return self.gen(x)def initialize_weights(model): for m in model.modules(): if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)): nn.init.normal_(m.weight.data, mean=0.0, std=.02) 梯度惩罚项函数为了求梯度惩罚，这里增加了求梯度惩罚项的函数如下： 1234567891011121314151617181920212223242526import torchimport torch.nndef gradient_penalty(critic, real, fake, device=&quot;cpu&quot;): batch_size, channels, H, W = real.shape epsilon = torch.rand((batch_size, 1, 1, 1)).repeat(1, channels, H, W).to(device) interpolated_images = real * epsilon + fake * (1 - epsilon) # 计算判别器输出 mix_scores = critic(interpolated_images) # 求导 gradient = torch.autograd.grad( inputs=interpolated_images, outputs=mix_scores, grad_outputs=torch.ones_like(mix_scores), create_graph=True, retain_graph=True, )[0] gradient = gradient.view(gradient.shape[0], -1) gradient_norm = gradient.norm(2, dim=1) # 求2-范数 gradient_penalty_value = torch.mean((gradient_norm - 1) ** 2) return gradient_penalty_value 参数设计超参数的设计这里参数选择参考理论简介部分。以下为具体的代码： 123456789101112131415161718# Hyperparameters etc (超参数)device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;lr = 1e-4# 也可以使用两组学习率，一个是生成器的、一个是判别器的。z_dim = 64# 同样的可以尝试 128, 256image_size = 64# gan对于超参数相当的敏感，# 换一个其他的参数可能就not work了batch_size = 64num_epoch = 6channels_img = 1features_disc = 64features_gen = 64# WGAN特有的参数critic_iteration = 5# weight_clip = 0.01LAMBEDA_GP = 10 优化器和损失函数的设置注意WGAN的损失函数都是自己写的，因此不设置损失函数了。 123456789101112# 设置优化器opt_disc = optim.RMSprop(disc_critic.parameters(), lr=lr)opt_gen = optim.RMSprop(gen.parameters(), lr=lr)fixed_noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)# 损失函数# criterion = nn.BCELoss()# Binary Cross Entropywriter_fake = SummaryWriter(f&quot;runs/WGAN_MNIST/fake&quot;)writer_real = SummaryWriter(f&quot;runs/WGAN_MNIST/real&quot;) 模型初始化和数据预处理这边也保持不变。 12345678910111213141516171819202122232425transforms = transforms.Compose([ transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize( [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)] ) # 自适应我们的通道数，几个通道都为0.5 # transforms.Normalize((0.1307,), (0.3081,)) # 参数谷歌的参数，计算mnist的偏差值 # 但是这组参数可能会导致不收敛，因此我们换用原来的参数])dataset = datasets.MNIST(root=&quot;./dataset&quot;, transform=transforms, download=True)loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)disc_critic = Discriminator(channels_img, features_disc).to(device)gen = Generator(z_dim, channels_img, features_gen).to(device)# 初始化模型initialize_weights(disc_critic)initialize_weights(gen) 模型训练主要的修改是给生成器去掉的参数截断功能，损失函数加入了求梯度惩罚项的部分，具体原理参考理论简介。 损失函数： L^{(i)} \\leftarrow D_{w}(\\tilde{\\boldsymbol{x}})-D_{w}(\\boldsymbol{x})+\\lambda\\left(\\left\\|\\nabla_{\\hat{\\boldsymbol{x}}} D_{w}(\\hat{\\boldsymbol{x}})\\right\\|_{2}-1\\right)^{2}主要的代码如下： 12345678910noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)fake = gen(noise) # G(z)critic_real = disc_critic(real).reshape(-1)critic_fake = disc_critic(fake).reshape(-1)gp = gradient_penalty(disc_critic, real, fake, device=device)# 这里自定义了损失函数# (f-GAN论文讲了，其实损失函数的设置对结果的影响不大)loss_critic = ( -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBEDA_GP*gp) 完整代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677step = 0gen.train()disc_critic.train()# trainfor epoch in range(num_epoch): for batch_idx, (real, _) in enumerate(loader): real = real.to(device) # 将图片后两维展平 第一维为batch_size # batch_size = real.shape[0] for _ in range(critic_iteration): # ------------------------------------------------------------ # Train Discriminator: # max {log(D(real)) + log(1 - D(G(Z))} # 等价于 min{-log(D(real)) - log(1 - D(G(Z))} noise = torch.randn((batch_size, z_dim, 1, 1)).to(device) fake = gen(noise) # G(z) critic_real = disc_critic(real).reshape(-1) critic_fake = disc_critic(fake).reshape(-1) gp = gradient_penalty(disc_critic, real, fake, device=device) # 这里自定义了损失函数 # (f-GAN论文讲了，其实损失函数的设置对结果的影响不大) loss_critic = ( -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBEDA_GP*gp ) # 初始化梯度 disc_critic.zero_grad() # 反向传播 loss_critic.backward(retain_graph=True) # 优化器优化 opt_disc.step() # ------------------------------------------------------------ # Train Generator # min log(1 - D(G(z)) -&gt; min -log(D(G(z)) # -&gt; max D(G(z)) # 开始的时候会因为梯度饱和训练不动 # 因此换了损失函数 # 我们在训练生成器时还想用之前判别器的梯度和参数 # 这里有两种办法 # lossD.backward(retain_grap=True) # disc_fake = disc(fake.detach()).view(-1) output = disc_critic(fake).reshape(-1) # 由于上面retain_graph=True, 因此相当于此时的判别器时固定的 loss_gen = - torch.mean(output) gen.zero_grad() loss_gen.backward() opt_gen.step() if batch_idx % 100 == 0: print( f&quot;Epoch [{epoch}/{num_epoch}] Batch {batch_idx}/{len(loader)} &quot; f&quot;loss_critic: {loss_critic:.4f}, loss_gen: {loss_gen:.4f}&quot; ) gen.eval() disc_critic.eval() with torch.no_grad(): fake = gen(fixed_noise) # 每次测试的噪声是不变的，都是将一组固定的噪声转换的fake 假的图片 img_grid_fake = torchvision.utils.make_grid( fake, normalize=True) img_grid_real = torchvision.utils.make_grid( real, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist real Images&quot;, img_grid_real, global_step=step ) step = step + 1 gen.train() disc_critic.train() 相比WGAN，加入梯度惩罚项以后的效果还是比较好的。","link":"/2022/02/12/Generative%20Adversarial%20Networks/WGAN-GP%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"title":"Pix2pix GAN 论文及模型搭建","text":"hljs.initHighlightingOnLoad(); 论文：Image-to-Image Translation with Conditional Adversarial Networks论文链接：https://arxiv.org/abs/1611.07004代码链接：https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix 本文主要介绍的pix2pix，并且自己定义损失函数，生成器主要使用的是U-Net(主要做语义分割的网络) 。 原论文简介教程1 对于CGAN，是将条件信息进行如label进行embedding之后，一起加入到网络中进行识别生成的。整体的条件信息还可以直接是图片。 判别器要做两件事情： 生成的图片的真假问题，如果是从我们的数据集中得到的，就为真；如果是生成器生成的，就为假。 其次还要判断生成的图片和真实的条件信息是否对应。 这里的我们也可以不加噪声，直接输出条件信息(图片)。 这里是在编码的过程中加入了随机噪声，加强了我模型的稳定性。 基于auto-encoder的想法，我们定义了U-Net网络。 U-Net将encoder的过程加到了decoder的上面，实现了跳跃连接，这样的可训练性更好。 pix2pix最后要经过一个patchGAN，使得最后得输出为一个矩阵来判断真假。再与真实的网络进行一个L1loss函数，实现条件信息和真实信息的吻合。 教程2文章总述： pix2pix本质上是一个CGAN，其输入里有一张图片 (相比传统的CGAN的输入为一个label+embedding) ，而不是一般的噪声量。 这个网络里面没有损失函数，因为判别器网络其实学习到的就是一个损失函数。 由于一般的基于欧式距离的损失函数会造成平均值效应，使得我们生成的图片比较的模糊。于是我们用判别器来学习出一种损失函数来到达生成图片的高清的效果。 目标函数： CGAN的目标函数为： 这里判别函数的输入x——原图片，y——目标图片。 将该损失函数和没有非CGAN进行对比，结果为：CGAN的效果更好。 为了生成器的精度，要加入正则化项，由于L2正则化会造成平均值损失，于是我们使用L1正则化项。 L1 loss function 可以去除模糊，提高清晰度： 最后的损失函数为： 网络结构生成器结构 总体上，还是使用的是卷积网络，Convolution-BatchNorm-ReLU/LeakyReLU的形式。 生成器的网络的使用的是U-Net 这里可以看作是及是将我们Encoder通过跳跃连接实现encoder和decoder的堆叠。 判别器结构 这里的判别器使用的是PatchGAN。 如图patchGAN输入是一个NXN的块，输出是整个块的true or fake，最后取所以的patch块的输出的平均值即可。 这种方法的优点是：参数少，运行速度快；并且使用的图片可以是任意大的图片。 优化和推断 使用标准的优化方法，一次判别器，一次生成器。 对于生成器来说，我们不使(用一般的$\\min \\{\\log(1-D(G(x,z)))\\}$作为损失函数，我们使用$\\max \\{\\log(D(G(x,z))\\}$ 作为损失函数。 这里的优化器使用的是Adam优化器，参数$\\beta_1=0.5, \\beta_2=0.999$，学习率$\\alpha=0.0002=2e-4$. 评估指标这里使用了we run “real vs. fake” perceptual studies on Amazon Mechanical Turk(AMT) 给1秒的时间来看图片，来判断图片的真假。 选择patchGAN的尺寸这里我们选择1x1-&gt;pixelGAN，NxN(整张图片)-&gt;ImageGAN，介于之间的是patchGAN，论文中比较了不同的持尺寸对生成结果的影响。 16x16 有较高的FCN-scores 并且 可以生成 artifacts。 70x70的结果也很不错，也达到了上述的要求。 附录生成器的网络结构： 这里的Ck-&gt;Convolution-BatchNorm-ReLU（channels=k）， CDK-&gt;Convolution-BatchNorm-Dropout-ReLU（channels=k）。 这里的卷积核都是4x4，stride=2. 以下为U-Net的网络结构：(这里是没有跳跃连接的) 有跳跃连接的U-Net解码器： 生成器的最后使用的是Tanh激活函数。 判别器的网络结构 使用的是LeakyReLU(0.2)，最后一层使用的是Sigmoid函数。 第一个卷积上没有使用BatchNorm。 Keras实现简介 Pytorch实现模型搭建由于模型的工作量较大，因此我们这里采用的将模型，训练过程以及相关参数的配置分开写。 判别器的搭建1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import torchimport torch.nn as nnclass CNNBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=2): super(CNNBlock, self).__init__() self.conv = nn.Sequential( nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode=&quot;reflect&quot;), # padding_mode # 参考https://blog.csdn.net/weixin_42211626/article/details/122542323?utm_medium=distribute. # pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecp # m-4-122542323.pc_agg_new_rank&amp;utm_term=padding_mode&amp;spm=1000.2123.3001.4430 nn.BatchNorm2d(out_channels), # 由于BatchNorm2d的影响，造成我们的bias要设成False nn.LeakyReLU(0.2), ) def forward(self, x): return self.conv(x)# x, y &lt;- 将输入和输出图片堆叠在一起class Discriminator(nn.Module): def __init__(self, in_channels=3, features=[64, 128, 256, 512]): # 256-&gt; 26x26 286-&gt;30x30 最后输出的形状是和输入由有关的 super(Discriminator, self).__init__() self.initial = nn.Sequential( nn.Conv2d(in_channels*2, features[0], kernel_size=4, stride=2, padding=1, padding_mode=&quot;reflect&quot;), nn.LeakyReLU(0.2) ) layer = [] in_channels = features[0] for feature in features[1:]: layer.append( CNNBlock(in_channels, feature, # stride在最后一层为1，其他为2 stride=1 if feature == features[-1] else 2), ) in_channels = feature layer.append( nn.Conv2d( in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=&quot;reflect&quot; ), ) self.model = nn.Sequential(*layer) def forward(self, x, y): x = torch.cat([x, y], dim=1) x = self.initial(x) return self.model(x) 生成器的搭建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113import torchimport torch.nn as nnclass Block(nn.Module): def __init__(self, in_channels, out_channels, down=True, act=&quot;relu&quot;, use_dropout=False): super(Block, self).__init__() self.conv = nn.Sequential( # 分情况，看是上取样还是下取样 nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=&quot;reflect&quot;) if down else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU() if act==&quot;relu&quot; else nn.LeakyReLU(0.2), ) self.use_dropout = use_dropout self.dropout = nn.Dropout(0.5) def forward(self, x): x = self.conv(x) # dropout 主要在网络的上三层来使用 return self.dropout(x) if self.use_dropout else xclass Generator(nn.Module): def __init__(self, in_channels=3, features=64): super(Generator, self).__init__() # 256 self.initial_down = nn.Sequential( nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=&quot;reflect&quot;), nn.LeakyReLU(0.2), ) # 128 x 128 self.down1 = Block(features, features * 2, down=True, act=&quot;leaky&quot;, use_dropout=False) # 64 x 64 self.down2 = Block( features * 2, features * 4, down=True, act=&quot;leaky&quot;, use_dropout=False ) # 32 x 32 self.down3 = Block( features * 4, features * 8, down=True, act=&quot;leaky&quot;, use_dropout=False ) # 16 x 16 self.down4 = Block( features * 8, features * 8, down=True, act=&quot;leaky&quot;, use_dropout=False ) # 8 x 8 self.down5 = Block( features * 8, features * 8, down=True, act=&quot;leaky&quot;, use_dropout=False ) # 4 x 4 self.down6 = Block( features * 8, features * 8, down=True, act=&quot;leaky&quot;, use_dropout=False ) # 2 x 2 self.bottleneck = nn.Sequential( nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode=&quot;reflect&quot;), nn.ReLU(), ) # 1 x 1 self.up1 = Block( features * 8, features * 8, down=False, act=&quot;relu&quot;, use_dropout=True ) self.up2 = Block( features * 8 * 2, features * 8, down=False, act=&quot;relu&quot;, use_dropout=True ) self.up3 = Block( features * 8 * 2, features * 8, down=False, act=&quot;relu&quot;, use_dropout=True ) self.up4 = Block( features * 8 * 2, features * 8, down=False, act=&quot;relu&quot;, use_dropout=False ) self.up5 = Block( features * 8 * 2, features * 4, down=False, act=&quot;relu&quot;, use_dropout=False ) self.up6 = Block( features * 4 * 2, features * 2, down=False, act=&quot;relu&quot;, use_dropout=False ) self.up7 = Block(features * 2 * 2, features, down=False, act=&quot;relu&quot;, use_dropout=False) self.final_up = nn.Sequential( nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1), nn.Tanh(), # [-1, 1] ) def forward(self, x): d1 = self.initial_down(x) d2 = self.down1(d1) d3 = self.down2(d2) d4 = self.down3(d3) d5 = self.down4(d4) d6 = self.down5(d5) d7 = self.down6(d6) bottleneck = self.bottleneck(d7) up1 = self.up1(bottleneck) up2 = self.up2(torch.cat([up1, d7], 1)) up3 = self.up3(torch.cat([up2, d6], 1)) up4 = self.up4(torch.cat([up3, d5], 1)) up5 = self.up5(torch.cat([up4, d4], 1)) up6 = self.up6(torch.cat([up5, d3], 1)) up7 = self.up7(torch.cat([up6, d2], 1)) return self.final_up(torch.cat([up7, d1], 1))def test(): x = torch.randn((1, 3, 256, 256)) model = Generator(in_channels=3, features=64) print(model) preds = model(x) print(preds.shape)if __name__ == &quot;__main__&quot;: test() print(torch.__version__) 总结 Pix2pix是用作图像翻译的CGAN Pix2pix用比较深的网络，进行精密的调参产生了不错的结果 Pix2pix需要配对的标签图像和实际图像 pix2pix获得了比较良好的图像翻译的效果,但训练pix2pix需要一番工夫。","link":"/2022/02/24/Generative%20Adversarial%20Networks/pix2pix-GAN-%E8%AE%BA%E6%96%87%E5%8F%8A%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA/"},{"title":"Pytorch中常用的高级操作与搭建完整流程","text":"hljs.initHighlightingOnLoad(); 本文主要从模型的保存和修改、如何导入和加载现有的模型、如何使用GPU以及完整的训练和测试过程进行介绍，主要的视频教程 。 本教程以官方文档为主，这里关注最多的是图像，因此可以使用跟图像处理相关的包，打开torchvision的文档。 现有网络的使用和修改打开torchvision文档，选择model可以得出我们的一些常用的模型，如图所示。 主要的模型涉及了图像分类、目标检测、语义识别和视频处理。 这里以分类模型的VGG为例，数据集使用的时CFIAR10 如果pretained=true则使用的时预训练好的参数，为False则直接重新初始化参数来训练。 progress(bool)代表是否显示预训练模型下载的进度条。 1234567import torchvisiontrain_data = torchvision.datasets.ImageNet(&quot;./data_image_net&quot;, split='train', download=True)# ../ 表示上级目录下导入 ./ 表示当前的目录下导入&gt;&gt;&gt;RuntimeError: The dataset is no longer publicly accessible. You need to download the archives externally and place them in the root directory. 目前这个数据集不适合公开的被下载，要自己手动下载，导入到对于的目录下，但是TM 147G也太大了，所以入门还是找一些小一点的数据集吧。 现有模型的使用下载的时候默认会下载到我们C盘中C:\\Users\\dell/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth 123456789101112131415161718192021# 导入网络的模型vgg16_pretrain = vgg16(pretrained=True)# 有预训练权重的,会下载一会，528vgg16_normal = vgg16(pretrained=False)# 没有权重，仅模型本身print(vgg16_pretrain)&gt;&gt;&gt;VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ...... (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(7, 7)) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) ...... (6): Linear(in_features=4096, out_features=1000, bias=True) )) 现有模型的修改模型层数的增加add_module() 1234567891011121314151617181920212223# 模型层的增加print(vgg16_normal.classifier[6])# 直接在模型最后增加vgg16_normal.add_module('linear1', nn.Linear(1000, 10))# 加入到最后一个模型块中vgg16_normal.classifier.add_module('linear0', nn.Linear(1000, 10))print(vgg16_normal)&gt;&gt;&gt; ( ......(classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace=True) (2): Dropout(p=0.5, inplace=False) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace=True) (5): Dropout(p=0.5, inplace=False) (6): Linear(in_features=4096, out_features=1000, bias=True) (linear0): Linear(in_features=1000, out_features=10, bias=True) ) (linear1): Linear(in_features=1000, out_features=10, bias=True)) 模型的修改 12345# -----------------------------------------------# 模型的修改vgg16_normal.classifier[7] = nn.Linear(1000, 256)vgg16_normal.linear0 = nn.Linear(256, 10)print(vgg16_normal) 注意： 在 Sequential里的模型，索引都是按照0、1、2、… 的索引来选取的，因此金国最后一层的名字为linear0，但是要求改时还是用数值7来索引vgg16_normal.classifier[7] 其次如果vgg16_normal.linear0不存在时，就会在模型的最后重新建立一个vgg16_normal.linear0的层。 至于Sequential()的一些操作，后期可以参考李沐的课程。 模型的保存和模型的加载这里将展示两种模型的保存和加载的方式，一种将网络的参数和结构全部保存下来，另一种只是保存模型的参数（我感觉模型的参数占用的内存应该达到90%以上，只保存参数感觉不怎么节省空间其实，不知道为什么官方推荐。） 保存和加载方式112345678910111213141516171819202122# 保存方式1，模型结构+模型参数vgg16_1 = vgg16(pretrained=False)torch.save(vgg16_1, &quot;vgg16_method1.pth&quot;)# 对应方式1的加载model = torch.load(&quot;vgg16_method1.pth&quot;)print(model)&gt;&gt;&gt;VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ...... (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(7, 7)) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) ...... (6): Linear(in_features=4096, out_features=1000, bias=True) )) 因为模型和权重的数据都保存了，打印的时候只是打印模型的结构，而不打印权重数据。 注意： 对于方式1，如果模型是自己定义，那么torch.load()时，如果模型定义的文件不是同一个文件，那么会报错。 解决的办法就是将我们我们自定义的模型和torch.load()放在用一个文件(这样有点蠢)，或者就是将定义的模型文件from model import *进来即可。 保存和加载方式2123456789# 保存方式2，模型参数(官方推荐)vgg16_2 = vgg16(pretrained=False)torch.save(vgg16_2.state_dict(), &quot;vgg16_method2.pth&quot;)# 对应方式1的加载model = torch.load(&quot;vgg16-397923af.pth&quot;)print(model)model = torch.load(&quot;vgg16_method2.pth&quot;)print(model) 官方带有预训练参数的模型和这种方法一样，都是采用的是保存参数而不是保存模型结构的方式。 直接torch.load()的话结果，打印出来都是参数字典的形式。 12345678# 对应方式2的加载# 先初始化模型vgg16_3 = vgg16(pretrained=False)# 获取参数存储dictdict_para = torch.load(&quot;vgg16-397923af.pth&quot;)# 将字典参数导入模型vgg16_3.load_state_dict(dict_para)print(vgg16_3) 完整的训练套路导入数据集1234567891011121314151617181920212223from torchvision.transforms import transformsfrom torchvision.datasets import CIFAR10# 准备数据集train_data = CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=False)test_data = CIFAR10(root=&quot;./root&quot;, train=False, transform=transforms.ToTensor(), download=False)# length长度train_data_size = len(train_data)test_data_size = len(test_data)# 打印信息print(&quot;训练数据集长度为：{}&quot;.format(train_data_size))print(&quot;测试数据集长度为：{}&quot;.format(test_data_size))# 利用DataLoader来加载数据库集train_loader = DataLoader(train_data, batch_size=64)test_loader = DataLoader(test_data, batch_size=64) 搭建网络1234567891011121314151617181920212223242526272829from torch import nnimport torch# 搭建神经网络class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.models = nn.Sequential( nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(64*4*4, 64), nn.Linear(64, 10), ) def forward(self, x): return self.models(x)# 验证正确性if __name__ == '__main__': net = Net() inputs = torch.ones((64, 3, 32, 32)) outputs = net(inputs) print(outputs.shape) 在train.py中导入网络，创建网络模型： 123from model import Net# 创建网络模型net = Net() 优化器和损失函数123456# 损失函数loss_fn = nn.CrossEntropyLoss()# 优化器learning_rate = 1e-2optimizer = optim.SGD(net.parameters(), learning_rate) 基本的训练过程12345678910111213141516171819202122232425262728293031# 设置训练网络和一些参数# 记录训练的次数total_train_step = 0# 记录测试次数total_test_step = 0# 训练的轮数epoch = 10# 添加tensorboardwriter = SummaryWriter(&quot;train_logs&quot;)for i in range(epoch): print(&quot;----------第{}轮训练开始----------&quot;.format(i+1)) # 训练步骤开始 for data in train_loader: imgs, targets = data outputs = net(imgs) loss = loss_fn(outputs, targets) # 优化器优化模型 optimizer.zero_grad() loss.backward() optimizer.step() total_train_step = total_train_step + 1 if total_train_step % 100 == 0: print(&quot;训练次数：{}，Loss:{}&quot;.format(total_train_step, loss.item())) writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step) # loss -&gt; tensor([xxx]) # loss.item() -&gt; xxx 直接返回真实的数据 这里的loss.item()就是将tensor类型变量里具体的数字输出出来。 以上的代码是对模型进行训练，那么如何评价训练的好坏情况?——那就是直接在测试集合进行测试。 12345678910111213141516# 测试步骤开始total_test_loss = 0.0with torch.no_grad(): for data in test_loader: imgs, targets = data outputs = net(imgs) loss = loss_fn(outputs, targets) total_test_loss = total_test_loss + loss.item() print(&quot;整体测试集上的Loss:{}&quot;.format(total_test_loss)) writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step) total_test_loss = total_test_step + 1 # 模型的保存 这里是将每轮的模型都进行保存 torch.save(net, &quot;net_{}.pth&quot;.format(i)) print(&quot;模型已经保存&quot;) 模型的优化过程对于目标检测和语义分割来说，可以直接使用测试误差来作为训练过程的评价指标。但是分类问题还有其他的方法，比如我们的outputs=[0.1, 0.2, 0.3, 0.4]其实是该图片属于各种情况的概率，而真实的输出可以是outputs=[3] 即为最后的判别类别的编号。 12345678910111213total_accuracy = 0for xxx ... ... accuracy = (outputs.argmax(1) == targets).sum() # 也可以使用max函数 pred = torch.max(outputs, dim=1)[1] accuracy0 = (pred == targets).sum() total_accuracy = total_accuracy + accuracy # total_accuracy = total_accuracy + accuracy0 print(&quot;整体测试数据的正确率为:{}&quot;.format(total_accuracy/len(test_loader))) 通过上述方法来实现输出准确率。 模型搭建的细节12net.train()net.eval() 由于我们的net是Net的实例化的对象，同时Net是继承nn.Module的一个子类。要去nn.Containers-&gt;nn.Module帮助文档里查阅。 其实，这两个层就是在有dropout和BatchNorm是才主要起作用。 使用GPU训练模型的方法方法一只要把对于的网络模型、数据(输入imgs、标注labels)和损失函数进行.cuda()，然后覆盖原来的即可。 12345678if torch.cuda.is_available(): # 修改模型 net = net.cuda() # 修改数据 imgs = imgs.cuda() targets = targets.cuda() # 修改损失函数 loss_fn = loss_fn.cuda() 土堆的提醒： colab的GPU免费版每周可以使用免费30小时。 对于colab,如果想要运行在terminal上的语言，需要加在命令前加！。 up测试结果，colab的速度是一般他自己电脑的4倍。运行一轮只要0.7s，而up的电脑要2.5s 但是上述方法不是很常用。 方法二这是比较常用的方法。 1234567891011121314151617# Device是torch.device类型的数据Device = torch.device(&quot;cpu&quot;)Device0 = torch.device(&quot;cuda&quot;)# 可以选择不同的显卡Device1 = torch.device(&quot;cuda:0&quot;)Device2 = torch.device(&quot;cuda:1&quot;)device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# 导入到网络中net = net.to(Device)# 修改数据imgs = imgs.to(Device)targets = targets.to(Device)# 修改损失函数loss_fn = loss_fn.to(Device)# 对于未来和损失函数来说直接to(device)即可 其他与方法一相同，也是对网络、数据以及损失函数进行设置。 以下为我在字节电脑上训练的速度结果。 123456789101112131415161718-------------CPU------------------------第2轮训练开始----------消耗的时间为:0.21944713592529297训练次数：800，Loss:1.8308976888656616消耗的时间为:1.417208194732666训练次数：900，Loss:1.782684564590454消耗的时间为:2.627971887588501训练次数：1000，Loss:1.8661954402923584消耗的时间为:3.8746509552001953训练次数：1100，Loss:1.9508962631225586消耗的时间为:5.333733797073364训练次数：1200，Loss:1.6595017910003662消耗的时间为:6.635249376296997训练次数：1300，Loss:1.6205933094024658消耗的时间为:7.973670244216919训练次数：1400，Loss:1.7197237014770508消耗的时间为:9.35597276687622训练次数：1500，Loss:1.8009873628616333 以下是使用cpu训练的效果： 123456789101112131415161718192021-------------GPU------------------------第2轮训练开始----------消耗的时间为:1.0422132015228271训练次数：800，Loss:1.8765838146209717消耗的时间为:6.844691276550293训练次数：900，Loss:1.856195330619812消耗的时间为:12.637196063995361训练次数：1000，Loss:1.9804853200912476消耗的时间为:18.599247694015503训练次数：1100，Loss:1.9813154935836792消耗的时间为:24.597208261489868训练次数：1200，Loss:1.7226444482803345消耗的时间为:30.361780405044556训练次数：1300，Loss:1.6570385694503784消耗的时间为:36.181212425231934训练次数：1400，Loss:1.7347835302352905消耗的时间为:41.99465990066528训练次数：1500，Loss:1.8110555410385132整体测试集上的Loss:304.21112048625946整体测试数据的正确率为:19.764331817626953模型已经保存 以下是colab的cpu与GPU的效果： 完整的验证/测试(demo)步骤主要的核心就是使用已经训练的好的模型。 主要提醒： Resize()的特点：输入的图格式和输出的格式是一一对应的。 12345678910111213141516171819202122232425262728293031323334353637import torchfrom PIL import Imagefrom torchvision.transforms import transformsfrom model import Net# 导入图片image_path = &quot;&quot;image = Image.open(image_path)print(image)# 数据增强处理transform = transforms.Compose([ transforms.Resize((32, 32)), transforms.ToTensor(),])image = transform(image)image = torch.reshape(image, (1, 3, 32, 32))# 导入模型# 注意使用第一种模型保存时要将模型导入# from model import Net 即可torch.load(&quot;net_0.pth&quot;)# 第二种导入方法net = Net()net.load_state_dict(torch.load(&quot;net_0.pth&quot;))# 养成练好得到习惯net.eval()with torch.no_grad(): # 节约内存和使用性能 outputs = net(image) pred_label = outputs.argmax(1) # 输出预测的类别print(pred_label) 比较标准的步骤请见教程。 注意： 如果是使用GPU训练的模型，但是测试时的设备如果为CPU，此时需要修改torch.load(&quot;xxx.pth&quot;,map_location=torch.device(&quot;cpu&quot;)) 实际项目中的参数问题 可以将require的参数改成defalut的，先让代码跑起来。","link":"/2022/02/23/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/Pytorch%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%90%AD%E5%BB%BA%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B/"},{"title":"Pytorch配置和初识篇","text":"hljs.initHighlightingOnLoad(); 本文主要从Pytorch的环境配置和安装、编辑器的配置教程、python学习中法宝以及Pycharm 和 Jupyter 的对比四个方面进行介绍。主要的视频教程 。 Pytorch的环境配置和安装主要内容可以参考视频教程 这里主要记录如何查看GPU配置。 首先，可以打开任务管理器直接查看显卡的配置。 打开在cmd里输入nvidia-smi 来查看当前显卡的CUDA版本。 如果显示没有该命令，则可以参考以下教程。 总结，在选择显卡pytorch对应的显卡的配置时 如果无英伟达显卡:CUDA选择None； 如果有英伟达显卡:CUDA选择9.2 编辑器的配置教程这里主要以jupyter notebook为例，详细教程请参考以下视频。 首先，打开Anaconda Prompt，激活需要的环境。 之后，conda list来查看当前已经安装好的包。 然后，安装conda install nb_conda 最后，启动即可，cmd中输入jupyter notebook 测试安装。 12import torchtorch.cuda.is_available() 但是，这个操作我这边一直行不通，我选择直接修改kernel的.json文件。 python学习中法宝 dir()函数，能让我们知道工具箱以及工具箱中的分隔区有什么东西。 help()函数，能让我们知道每个工具是如何使用的，工具的使用方法。 实战演练： 以torch为例，我们来查找torch这个包下面包含的分区。 1234dir(torch.cuda.is_available)# 返回该函数下面的属性dir(torch.cuda.is_available())# 返回的是该函数返回值下面的属性，这里返回的是bool变量的属性 help的使用也是同理的。 返回是一个bool值，表示cuda是否可用。 如果加上括号就得出bool值得帮助。 Pycharm 和 Jupyter 的对比 python的文件是整体是一个块，如果一步出错编译以后再次运行是从头开始运行的。效率低下，每次都要重新来一次 优点：通用，传播方便，适用于大型项目 缺点：需要从头运行 python控制台，是一句是一个块，修改之后就是从出错的地方开始往下运行。代码的阅读性不好 其实可以多行输入，在输入完一句之后可以Ctrl+Enter，出现三个点，继续输入下一句。 优点：显示每个变量属性 缺点：不利于代码阅读及修改 jupyter可以自己定义代码块的大小，可以是一句，也可以是多句。功能介于二者之间 优点：利于代码的阅读和修改 缺点：环境需要配置","link":"/2022/02/10/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/Pytorch%E9%85%8D%E7%BD%AE%E5%92%8C%E5%88%9D%E8%AF%86%E7%AF%87/"},{"title":"Pytorch基本网络的搭建过程","text":"hljs.initHighlightingOnLoad(); 本文主要从网络的搭建、损失函数和优化器三个方面进行介绍，并且以下教程主要还是出自于官方的文档，因此还是有时间多看看官方文档，主要的视频教程 。 神经网络基本骨架 本节主要讲的是nn.Containers内的工具。 nn.Module这是一个基类，所有的神经网络的搭建都需要去集成这个类，将整个类的__init__()和forward()进行重写即可。这里我们以官网上的一个教程为例。 123456789101112import torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 通过调试可以发现，进入类中第一步就会进入到我们的forward()函数中，进行运行，再通过return返回到类的外部。 卷积操作Conv2d()torch提供了两个一个是torch.nn一个是torch.nn.functional前者可以看作是后者的一个封装，调研起来会更方便，但是后者实现的更加基础，相当于前者的一些具体的实现。 这里是nn.Conv2d的帮助文档，相比之下比functional.conv2d的教程要详细很多。 123456789101112131415161718192021222324252627282930313233343536373839404142import torchimport torch.nn.functional as Finput = torch.tensor([[1, 2, 0, 3, 1], [0, 1, 2, 3, 1], [1, 2, 1, 0, 0], [5, 2, 3, 1, 1], [2, 1, 0, 1, 1]])# 养成良好的习惯，将矩阵写成以上的格式kernel = torch.tensor([[1, 2, 1], [0, 1, 0], [2, 1, 0]])input = torch.reshape(input, (1, 1, 5, 5))kernel = torch.reshape(kernel, (1, 1, 3, 3))print(input.shape)print(kernel.shape)output = F.conv2d(input=input, weight=kernel, stride=1)print(output)output2 = F.conv2d(input=input, weight=kernel, stride=2)print(output2)output3 = F.conv2d(input=input, weight=kernel, stride=1, padding=1)print(output3)&gt;&gt;&gt;torch.Size([1, 1, 5, 5])torch.Size([1, 1, 3, 3])tensor([[[[10, 12, 12], [18, 16, 16], [13, 9, 3]]]])tensor([[[[10, 12], [13, 3]]]])tensor([[[[ 1, 3, 4, 10, 8], [ 5, 10, 12, 12, 6], [ 7, 18, 16, 16, 8], [11, 13, 9, 3, 4], [14, 13, 9, 7, 4]]]]) 以下主要来讲解的是nn.Conv2d()的操作。 Parameters参数（这里面最常用的是上面的是前五个） in_channels (int) – Number of channels in the input image 输入的通道数 out_channels (int) – Number of channels produced by the convolution 输出的通道数 kernel_size (int or tuple) – Size of the convolving kernel 可以自定义卷积核的大小，可以不是方形的结构。 stride (int or tuple, optional) – Stride of the convolution. 指的是卷积的步长 Default: 1 padding (int, tuple or str, optional) – Padding added to all four sides of the input. 是否再边缘进行填充Default: 0 padding_mode (string**, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros' dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1 groups (int, optional) – Number of blocked connections from input channels to output channels. 分组卷积，在ResNeXt 网络中多见到。 Default: 1 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True 详细的理解可以参考Link kernel_size 是我们实际不断去学习的参数。 以下为输入和输出的形状。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torchimport torchvisionimport torch.nn as nnfrom torch.nn import Conv2dfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterfrom torchvision.transforms import transformstrain_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=True)dataloader = DataLoader(dataset=train_set, batch_size=64, num_workers=0, drop_last=False, shuffle=True)# 设置网络class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0) def forward(self, x): x = self.conv1(x) return xnet = Net()print(net)# 打印网络的相关的参数step = 0writer = SummaryWriter(&quot;conv&quot;)for data in dataloader: img, target = data output = net(img) # print(img.shape) # print(output.shape) # torch.Size([64, 3, 32, 32]) writer.add_images(&quot;input&quot;, img, step) # torch.Size([64, 6, 30, 30]) # tensorboard 是没有办法显示6 channel的图片的 output = torch.reshape(output, (-1, 3, 30, 30)) writer.add_images(&quot;output&quot;, output, step) step += 1 如图为卷积处理前后图片的对比情况。 池化层 Parameters kernel_size – the size of the window to take a max over stride – the stride of the window. Default value is kernel_size，默认是和kernel_size一样的。 padding – implicit zero padding to be added on both sides dilation – a parameter that controls the stride of elements in the window 空洞卷积。 return_indices – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later ceil_mode – when True, will use ceil instead of floor to compute the output shape 取整方式，上取证还是下取整。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import torchimport torchvisionimport torch.nn as nnfrom torch.nn import MaxPool2dfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterfrom torchvision.transforms import transformsinput = torch.tensor([[1, 2, 0, 3, 1], [0, 1, 2, 3, 1], [1, 2, 1, 0, 0], [5, 2, 3, 1, 1], [2, 1, 0, 1, 1]], dtype=torch.float32)# 养成良好的习惯，将矩阵写成以上的格式# 设置网络class Net(nn.Module): def __init__(self, ceil_mode): super(Net, self).__init__() self.ceil_mode = ceil_mode self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=self.ceil_mode) def forward(self, x): output = self.maxpool1(x) return outputnet1 = Net(ceil_mode=True)net2 = Net(ceil_mode=False)print(net1)print(net2)# 打印网络的相关的参数input = torch.reshape(input, (-1, 1, 5, 5))output1 = net1(input)output2 = net2(input)print(&quot;ceil_mode=true\\n&quot;, output1)print(&quot;ceil_mode=False\\n&quot;, output2)&gt;&gt;&gt;ceil_mode=true tensor([[[[2., 3.], [5., 1.]]]])ceil_mode=False tensor([[[[2.]]]]) 最大池化是保留主要的图片特征，会变模糊，eg.1080P-&gt;720P 12345678910111213141516171819train_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=True)dataloader = DataLoader(dataset=train_set, batch_size=64, num_workers=0, drop_last=False, shuffle=True)step = 0writer = SummaryWriter(&quot;maxpooling&quot;)for data in dataloader: img, target = data output = net1(img) writer.add_images(&quot;input&quot;, img, step) writer.add_images(&quot;output&quot;, output, step) step += 1 这里padding层的作用跟padding是意义的，可以用0或者任意的一个常数去进行，用的比较少，此处不在详细介绍。 非线性激活函数比较常用的nn.ReLU(inplace=Flase)，nn.Sigmoid()。 inplace的作用其实就是是否在原来的位置进行替换。 默认inplace=False , 这样可以保留原始的数据不丢失。 以下我们使用Sigmoid激活函数为例，来观察处理前后的情况。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import torchimport torchvisionimport torch.nn as nnfrom torch.nn import ReLUfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterfrom torchvision.transforms import transformsinput = torch.tensor([[1, -0.5], [-1, 3]])input = torch.reshape(input, (-1, 1, 2, 2))class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.relu = ReLU() def forward(self, input): output = self.relu(input) return outputnet = Net()print(net)output = net(input)print(output)# 图片操作情况# ----------------------------------------------------train_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=True)dataloader = DataLoader(dataset=train_set, batch_size=64, num_workers=0, drop_last=False, shuffle=True)class Net2(nn.Module): def __init__(self): super(Net2, self).__init__() self.sigmoid = nn.Sigmoid() def forward(self, input): output = self.sigmoid(input) return outputnet2 = Net2()print(net2)step = 0writer = SummaryWriter(&quot;Sigmoid&quot;)for data in dataloader: img, target = data output = net2(img) writer.add_images(&quot;input&quot;, img, step) writer.add_images(&quot;output&quot;, output, step) step += 1 线性层nn.Linear() 12345678910111213141516171819202122232425262728293031323334353637383940414243import torchimport torchvisionimport torch.nn as nnfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWriterfrom torchvision.transforms import transformstrain_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=True)dataloader = DataLoader(dataset=train_set, batch_size=64, num_workers=0, drop_last=False, shuffle=True)# 设置网络class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.linear1 = nn.Linear(in_features=196608, out_features=10) def forward(self, x): output = self.linear1(x) return outputnet = Net()step = 0writer = SummaryWriter(&quot;maxpooling&quot;)for data in dataloader: img, target = data print(img.shape) # output = torch.reshape(img, (1, 1, 1, -1)) output = torch.flatten(img) print(output.shape) output = net(output) print(output.shape) 使用torch.flatten()得到的结果为 123torch.Size([64, 3, 32, 32])torch.Size([196608])torch.Size([10]) 就是最后直接展平成为一维。 nn.Sequential()实战这里提供一个实际的例子，来展示nn.Sequential()的使用过程。 1234567891011121314151617181920212223242526272829303132333435import torchimport torch.nn as nnfrom torch.utils.tensorboard import SummaryWriterclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.models = nn.Sequential( nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten(), # 默认式和kernel_size相等的 nn.Linear(1024, 64), nn.Linear(64, 10), ) def forward(self, x): return self.models(x)net = Net()print(net)input = torch.ones((64, 3, 32, 32))print(input.shape)output = net(input)writer = SummaryWriter(&quot;Sequential&quot;)writer.add_graph(net, input)writer.close() 如图所示，为使用tensorboard后的基本结果，其可以显示基本的网络连接和维度上的变化。 损失函数 损失函数根据定义来讲一定是越小越好。 Loss function 衡量的是实际计算和目标之间的差距。 为我们更新参数提供依据，即反向传播。 L1Loss以下以L1Loss来举例： 要重点注意的时输入与输出的Shape: Input: (), where means any number of dimensions. Target: (*), same shape as the input. Output: scalar. If reduction is 'none', then (*), same shape as the input. 12345678910111213141516import torchimport torch.nn as nnfrom torch.nn import L1Loss# 损失函数一般在torch.nn里inputs = torch.tensor([1, 2, 3], dtype=torch.float32)targets = torch.tensor([1, 2, 5], dtype=torch.float32)inputs = torch.reshape(inputs, (1, 1, 1, 3))targets = torch.reshape(targets, (1, 1, 1, 3))loss = L1Loss(reduction='mean')# reduction='mean' 时我们的inputs和targets要都是float类型才对result = loss(inputs, targets)print(result) MSELoss之后，我们以最小二乘法常用的MSELoss为例： 其主要的使用方法和上面的基本相同，这里不在赘述。 CrossEntropyLoss然后，我们以分类任务中比较常用的交叉熵损失函数为例： 以上公式和视频里的公式不同，因为这里将交叉熵softmax进行了内置处理。 Shape: Input: (N, C) where C = number of classes, or$ (N, C, d_1, d_2, …, d_K)$ with $K \\geq 1$ in the case of K-dimensional loss. 这里输入需要连两个参数，第二个参数为分类数(就是其所示类别的编号数) ； 如上面的例子，狗的分类数为1，C=[0, 1, 0] 这里要输入的必须为one-hot编码 Target:（N） If containing class indices, shape (N)where each value is $ 0 \\leq \\text{targets}[i] \\leq C-10$, or $(N, d_1, d_2, …, d_K)$ with $K \\geq 1$ in the case of K-dimensional loss. If containing class probabilities, same shape as the input. Output: If reduction is 'none', shape (N) or $(N, d_1, d_2, …, d_K)$ with $K \\geq 1$ in the case of K-dimensional loss. Otherwise, scalar. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch.nn as nnfrom torch.utils.tensorboard import SummaryWriterfrom torch.utils.data import DataLoaderfrom torchvision.transforms import transformsimport torchvisiontrain_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=transforms.ToTensor(), download=True)dataloader = DataLoader(dataset=train_set, batch_size=1, num_workers=0, drop_last=False, shuffle=True)class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.models = nn.Sequential( nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten(), # 默认式和kernel_size相等的 nn.Linear(1024, 64), nn.Linear(64, 10), ) def forward(self, x): return self.models(x)net = Net()loss = nn.CrossEntropyLoss()for i, data in enumerate(dataloader): imgs, targets = data outputs = net(imgs) # print(outputs) # print(targets) result = loss(outputs, targets) print(result) result.backward() if i == 10: break 提供反向传播使其拥有grad参数。 优化器优化器的构件过程12optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)optimizer = optim.Adam([var1, var2], lr=0.0001) 优化器的使用过程123456for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() 这里有很多优化器，不同的优化器所使用的参数是不同的，但是共有的参数是para=和 lr= (即要优化的参数和学习率)","link":"/2022/02/23/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/Pytorch%E5%9F%BA%E6%9C%AC%E7%BD%91%E7%BB%9C%E7%9A%84%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/"},{"title":"Pytorch数据处理和可视化篇","text":"hljs.initHighlightingOnLoad(); 本文主要从Pytorch数据加载的初识、数据集Dataset的代码实践、TensorBoard基础教程、transforms进行图片的预处理、Torchvision里数据集的使用以及DataLoader的使用五个大方面来介绍Pytorch在运行过程中数据的修饰和预处理过程。主要的视频教程 。 Pytorch数据加载的初识 数据：可以比作垃圾的海洋，从数据(垃圾)中获取由于的东西。 Dataset：取出其中的某一类有用的数据(垃圾)，并获取对应的label值。 Dateset的几种组织形式： 第一种是文件夹的名称为对应的label。 第二种是图片和文件夹分属在不同的文件夹中，label以.txt形式保存。 DataLoader：将数据进行打包和压缩，为后面的网络提供不同的数据形式。 Dataset类的使用： 1234567from torch.utils.data import Dataset# 导入dataset类help(Dataset)# 获取简易的把帮助Dataset??# 在jupyter里获取详细的帮助# 在pycharm里一般是按住ctrl再点击dataset dataset是一个抽象类，所有的子类都应该重写__getitme__方法，这个方法是用来获取数据集对应的label的。 也可以选择重写__len__用来获取数据的长度。 12345def __getitem__(self, index): raise NotImplementedErrordef __add__(self, other): return ConcatDataset([self, other]) getitem的作用：使得数据集可以支持下标的引用 len的作用：使得数据集类可以通过len()函数来返回我们的长度 数据集Dataset的代码实践图片的读取12345# 测试图片的属性from PIL import Imageimg_path=&quot;flower_photos\\\\daisy\\\\5673551_01d1ea993e_n.jpg&quot;img.size # 测试证明读取数据成功img.show() # 展示图片 路径的读取12345678910import os# 用来读取文件夹地址的包dir_path=&quot;flower_photos/roses&quot;img_path_list=os.listdir(dir_path)# 读取指定的文件夹下的文件名，以list的形式读取文件名root_dir=&quot;flower_photos&quot;label_dir=&quot;roses&quot;path=os.path.join(root_dir,label_dir)# 该函数可以按照不同的系统来分配适当的连接符# 对于windows 用\\\\连接 对于linux使用一般的 / 连接 构建数据集类1234567891011121314151617class MyData(Dataset): def __init__(self, root_dir, label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(self.root_dir, self.label_dir) self.img_path = os.listdir(self.path) # 得到文件下面所有图片的名称，组成一个列表 def __getitem__(self, idx): img_name = self.img_path[idx] img_item = os.path.join(self.root_dir, self.label_dir, img_name) img = Image.open(img_item) label = self.label_dir return img, label def __len__(self): return len(self.img_path) 带双下划线的是属性函数，是自动调用的函数，不需要显式的调用。如__len__()起作用是当我们调用len(MyData)时。 测试数据集的测试123456789# 图片的读取root_dir = &quot;flower_photos&quot;label_list = os.listdir(root_dir)label_dir = label_list[1]flower_set = MyData(root_dir, label_dir)# flower_set对象其实是一个图像集，靠索引来读取数据img, label = flower_set[1]img.show() __getitem__起作用时我们以索引的方式调用数据集对象时。 程序的输出如下图所示： 1234567# 数据集的拼接roses_dir = label_list[3]daisy_dir = label_list[0]rose_set = MyData(root_dir, roses_dir)daisy_set = MyData(root_dir, daisy_dir)flower_set = rose_set + daisy_setprint(len(rose_set), len(daisy_set), len(flower_set)) 通过加号可以直接实现两个数据集的合并。 以下代码创建第二类，标签和图片分里的数据集的代码(和本实验不同，大概读懂意思即可，可以作为模板来套用)： 12345678910root_dir = &quot;dataset/train&quot;target_dir = &quot;ants_image&quot;img_path = os.listdir(os.path.join(root_dir，arget_dir))label = target_dir.split('_')[0]# 相当于去除ants_image的第一个字antsout_dir = &quot;ants_label&quot;for i in img_path: file_name = i.split(&quot;.jpg&quot;)[0] with open(os.path.join(root_dir,out_dir,&quot;{}.txt&quot;.format(file_name)),'w') as f; f.write(label) TensorBoard基础教程TensorBoard的安装tensorboard起初只能tensorflow才能使用，后来pytorch1.1之后也可以使用了。 SummaryWriter类的使用TensorBoard的帮助文档如下图所示： 主要是想log_dir中写内容的事件文件，主要的参数是前两个参数，后面的参数直接使用默认值就好了。 1234567891011121314Examples::from torch.utils.tensorboard import SummaryWriter# create a summary writer with automatically generated folder name.writer = SummaryWriter()# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/# create a summary writer using the specified folder name.writer = SummaryWriter(&quot;my_experiment&quot;)# folder location: my_experiment# create a summary writer with comment appended.writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;)# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ 这里初始化类的主要过程，可以直接初始化，此时文件保存在默认的路径下面，location: runs/May04_22-14-54_s-MacBook-Pro.local/下。 也可以设置保存的路径为my_experiment ，此时文件保存在my_experiment下。 pycharm 和 jupyter中的注释使用ctrl+/ texstdio中的注释是ctrl+t add_scalar()的使用add_scalar()经常用来绘制train/val_loss。 tag：表示的是图表的数值。 scalar_value：表示需要去保存的数值的规模。(Y轴的规模) global_step：表示需要保存多少步。(X轴的规模) 1234567from torch.utils.tensorboard import SummaryWriterwriter = SummaryWriter(&quot;logs&quot;)# 将事件文件保存在logs文件下# y = xfor i in range(100): writer.add_scalar(tag=&quot;y=x&quot;, scalar_value=i, global_step=i)writer.close() tensorboard的打开，这里的logdir=事件文件所在文件夹名,切记不可以有中文字符 12345tensorboard --logdir=logs# logdir=事件文件所在文件夹名# 不可以有中文字符# 有时实验室服务器的6006端口比较紧张，可以自行设计打开的端口tensorboard --logdir=logs --port=6007 tensorboard打不开的原因：浏览器的问题，换成原始的Edge就没问题了。 如果tag=“ ”忘记改名，就可能出现如下多个内容画到了同一图上面的情况。 add_image()的使用 其他的参数大概都是和add_scalar相同，但是图片的数据类型要注意，这里img_tensor要是tensor类型和numpy.array类型的。 如图所示，PIL读取的数据类型不符合要求，因此这里使用opencv来读取图片数据，opencv读取得到的类型是array类型的。 也可以直接将PIL的类型转换为arrry。 但是，这里要注意，输入图片的维度也是有要求的，默认是(3,H,W)类型的，如果要改成(3,H,W)需要修改dataformats='CHW'。 12345678910111213141516from torch.utils.tensorboard import SummaryWriterimport numpy as npimg = np.zeros((3, 100, 100))img[0] = np.arange(0, 10000).reshape(100, 100) / 10000img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000img_HWC = np.zeros((100, 100, 3))img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000writer = SummaryWriter()writer.add_image('my_image', img, 0)# If you have non-default dimension setting, set the dataformats argument.writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')writer.close() 123456789101112131415from torch.utils.tensorboard import SummaryWriterimport numpy as npfrom PIL import Imagewriter = SummaryWriter(&quot;logs&quot;)# 将事件文件保存在logs文件下img_path = &quot;flower_photos/roses/145862135_ab710de93c_n.jpg&quot;img_PIL = Image.open(img_path)img_array = np.array(img_PIL)print(type(img_array))# 是np.array类型，但是数据的维度排列不是很匹配print(img_array.shape)writer.add_image(&quot;roses&quot;, img_array, 1, dataformats='HWC')writer.close() 从PIL到numpy，需要在add_image()中指定shape中每一个数字/维表示的含义 如果tag不变，所有的图像都会画在同一个tag的下面，注意部署一定要修改，不然就会直接覆盖，通过左右滑动来切换。 transforms进行图片的预处理 transforms的结构和用法 整理，在pycharm中打开文档，利用structure来分析器结构。 快捷键设置：到setting-&gt;keymap-&gt;搜索目标关键字即可 小贴士：alt+7可以调出structure的栏目，主要可以用来显示我们的函数里所包含的类（功能）和变量 该包相当于一个工具的模具（模板） （ctrl+p用来显示数该函数的变量信息） tensor数据类型整理通过tensorforms.ToTensor()去理解tensors的数据类型的问题。 这里的__call__代表的是传入的参数应该的什么类型。 1234567891011from torchvision.transforms import transformsfrom PIL import Imageimg_path = &quot;flower_photos/tulips/10791227_7168491604.jpg&quot;img = Image.open(img_path)# 使用Totensortensor_trans = transforms.ToTensor()tensor_img = tensor_trans(img)print(tensor_img) 这里Totensor()是一个类，需要实例化才能使用。 以下为我们转移到交互窗口的进行查看过程的数据。tensor的数据类型一共包含以下数据的属性和类型。 pycharm 出现问题时，使用alt+enter可以弹出相应的解决方案。 常见的transforms ToTensor()的使用 1234567891011from torchvision.transforms import transformsfrom PIL import Imageimg_path = &quot;flower_photos/tulips/10791227_7168491604.jpg&quot;img = Image.open(img_path)# 使用Totensortensor_trans = transforms.ToTensor()tensor_img = tensor_trans(img)print(tensor_img) Normalized()的用法 求图片张量的每一个channel的平均值和标准差。 1234trans_norm = transforms.Normalize([.5, .5, .5], [.5, .5, .5])img_norm = trans_norm(tensor_img)writer.add_image(&quot;Normalized&quot;, img_norm) 公式主要的作用相当于是改变数据分布的范围。 $output[channel] = \\dfrac {input[channel] - mean[channel]} {std[channel]}$ PyCharm小技巧设置:忽略大小写，进行提示匹配一般情况下，你需要输入R，才能提示出Resize 我们想设置，即便你输入的是r，也能提示出Resize 也就是忽略了大小写进行匹配提示。 Resize()的作用 主要的作用是按照指定的长宽来缩放图片。 如果输入(h,w)，则将图片变为指定的 (h,w) 如果输入 int a (小于最短的边)，则将图片的最小边变为a，长边按照比例来缩放。如果大于最长的边，图片最长边为a，最短边就按比例缩放。 参数必须为一个图片PIL，不可以是一个tensor，因此在compose里排列的顺序一定要先Resize后Totensor。 代码如下： 123456789101112# Reszie# 注意先后的顺序，先Reszie，后ToTensor# img PIL -&gt; resize -&gt; img_resize PILtrans_resize = transforms.Resize((512, 512))img_resize = trans_resize(img)# img_resize PIL -&gt; totensor -&gt; img_resizetensortensor_trans = transforms.ToTensor()img_resize = tensor_trans(img_resize)writer.add_image(&quot;Reszie&quot;, img_resize)# ------------------------------------------------- Compose()的使用 这个类的主要作用是将不同的transforms类进行合并操作。 Compose()中的参数需要是一个列表Python中，列表的表示形式为[数据1，数据2，…] 在Compose中，数据需要是transforms类型所以得到，Compose([transforms参数1, transforms参数2, …]) 1234567891011# Compose# 注意先后的顺序，先Reszie，后ToTensortrans_resize = transforms.Resize(512)tensor_trans = transforms.ToTensor()trans_compose = transforms.Compose([trans_resize, tensor_trans])# 也可以不用实例化，直接生成trans_compose = transforms.Compose([ transforms.Resize(512), transforms.ToTensor()])img_resize_2 = trans_compose(img) RandomCrop的用法 主要的作用：对图像进行随机裁剪 参数：size的如果是序列(h,w)，则将图片变为指定的 (h,w)，如果输入 int a (小于最短的边)，则将图片的最小边变为a，长边按照比例来缩放。如果大于最长的边，图片最长边为a，最短边就按比例缩放。 123456# Randomcroptrans_crop = transforms.RandomCrop(100, 80)trans_compose1 = transforms.Compose([trans_crop, tensor_trans])for i in range(10): img_crop = trans_compose1(img) writer.add_image(&quot;RandomCrop100,80&quot;, img_crop, i) python__call__的用法1234567891011121314class Person: def __call__(self, name): print(&quot;__call__&quot;+&quot;HELLO &quot;+name) def hello(self, name): print(&quot;hello &quot;+name)person = Person()person(&quot;Tom&quot;)person.hello(&quot;Tom&quot;)# output:&gt;&gt;&gt; __call__HELLO Tom&gt;&gt;&gt; hello Tom call的意思其实就是调用，使用对象加()即可作为一个函数来调用，是一个内置的方法。 hello()是对象配置的一个属性，只能用.hello()来显式调用。 总结：首先，注意输入和输出；其次，关注官方文档；然后，关注这个方法需要的参数。 Torchvision里数据集的使用这里Torchvision是主要服务计算机视觉的包，主要提供一些数据集和模型来以及一些预训练号的参数来方便训练。 CIFARCLASStorchvision.datasets.CIFAR10(root: str, train: bool = True, transform:Optional[Callable] = None, target_transform: Optional[Callable] = None, download:bool = False)[SOURCE] CIFAR10 Dataset的参数： root (string) – Root directory of dataset where directory cifar-10-batches-py exists or will be saved to if download is set to True. 主要是保存文件夹的位置。 train (bool, optional) – If True, creates dataset from training set, otherwise creates from test set.是否为训练集True代表是训练集。 transform (callable**, optional) – A function/transform that takes in an PIL image and returns a transformed version. E.g, transforms.RandomCrop使用的transforms的格式。 target_transform (callable**, optional) – A function/transform that takes in the target and transforms it. download (bool, optional) – If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.是否下载。 这里如果下载速度过慢，可以使用迅雷进行加速。 12345678910111213141516171819202122232425262728import torchvisionfrom torch.utils.tensorboard import SummaryWriterdataset_trans = torchvision.transforms.Compose([ torchvision.transforms.ToTensor()])train_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=True, transform=dataset_trans, download=True)test_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;, train=False, transform=dataset_trans, download=True)# 读取测试img, target = train_set[0]print(train_set[0])# 转换字典的键值idx_classes = {}idx = 0for name in train_set.class_to_idx: idx_classes[idx] = name idx = idx + 1print(idx_classes[target])# tensorboard可视化writer = SummaryWriter(&quot;p10&quot;)for i in range(10): img, target = test_set[i] writer.add_image(&quot;test&quot;, img, i)writer.close() 源代码里有相关的下载链接。 DataLoader的使用dataset相当于一组牌，dataloader相当于如何抽一组牌。 torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False)[SOURCE]** Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. The DataLoader supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning. See torch.utils.data documentation page for more details. Parameters主要参数： dataset (Dataset) – dataset from which to load the data.之前我们自己创建或者导入的数据集。 batch_size (int, optional) – how many samples per batch to load (default: 1).每一批取到的数据量，每一批的数据量越大越好。 shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).是否拉乱顺序，对于训练集，最好打乱顺序 sampler (Sampler or Iterable**, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented. If specified, shuffle must not be specified. batch_sampler (Sampler or Iterable**, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last. num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)进程数，但是windows只能设为0 collate_fn (callable**, optional) – merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory (bool, optional) – If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below. drop_last (bool, optional) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False) 每次按照批量来存取，最后不能除尽的几张是否舍去。 timeout (numeric**, optional) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0) worker_init_fn (callable**, optional) – If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None) generator (torch.Generator, optional) – If not None, this RNG will be used by RandomSampler to generate random indexes and multiprocessing to generate base_seed for workers. (default: None) prefetch_factor (int, optional**, keyword-only arg) – Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers. (default: 2) persistent_workers (bool, optional) – If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. (default: False) dataloader是将img和target分别进行打包，在dim=0上增加一个维度。 12345678910111213141516171819202122232425262728293031323334import torchvisionfrom torch.utils.tensorboard import SummaryWriterfrom torch.utils.data import DataLoaderdataset_trans = torchvision.transforms.Compose([ torchvision.transforms.ToTensor()])train_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;,train=True,transform=dataset_trans,download=True)test_set = torchvision.datasets.CIFAR10(root=&quot;./root&quot;,train=False,transform=dataset_trans,download=True)## 设置DataLoader类test_loader = DataLoader(dataset=test_set, batch_size=4, num_workers=0, drop_last=False, shuffle=False)# 测试数据中的每一张图片及targetimg, target = test_set[0]print(img.shape)print(target)# 测试dataloaderfor data in test_loader: imgs, targets = data print(imgs.shape) print(targets)&gt;&gt;&gt;output:torch.Size([3, 32, 32])3torch.Size([4, 3, 32, 32])tensor([3, 8, 8, 0]) 这里我们通过tensorboard来测试其效果 12345678910writer = SummaryWriter(&quot;dataloader&quot;)# 测试dataloaderfor epoch in range(2): for idx, data in enumerate(test_loader): imgs, targets = data # print(imgs.shape) # print(targets) # 由于每次输出为多张图片，这里将其平铺起来 writer.add_images(&quot;Epoch:{}&quot;.format(epoch), imgs, idx)writer.close() 这里，我们选择留下未除尽的内容，shuffle=False时，二者一模一样。反之，两次就不相同了。","link":"/2022/02/10/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/pytorch%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AF%87/"},{"title":"张量的创建与运算","text":"张量是一种特殊的数据结构，它于数组和矩阵很相似。我们用张量来标记模型的输入、输出和模型的参数。 张量（Tensor）和数组非常的相似，但是Tensor可以实现在硬件的加速。 tensors and NumPy 数组可以共享同一个内存。 hljs.initHighlightingOnLoad(); 初始化张量12import torchimport numpy as np 通过列表初始化 12345data = [ [1,2],[3,4] ]x_data = torch.tensor(data)type(data) # &lt;class 'list'&gt;type(x_data) # &lt;class 'torch.Tensor'&gt; 通过数组初始化 1234np_array = np.array(data)x_np = torch.from_numpy(np_array)# 默认的数据类型为 torch.float32 从另一个张量中初始化一个新的张量 1234567891011121314x_ones = torch.ones_like(x_data) # retains the properties of x_dataprint(f&quot;Ones Tensor: \\n {x_ones} \\n&quot;)x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_dataprint(f&quot;Random Tensor: \\n {x_rand} \\n&quot;)output:Ones Tensor: tensor([[1, 1], [1, 1]])Random Tensor: tensor([[0.4557, 0.7406], [0.5935, 0.1859]]) 用随机数或常值生成 12345678shape = ( 2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape)print(f&quot;Random Tensor: \\n {rand_tensor} \\n&quot;)print(f&quot;Ones Tensor: \\n {ones_tensor} \\n&quot;)print(f&quot;Zeros Tensor: \\n {zeros_tensor}&quot;) 这里的shape可以(2,3) or (2,3,) or [2,3] or [2,3,] Tensor的属性123456789101112tensor = torch.rand(3,4)tensor.shape # 形状 torch.Size([3, 4])tensor.dtype # 数据类型 torch.float32tensor.device # 使用的设备 device(type='cpu')print(f&quot;Shape of tensor: {tensor.shape}&quot;)print(f&quot;Datatype of tensor: {tensor.dtype}&quot;)print(f&quot;Device tensor is stored on: {tensor.device}&quot;)Shape of tensor: Datatype of tensor: torch.float32Device tensor is stored on: cpu Tensor的操作Tensor的主要操作包含100种包含矩阵运算、切片等。具体的操作API点击这里。 常用的操作如下： 关于Tensor的操作 is_tensor(x)判断是否为Tensor 123&gt;&gt;&gt; x=torch.tensor([1,2,3])&gt;&gt;&gt; torch.is_tensor(x)True is_nonzero(x)判断单一元素的Tensor是否为0 12345678910111213141516&gt;&gt;&gt; torch.is_nonzero(torch.tensor([0.]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1.5]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([False]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([3]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1, 3, 5]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with more than one value is ambiguous&gt;&gt;&gt; torch.is_nonzero(torch.tensor([]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with no values is ambiguous nueml(x)统计张量里的元素数目 123456&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4, 5)&gt;&gt;&gt; torch.numel(a)120&gt;&gt;&gt; a = torch.zeros(4,4)&gt;&gt;&gt; torch.numel(a)16 创建Tensor操作 tensor(x)创建张量 from_numpy(a)也是创建张量，但是不同的是此方法的创建的tensor和array是共享内存的。 1234567&gt;&gt;&gt; a = numpy.array([1, 2, 3])&gt;&gt;&gt; t = torch.from_numpy(a)&gt;&gt;&gt; ttensor([ 1, 2, 3])&gt;&gt;&gt; t[0] = -1&gt;&gt;&gt; aarray([-1, 2, 3]) zeros() 创建全0矩阵 torch.zeros(size, , out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 主要参数： *size：形状可以是元组、列表、切片等。 requires_grad=False：是否要求梯度。 dtype=None:默认是None,因为set_default_tensor_type()函数可以设置默认的dtype()类型。 arange()和range()函数都是用于一维计数，配合for来使用，基本的功能也是继承numpy和python的基本语法。 arange-&gt;[start, end)，size=$\\lceil \\frac{end-start}{step} \\rceil$，并且start、end、step —&gt;&gt; int range-&gt;[start, end]，size=$\\lfloor \\frac{end-start}{step} \\rfloor+1$，并且start、end、step —&gt;&gt; float eye(n,m=None) 单位矩阵 full(size,fill_value ) 就是用某个数值来填充某个size的张量。同样的还有full_like() 索引、切片、旋转以及聚合的操作 cat(tensors, dim=0) 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; x = torch.randn(2, 3)&gt;&gt;&gt; xtensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 0)tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 1)tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; x1 = torch.randn(2, 3)&gt;&gt;&gt; x2 = torch.randn(2, 2)&gt;&gt;&gt; s = torch.cat((x1,x2),dim=1)&gt;&gt;&gt; stensor([[-0.5980, 0.2570, 1.1660, -0.0306, -1.0363], [ 0.2817, -0.1498, -0.6464, -0.3204, -1.6839]])# 这里dim=1上是不同的dim=0上是相同的，因此可以实现在dim=1上的切片，dim=0是用来对齐的。&gt;&gt;&gt; x3 = torch.randn(3, 2)&gt;&gt;&gt; s = torch.cat([x2,x3],dim=0)&gt;&gt;&gt; stensor([[-0.0306, -1.0363], [-0.3204, -1.6839], [-0.0858, 0.9804], [ 0.1920, -0.1728], [ 1.0318, -1.6507]])","link":"/2022/01/23/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%BF%90%E7%AE%97/"},{"title":"Latex公式排版快速教程","text":"src=\"//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js\"> hljs.initHighlightingOnLoad(); 本文主要关注Latex在公式排版的技巧，并且配合Markdown更好的编辑公式。主要包含希腊字母、上下标、分式与根式、运算符、标注、箭头、括号与定界符、多行公式、大括号、矩阵以及实战书写几个公式。 typora有些latex字符是不识别的，因此可能出现一些乱码问题。 行内公式创建行内的公式的方法有三种： 美元号：a+b=b+a 小括号：\\( a+b=b+a\\) math环境：\\begin{math} a+b=b+a \\end{math} 行间公式创建行间公式的主要方法有： 双美元号：$$ $$ 中括号：\\[a+b=b+a\\] displaymath环境：\\begin{displaymath} a+b=b+a \\end{displaymath} equation环境(自动生成编号)：\\begin{equation} a+b=b+a \\end{equation}，同时可以对生成的公式用\\label进行交叉引用，如下图所示。 equation*环境(不自动生成编号)：\\begin{equation*} a+b=b+a \\end{equation*}，同时可以对生成的公式用\\label进行交叉引用，如下图所示。 此时交叉引用的编号为小结的编号。 带星号的equation环境需要使用amsmath宏包。 1\\usepackage{amsmath} 希腊字母输入方法：\\+字母的拼写 常用的希腊字母表 对于有大写的字母来说，直接将首字母大写即可得到大写的希腊字母，对于没有大写的字母如$\\alpha$和$\\beta$，如果首字母大写对应的是$\\Alpha$和$\\Beta$即AB。 对于变体字的输入，直接在前面加var即可。 上下标 一般来说，上下标直接使用^和_即可。 对于斜体的要加大括号，否则就会只对第一个有效。 1234$ a^2 , a_2 x^{y+z},p_{ij},p_ij$ a^2 , a_2, \\, x^{y+z},p_{ij},p_ij 英文字母只有在表示变量(或单一字符的函数名称，如f(r))时才可使用斜体，其余情况都应使用罗马体(直立体)。 1234567$ x_i 此时为斜体 x_{\\rm i} 此时为直立体roman x_{\\mathrm i} \\rm is short for \\mathrm x_{\\text i} \\text{e} ,\\text{i} 自然对数和虚数单位也要为直立体$ x_i, i=1,2...n\\\\ x_{\\rm i} ,i是input\\\\ x_{\\mathrm i},x_{\\text i}\\\\ \\text{A B},\\rm{AB}\\\\ \\text{e} 自然对数,\\text{i} 虚数单位 \\text{}和\\rm{}的区别是前者支持空格，后者不支持空格。 分式于根式\\frac(fraction,分数) 12345$ \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y} \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}$ 单个字符可以不用大括号，原理与上面相似。 如果感觉嵌套时的字符比较小的话，可以用\\dfrac{}{}. \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y}\\\\ \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}\\sqrt[]{}(square root,平方根) 123$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z}$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z} 对于非平方根的数在\\sqrt后加[]来自定义。 普通运算符12345678910$ +- \\times,\\cdot,\\div \\pm,\\mp &gt;&lt;,\\ge,\\le,\\gg,\\ll,\\ne,\\approx,\\equiv \\cap,\\cup,\\in,\\notin,\\subseteq,\\subsetneqq,\\subnsetneqq \\varnothing,\\forall,\\exists,\\nexists\\because,\\therefore \\mathbb R,\\R,\\Q,\\N,\\Z_+ \\mathcal F,\\mathscr F$ $\\pm$ ：\\pm(plus-mius 正负号) $\\mp$：\\mp(mius-plus 负正号) $\\ge$：\\ge(greater than or equal 大于等于) $\\le$：\\le(less than or equal 大于等于) $\\gg,\\ll$：\\gg,\\ll（远大于,远小于） $\\ne$：\\ne（not equal, 不等于） $\\approx$：\\approx(approximate, 约等于) $\\equiv$：\\equiv(equivalent, 恒等的) $\\cap,\\cup$：\\cap，\\cup（交集，并集） $\\in,\\notin$：\\in,\\notin（属于，不属于） $\\subseteq,\\subsetneqq,\\subsetneq$：\\subseteq,\\subsetneqq,\\subsetneq（子集，真子集） $\\supseteq,\\supsetneqq,\\supsetneq$：\\suqseteq,\\suqsetneqq,\\suqsetneq（与上面相反） $\\varnothing,\\forall$：\\varnothing（空集）,\\forall(与任意的) $\\exists,\\nexists$：\\exists,\\nexists（存在，不存在） $\\because,\\therefore$：\\because,\\therefore（因为，所以） $\\R,\\Q,\\N,\\Z$：\\R,\\Q,\\N,\\Z对于数集来说特有的字符，可以直接使用\\转义即可，但是除了数集以外的其他字符就无法使用了。完整写法为：\\mathbb R $\\mathcal F,\\mathscr F$：\\mathcal F,\\mathscr F（花体字符） 以下为上面字符的运行结果。 +-\\\\ \\times,\\cdot,\\div\\\\ \\pm,\\mp\\\\ >","link":"/2022/01/24/Latex/Latex%E5%85%AC%E5%BC%8F%E6%8E%92%E7%89%88%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B/"},{"title":"Latex期刊论文的排版","text":"本文主要针对与IEEE的一个Latex模板，主要从模板下载、语句解释、插入图片、插入公式、插入算法图、插入引用等方面来讲解如何使用模板。该教程属于简易教程，深入学习请看后续的详细教程。视频参考 Latex模板下载 模板下载:IEEE模板:http://www.ieee.org/publications_standards/publications/authors/author_templates.html 通用模板:https://www.overleaf.com/ 其他方法:百度,csdn等网页找 Latex的核心思想就是内容与格式分离 模板的基本语句解释 \\begin{document}是文件的开始，之前为导言区，可以加入各种各样的宏包。 \\begin{document}之后到\\begin{abstract}之前用来写作者信息，联系方式以及致谢等信息。 \\begin{IEEEkeywords} 后面写关键词。 \\section{Introduction} 之后为介绍综述部分。 \\subsection{name} 为子标题部分。 \\section{References Section} 参考文献部分。 \\begin{IEEEbiography} 开始作者生平部分。 插入图片 首先，导入宏包 \\usepackage{graphicx}。 其次，导入代码块，其中的后缀名可以去查看详细的教程。 最后，编辑图片的大小样式。 !(https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/latex/202201251022521.png) 插入公式公式部分主要的内容参考之前的专门写公式那篇博客。 首先，导入宏包 \\usepackage{amsmath,amsfonts} 其次，行间公式如图，文章终会自行标号，也可以自行标号\\tag{1.1}。 \\begin{equation} \\label{deqn_ex1} x = \\sum_{i=0}^{n} 2{i} Q. \\tag{1.1} \\end{equation} 最后，行内的公式的写法是在$ $之间直接写即可，如$x^2+y^2=0$ 插入参考文献实用办法插入参考文献 首先，引入宏包 \\usepackage[colorlinks,linkeolor-black,anchorcolor-black,citecolor-black]{hyperref }%用于调整多个参考文献的间距。直接用就好。 模板的插入方法，直接插入。 也可以自己使用BibTex格式的文件来插入，但是在实际编译的过程中要记得将BibTex文件也进行编译。 到百度上下载一个BibTex的文件。 引用BIb文件。 以下为BibTex文件的内容。 12345678@article{2021Exploiting,title={Exploiting Vector Attention and Contextual Prior for Ultrasound Image Segmentation},author={ Xu, L. and Gao, S. and Shi, L. and Wei, B. and He, Y. },journal={Neurocomputing},volume={454},number={1},year={2021},} 引用，BibTex也要编译，否则出现的是？，但是目前TexStduio我还没有找到在哪里编译BibTex文件。 插入算法图 首先，导入宏包 \\usepackage[ruled,linesnumbered]{algorithm2e}。 之后，导入算法块即可。 工具补充 补充好用网页:手写公式转latex https://editor.codecogs.com/ 手写符号，转latex表达 https://detexify.kirelabs.org/classify/html 截图看公式 https://mathpix.com/ 手写表格，转latex表达 https://www.tablesgenerator.com/","link":"/2022/01/25/Latex/Latex%E6%9C%9F%E5%88%8A%E8%AE%BA%E6%96%87%E7%9A%84%E6%8E%92%E7%89%88/"},{"title":"Latex基础教程(一)","text":"hljs.initHighlightingOnLoad(); 本文主主要包含Latex文件基本结构、如何处理中文、字体字号的设置、文档篇章的设置、特殊字符的输入以及图像的插入和排版，主要参考了B站的latex中文教程-15集从入门到精通包含各种latex操作视频的前8讲。 Latex文件的基本结构导言区 在latex中，我们使用% 来进行注释。 导言区主要进行全局设置 \\title{}设置文章的标题 \\author{}设置文章的的作者 \\date{}设置文章的时间 但是设置的全局的属性是看不到的，要在正文区加\\maketitle才可以显示出来 如果使用的是book类，则输出title是单独在一页的。 1234567% 导言区\\documentclass{book}% report book letter article\\title{My First Document}\\author{Zhengtong Cao}\\date{\\today} 正文区 使用\\begin{}和\\end{}来创建一个环境。 每个文章里最多有一个document环境。 12345678% 正文区\\begin{document} \\maketitle hello, \\LaTeX Let $f(x)$ be define by the formula $f(x)=3x^2+x-1$ \\end{document} 如果两句话之间加一个空行，则相当于一个换行操作。 两段话之间可以加入多个空行，但是现实的时候就只有一个空行了。 这里的空行是实实在在的空行，不可以是注释行。之前错误的以为注释行可以作为一个空行，但是编译出来发现之前的换行消失了。 单 是行内公式，双$$$ $$$的作用是行间公式， \\begin{equation},\\end{equation}环境可以产生带编号的行间公式。 123\\begin{equation} AB^2+BC^2=AC^2\\end{equation} Latex中的中文处理texstdio配置设置编译器为XeLateX 设置默认编码为UTF-8 在导言区导入ctex宏包 未定义符号的定义1234$\\angle$A=90$\\degree$% latex内没有对应的命令\\degree的命令，编译时会显示错误，要在导言区重新定义\\newcommand{\\degree}{^\\circ} latex内没有对应的命令\\degree的命令，要在导言区重新定义，\\newcommand{\\degree}{^\\circ} 由于latex的编译器不同造成的，在typora里就定义了\\degree命令，但在latex里就没有，要重新定义。 中文的输入123456\\usepackage{ctex}\\title{\\heiti \\LaTeX 学习笔记}%\\author{Zhengtong Cao}\\author{\\kaishu 曹政通}\\date{\\today} 字体的设置：\\heiti 黑体、kaishu 楷体。 导入宏包后直接输入即可，无视下面的红色下滑线。 在cmd里输入以下命令，可以弹出ctex的宏包手册。这里也可以直接导入\\ctexart,\\ctexbook等。 1texdoc ctex 可以使用texdoc命令来查看各种文档 12texdoc lshort-zh# 一个latex的简易学习文件，112分钟入门 Latex字体字号的设置 字体族设置字体族主要分为罗马字体\\textrm{Roman Family}；无衬线字体\\textsf{San serif Family}；打字机字体\\texttt{Typewriter} 如图，\\rmfamily 代表以后的字体都是罗马体，如果之后又其他的字体的设置如\\ttfamily 则上个作用自动结束，开始新的作用。 一般使用时会加上{\\rmfamily xxx}来限定字体族的作用范围。 \\rmfamily罗马体，\\sffamily 无衬线字体，\\ttfamily打字机字体。 字体系列设置字体系列主要分为粗细、宽度设置如\\textmd{ Medium Series } 和 \\textbf{ Boldface Series }（字体设置命令） { \\mdseries xxx }和{ \\bfseries xxx } (字体设置声明) 字体形状命令字体形状直立\\textup{upright Shape}、斜体\\textit{Italic Shape}、伪斜体\\textsl{s1anted Shape}、小型大写\\textsc{Small caps Shape}（字体设置命令） { \\upshape Upright shape} {\\itshape Italic shape} {\\slshape Slanted Shape} {\\scshape Small caps Shape}(字体设置声明) 中文字体{\\songti 宋体} {\\heiti 黑体} {\\fangsong 仿宋} {\\kaishu 楷书}中文字体的\\textbf{粗体}（黑体）与\\textit{斜体}（楷体） 字体大小的设置 设置全文的默认字号大小，一般只有种10pt、11pt、12pt 对于\\ctex宏包来说又一些设置自好操作命令。 自定义字体操作 latex的思想时将内容和排版分里，因此经常在导言区设置\\newcommand{}{}来设计字体样式。 Latex文档的篇章结构提纲构建的几个命令： 1234\\chapter{⟨title⟩} %章\\section{⟨title⟩} %节\\subsection{⟨title⟩} %小节\\subsubsection{⟨title⟩} %子小节 其中\\chapter 只在book 和report 文档类有定义。这些命令生成章节标题，并能够自动编号。 article 文档类带编号的层级为\\section / \\subsection / \\subsubsection 三级； report/book 文档类带编号的层级为\\chapter / \\section / \\subsection 三级 如下，对于节操作的一些参数设计： 带可选参数的变体：\\section[⟨short title⟩]{⟨title⟩}标题使用⟨title⟩ 参数，在目录和页眉页脚中使用⟨short title⟩ 参数 带星号的变体：\\section*{⟨title⟩}标题不带编号，也不生成目录项和页眉页脚 分段操作 分段操作一般是插入一个空行，也可以使用\\par,但是多用插入空行的命令。\\\\的作用是换行而不是分段。 \\ctexart 命令 通过\\ctexart 设置布局时section是居中排版的. 使用\\ctexset命令可以自定义ctexart格式。 排版以后的格式如图所示。 目录的生成 在LATEX 中生成目录非常容易，只需在合适的地方使用命令：\\tableofcontents 这个命令会生成单独的一章（book / report）或一节（article），标题默认为“Contents“ \\tableofcontents生成的章节默认不写入目录（\\section*或\\chapter*） Latex中的特殊字符空白符号 空行分段，多个空行等同1个； 自动缩进，绝对不能使用空格代替； 英文中多个空格处理为1个空格，中文中空格将被忽略； 汉字与其它字符的间距会自动由XeLaTeX处理； 禁止使用中文全角空格。 通过命令来生成空格字符： 12345678910111213141516171819202122% 1em(当前字体中M的宽度)产生一个空格的宽度a\\quad b% 2em 产生的两个空格的宽度a\\qquad b% 约为1/6个空格的宽度a\\,b a\\thinspace b% 0.5个空格命令a\\enspace b% 产生一个空格a\\ b% 硬空格a~b% 1pc=12pt=4.218mm % 产生固定宽度值的空白 a\\kern 1pc ba\\kern -1em ba\\hskip 1em ba\\hspace{35pt}b% 占位宽度(根据大括号内的占位符的宽度产生空白)a\\hphantom{xyz}b%弹性长度(即占满整个的空间)a\\hfill b Latex的控制符由于有些符号在Latex中具有特殊的含义，因此输入的时候前面要加\\ (注意，\\\\代表换行操作，因此这里用\\textbackslash来代替) 1\\# \\$ \\% \\{ \\} \\~{} \\_{} \\&amp; \\textbackslash 输出结果如下： Latex排版符号排版中的特殊符号如下： 1\\S \\P \\dag \\ddag \\copyright \\pounds TEX标志符号123456789101112131415% 基本符号\\Tex{} \\LaTeX{} \\LaTeXe{}\\usepackage{xltxtra}% 提供了针对XeTeX的改进并且加入了XeTeX的LOGO% xltxra宏包\\XeLaTeX\\usepackage{texnames}% texnames宏包提供\\AmSTeX{} \\AmS-\\LaTeX{}\\BibTeX{} \\LuaTeX{}\\usepackage{mflogo}% mflogo宏包\\METAFONT{} \\MF{} \\MP{} 输出结果： 引号1`(左引号) '(右引号) ``(左双引号) ''(右双引号) 连字符使用几个减号的累加来代表不同长度的连字符。 1- -- --- 非英文字符12% 非英文字符\\oe \\OE \\ae \\AE \\aa \\AA \\o \\O \\l \\L \\ss \\SS !`?` 重音符号(以o为例)12%重音符号(以o为例)\\`o \\'o \\^o \\''o \\~o \\=o \\.o \\u{o} \\v{o}\\H{o} \\r{o} \\t{o} \\b{o} \\c{o} \\d{o} Latex的图像插入123456%导言区: \\usepackage{graphicx}%语法:\\includegraphics[&lt;选项&gt;]{&lt;文件名&gt;}%格式: EPS,PDF,PNG,JPEG,BMP\\usepackage{graphicx}\\graphicspath{{figures/},{pic/}} %图片在当前目录下的 figures目录 \\includegraphics[&lt;选项&gt;]{&lt;文件名&gt;} 的必选参数为文件名，可选参数为图片的缩放和旋转。 文件名，可以加类型后缀.jpg .png \\graphicspath{ {figures/},{pic/} } 指定图片的搜索路径，多个路径使用，隔开。 hexo 排版中连续两个大括号之间要加空格。 123456789101112% 指定缩放比例\\includegraphics[scale=0.3]{lion}\\includegraphics[scale=0.03]{mountain}\\includegraphics[scale=0.3]{oscilloscope}% 指定固定宽度和高度\\includegraphics[height=2cm]{lion}\\includegraphics[width=2cm]{lion.jpg}% 指定相对的高度和宽度\\includegraphics[width=0.2 \\textwidth]{lion}\\includegraphics[width=0.2 \\textheight]{mountain}% 指定多个参数\\includegraphics[angle=-45,width=0.2\\textwidth]{lion} 细节查看: 1texdoc graphic","link":"/2022/02/08/Latex/Latex%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B(%E4%B8%80)/"},{"title":"Latex基础教程（二）","text":"hljs.initHighlightingOnLoad(); 本文主主要包含Latex的表格操、作浮动体的设置、参考文献以及自定义命令的设置，主要参考了B站的latex中文教程-15集从入门到精通包含各种latex操作视频的后9讲。 Latex中的表格123\\begin{tabular}[&lt;垂直对齐方式&gt;]{&lt;列格式说明&gt;} &lt;表项&gt;&amp;&lt;表项&gt;&amp; ...&lt;表项入&gt; \\\\\\end{tabular} 用\\\\\\表示换行 用&amp;表示不同的列 对于格式说明参数主要有： l-本列左对齐 c-本列居中对齐 r-本列右对齐 p{&lt;宽&gt;}-本列宽度固定,能够自动换行 如图，一共五列，因此就有五个格式说明符。 其次，两个列之间加一个竖线加一个”|“，如果加一个双竖线就加一个”||“。 如果要加一个横线了，就在行前或行后加\\hline。 帮助文档的打开 123texdoc booktab # 三线表texdoc longtab # 长表格宏包texdoc tabu # 综合表格宏包 Latex中的浮动体浮动体的创建操作LATEX 预定义了两类浮动体环境figure 和table。习惯上figure 里放图片，table 里放表格，但并没有严格限制，可以在任何一个浮动体里放置文字、公式、表格、图片等等任意内容。 对于一般的图像，有figure浮动体环境。 对于表格，有table浮动体环境。 结果可以看出图像和表格的位置都发生了浮动效果。 给浮动体加属性以table 环境的用法举例： 123\\begin{table}[⟨placement⟩]...\\end{table} ⟨placement⟩ 参数提供了一些符号用来表示浮动体允许排版的位置，如hbp 允许浮动体排版在当前位置、底部或者单独成页。table 和figure 浮动体的默认设置为tbp。 \\caption{...}为设置浮动体的标题。 \\centering为设置图片的居中和偏左偏右。 \\label{...}为设置标签操作，方便后面的应用。 \\ref{...}为引用设置，和标签在一起来实现交叉引用。 这里浮动体的交叉引用和标号是自动完成的。 总结： 浮动体可以实现灵活的分页（避免无法分割的内容产生的页面六百留白） 可以给图表添加标题。 交叉引用。 123456789figure环境(table环境与之类似)\\begin{figure}[&lt;允许位置&gt;]&lt;任意内容&gt;...\\end{figure}&lt;允许位置&gt;参数(默认tbp)% h，此处( here)-代码所在的上下文位置% t，页顶(top)-代码所在页面或之后页面的顶部% b，页底( bottom)一代码所在页面或之后页面的底部% p，独立一页(page)-浮动页面 标题控制( caption、bicaption等宏包) 并排与子图表( subcaption、subfig、floatrow等宏包) 绕排(picinpar、 wrapfig等宏包) Latex中的参考文献thebibliography环境的使用 一次管理，一次使用参考文献格式: 12345\\begin{thebibliography}{编号样本}\\bibitem[记号]{引用标志}文献条目1\\bibitem[记号]{引用标志}文献条目2end{thebibliography}% 其中文献条目包括:作者，题目，出版社，年代，版本，页码等。 如下为一个具体的案例： 123456789101112引用文章\\cite{article1}，引用一本书\\cite{book1}\\begin{thebibliography}{99}\\bibitem{article1}陈立辉,苏伟,蔡川,陈晓云，\\emph{基于LaTex的Meb数堂公式提取方法研究}[7].计算机科学．2014(86)\\bibitem{book1}William H. Press,saul A. Ieukolsky,william T. Vetterling,Brian P. Elanneny.,\\emph{Numerical Recipes 3rd Edition:The Art of scientific Computing}Cambridge University Press,New York ,2007.\\bibitem{latexGuide} Kopka Helmut,w.Daly Patrick,\\emph{Guide to \\LaTeX}, $4^{th}$ Edition.Available at \\texttt{http://www.amazon.com}.\\bibitem{latexMath} Graetzer. George，\\emph{Math Into \\LaTeX},BirkhAtuser Boston;3 edition (June 22，2000).\\end{thebibliography} \\emph{}表示要强调的具体内容。 引用的时候可以采用：\\cite{引用标志1,引用标志2,...}。因此，这样管理参考文献需要给每个参考文献进行详细排版，比较的麻烦，同时也方便文献的跨文献的引用。 因此需要一个可以一次管理多次使用的包。 使用BibTex文件进行参考文献管理 bibtex文件的格式如下： 12345@⟨type⟩{⟨citation⟩, ⟨key1⟩ = {⟨value1⟩}, ⟨key2⟩ = {⟨value2⟩},...} 其中⟨type⟩ 为文献的类别，如article 为学术论文，book 为书籍，incollection 为论文集中的某一篇，等等。 ⟨citation⟩ 为\\cite 命令使用的文献标签。在⟨citation⟩ 之后为条目里的各个字段，以⟨key⟩ = {⟨value⟩} 的形式组织。 我们在此简单列举学术论文里使用较多的BIBTEX 文献条目类别： article 学术论文，必需字段有author, title, journal, year; 可选字段包括volume, number,pages, doi 等； book 书籍，必需字段有author/editor, title, publisher, year; 可选字段包括volume/number,series, address 等； incollection 论文集中的一篇，必需字段有author, title,booktitle, publisher, year; 可选字段包括editor, volume/number, chapter, pages, address 等； inbook 书中的一章，必需字段有author/editor, title,chapter/pages, publisher, year; 可选字段包括volume/number, series, address 等。 具体的使用： 在导言区设置参考文献的格式 1234\\bibliographystyle{plain}%plain unsrt alpha abbrv\\bibliographystyle[round]{plain}% 引用的括号变为圆括号 在正文区设置参考文献 1234567%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\bibliography{test} % 可以不写扩展名\\end{document} 然后bibtex.exe会编译.aux的辅助文件，根据\\citation在.bib文件中选择指定的参考文献，并指定的参考文献按照指定的样式进行排版，生成另一个.bbl辅助文件。 \\cite {xxx}，引用的标志为下图所示。 使用google的相应功能来实现数据库的维护。 在搜索结果中打开引用链接。 打开bibtex可以得到该文件对于的bibtex数据。 将生成的bibtex数据copy到文献数据库中即可。 使用知网导入数据，需要导入zotero的FireFox浏览器。 1.打开浏览器的关联插件； 2.选择需要的文献。 3.在Zotero里选择导出的文献，来执行导出条目的操作。 4.打开test.bib文件 5.引用之后的排版如下： 1234567%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\bibliography{test} % 可以不写扩展名\\end{document} 默认只能显示导入数据库内已经引用的文献。 对于还未引用的文献，可以使用\\nocite{}来显示。 12\\nocite{*} % 表示所有未引用的参考文献\\notice{xxx} % 特定的未引用的参考文献 特别注意，重新编译的时候要手动删除之前的参考文献，否则编译完之后没有变化。 12345678%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\nocite{*} \\bibliography{test} % 可以不写扩展名\\end{document} 输出的结果如下： 使用BibLaTex文件进行参考文献管理biblatex 宏包是一套基于LATEX 宏命令的参考文献解决方案，提供了便捷的格式控制和强大的排序、分类、筛选、多文献表等功能。biblatex 宏包也因其对UTF-8 和中文参考文献的良好支持，被国内较多LATEX 模板采用。 新的TEX参考文献排版引擎biblatex/ biber样式文件(参考文献样式文件—bbx文件，引用样式文件—cbx文件)使用LATEx编写支持根据本地化排版，如: 12biber -l zh__pinyin texfile %用于指定按拼音排序biber -l zh__stroke texfile %用于按笔画排序 配置编译器，将默认的文献工具设置为Biber。 首先是在导言区调用biblatex 宏包。宏包支持以⟨key⟩=⟨value⟩ 形式指定选项，包括参考文献样式style、参考文献著录排序的规则sorting 等。 1\\usepackage[style=numeric,backend=biber]{biblatex} 接着在导言区使用\\addbibresource 命令为biblatex 引入参考文献数据库。与基于BIBTEX的传统方式不同的是，这里需要写完整的文件名。 1\\addbibresource{test.bib} 在正文中使用\\cite 命令引用参考文献。除此之外还可以使用丰富的命令达到不同的引用效果， 如\\citeauthor 和\\citeyear 分别单独引用作者和年份， \\textcite 和\\parencite分别类似natbib 宏包提供的\\citet 和\\citep 命令，以及脚注式引用\\footcite 等。 最后在需要排版参考文献的位置使用命令\\printbibliography 默认的title是英文的Reference，可以通过增加可选参数来修改。 ```latex\\printbibliography[title={参考文献}] 123456789101112 &gt; 重新编译时，要清除上一次生成的辅助文件。- **开源的样式文件**https://gitlab.com/CasperVector/biblatex-caspervector - 先将格式文件拷贝到当前工作目录中。 ![](https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/latex/202202072320093.png) ```latex \\usepackage[style=caspervector,backend=biber,utf8]{biblatex} % 修改导言区的文件，使得引用caspervector样式 但是文章是中英文混排的，需要修改biber.exe的相关配置。 并且修改导言区的宏包配置。 12345678\\usepackage[style=caspervector,backend=biber,utf8,sorting=centy]{biblatex}% sorting=centy 就是按先英文、再中文、再姓名、再标题、再出版年份的顺序进行排序% c——chinese 中文% e——English 英文% n——name 作者姓名% t——title 文献标题% y——year 出版年份 这里需要连续编译两次，来产生正确的编号。 使用.bat进行批处理编译流程。 LaTeX自定义命令和环境\\newcommand一定义命令命令只能由字母组成,不能以 \\end开头 1\\newcommand&lt;命令&gt;[&lt;参数个数&gt;][&lt;首参数默认值&gt;]{&lt;具体定义&gt;} \\newcommand可以是简单字符串替换12%例如:使用\\PRC相当于 People 's Republic of \\emph{China}这一串内容\\newcommand \\PRC{People's Republic of \\emph{china}} \\newcommand也可以使用参数1234567891011%参数个数可以从1到9,使用时用#1,#2,..... .,#9表示\\newcommand \\ loves[2]{#1 喜欢#2}\\newcommand \\hatedby[2]{#2不受#1喜欢}\\begin{document}\\loves{猫儿}{鱼}\\hatedby{猫儿}{萝卜}\\end{document}% 猫儿喜欢鱼% 萝卜不受猫儿喜欢 \\newcommand的参数也可以有默认值123456789%指定参数个数的同时指定了首个参数的默认值，那么这个命令的%第一个参数就成为可选的参数(要使用中括号指定)\\newcommand \\love[3][喜欢]{#2#1#3}\\begin{document}\\love[最爱]{猫儿}{鱼}\\end{document}% 猫儿最爱鱼 \\renewcommand-重定义命令1234%与 \\newcommand 命令作用和用法相同,但只能用于已有命令% \\renewcommand&lt;命令&gt;[&lt;参数个数&gt;][&lt;首参数默认值&gt;]{&lt;具体定义&gt;}\\renewcommand\\abstractname{内容简介}% 将摘要的名称改为内容简介 注意，该命令只能修改已经定义的命令，不能修改还没有的命令，其他地方的使用方法相似。 定义和重定义环境12345% 基本用法和重定义命令类似\\newenvironment{&lt;环境名称&gt;}[&lt;参数个数&gt;][&lt;首参数默认值&gt;] {&lt;环境前定义&gt;}{&lt;环境后定义&gt;}\\renewenvironment{&lt;环境名称&gt;}[&lt;参数个数&gt;][&lt;首参数默认值&gt;]% {&lt;环境前定义&gt;}{&lt;环境后定义&gt;} 为book类中定义摘要( abstract)环境 12345678910111213% 导言\\newenvironment{myabstract}[1][摘要]%{\\small \\begin{center}\\bfseries #1 \\end{center}% \\begin{quotation}}%{\\end{quotation}}% 正文\\begin{document}\\begin{myabstract}[我的摘要]% 我的摘要 -&gt; #1参数 这是一段自定义格式的摘要...\\end{document} 重定义参数的嵌套使用： 123456789101112131415% 环境参数只有&lt;环境前定义&gt;中可以使用参数，% &lt;环境后定义&gt;中不能再使用环境参数。% 如果需要，可以先把前面得到的参数保存在一个命令中，在后面使用:\\newenvironment{Quotation}[1]%{\\newcommand \\quotesource{#1}% \\begin{quotation}}% {\\par \\hfill--- 《textit{\\quotesource}》% \\end{quotation}} % 正文\\begin{document} \\begin{Quotation}{易$\\cdot$乾} 初九,潜龙勿用。 \\end{Quotation}.\\end{document} 总结： 定义命令和环境是进行LaTeX格式定制、达成内容与格式分离且标的利器。 使用自定义的命令和环境把字体、字号、缩进、对齐、间距等各种琐细的内容包装起来，赋以一个有意义的名字,可以使文挡结构清晰、代码整洁、易于维护。 在使用宏定义的功能时，要综合利用各种已有的命令、环境、变量等功能，事实上，前面所介绍的长度变量与盒子、字体字号等内容，大多并丕直接出现在文档正文史，而主要都是用在实现各种结构化的宏定义里。 问题汇总 中文乱码问题。在网上下载了一个中文模板，跑起来没问题，语句测试也没有问题。但是在我的文件里却一再出现乱码。 原因：编码问题。.tex文件要以utf-8格式存储。然后导言区加入： 1\\usepackage[UTF8,noindent]{ctex} 编译器的配置。右侧的Default compiler默认值是pdflatex。这个并不支持中文的。因此将其设置为xelatex。 更多教程请见https://www.bilibili.com/video/BV1Zh411y7ps?p=2","link":"/2022/02/08/Latex/Latex%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B(%E4%BA%8C)/"},{"title":"Ch1-Ch2 概述和预备知识","text":"hljs.initHighlightingOnLoad(); 本文主要讲解的是视觉SLAM的第一章和第二章的内容，主要介绍了SLAM是什么，有几部分组成，本书主要介绍的主要的内容等。对于Cmake和相关的作业后面还会有一些学习的补充。 课程内容与预备知识SLAM的应用实例SLAM是做什么的？ 室内室外的定位过程 对于视觉SLAM其实是通过使用相机本身的成像来进行位置的估计，通过提取相关的特征点，来反推相机的姿态的。本课程主要探索的是，这些点是如何提取的，以及如何根据点的信息来反推相机的姿态信息。 当然，可以使用GPS激光等其他的传感器来进行分析的，但是现阶段相机是完全可以实现上述定位的过程的。 稀疏-半稠密重建 如图就是一个典型的半稠密建图semi-dense，这样的工作主要是使用单目相机等廉价的相机来实现的。 稠密重建 使用的是比较昂贵的RGBD相机来实现的，既可以采集到图像也可以采集到深度信息。 总结：SLAM可以做的就是定位和环境重建。 SLAM可以用在什么地方？ 手持设备的定位； 自动驾驶汽车；SLAM的精度要比GPS搞，GPS一般可以达到10m左右。SLAM的定位精度在5cm，但是这个受到相机精度的影响。 AR增强现实。 课程内容 SLAM：Simultaneous Localization and Mapping，即同时定位和地图构建。 它是指搭载特定的传感器的主体，在没有环境先验信息的情况下，于运动的过程建立环境模型，同时估计自己的运动。对于以相机为主体传感器的系统，被称为视觉SLAM。 SLAM背后的数学知识，主要是前六章的在讲解，主要有三维空间的刚体运动，李群和李代数、非线性优化。 SLAM背后的计算机视觉，主要是低五章的相机模型，PCL和Opencv等。 工程实践主要是后七章的内容，主要有视觉里程计VIO、后端、回环检测和建图。 教材推荐： 视觉SLAM十四讲，比较浅显，容易入门。 多视图几何MVG，比较全面的计算机几何的一本书，太全面了，会淹没在一些细节中，导致比较难以理解。 机器人状态估计，但是比较偏robotic，偏估计，视觉的东西比较少，数学公式极其多，很深刻。 本门看强调在理解公式的基础上进行代码的实践。 其中，第九讲是个工程问题，自己照着敲代码就可以，第十四讲是展望。 预备知识与课程使用的环境 数学：高等数学、线性代数（矩阵论）、概率论 编程：C++、Linux，了解语法和基本命令即可 英语：文献、文档阅读能力 环境：Ubuntu 16.04 初识SLAM 一般情况下，这两个问题是同时解决的。 传感器主要分为内置的和外置的。 外置的传感器会对使用范围有限制，对使用的环境有多的依赖，而内置的相对的比较自由一些。 内置的传感器测量的数据比较简介，是将测量的数据通过传感器模型进行处理才可以得到想要的数据，而外置传感器如GPS，可以直接获取。 相机的特点是便宜，轻便，信息丰富，适合民用。 深度相机：会产生两个图，RGB和深度图，通过物理方法来获取深度信息，可以获取立体信息。 主要使用的是TOF和红外结构光的方法； 但是其测量的距离可能较短，其次就是噪声大容易受到日光的干扰，无法测量透视的物体； 所以其主要在室内使用，室外较难应用。 双目相机：会有两个图，通过视差来计算深度信息，可以获取立体的信息。 是通过两个相机之间的距离，基线来确定的； 其测量的范围也是受到基线和镜头分辨率的的影响； 对计算的要求较高，需要GPU加速。 单目相机：无深度信息，需要其他的手段来估计。 就是距离较近的事物移动速度快； 较远的事物移动速度慢，这样可以较好的来估计位置的相对关系； 但是，其存在一定的尺度不确定性，就是我们不知道其这是的尺寸，只能得到相对值。 根据近处的事物运动快，远处的事物运动慢来进行间接的测距，但在两张图上捕捉同一个特征点是有点难度的。单双目其实都是这个原理 解决短距离和小范围的情况时，可以使用视觉里程计VO，输入时一张一张的图片，输出为预测得到的距离定位的信息。 但如果时远距离长时间的定位和建图的，之前产生误差和噪声，随着世实践会逐渐的累积，产生漂移，需要后端来进行优化。其主要解决的是一个估计和优化问题，没有很多计算机视觉的内容。 最后又回到起始点，此时回来以后不一定会回到原点，需要进行检测，将偏移的轨迹归位。 有些场合还是需要建图算法。 前端，即视觉里程计，就是用来计算和估计图像的相对位置。 后端，滤波和图优化，就是进行噪声消除和优化误差的。 视觉SLAM流程包括以下步骤: 传感器信息读取: 在视觉SLAM中主要为相机图像信息的读取和预处理。如果是在机器人中，还可能有码盘、惯性传感器等信息的读取和同步。 视觉里程计(Visual Odometry,VO): 视觉里程计的任务是估算相邻图像间相机的运动,以及局部地图的样子。VO又称为前端(Front End)。 视觉里程计不可避免地会出现累积漂移(Accumulating Drift)问题。 需要后端和回环检测来减少漂移现象。 前端的主要任务是图像的特征提取和匹配。 后端优化 (Optimization): 后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息,对它们进行优化,得到全局一致的轨迹和地图。由于接在VO之后，又称为后端(Back End)。 在视觉 SLAM中，后端则主要是滤波与非线性优化算法。 其实就是状态估计问题，机器人学中的状态估计和因子图主要解决的其实就是后端的问题。 回环检测 (Loop Closing): 回环检测判断机器人是否到达过先前的位置。如果检测到回环，它会把信息提供给后端进行处理。 回环检测的核心问题就是减少消除由于时间漂移造成的累积误差 其次就是如何识别出是否已经回到原点了。 建图 (Mapping): 它根据估计的轨迹,建立与任务要求对应的地图. 地图的形式包括： 度量地图：精确表示地图物体的位置关系分为稀疏和稠密，这里稀疏图仅仅包就特定的物体作为路标，而稠密图将三维空间网格化，每个网格仅仅有占用、未知、空闲三个状态。 拓扑地图：更强调地图元素之间的关系，有节点和边组成，并且仅仅考虑节点的连通性。 ​ 视觉SLAM的数学描述这里的核心方程就是一个运动方程，一个观测方程，主要解决的就是如何通过带噪声的数据，来估计内部的隐变量(即确定运动方程的参数) 这里，设$x_k$为k时刻的相机的状态位置，$y_i$ 代表路标； $z_{k,j}$ 代表k时刻第j个路标的测量值，其可以是像素在照片中的坐标（相机）或是一个距离和角度信息（激光），跟传感器的形式有关； $v_{k,j}$为测量噪声。 x_k \\rightarrow x_{k+1}\\\\ x_{k+1}=f(x_k,u_k) \\quad 运动方程\\quad u_k为输入\\\\ z_{k,j}=g(x_k,y_j)+v_{k,j} \\quad 测量方程 $(u_k,z_{k,j}) \\rightarrow x_k,y_j$ ：这里对于 $x_k$ 的确定称为定位，对于 $y_j$ 的确定称为建图。 以下是高博的手稿： 噪声$v_{k,j}$ 可以分为高斯系统和非高斯系统： 最简单的线性高斯系统，使用kalman filter 就可以很好的解决； 对于复杂非线性的高斯系统，可以使用Extended Kalman Filter来解决，在21世纪初期，EKF一直都是主流算法。 但是EKF有两个主要的缺点，主要是线性化之后的误差和噪声高斯化的假设，于是引入了粒子滤波等。 现如今，滤波算法都不如图优化的方法，如果计算条件允许，我们将优先考虑使用图优化的方法。 代码实战本章的代码实在太简单了，因此这里将一些基础知识： 之前我们编译可以直接使用g++ 或 clang (高博说clang的效果是比g++)要好一点的， 1234g++ helloSLAM.cpp# 使用g++直接来编译程序clang helloSLAM.cpp# 使用clang来编译程序 但是，对于大规模的项目，比如里面包含了`xxx.h 之类的库文件的直接编译就显得麻烦了，因此这里使用Cmake编译工具。 1234567891011121314151617181920212223# 声明要求的 cmake 最低版本cmake_minimum_required(VERSION 2.8)# 声明一个 cmake 工程project(HelloSLAM)# 设置编译模式set(CMAKE_BUILD_TYPE &quot;Debug&quot;)# 添加一个可执行程序# 语法：add_executable( 程序名 源代码文件 ）add_executable(helloSLAM helloSLAM.cpp)# 添加hello库add_library(hello libHelloSLAM.cpp)# 共享库add_library(hello_shared SHARED libHelloSLAM.cpp)# 添加可执行程序调用hello库中函数add_executable(useHello useHello.cpp)# 将库文件链接到可执行程序上target_link_libraries(useHello hello_shared) add_executable 函数是将含有main的文件编译称为可执行文件 add_library 函数将.h文件编成为库文件，方便调用。 target_link_libraries将库文件链接到可执行程序上，这样才能其真正的调用的.h文件。","link":"/2022/03/20/SLAM/ch1-ch2-%E6%A6%82%E8%BF%B0%E5%92%8C%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"title":"Kalman Filter小项目","text":"hljs.initHighlightingOnLoad(); 本文是通过一个位置判断的项目，来测试kalman filter的简单使用，了解其在opencv中的具体实现。 实现的简单的kalman filter123456789101112class KalmanFilter: kf = cv2.KalmanFilter(4, 2) kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32) kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) def predict(self, coordX, coordY): ''' This function estimates the position of the object''' measured = np.array([[np.float32(coordX)], [np.float32(coordY)]]) self.kf.correct(measured) predicted = self.kf.predict() x, y = int(predicted[0]), int(predicted[1]) return x, y 这个kalman滤波器主要是用来预测位置的。 绘制坐标点并预测 1234567891011121314img = cv2.imread(&quot;Pysource Kalman filter/blue_background.webp&quot;)ball_positions = [(50, 100), (100, 100), (150, 100), (200, 100), (250, 100), (300, 100), (350, 100)]for pt in ball_positions: cv2.circle(img, pt, 15, (0, 20, 220), -1) # 参数 绘图对象 位置 大小 颜色BGR 粗细 -1代表实心 # 绘制预测点 predicted = kf.predict(pt[0], pt[1]) cv2.circle(img, predicted, 15, (20, 220, 0), 4)cv2.imshow(&quot;Img&quot;, img)cv2.waitKey(0) 1234567891011121314# 根据上述值向后预测10代for i in range(10): predicted = kf.predict(predicted[0], predicted[1]) cv2.circle(img, predicted, 15, (20, 220, 0), 4) print(predicted)&gt;&gt;&gt;(550, 99)(600, 98)(649, 97)(698, 96)(747, 95)(796, 94)(845, 92)(894, 90)(942, 88) 123456789101112131415ball2_positions = [(4, 300), (61, 256), (116, 214), (170, 180), (225, 148), (279, 120), (332, 97), (383, 80), (434, 66), (484, 55), (535, 49), (586, 49), (634, 50),(683, 58), (731, 69), (778, 82), (824, 101), (870, 124), (917, 148),(962, 169), (1006, 212), (1051, 249), (1093, 290)]for pt in ball2_positions: cv2.circle(img, pt, 15, (0, 20, 220), -1) # 参数 绘图对象 位置 大小 颜色BGR 粗细 -1代表实心 # 绘制预测点 predicted = kf.predict(pt[0], pt[1]) cv2.circle(img, predicted, 15, (20, 220, 0), 4)# 根据上述值向后预测10代for i in range(10): predicted = kf.predict(predicted[0], predicted[1]) cv2.circle(img, predicted, 15, (20, 220, 0), 4) print(predicted) 同理，预测第二个球的轨迹。 orange轨迹预测12# 创建橘子检测器od = OrangeDetector() 1234# 实时的检测orange的轨迹orange_bbbox = od.detect(frame)x1, y1, x2, y2 = orange_bbboxcv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 4) 之后我们将矩形框转换为中心点 12345678# 视频播完就退出orange_bbbox = od.detect(frame)x1, y1, x2, y2 = orange_bbbox# cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 4)# 确定orange的中心cx = int((x1 + x2) / 2)cy = int((y1 + y2) / 2)cv2.circle(frame, (cx, cy), 20, (0, 0, 255), -1) 以上是根据目标检测得到的实时orange的位置，之后我们来用kalman filter预测Orange位置。 123# 滤波器预测下一时刻的位置predicted = kf.predict(cx, cy)cv2.circle(frame, predicted, 20, (220, 20, 0), 5) 完整代码： 1234567891011121314151617181920212223242526272829303132333435import cv2from orange_detector import OrangeDetectorfrom kalmanfilter import KalmanFilter# 读取视频cap = cv2.VideoCapture(&quot;Pysource Kalman filter/orange.mp4&quot;)# cap = cv2.VideoCapture(0)# 创建橘子检测器od = OrangeDetector()# 创建kfkf = KalmanFilter()while True: ret, frame = cap.read() if ret is False: break # 视频播完就退出 orange_bbbox = od.detect(frame) x1, y1, x2, y2 = orange_bbbox # cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 4) # 确定orange的中心 cx = int((x1 + x2) / 2) cy = int((y1 + y2) / 2) cv2.circle(frame, (cx, cy), 20, (0, 0, 255), -1) # 滤波器预测下一时刻的位置 predicted = kf.predict(cx, cy) cv2.circle(frame, predicted, 20, (220, 20, 0), 5) # print(orange_bbbox) cv2.imshow(&quot;Frame&quot;, frame) key = cv2.waitKey(50) if key == 27: break","link":"/2022/02/13/opencv/kalman-filter%E5%B0%8F%E9%A1%B9%E7%9B%AE/"},{"title":"Object_detection_app项目","text":"hljs.initHighlightingOnLoad(); 本项目主要是利用yolov4目标检测网络，实现对固定目标的识别功能，最后将其打包形成.exe文件。但是，最后编译的过程还有一定的bug,还未能实现封装。 初始化相机12345678910cap = cv2.VideoCapture(0)# 修改相机参数 整理修改的是相机的frame的H,Wcap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)while True: # 如果不加while循环的话，生成的程序会一闪而过 ret, frame = cap.read() cv2.imshow(&quot;Frame&quot;, frame) cv2.waitKey(1) # 单位是ms # 等待时间设为0的话，视像头会会静止，关闭一次窗口才刷新一次 导入目标检测网络1234567# opencv DNNnet = cv2.dnn.readNet(&quot;object_detection_crash_course/dnn_model/yolov4-tiny.weights&quot;, &quot;object_detection_crash_course/dnn_model/yolov4-tiny.cfg&quot;)model = cv2.dnn_DetectionModel(net)# 导入模型model.setInputParams(size=(320, 320), scale=1/255)# size越大，清晰度越大，但是可以速度比较慢# scale的功能是缩放 [0,255]-&gt;[0,1] 导入类别文件123456# 导入类别文件classes=[]with open(&quot;object_detection_crash_course/dnn_model/classes.txt&quot;,&quot;r&quot;) as file_object: for class_name in file_object: class_name = class_name.strip() classes.append(class_name) 目标检测这部分的代码放到相加的whie循环中： 1234567891011121314151617# 目标检测class_idx, scores, bboxs = model.detect(frame)# 返回值依次是类别的idx， 所得的分数， boundingboxs边界框# print(f&quot;class_idx:{class_idx}\\n scores:{scores} \\n bboxs:{bboxs}&quot;)for class_id, score, bbox in zip(class_idx, scores, bboxs): (x, y, w, h) = bbox class_name = classes[class_id] # class_name = classes[class_id[0]] # 4.4.0的版本 # 绘制目标检测三角形, 在窗口对象上绘制 cv2.rectangle(frame, (x, y), (x+w, y+h), (200, 0, 50), 3) # 参数为绘制的对象, 绘制长方形的左上点合右下点, 颜色RGB, 框的粗细 # 识别的种类合coco数据集有关 cv2.putText(frame, str(class_name), (x, y-5), cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(200, 0, 50), thickness=2) 设计鼠标点击1234567891011121314151617181920button_person = Falsedef click_button(event, x, y, flags, params): global button_person if event == cv2.EVENT_LBUTTONDOWN: # print(x, y) polygan = np.array([[(20, 20), (220, 20), (220, 70), (20, 70)]]) is_inside = cv2.pointPolygonTest(polygan, (x,y), False) if is_inside: print(&quot;inside the button&quot;) if button_person is False: button_person = True else: button_person = False # 相当于一个开关，点击以下开始识别，再点一下就关闭识别# 产生一个新的窗口cv2.namedWindow(&quot;Frame&quot;)cv2.setMouseCallback(&quot;Frame&quot;, click_button) 之后就可以来设计窗口的打开的开关： 绘制类别字体1234567# 创建按钮# 这里使用多边行来绘制polygan = np.array([[(20, 20), (220, 20), (220, 70), (20, 70)]])cv2.fillPoly(frame, polygan, (0, 0, 200))# cv2.rectangle(frame, (20, 20), (220, 70), (0, 0, 200), -1)# 厚度为-1代表布满cv2.putText(frame, &quot;Person&quot;, (30, 60), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3) 由于绘制字体类别和设计鼠标点击的逻辑的内容有些复杂，因此我们直接导入写好的文件。 设置按钮这里定义了一个Button类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import cv2import numpy as npclass Buttons: def __init__(self): # Font self.font = cv2.FONT_HERSHEY_PLAIN self.text_scale = 3 self.text_thick = 3 self.x_margin = 20 self.y_margin = 10 # Buttons self.buttons = {} self.button_index = 0 self.buttons_area = [] np.random.seed(0) self.colors = [] self.generate_random_colors() def generate_random_colors(self): for i in range(91): random_c = np.random.randint(256, size=3) self.colors.append((int(random_c[0]), int(random_c[1]), int(random_c[2]))) def add_button(self, text, x, y): # Get text size textsize = cv2.getTextSize(text, self.font, self.text_scale, self.text_thick)[0] right_x = x + (self.x_margin * 2) + textsize[0] bottom_y = y + (self.y_margin * 2) + textsize[1] self.buttons[self.button_index] = {&quot;text&quot;: text, &quot;position&quot;: [x, y, right_x, bottom_y], &quot;active&quot;: False} self.button_index += 1 def display_buttons(self, frame): for b_index, button_value in self.buttons.items(): button_text = button_value[&quot;text&quot;] (x, y, right_x, bottom_y) = button_value[&quot;position&quot;] active = button_value[&quot;active&quot;] if active: button_color = (0, 0, 200) text_color = (255, 255, 255) thickness = -1 else: button_color = (0, 0, 200) text_color = (0, 0, 200) thickness = 3 # Get text size cv2.rectangle(frame, (x, y), (right_x, bottom_y), button_color, thickness) cv2.putText(frame, button_text, (x + self.x_margin, bottom_y - self.y_margin), self.font, self.text_scale, text_color, self.text_thick) return frame def button_click(self, mouse_x, mouse_y): for b_index, button_value in self.buttons.items(): (x, y, right_x, bottom_y) = button_value[&quot;position&quot;] active = button_value[&quot;active&quot;] area = [(x, y), (right_x, y), (right_x, bottom_y), (x, bottom_y)] inside = cv2.pointPolygonTest(np.array(area, np.int32), (int(mouse_x), int(mouse_y)), False) if inside &gt; 0: print(&quot;IS Ac&quot;, active) new_status = False if active is True else True self.buttons[b_index][&quot;active&quot;] = new_status def active_buttons_list(self): active_list = [] for b_index, button_value in self.buttons.items(): active = button_value[&quot;active&quot;] text = button_value[&quot;text&quot;] if active: active_list.append(str(text).lower()) return active_list 之后开始实例化Button: 显示button： 设计点击激活操作： 完整的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import cv2import numpy as npfrom object_detection_crash_course.gui_buttons import Buttons# 初始化Buttonbutton = Buttons()button.add_button(&quot;person&quot;, 20, 20)button.add_button(&quot;cell phone&quot;, 20, 100)button.add_button(&quot;keyboard&quot;, 20, 180)button.add_button(&quot;remote&quot;, 20, 260)button.add_button(&quot;scissors&quot;, 20, 340)colors = button.colors# opencv DNNnet = cv2.dnn.readNet(&quot;object_detection_crash_course/dnn_model/yolov4-tiny.weights&quot;, &quot;object_detection_crash_course/dnn_model/yolov4-tiny.cfg&quot;)model = cv2.dnn_DetectionModel(net)# 导入模型model.setInputParams(size=(416, 416), scale=1/255)# size越大，清晰度越大，但是可以速度比较慢# scale的功能是缩放 [0,255]-&gt;[0,1]# 导入类别文件classes=[]with open(&quot;object_detection_crash_course/dnn_model/classes.txt&quot;,&quot;r&quot;) as file_object: for class_name in file_object: class_name = class_name.strip() classes.append(class_name)# 初始化相机cap = cv2.VideoCapture(0)# 修改相机参数 整理修改的是相机的frame的H,Wcap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)# FULL HD = 1920x1080# button_person = Falsedef click_button(event, x, y, flags, params): # global button_person if event == cv2.EVENT_LBUTTONDOWN: button.button_click(x, y) # print(x, y) # polygan = np.array([[(20, 20), (220, 20), (220, 70), (20, 70)]]) # # is_inside = cv2.pointPolygonTest(polygan, (x,y), False) # if is_inside: # print(&quot;inside the button&quot;) # if button_person is False: # button_person = True # else: # button_person = False # # 相当于一个开关，点击以下开始识别，再点一下就关闭识别# 产生一个新的窗口cv2.namedWindow(&quot;Frame&quot;)cv2.setMouseCallback(&quot;Frame&quot;, click_button)while True: # 如果不加while循环的话，生成的程序会一闪而过 ret, frame = cap.read() # 导出激活的button active_button = button.active_buttons_list() # 目标检测 class_idx, scores, bboxs = model.detect(frame) # 返回值依次是类别的idx， 所得的分数， boundingboxs边界框 # print(f&quot;class_idx:{class_idx}\\n scores:{scores} \\n bboxs:{bboxs}&quot;) for class_id, score, bbox in zip(class_idx, scores, bboxs): (x, y, w, h) = bbox class_name = classes[class_id] # class_name = classes[class_id[0]] # 4.4.0的版本 color = colors[class_id] # 根据id分配颜色 # if button_person and class_name == &quot;person&quot;: if class_name in active_button: # 绘制目标检测三角形, 在窗口对象上绘制 cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3) # 参数为绘制的对象, 绘制长方形的左上点合右下点, 颜色RGB, 框的粗细 # 识别的种类合coco数据集有关 cv2.putText(frame, str(class_name), (x, y-5), cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=color, thickness=2) # # 创建按钮 # # 这里使用多边行来绘制 # polygan = np.array([[(20, 20), (220, 20), (220, 70), (20, 70)]]) # cv2.fillPoly(frame, polygan, (0, 0, 200)) # # cv2.rectangle(frame, (20, 20), (220, 70), (0, 0, 200), -1) # # 厚度为-1代表布满 # cv2.putText(frame, &quot;Person&quot;, (30, 60), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3) # 显示Button button.display_buttons(frame) cv2.imshow(&quot;Frame&quot;, frame) cv2.waitKey(1) # 单位是ms # 等待时间设为0的话，视像头会会静止，关闭一次窗口才刷新一次 项目部署12345678import sysfrom cx_Freeze import setup, Executablesetup(name=&quot;Simple Object Detection Software&quot;, version=&quot;0.1&quot;, description=&quot;This software detects objects in realtime&quot;, executables=[Executable(&quot;main.py&quot;)] ) 结果出现了报错应该是cx_Freeze的问题，目前没解决。","link":"/2022/02/13/opencv/object-detection-app%E9%A1%B9%E7%9B%AE/"},{"title":"车流统计项目","text":"hljs.initHighlightingOnLoad(); 本项目主要是来识别某路段的车流数量，主要分为目标识别和车流数量统计两个部分，对于车流数量计算部分还是需要很强的算法基础，在写的过程中不断会出现新的问题，需要一步一步的调试。但是该项目还有一定的BUG，还有待改进。 目标识别12345678910from object_detection import ObjectDetection# 初始化目标检测od = ObjectDetection()# Detect objects on frame(class_ids, scores, boxes) = od.detect(frame)for box in boxes: (x, y, w, h) = box cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2) 车流数量识别识别两帧中的相同车辆下面要判断连续两帧中的汽车是否为同一个汽车，来避免重复计数。 这里通过连续绘制车辆运行过程的中心点来进行识别是否为同一辆车： 1234567891011for box in boxes: (x, y, w, h) = box # print(&quot;FRAME N°&quot;, count, &quot; &quot;, x, y, w, h) cx = int((x + x + w) / 2) cy = int((y + y + h) / 2) center_point.append((cx, cy)) cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1) cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)for pt in center_point: cv2.circle(frame, pt, 5, (0, 0, 255), -1) 如上面的轨迹检测将会造成我们的中心点的数据越来有多，因此当我们判断好这两量车是同一辆是，可以释放掉同一量车前面时刻的路径。 12345&gt;&gt;&gt;CUR[(567, 905), (434, 750), (1724, 626), (930, 534), (857, 567), (1019, 650), (761, 655), (612, 474), (881, 473), (753, 463), (1867, 590), (641, 436), (687, 451), (943, 459), (1347, 984), (1114, 435), (1417, 465)]PRE[(571, 891), (437, 742), (1750, 635), (761, 648), (1018, 647), (928, 533), (856, 565), (612, 473), (881, 473), (1336, 980), (753, 463), (1118, 436), (942, 458), (1877, 605), (642, 435), (688, 450), (1268, 433), (1424, 466)] 以上为两次的输出结果，由此可以看出来有几对是一一对应的。 12345678910111213141516tracking_objects = {}# 检测车辆的序号track_id = 0for pt in center_points_cur_frame: for pt2 in center_points_pre_frame: distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 10: tracking_objects[track_id] = pt track_id += 1 # 再图中绘制出每一个图片对应的位置for object_id, pt in tracking_objects.items(): cv2.circle(frame, pt, 5, (0, 0, 255), -1) cv2.putText(frame, str(object_id), (pt[0], pt[1] - 7), 0, 1, (0, 0, 255), 2) 但是出现了以下异常的情况，一些车辆被识别但没有被统计。 原因可能是，近处的车移动量会大一点，造成违背计算在内。将distance &lt; 10 改为 distance &lt; 20. 统计车辆的id但是每张图的id都不相同，会不断的添加新的id，于是出现以下的BUG： 其原因是，第一次pre还没有数据，cur也是刚刚才有数据，于是给新的项目赋予了track_id， 下一次的比较又会给旧的目标赋予新的track_id, 于是出现以上错误。 第二次比较时，要将tracking_object的数据和新的目标点数据数据进行比较，代码如下： 123456789101112131415if count &lt;= 2: for pt in center_points_cur_frame: for pt2 in center_points_pre_frame: distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 20: tracking_objects[track_id] = pt track_id += 1else: for pt in center_points_cur_frame: for object_id, pt2 in tracking_objects.items(): distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 20: tracking_objects[object_id] = pt 之后，如图所示没有出现新的问题，就是运行过程中的id掉了一地，没有跟着一起移动。 123456789101112131415161718for object_id, pt2 in tracking_objects.items(): object_exist = False # 判断这个对象是否存在 for pt in center_points_cur_frame: distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 20: tracking_objects[object_id] = pt object_exist = True # 已经证实器存在之后，就不用进行下面的操作了 # 就是跳出本次for循环，这样可以提高效率 if object_exist == False: # 如果这个id遍历了一圈还没有结果，那么就直接删除 tracking_objects.pop(object_id) # 但是，循环过程中时不可以随便的改变里面的元素的 # 因此要创建副本 接下来的问题就是循环过程中时不可以随便的改变里面的元素的，因此要创建副本，具体的操作如下，参与循环的是副本，进行改变的是真实参数： 下面我们为新识别出来的车辆增加标签。 完整代码以下是完整的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import cv2import numpy as npfrom object_detection import ObjectDetectionimport math# 初始化目标检测od = ObjectDetection()cap = cv2.VideoCapture(&quot;los_angeles.mp4&quot;)# 初始化计算器count = 0# center_point = []center_points_pre_frame = []tracking_objects = {}# 检测车辆的序号track_id = 0while True: ret, frame = cap.read() count += 1 if not ret: break # 当前窗口内的点 center_points_cur_frame = [] # Detect objects on frame (class_ids, scores, boxes) = od.detect(frame) for box in boxes: (x, y, w, h) = box # print(&quot;FRAME N°&quot;, count, &quot; &quot;, x, y, w, h) cx = int((x + x + w) / 2) cy = int((y + y + h) / 2) center_points_cur_frame.append((cx, cy)) cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1) cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2) if count &lt;= 2: for pt in center_points_cur_frame: for pt2 in center_points_pre_frame: distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 20: tracking_objects[track_id] = pt track_id += 1 else: tracking_objects = tracking_objects.copy() center_points_cur_frame_copy = center_points_cur_frame.copy() for object_id, pt2 in tracking_objects.copy().items(): object_exist = False # 判断这个对象是否存在 for pt in center_points_cur_frame: distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1]) if distance &lt; 20: tracking_objects[object_id] = pt object_exist = True # 已经证实器存在之后，就不用进行下面的操作了 # 就是跳出本次for循环，这样可以提高效率 if pt in center_points_cur_frame: center_points_cur_frame.remove(pt) # 如果存在，就是个旧的点，将其删去后就是新的点了 # 但是多次循环会造成一个点删除了多次 if object_exist == False: # 如果这个id遍历了一圈还没有结果，那么就直接删除 tracking_objects.pop(object_id) # 但是，再循环过程中时不可以随便的改变里面的元素的 # 因此要创建副本 # 增加新的点 for pt in center_points_cur_frame: tracking_objects[track_id] = pt track_id += 1 # 再图中绘制出每一个图片对应的位置 for object_id, pt in tracking_objects.items(): cv2.circle(frame, pt, 5, (0, 0, 255), -1) cv2.putText(frame, str(object_id), (pt[0], pt[1] - 7), 0, 1, (0, 0, 255), 2) print(&quot;CUR&quot;) print(center_points_cur_frame) print(&quot;PRE&quot;) print(center_points_pre_frame) # 保留上一帧中的数据 center_points_pre_frame = center_points_cur_frame.copy() cv2.imshow('Frame', frame) key = cv2.waitKey(1) if key == 27: breakcap.release()cv2.destroyAllWindows()","link":"/2022/02/13/opencv/%E8%BD%A6%E6%B5%81%E7%BB%9F%E8%AE%A1%E9%A1%B9%E7%9B%AE/"},{"title":"第一章绪论","text":"振动力学是力学专业的重要专业基础课，由此开始进入动力学的研究范畴，在航空航天、机械、土木等许多工程领域有着重要的应用背景。本文为第一章绪论，初步的介绍基本概念、学习目的、问题的提法、振动模型的建立以及系统的分类。 1.1 基本概念与学习目的 一般力学的对象主要是有限自由度系统的运动及其控制，有时它包含一个或多个无限自由度子系统。它包括运动稳定性理论、振动理论、动力系统理论、多体系统力学、机械动力学等。包括理论力学、振动力学、非线性力学。 固体力学是研究可变形固体在外界因素作用下所产生的应力、应变、位移和破坏等的力学分支。固体力学在力学中形成较早，应用也较广。包括材料力学、弹性力学、塑性力学、非线性介质力学。 流体力学是研究流体{液体和气体)的力学运动规律及其应用的学科。主要研究在各种力的作用下，流体本身的状态，以及流体和固体壁面,流体和流体间、流体与其他运动形态之间的相互作用的力学分支。包括流体力学、高等流体力学。 定义： 从广义上讲，如果表征一种运动的物理量作时而增大时而减小的反复变化，就可以称这种运动为振动 如果变化的物理量是一些机械量或力学量，例如物体的位移、速度、加速度、应力及应变等等，这种振动便称为机械振动 振动是自然界最普遍的现象之一 各种物理现象，诸如声、光、热等都包含振动 (1）心脏的搏动、耳膜和声带的振动，(2）桥梁和建筑物在风和地震作用下的振动,(3)飞机和轮船航行中的振动，（4）机床和刀具在加工时的振动 振动力学：借助数学、物理、实验和计算技术，探讨各种振动现象，阐明振动的基本规律，以便克服振动的消极因素，利用其积极因素，为合理解决各种振动问题提供理论依据。 学习的目的： 运用振动理论去创造和设计新型的振动设备、仪器及自动化装置 掌握振动的基本理论和分析方法，用以确定和限制振动对工程结构和机械产品的性能、寿命和安全的有害影响 1.2振动问题的提法 通常的研究对象被称作系统 它可以是一个零部件、一台机器、一个完整的工程结构 外部的激振力等因素被称作激励（输入） 系统发生的振动称为响应（输出） 振动的问题可以分为三类： 已知激励和系统，求响应（正问题） 动力响应分析，一般是建立微分方程，数值方法求解即可。 主要任务在于验算结构、产品等在工作时的动力响应（如变形、位移、应力等）是否满足预定的安全要求和其它要求 在产品设计阶段，对具体设计方案进行动力响应验算，若不符合要求再作修改，直到达到要求而最终确定设计方案，这一过程就是所谓的振动设计 这里比如响应中的反应设计的安全，加速度反应设计的舒适性特性。 高层建筑要有抗震要求，潜艇要有声学要求。 火箭-&gt;细长杆，尾端燃料推进器会给火箭本体造成振动（轴向、弯曲、扭振），从而影响卫星，因此火箭和推进器之间要加减震适配器。 第二类：已知和响应，求系统（第一个问题） 系统识别，系统辨识 求系统，主要是指获得对于系统的物理参数（如质量、刚数等）和系统关于振动的固有特性（如固有频率、主振型等）的认识 以估计物理参数为任务的叫做物理参数辨识，以估计系统振动固有特性为任务的叫做模态参数辨识或者试验模态分析 激励-&gt;卫星的姿态调整；响应-&gt;卫星的传感器（包括陀螺仪、端板上的加速度传感器） 机械臂本身的参数辨识 ; 空间机械臂抓取,输入(激励)为抓取前各个关节的力矩和加速度信息,输出(响应)为抓取后的力矩和加速度—&gt;&gt;得出被抓取的碎片的质量和惯量. 第三类：已知系统和响应，求激励（第二个逆问题） 环境预测 例如:为了避免产品在公路运输中的损坏，需要通过实地行车记录汽车振动和产品振动，以估计运输过程中是怎样的一种振动环境，运输过程对于产品是怎样的一种激励，这样才能有根据地为产品设计可靠的减震包装 对于火箭来说，系统的响应为传感器的输出，系统为火箭，反推激励-&gt;升空过程中的空气振动。 对于坦克来说，发射的炮弹为响应，坦克系统，反推地面环境对系统发射炮弹的激励。 相比之下，逆问题的求解要比正问题复杂，正问题建立ODE和PDE，再用数值方法求解即可。 1.3力学模型 振动系统的三要素：质量、刚度、阻尼 质量是感受惯性（包括转动惯量）的元件 刚度是感受弹性的元件 阻尼是耗能元件 描述振动系统的两类力学模型:（一般是建立数学模型） 连续系统模型（无限多自由度系统，分布参数系统） 结构参数（质量，刚度，阻尼等）在空间上连续分布 数学工具：偏微分方程 求解是将PDE离散化转化为ODE 离散系统模型（多自由度系统，单自由度系统） 结构参数为集中参量 数学工具：常微分方程 1.4振动及系统的分类按照微分方程的形式可以分为： 线性振动：描述其运动的方程为线性微分方程，相应的系统称为线性系统。线性系统的一个重要特性是线性叠加原理成立 非线性振动：描述其运动的方程为非线性微分方程，相应的系统称为非线性系统。对于非线性振动，线性叠加原理不成立 理论上，线性振动有统一的解决方法；而非线性振动就没有统一的方法。 按照激励的有无和性质可以分为： 固有振动：无激励时系统所有可能的运动集合（不是现实的振动，仅反映系统关于振动的固有属性) 自由振动：激励消失后系统所做的振动（现实的振动) 强迫振动：系统在外部激励作用下所做的振动 随机振动：系统在非确定性的随机激励下所做的振动，例如行驶在公路上的汽车的振动，激励无法使用函数来表示，只能用一个随机过程来表示 自激振动：系统受其自身运动诱发出来的激励作用而产生和维持的振动例如提琴发出的乐声，切削加工的高频振动，机翼的颤振等 参数振动：激励以系统本身的参数随时间变化的形式出现的振动，例如秋千被越荡越高。秋千受到的激励以摆长随时间变化的形式出现，而摆长的变化由人体的下蹲及站立造成。","link":"/2022/01/23/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BB%AA%E8%AE%BA/"},{"title":"第三章 单自由度系统的受迫振动-第一部分","text":"hljs.initHighlightingOnLoad(); 本文从线性系统的受迫振动、稳态响应的特性、受迫振动的过渡阶段、单自由度库仑摩擦力系统的受迫振动的近似分析四个方面进行讲解。 线性系统的受迫振动简谐力激励下的受迫振动 其实部和虚部分别和 $F_0cos\\omega t$ 、$F_0sin\\omega t$ 相对应。 受力分析： 振动的微分方程：$m \\ddot{x}(t)+c \\dot{x}(t)+k x(t)=F_{0} e^{i \\omega t}$ ，是显含时间的，非齐次微分方程。 这里x为复数变量，分别对应 $F_0cos\\omega t$ 、$F_0sin\\omega t$ 这里设$x=\\bar{x}e^{i\\omega t}$ , 其中的$\\bar{x}$ ： 为稳态响应的复振幅 代入刀振动方程中可得：$\\left(-m \\omega^{2}+i c \\omega+k\\right) \\bar{x} e^{i \\omega t}=F_{0} e^{i \\omega t}$ $\\Rightarrow \\bar{x} = H(\\omega ) F_0$ 复频响应函数：$H(\\omega) = \\dfrac 1 {k-m\\omega^2+ic\\omega}$ 振动方程化为：$\\ddot{x}(t)+2 \\xi \\omega_{0} \\dot{x}(t)+\\omega_{0}^{2} x(t)=B \\omega_{0}^{2} e^{i \\omega t}$ 其中$\\omega_0=\\sqrt{\\dfrac k m}$, $B=\\dfrac {F_0} k$ (静变形) ，$\\xi=\\dfrac{c}{2 \\sqrt{k m}}$ 引入外部激励频率与系统固有频率之比：$s = \\dfrac \\omega {\\omega_0}$ 则有： $H(\\omega)$同时反映了系统响应的幅频特性和相频特性 其中有$\\dfrac{m}{k} \\omega^{2}=\\dfrac{\\omega^{2}}{\\omega_{0}^{2}}=s^{2} \\quad \\dfrac{c \\omega}{k}=\\dfrac{c \\omega}{m \\omega_{0}^{2}}=2 \\xi \\omega_{0} \\dfrac{\\omega}{\\omega_{0}^{2}}=2 \\xi \\dfrac{\\omega}{\\omega_{0}}=2 \\xi s$ $x(t)=\\bar{x} e^{i \\omega t}\\quad \\bar{x}=H(\\omega) F_{0}\\quad H(\\omega)=\\frac{1}{k} \\beta e^{-i \\theta}$ 带入得：$\\Rightarrow x(t)=\\dfrac{F_{0}}{k} \\beta e^{i(\\omega t-\\theta)}=A e^{i(\\omega t-\\theta)}$ 有上式可得，阻尼是产生相位差得根源，而自由振动中简谐振动的相位差造成的原因是初始条件造成的。 没有阻尼c时，$\\zeta=0$ 没有相位差。 主要的公式总结如下： 结论如下： 线性系统对简谐激励的稳态响应是频率等同于激振频率、而相位滞后激振力的简谐振动。位移相位要滞后于输入力的相位。 稳态响应的振幅及相位只取决于系统本身的物理性质（m, k, c）和激振力的频率及力幅，而与系统进入运动的方式（即初始条件）无关。 对于有阻尼振动，初始条件的影响为暂态的，最后就衰减没了。 对于无阻尼的振动，其振动的解应该是稳态和暂态的叠加，是与初始条件有关的。 稳态响应特性复频特性 当$s\\ll 1$时，$(\\omega \\ll \\omega_0)$: 激振频率相对于系统固有频率很低，$\\beta \\approx 1$ 结论：响应的振幅A 与静位移B 相当 就是说外部的激励非常的慢的时候，基本上产生的振幅和静位移相当了。 当$s\\gg 1$时，$(\\omega \\gg \\omega_0)$: 激振频率相对于系统固有频率很高，$\\beta \\approx 0$ 结论：响应的振幅很小 外部的激励非常的快的时候，质量m反应不过来了，振幅几乎没啥响应。 对于$s\\ll 1$和$s\\gg 1$情况而言： 对应于不同 $\\zeta$值，曲线较为密集，说明阻尼的影响不显著 结论：系统即使按无阻尼情况考虑也是可以的 当$s\\approx 1$时，$(\\omega \\approx \\omega_0)$: 对应于较小 $\\zeta$ 值，$\\beta(s)$ 迅速增大，当 $\\zeta$ = 0 $\\Rightarrow$ $\\beta(s) \\rightarrow \\infty$ 结论：共振振幅无穷大； 应用： 对于成像卫星而言，共振会造成所成的像有抖动，模糊，此时的共振需要防止。 对于矿山用的振动筛以及手机的信号都是利用共振现象来放大振幅。 但共振对于来自阻尼的影响很敏感，在s=1 附近的区域内，增加阻尼使振幅明显下降 注意$\\beta_{max}$的位置 对于有阻尼系统，$\\beta_{max}$ 并不出现在s=1处，而且稍偏左 $\\dfrac {d\\beta} {ds}=0 \\Rightarrow s=\\sqrt{1-2\\zeta^2} $ 对应的峰值：$\\beta_{max}=\\dfrac 1 {2\\zeta \\sqrt{1-\\zeta^2}}$ 当$\\zeta &gt; 1/\\sqrt 2$时，$\\beta&lt;1$: 振幅没有峰值 品质因子和半功率带宽之间的关系： 阻尼越弱，对应的$\\zeta$ 会非常的小，会造成 Q 越大，带宽越窄，共振峰越陡峭 相频特性 当$s\\ll 1$时，$(\\omega \\ll \\omega_0)$: 相位差 $\\theta \\approx 0$ 位移与激振力在相位上几乎相同 当$s\\gg 1$时，$(\\omega \\gg \\omega_0)$: $\\theta \\approx \\pi$ 位移与激振力反相 (其实这就解释了为什么此时的响应振幅几乎为0) 当$s\\approx 1$时，$(\\omega \\approx \\omega_0)$: 共振时的相位差为$\\dfrac \\pi 2$ ，与阻尼无关 高层结构地基上有阻尼结构，其恢复力和位移之间存在滞回特性滞回环，时间上的之后。 而激励和位移之间存在相位是的滞后特性。 受迫振动的过渡阶段无阻尼受迫振动的过渡阶段受迫振动的过渡阶段： 在系统受到激励开始振动的初始阶段，其自由振动伴随受迫振动同时发生。系统的响应是暂态响应与稳态响应的叠加。 考虑无阻尼正弦激励的情况： 解得通解是： 带入初始的条件：$x(0)=x_{0} \\quad \\Rightarrow \\quad c_{1}=x_{0}$ $\\dot{x}(0)=\\dot{x}_{0} \\ \\Rightarrow \\ \\dot{x}(0)=c_{2} \\omega_{0}+\\dfrac{B}{1-s^{2}} \\ \\Rightarrow \\ c_{2}=\\dfrac{\\dot{x}_{0}}{\\omega_{0}}-\\dfrac{B s}{1-s^{2}}$ 得出最后的解为： 自由伴随的特点：以系统固有频率为振动频率。 零初始条件： 如果为零初始条件，则自由伴随依然存在： 其解的表达式：$x(t)=-\\dfrac{B s}{1-s^{2}} \\sin \\omega_{0} t+\\dfrac{B}{1-s^{2}} \\sin \\omega t$ $s","link":"/2022/03/06/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%97%E8%BF%AB%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第三章 单自由度系统的受迫振动-第三部分","text":"hljs.initHighlightingOnLoad(); 本文从任意周期的激励响应，非周期的激励响应以及任意激励的响应（杜哈梅积分）三个方面进行讲解，并复习了关于傅里叶级数得相关知识。 任意周期激励的响应理论基础前面讨论的强迫振动，都假设了系统受到激励为简谐激励，但实际工程问题中遇到的大多是周期激励而很少为简谐激励。 假定粘性阻尼系统受到的周期激振力：$F(t)=F(t+T)$, T为周期。 则傅里叶级数展开为： F(t)=\\frac{a_{0}}{2}+\\sum_{n=1}^{\\infty}\\left(a_{n} \\cos n \\omega_{1} t+b_{n} \\sin n \\omega_{1} t\\right)=\\frac{a_{0}}{2}+\\sum_{n=1}^{\\infty} c_{n} \\sin \\left(n \\omega_{1} t+\\varphi_{n}\\right)其中：$c_n=\\sqrt{a_n^2+b_n^2},\\quad \\varphi_n=tg^{-1}\\dfrac {a_n} {b_n}$ , $\\tau$为任一时刻; \\begin{align} a_{0}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) d t\\\\ a_{n}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) \\cos n \\omega_{1} t d t \\quad n的偶函数\\\\ b_{n}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) \\sin n \\omega_{1} t d t \\quad n的奇函数\\\\ \\end{align}之后建立运动的微分方程： 其中： $s=\\dfrac {\\omega_{1}}{\\omega_{0}} \\quad \\beta=\\dfrac{1}{\\sqrt{\\left(1-n^2s^{2}\\right)^{2}+(2 \\xi ns)^{2}}} \\quad \\theta_n=\\operatorname{tg}^{-1} \\dfrac{2 \\xi n{s}}{1-n^2s^{2}} $ 其中，$\\dfrac {a_0}{2k}$ 代表着平衡的位置，当$\\dfrac {a_0}{2}$ 作用于系统上所产生的静变形 周期激励通过傅氏变换被表示成了一系列频率为基频整数倍的简谐激励的叠加，这种对系统响应的分析被成为谐波分析法 由欧拉公式，我们可以将其转化成为复数表示 $ \\sin n \\omega_{1} t=\\dfrac{i}{2}\\left(e^{-i n \\omega_{1} t}-e^{i n \\omega_{1} t}\\right) $, $ \\cos n \\omega_{1} t=\\dfrac{i}{2}\\left(e^{-i n \\omega_{1} t}+e^{i n \\omega_{1} t}\\right) $ 此时的可以将原来的傅里叶技术式转化为： \\begin{align} F(t)&=\\frac{a_{0}}{2}+\\sum_{n=1}^{\\infty}\\left(a_{n} \\cos n \\omega_{1} t+b_{n} \\sin n \\omega_{1} t\\right)\\\\ &=\\frac{a_{0}}{2}+\\sum_{n=1}^{\\infty} \\frac {a_n-ib_n} 2 e^{i n \\omega_{1} t} + \\sum_{n=1}^{\\infty} \\frac {a_n+ib_n} 2 e^{-i n \\omega_{1} t}\\\\ &=\\sum_{n=1}^{\\infty} F_ne^{i n \\omega_{1} t} \\end{align}其中的对于每一项的系数：(取$\\tau=-\\frac T 2$) \\begin{align} F_n&=\\dfrac {a_n-ib_n} 2= \\frac{1}{T} \\int_{\\tau}^{\\tau+T} F(t) [\\cos n \\omega_{1} t - i\\sin n \\omega_{1}t]\\ d t\\\\ &= \\frac{1}{T} \\int_{\\tau}^{\\tau+T} F(t) e^{- i n \\omega_{1} t} dt = \\frac{1}{T} \\int_{-\\frac T 2}^{\\frac T 2} F(t) e^{- i n \\omega_{1} t} dt \\end{align}此时，在复数表示下的系统动力学方程为： m \\ddot{x}(t)+c \\dot{x}(t)+k x(t)=\\sum_{n=1}^{\\infty} F_ne^{i n \\omega_{1} t}有叠加原理可得，系统的稳态响应为： x(t)=\\sum_\\limits{n=-\\infty}^{\\infty} A_ne^{i(n \\omega_{1} t - \\theta_n)} \\quad \\theta_n=\\operatorname{tg}^{-1} \\dfrac{2 \\xi n{s}}{1-n^2s^{2}}将上式进行求导可得： \\dot x(t)=\\sum_\\limits{n=-\\infty}^{\\infty} iA_n n\\omega_{1} e^{i(n \\omega_{1} t - \\theta_n)} \\quad \\ddot x(t)=-\\sum_\\limits{n=-\\infty}^{\\infty} A_n n^2 \\omega_{1}^2 e^{i(n \\omega_{1} t - \\theta_n)}带入到原运动方程中可得： \\sum_{n=-\\infty}^{\\infty}\\left[-m A_{n} n^{2} \\omega_{1}^{2}+i c A_{n} n \\omega_{1}+k A_{n}\\right] e^{i\\left(n \\omega_{1} t-\\theta_{n}\\right)}=\\sum_{n=-\\infty}^{\\infty} F_{n} e^{i n \\omega_{1} t} 因此有：$\\beta=\\dfrac{1}{\\sqrt{\\left(1-n^2s^{2}\\right)^{2}+(2 \\xi ns)^{2}}} \\quad A_n=\\dfrac 1 k \\beta_n F_n$ 解得系统的响应为： x(t)=\\sum_{n=-\\infty}^{\\infty} \\frac{1}{k \\sqrt{\\left(1-n^{2} s^{2}\\right)^{2}+(2 \\xi n s)^{2}}} F_{n} e^{i\\left(n \\omega_{1} t-\\theta_{n}\\right)}其中$\\beta_n$、$\\theta_n$ 分别为第n次谐波激励所对应的振幅放大因子和相位差。 相关例题 理想方波只有“高”和“低”这两个值。电流或电压的波形为矩形的信号即为矩形波信号。方波在数码开关电路中广泛应用。因为方波可以快速从一个值转至另一个(即0→1或1→0)，所以方波就用作时钟讯号来准确地触发同步电路。如果用频率定义域来表示方波，就会出现一连串的谐波。这可能会产生电磁波和电流脉波，影响周围的电路，产生噪声。 首先是确定傅里叶级数的展开式： 激励的周期：$T=\\dfrac {2\\pi} \\omega=\\dfrac {12\\pi} {\\omega_0}$ , 其中弹簧—质量的固有频率； 于是有：$\\omega_0=\\dfrac {12\\pi} T ,\\quad \\omega_1=\\dfrac {\\omega_0} 6 = \\dfrac {2\\pi} T$ F(t)=\\frac{a_{0}}{2}+\\sum_{n=1}^{\\infty}\\left(a_{n} \\cos n \\omega_{1} t+b_{n} \\sin n \\omega_{1} t\\right)\\\\ \\begin{align} a_{0}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) d t\\\\ a_{n}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) \\cos n \\omega_{1} t d t \\quad n的偶函数\\\\ b_{n}&=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) \\sin n \\omega_{1} t d t \\quad n的奇函数\\\\ \\end{align} 其中，$a_0$为一个周期内信号围成的总面积，得$a_0=0$; 区间 $[0, T]$ 内，$F(t)$ 关于$\\dfrac T 2$为反对称， 而$\\cos n\\omega_1 t$关于$\\dfrac T 2$对称的，因此$a_n=0$ ； 可以那a1来进行举例，很容易可以看出 区间 $\\left[0, \\dfrac T 2 \\right]$ 内，$F(t)$ 关于$\\dfrac T 4$为对称， 而$\\sin n\\omega_1 t$关于 $\\dfrac T 4$ 反对称的，同时区间 $\\left[\\dfrac T 2,T \\right]$ 内，$F(t)$ 关于$\\dfrac {3T} 4$为对称， 而$\\sin n\\omega_1 t$关于 $\\dfrac T 4$ 反对称的，因此$b_n=0,\\ n=2,4,6,\\cdots$ ； 经过上面的推理，原表达式可以化简成： F(t)=\\sum_{n=1}^{\\infty} b_{n} \\sin n \\omega_{1} t, \\\\ b_{n}=\\frac{2}{T} \\int_{\\tau}^{\\tau+T} F(t) \\sin n \\omega_{1} t\\ d t ,\\quad n= 1,3,5,\\cdots于是在n取奇数时， b_{n}=\\frac{2}{T} \\int_{0}^{T} F(t) \\sin n \\omega_{1} t\\ d t = \\frac{8}{T} \\int_{0}^{T/4} F_0 \\sin n \\omega_{1} t\\ d t=\\frac {4 F_0} {n\\pi}\\\\ n= 1,3,5,\\cdots最终求得周期性激励$F(t)$的展开式为： \\begin{aligned} F(t) &=\\sum_{n=1}^{\\infty} b_{n} \\sin n \\omega_{1} t=\\frac{4 F_{0}}{\\pi} \\sum_{n=1,3,5 \\ldots }^{\\infty} \\frac{1}{n} \\sin n \\omega_{1} t \\\\ &=\\frac{4 F_{0}}{\\pi}\\left(\\sin \\omega_{1} t+\\frac{1}{3} \\sin 3 \\omega_{1} t+\\frac{1}{5} \\sin 5 \\omega_{1} t+\\cdots\\right) \\end{aligned} 之后将激励带入到系统的运动方程中去： m \\ddot{x}(t)+c \\dot{x}(t)+k x(t)=F(t)\\\\ \\Rightarrow x=\\frac{4 F_{0}}{\\pi} \\sum_{n=1,3,5 \\ldots }^{\\infty} \\beta_n \\sin (n \\omega_{1} t-\\theta_n)其中，$s=\\dfrac {\\omega_{1}}{\\omega_{0}} \\quad \\beta=\\dfrac{1}{\\sqrt{\\left(1-n^2s^{2}\\right)^{2}+(2 \\xi ns)^{2}}} \\quad \\theta_n=\\operatorname{tg}^{-1} \\dfrac{2 \\xi n{s}}{1-n^2s^{2}} $ 但不计阻尼时： x(t)=\\frac{4 F_{0}}{\\pi k} \\sum_{n=1,3,5 \\ldots}^{\\infty} \\frac{1}{n\\left(1-n^{2} s^{2}\\right)} \\sin n \\omega_{1} t 工程上的周期激励较多，比简谐激励少。 首先，求解傅里叶级数展开的表达式，这里跟上题的方法类似，还可以根据奇偶性进行化简。 为了简化，这里主要取前三项,带入到系统的动力学方程： F(t) \\approx 25000 A-\\frac{2 \\times 10^{5} A}{\\pi^{2}} \\cos \\omega t-\\frac{2 \\times 10^{5} A}{9 \\pi^{2}} \\cos 3 \\omega t \\\\ m \\ddot{x}(t)+c \\dot{x}(t)+k x(t)=F(t)得出阀稳态响应： \\begin{aligned} x_{p}(t)=& \\frac{25000 A}{k}-\\frac{2 \\times 10^{5} A /\\left(k \\pi^{2}\\right)}{\\sqrt{\\left(1-s^{2}\\right)^{2}+(2 \\xi s)^{2}}} \\cos \\left(\\omega t-\\phi_{1}\\right) \\\\ &-\\frac{2 \\times 10^{5} A /\\left(9 k \\pi^{2}\\right)}{\\sqrt{\\left(1-9 s^{2}\\right)^{2}+(6 \\xi s)^{2}}} \\cos \\left(3 \\omega t-\\phi_{3}\\right) \\end{aligned} 非周期激励的响应理论基础 对于脉冲激励情形，系统只有暂态响应而不存在稳态响应； 单位脉冲力可利用狄拉克（Dirac）分布函数δ(t) 表示； δ函数也称为单位脉冲函数，定义为： $\\delta(t-\\tau)$的图象用位于时刻τ、长度为 1 的有向线段表示。 以下引入信号与系统中讲过的 $\\delta$ 函数的定义和性质： 定义 \\delta(t-\\tau)=\\left\\{\\begin{array}{ll}\\infty & (t=\\tau) \\\\ 0 & (t \\neq \\tau)\\end{array} \\qquad \\int_{-\\infty}^{+\\infty} \\delta(t-\\tau) d t=1\\right. \\delta(t-\\tau)=\\lim_\\limits{\\varepsilon \\rightarrow 0} \\delta_{\\varepsilon}(t-\\tau)其中，$\\delta_{\\varepsilon}(t-\\tau)$ 也可以定义为其它形状的面积为 1 的脉冲，其量纲为1/秒，表达式为： \\delta_{\\varepsilon}(t-\\tau)=\\left\\{\\begin{array}{ll}\\dfrac 1 \\varepsilon & (\\taut_{1} \\ (2)\\end{array}\\right.（1）当 $0 \\le t &lt; t_1$ 时，应用上面例题的结果为： \\begin{aligned} x(t) & =\\frac{Q_{0}}{k}\\left(1-\\cos \\omega_{0} t\\right) \\end{aligned}（2）当 $t_1 \\le t &lt; t_2$ 时， 叠加可得： \\begin{align} x(t)&=x_{1}(t)+x_{2}(t)\\\\&=\\frac{Q_{1}}{k}\\left[\\cos \\omega_{0}\\left(t-t_{1}\\right)-\\cos \\omega_{0} t\\right]-\\frac{Q_{2}}{k}\\left[1-\\cos \\omega_{0}\\left(t-t_{1}\\right)\\right] \\end{align}（3）当$t_2&lt;t$ 时， 对于Q1，应用(2)式：$x_1(t)=\\dfrac{Q_{1}}{k}\\left[\\cos \\omega_{0}\\left(t-t_{1}\\right)-\\cos \\omega_{0} t\\right]$ 对于Q2，应用(2)式，注意力的作用时间滞后t1： \\begin{aligned} x_{2}(t) &=-\\frac{Q_{2}}{k}\\left\\{\\cos \\omega_{0}\\left[\\left(t-t_{1}\\right)-\\left(t_{2}-t_{1}\\right)\\right]-\\cos \\omega_{0}\\left(t-t_{1}\\right)\\right\\} \\\\ &=-\\frac{Q_{2}}{k}\\left[\\cos \\omega_{0}\\left(t-t_{2}\\right)-\\cos \\omega_{0}\\left(t-t_{1}\\right)\\right] \\end{aligned}将两式相加： \\begin{align} x(t)&=x_{1}(t)+x_{2}(t)\\\\&=\\frac{Q_{1}}{k}\\left[\\cos \\omega_{0}\\left(t-t_{1}\\right)-\\cos \\omega_{0} t\\right]-\\frac{Q_{2}}{k}\\left[\\cos \\omega_{0}\\left(t-t_{2}\\right)-\\cos \\omega_{0}\\left(t-t_{1}\\right)\\right]\\\\ \\end{align}","link":"/2022/03/09/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%97%E8%BF%AB%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86/"},{"title":"第三章 单自由度系统的受迫振动-第二部分","text":"hljs.initHighlightingOnLoad(); 本文从简谐惯性力的受迫振动，机械阻抗与导纳，以及一些工程上的受迫振动三个方面进行讲解，在单自由度振动上面花了很多的时间，后期的对于多自由度的问题可以是呀模态叠加法是来将其转化为单自由度的问题。 简谐惯性力的受迫振动背景：地基振动，转子偏心引起的受迫振动 特点：激振惯性力的幅值与频率的平方成正比例 以地基的位移为坐标 通过上面的推理可得： m_1\\ddot{x_1}(t)+c\\dot x_1(t)+kx_1(t)=mD\\omega^2e^{i\\omega t}这里我们设：$mD\\omega^2=F_0$ 同时由于$\\omega_0^2=\\dfrac k m,\\ s=\\dfrac \\omega {\\omega_0}$ 振动的解析表达式如下： x_{1}=\\beta B e^{i\\left(\\omega t-\\theta_{1}\\right)}=\\beta \\frac{F_{0}}{k} e^{i\\left(\\omega t-\\theta_{1}\\right)}=\\beta \\frac{m D \\omega^{2}}{k} e^{i\\left(\\omega t-\\theta_{1}\\right)}\\\\ =\\frac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}} D e^{i\\left(\\omega t-\\theta_{1}\\right)}=\\beta_{1} D e^{i\\left(\\omega t-\\theta_{1}\\right)}其中，振幅放大因子为：$\\beta_1=\\dfrac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}}$, 相位差为：\\theta_{1}(s)=\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}} 这里我们对比简谐激励的振动解析表达式： 二者的相位差还是一样的，就是振幅放大因子多了个$s^2$ 这里，我们的可以看出最左边式s&gt;1，质量和地基是同步的； 中间的是s=1，此时相当于发生了共振，其振幅相当大； 最右边是s&lt;1，此时相对的振动的位移是小于地基振动的幅值的。 以绝对位移为坐标 如果以绝对位移为坐标：$x(t)=x_{1}(t)+x_{f}(t)$ 其中：$x_{1}(t)=\\beta_{1} D e^{i\\left(\\omega t-\\theta_{1}\\right)}$ ，$x_{f}(t)=D e^{i \\omega t}$； 于是：$x(t)=\\beta_{1} D e^{i\\left(\\omega t-\\theta_{1}\\right)}+D e^{i \\omega t}=(\\beta_{1}+e^{i\\theta_{1}})D e^{i\\left(\\omega t-\\theta_{1}\\right)}$ 其中，振幅放大因子为：$\\beta_1=\\dfrac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}}$, 相位差为：$\\theta_{1}(s)=\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}$ 于是有： \\begin{align} \\beta_{1}+e^{i \\theta_{1}}&=\\frac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}+\\left(\\cos \\theta_{1}+i \\sin \\theta_{1}\\right)\\\\ &=\\frac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}+\\frac{1-s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}+i \\frac{2 \\zeta s}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}\\\\ &=\\frac{1+2 i \\xi_{S}}{\\sqrt{\\left(1-S^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}=\\frac{1}{\\sqrt{\\left(1-S^{2}\\right)^{2}+\\left(2 \\zeta_{S}\\right)^{2}}} \\sqrt{1+\\left(2 \\xi_{S}\\right)^{2}} e^{i \\theta_{2}}\\\\ &=\\sqrt{\\frac{1+\\left(2 \\xi_{S}\\right)^{2}}{\\left(1-S^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}} e^{i \\theta_{2}}\\\\ &=\\beta_{2} e^{i \\theta_{2}} \\end{align} 于是有： 表达式 振幅 相位 地基位移 $\\beta_{1} D e^{i\\left(\\omega t-\\theta_{1}\\right)}$ $\\dfrac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}}$ $\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}$ 绝对位移 $\\beta_{2} e^{i \\theta_{2}}$ $\\sqrt{\\dfrac{1+\\left(2 \\xi_{S}\\right)^{2}}{\\left(1-S^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}$ $\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}-\\operatorname{tg}^{-1}\\left(2 \\xi_{S}\\right)$ 最后带入到表达式中，得到振动的解析表达式为： $x(t)=\\beta_{2} D e^{i\\left[\\omega t-\\left(\\theta_{1}-\\theta_{2}\\right)\\right]}=\\beta_{2} D e^{i(\\omega t-\\theta)}$，其中$\\theta=\\theta_{1}-\\theta_{2}$ 无阻尼时的表达式为：$x(t)=D \\dfrac{1}{1-s^{2}} e^{i \\omega t}$ 使用其他的方法进行分析角度位移为坐标的情况 x(t)=\\frac{k D}{k} \\frac{1}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}} \\sin \\left(\\omega t-\\theta_{1}\\right)+\\frac{c D \\omega}{k} \\frac{1}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}} \\cos \\left(\\omega t-\\theta_{1}\\right)\\\\ =\\frac{D}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}}\\left[\\sin \\left(\\omega t-\\theta_{1}\\right)+2 \\xi s \\cos \\left(\\omega t-\\theta_{1}\\right)\\right]其中有， $\\dfrac{c \\omega}{k}=\\dfrac{c \\omega}{\\omega_{0}^{2} m}=\\dfrac{c}{m} \\cdot \\dfrac{s}{\\omega_{0}}=2 \\xi \\omega_{0} \\dfrac{s}{\\omega_{0}}=2 \\xi_{S}$， $\\theta_1=\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}$ 之后，将$\\sin \\theta_{2}=\\dfrac{2 \\xi_{S}}{\\sqrt{1+\\left(2 \\xi_{S}\\right)^{2}}}$和$\\cos \\theta_{2}=\\dfrac1 {\\sqrt{1+\\left(2 \\xi_{S}\\right)^{2}}}$ 此时有$\\theta_2=\\operatorname{tg}^{-1}\\left(2 \\xi_{S}\\right)$ 于是令：$\\theta = \\theta_1-\\theta_2$ , $\\beta=\\sqrt{\\dfrac{1+\\left(2 \\xi_{S}\\right)^{2}}{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}}$ 带入到上述式子中。 和前面第一种方法的结果是一样的。 实际案例 首先，确定系统输入的激励： 之后，求解再空载和满载的时候，我们的阻尼c是不变的，改变的只有质量； 因此根据公式$c_{cr}=2\\sqrt{km},\\ \\dfrac c m=2\\zeta\\omega_0$ 可得： $\\Rightarrow \\ c=\\zeta c_{cr}=2\\zeta \\sqrt{km}$, 由于c和k是常数，因此可以得出：$\\zeta$ 和 $\\sqrt m$ 成反比 进而得到空载时的阻尼比为：$\\xi_{2}=\\xi_{1} \\sqrt{\\dfrac{m_{1}}{m_{2}}}=1.0$ ; 满载和空载时的频率比： 满载：$s_{1}=\\dfrac{\\omega}{\\omega_{01}}=\\omega \\sqrt{\\dfrac{m_{1}}{k}}=1.87$ 空载：$s_{2}=\\dfrac{\\omega}{\\omega_{02}}=\\omega \\sqrt{\\dfrac{m_{2}}{k}}=1.87$ 然后，计算振幅，满载时振幅 B1，空载时振幅 B2： 满载：$\\dfrac{B_{1}}{a}=\\sqrt{\\dfrac{1+\\left(2 \\xi_{1} s_{1}\\right)^{2}}{\\left(1-s_{1}^{2}\\right)^{2}+\\left(2 \\xi_{1} s_{1}\\right)^{2}}}=0.68$ 空载：$\\dfrac{B_{2}}{a}=\\sqrt{\\dfrac{1+\\left(2 \\xi_{2} s_{2}\\right)^{2}}{\\left(1-s_{2}^{2}\\right)^{2}+\\left(2 \\xi_{2} s_{2}\\right)^{2}}}=1.13$ 因此可得振幅比为：$B_1/B_2=0.60$ 首先，将模型进行简化，并求解系统的固有频率$\\omega=\\sqrt{k/m}=\\sqrt{g/\\delta}$： 等效的时候可以将我们的杆子看作刚体，将A处的运动等效过去；然后再将杆子看作是柔性体，计算刚度k。 之后，列出动力学方程： $m \\ddot{x}+k\\left(x-x_{f}\\right)=0 \\Rightarrow m \\ddot{x}+k x=\\dfrac {k b d} a \\sin \\omega t$ 根据上面的求绝对位移为坐标，且无阻尼情况下的方程， 计算可得：$\\bar{x}=\\dfrac{k b d / a}{k} \\cdot \\dfrac{1}{1-s^{2}}=\\dfrac{b d}{a} \\cdot \\dfrac{1}{1-s^{2}} \\quad s=\\dfrac{\\omega}{\\omega_{0}}$ 支撑运动的小结 这里的输入不是力，是基础的位移。 这里我们有两种坐标形式来考虑动力学方程的建立，一个是使用相对位移坐标，另一个是研究绝对位移坐标。 振幅放大因子，两种位移坐标下是不一样的。 如果要想隔振有效果，那么$s&gt;\\sqrt{2}$ 转子偏心问题高速旋转机械中，偏心质量产生的离心惯性力是主要的激励来源。旋转机械总质量为M，转子偏心质量为m，偏心距为e，转子转动角速度为 $\\omega$ 这里$me$：不平衡量，$me\\omega^2$：不平衡量引起的离心惯性力。 于是我们设：$F_0=me\\omega^2$, $x(t)=\\beta B \\sin (\\omega t-\\theta)$ 其中$\\beta=\\dfrac 1 {\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2} } }$, $B=\\dfrac {F_0} k=\\dfrac {me\\omega^2} k$ , $s=\\dfrac{\\omega}{\\omega_{0}}$, $\\theta=\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}$, 注意$\\omega = \\sqrt{\\dfrac K M}$ 这里B可以写作为：$B=\\dfrac {F_0} k=\\dfrac {me\\omega^2} k = \\dfrac {me\\omega^2} {\\omega_0^2M}=\\dfrac {me} {M} s^2$ 此时振动的表达式为： $x(t)=\\dfrac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}} \\dfrac{m e}{M} \\sin (\\omega t-\\theta)=\\beta_{1} B_{1} \\sin (\\omega t-\\theta)$ 其中，$\\beta=\\dfrac 1 {\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2} } }$, $B_1=\\dfrac {me} M$ 公式：$x(t)=\\dfrac{s^{2}}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}} \\dfrac{m e}{M} \\sin (\\omega t-\\theta)$ 首先，共振的时候，我们的s=1; 代入得共振时的最大振幅是：$\\dfrac 1 {2\\zeta} \\dfrac {me}{M}=0.1(m) \\ \\Rightarrow \\ e=0.1(m)$ 其次，这里假设增加质量后阻尼是不变的，其实是要变的： $\\dfrac 1 {2\\zeta} \\dfrac {me}{M+\\Delta M}=0.01(m) \\ \\Rightarrow \\ \\dfrac{\\Delta M} {M}=9$ 得出：$\\Delta M=9M$ 机械阻抗与导纳 工程中常用机械阻抗来分析结构的动力特性； 机械阻抗定义为：简谐激振时复数形式的输入与输出之比； 位移阻抗 Z_{x}(\\omega)=\\dfrac{F_{0} e^{i \\omega t}}{\\bar{x} e^{i \\omega t}}=\\dfrac{F_{0}}{\\bar{x}}=\\dfrac{1}{H(\\omega)}=k-m \\omega^{2}+i c \\omega\\\\ H(\\omega)=\\frac{1}{k-m \\omega^{2}+i c \\omega}位移阻抗与复频响应函数互为倒数， $H(\\omega)$ 也称为导纳。 输出也可以定义为速度或加速度，相应的机械阻抗称为速度阻抗和加速度阻抗。 速度阻抗 Z_{\\dot x}(\\omega)=\\frac{F_{0} e^{i \\omega t}}{\\dot{x}}=\\frac{F_{0} e^{i \\omega t}}{i \\omega \\bar{x} e^{i \\omega t}}=\\frac{1}{i \\omega} Z_{x}(\\omega) 加速度阻抗 Z_{\\ddot{x}}(\\omega)=-\\frac{1}{\\omega^{2}} Z_{x}(\\omega) 机械阻抗的倒数称为机械导纳，相应 $Z_{x}(\\omega)$、$Z_{\\dot x}(\\omega)$ 、$Z_{\\ddot x}(\\omega)$ 分别有位移导纳、速度导纳和加速度导纳。 机械阻抗和机械导纳都仅仅取决于系统本身的动力特性（m，k，c），它们都是复数。 现已有多种专门测试机械阻抗的分析仪器，根据系统的机械阻抗可以确定和分析系统的固有频率、相对阻尼系数等参数及其它动力特征 复频响应函数又可写为： H(\\omega)=\\frac{1}{k-m \\omega^{2}+i c \\omega}=\\frac{1}{k} \\cdot \\frac{1}{\\left(1-s^{2}\\right)+i\\left(2 \\xi_{S}\\right)}其中的模与幅角为： |H(\\omega)|=\\frac{1}{k} \\cdot \\frac{1}{\\sqrt{\\left(1-s^{2}\\right)^{2}+(2 \\xi s)^{2}}}=\\frac{\\beta}{k}=\\frac{\\beta}{F_{0} / B}=\\frac{\\beta B}{F_{0}}\\\\ \\arg H(\\omega)=\\operatorname{tg}^{-1} \\frac{2 \\xi_{S}}{\\left(1-S^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2}}=-\\theta$H(\\omega)$同时反映了系统响应的幅频特性和相频特性。 $\\operatorname{Re}(H)=\\dfrac{1}{k} \\cdot \\dfrac{1-s^{2}}{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi{s}\\right)^{2}} \\quad \\operatorname{Im}(H)=-\\dfrac{1}{k} \\cdot \\dfrac{2 \\xi_{s}}{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}$ 还可以用频率比 s 或相对阻尼系数 $\\xi$ 作参变量，把 $H(\\omega)$ 画在复平面上，这样得到的曲线称为乃奎斯特图(Nyquict plot) 工程中的受迫振动问题惯性式测振仪 此时，由$s=\\dfrac \\omega {\\omega_0}$ 此时 $s \\rightarrow \\infty \\Leftrightarrow \\omega&gt;&gt;\\omega_{0}$ 有$\\lim \\limits_{s \\rightarrow \\infty} A_{1} \\approx D$ 低固有频率的测量仪用于测量振动的位移幅值，称为位移计。 当仪器固有频率远小于外壳振动频率时，仪器读数幅值 A1 接近外壳振动的振幅 D。 A1还可以写成：$A_{1}=\\dfrac{1}{\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi{s}\\right)^{2}}}\\left(\\dfrac{D \\omega^{2}}{\\omega_{0}^{2}}\\right)$ 此时，由$s=\\dfrac \\omega {\\omega_0}$ 此时 $s \\rightarrow 0 \\Leftrightarrow \\omega \\ll \\omega_{0}$ 于是有$\\lim \\limits_{s \\rightarrow 0} A_{1} \\approx \\dfrac 1 {\\omega_0^2}(D\\omega^2)$ ；其中$D\\omega^2$：被测物体的加速度幅值。 当仪器的固有频率远大于外壳振动频率时，仪器读数的幅值 A1与外壳加速度的幅值成正比。 高固有频率测量仪用于测量振动的加速度幅值，称为加速计。 振动的隔离主动隔振将作为振源的机器设备与地基隔离，以减少对环境的影响称为主动隔振。 具体的计算如下所示： 其中，$\\beta=\\dfrac 1 {\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2} } }$,$s=\\dfrac{\\omega}{\\omega_{0}}$, $\\theta=\\operatorname{tg}^{-1} \\dfrac{2 \\xi s}{1-s^{2}}$ 其中，$\\theta_{2}=\\operatorname{tg}^{-1} 2 \\xi s ,\\quad \\dfrac{c \\omega}{k}=\\dfrac{c \\omega}{\\omega_{0}{ }^{2} m}=\\dfrac{c}{m} \\cdot \\dfrac{s}{\\omega_{0}}=2 \\xi \\omega_{0} \\dfrac{s}{\\omega_{0}}=2 \\xi_{S}$ 因此可得隔振系数为：$\\eta = \\dfrac{F_{1\\max} } {F_0} = \\sqrt{\\dfrac{1+\\left(2 \\xi_{S}\\right)^{2}}{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi_{S}\\right)^{2} } }$ 画出主动隔振系数的图像，可得到以下的结论： 典型例题： 小结：本节课是如何计算隔振后的力，主动隔振系数的计算、已经频率比的选择问题。 被动隔振将地基的振动与机器设备隔离，以避免将振动传至设备，称为被动隔振。 这里主动隔振系数和被动隔振系数的表达式时相同的，但是其中的内涵是不一样的。 主动隔振系数是力之比，而被动隔振系数是位移之比。 典型例题： 为计算梁自身质量对其横向振动固有频率的影响，需确定梁质量等效到自由端时的等效质量，然后可按单自由度计算悬臂梁横向振动的固有频率。 这里我们首先计算是悬臂梁的等效质量： 等效之后系统称为一个单自由度系统： 根据刚度和等效的质量可以得出： 电路板的固有频率：$\\omega_0 = \\sqrt{\\dfrac {k_b}{m_{eq}}}=\\sqrt{\\dfrac{1.296\\times10^6}{0.5893}}rad/s=1482.99\\ rad/s$ 计算机底座的频率：$\\omega = \\dfrac{2\\pi \\times 3000}{60} = 312.66\\ rad/s$ 频率之比：$s=\\dfrac{\\omega}{\\omega_0}=\\dfrac{312.66}{1482.99}=0.2108$ 位移传递率： \\eta = \\sqrt{\\dfrac{1+\\left(2 \\xi_{S}\\right)^{2}}{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi{s}\\right)^{2}}}=\\sqrt{\\dfrac{1+\\left(2 \\times 0.01\\times0.2108\\right)^{2}}{\\left(1-0.2108^{2}\\right)^{2}+\\left(2 \\times0.01\\times{0.2108}\\right)^{2}}}=1.0465 位移传递率（104.65%）已超过最大许可值（10%）; 因此这里假装了隔振器，这里加入以后可能会成为一个双自由度的系统，因此为了简化模型，将梁简化为刚体。 于是计算隔振器的频率和刚度： $k=\\dfrac {M\\omega^2} {s^2} = \\dfrac {2.75\\times 312.66^2}{11.0218}N/m = 24390.7309\\ N/m$ 隔振器的阻尼常数为： $c=2\\xi\\sqrt{Mk}=2\\times 0.01 \\sqrt {2.75\\times24390.7309}=5.1797\\ N\\cdot s/m$ 转子的临界转速气轮机、发电机等高速旋转机械在开机或停机过程中经过某一转速附近时，支撑系统经常会发生剧烈振动。 轴以角速度$\\omega$恒速旋转，轴沿着x和y方向的横向刚度：$k=\\dfrac {48EI} {l^3}$ 由于离心惯性力，轴产生的静扰度$OO_1=f$ 粘性阻尼力正比于圆盘形心 $O_1$ 的速度 设形心 $O_1$ 的坐标$(x,y)$，质心C的坐标为$(x+e\\cos\\omega t,\\ y+\\sin \\omega t)$ 由质心的运动定理： m\\frac{d^2}{dt^2} (x+e\\cos\\omega t)=-kx-c\\dot x\\\\ m\\frac{d^2}{dt^2} (y+e\\sin\\omega t)=-ky-c\\dot y\\\\ 设：$\\omega_0 =\\sqrt{k/m}=\\sqrt{g/l_0}$ ，其中$l_0$是静变形，$\\omega_0 $ 转子不转动而作横向自由振动时的固有频率 此时动扰度为：$f=\\sqrt{x^2+y^2}=e\\beta_1=\\dfrac {es^2} {\\sqrt{\\left(1-s^{2}\\right)^{2}+\\left(2 \\xi{s}\\right)^{2} } }$ 当s=1时：$f=\\dfrac e {2\\xi}$ ,此时的$\\omega=\\omega_0$,即转动频率与转子的固有频率相等； 可见，当阻尼比$\\xi$ 较小时，即使转子平衡得很好(e 很小)，动挠度f 也会相当大，容易使轴破坏，这样的转速称为临界转速： 每分钟的转速表示：$n_f=\\dfrac {60\\omega_f}{2 \\pi} (r/min)$ 其中，$\\omega_f=\\omega_0=\\sqrt{k/m}$ 当s&gt;&gt;1时，即$\\omega \\gg \\omega_0$, 有：$\\beta_1 \\approx1$ , $\\theta_1 \\approx \\pi$ , 转动频率远大于转子固有频率, 出现自动定心现象。 这里面主要学会如何求临界转速，以及了解自动定心现象。 计算实例 这里，在单自由度振动上面花了很多的时间，后期的对于多自由度的问题可以是呀模态叠加法是来将其转化为单自由度的问题。","link":"/2022/03/08/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%97%E8%BF%AB%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"第二章单自由度系统自由振动_第一部分","text":"单自由度系统振动的第一部分，主要讲的是无阻尼自由振动、能量法、瑞利法以及等效刚度与质量。 无阻尼的自由振动令$x$为位移，以质量块静平衡位置为原点，$\\lambda$为静变形。受到初始扰动时，由牛顿第二定律，得： m\\ddot x(t) = mg - k(\\lambda+x(t))在静平衡时的位置：$mg = k\\lambda$ 则物体的振动或自由振动的微分方程为： m\\ddot x(t)+kx(t)=0令：$\\omega_0=\\sqrt \\frac{k}{m}$ 固有频率，单位：弧度/秒（rad/s) 则有微分方程为：$\\ddot x(t) + \\omega_0^2x(t)=0 \\Rightarrow$ 对应得特征方程为：$ms^2+k=0 \\Rightarrow$ 特征根：$s_{1,2}=\\pm i\\omega_0$ $s_1、s_2$都满足特征方程，因此通解可以写为 \\begin{align} x(t) &= A_1e^{s_1t}+A_2 e^{s_2t}\\\\ &=A_1e^{i\\omega t}+A_2 e^{-i\\omega t}\\\\ &= c_1 \\cos (\\omega_0t) +c_2 \\sin (\\omega_0t)\\\\ &= A \\sin (\\omega_0t+\\varphi) \\end{align}$c_1和c_2$为新常数，主要由初始条件来决定 振幅：$A=\\sqrt {(c_1^2+c_2^2)}$ 初相位：$\\varphi=tg^{-1} \\left (\\dfrac {c1}{c2} \\right )$ $\\omega_0$ ：系统固有的数值特征，与系统是否振动以及如何振动无关。 $A,\\varphi$：非系统固有数字特征，与系统所受激励和初始状态有关。 考虑系统在初始扰动下的自由振动，设$t=\\tau$的初始位移和初始速度为：$x(\\tau)=x_\\tau \\qquad \\dot x(\\tau)=\\dot x_\\tau$ 则令： c_1=b_1 \\cos(\\omega_0 \\tau)-b_2\\sin (\\omega_0\\tau)\\\\ c_2=b_1 \\sin(\\omega_0 \\tau)-b_2\\cos (\\omega_0\\tau)带入得：$b_1=x_\\tau \\quad b_2=\\dfrac{\\dot x_\\tau}{\\omega_0}$ 并且$\\tau$时刻后得自由振动的解为： x(t) = x_\\tau \\cos \\omega_0(t-\\tau) +\\frac{\\dot x_\\tau}{\\omega_0} \\sin \\omega_0(t-\\tau)\\\\带入零时刻的初始条件$x(0)=x_0 \\qquad \\dot x(0)=\\dot x_0$可得： x(t) = x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)=A\\sin(\\omega_0t+\\varphi)此时的振幅为$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}$，相位为$\\varphi=tg^{-1} \\dfrac{x_0\\omega_0}{\\dot x_0}$ 无阻尼的质量弹簧系统受到初始扰动后，其自由振动是以$\\omega_0$为振动顿率的简谐振动,并且永无休止。 初始条件的说明：初始条件是外界能量转入的一种方式， 有初始位移即转入了弹性势能。 有初始速度即转入了动能，用锤子敲击的脉冲就是输入了动能。 如图所示：可以得出， 弹簧的刚度为蓝色最大、黑色最小。 刚度越大、圆频率$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 越大，周期（$T=\\dfrac{2\\pi}{\\omega_0}$）越小。 由此得出圆频率的另一种计算方法： 由于在静止情况下$mg=k\\lambda$ 可得：$\\omega_0=\\sqrt{\\dfrac{k}{m}}=\\sqrt{\\dfrac{g}{\\lambda}}$ 对于不易得到m和k 的系统，若能测出静变形$\\lambda$，则用该式计算较为方便。 无阻尼振动的计算实例 首先，我们规定的原点一般为静平衡位置，这样可以时建模得到了微分方程为齐次的，在原长处建模时，微分方程为非齐次的。 m\\ddot x+kx=0\\\\ 如果以原长的位置进行建模：\\\\ m\\ddot x+k x=mg 由题可得振动的频率为：$\\omega_0=\\sqrt{\\dfrac{gk}{W}}=19.6\\,rad/s$ 重物匀速下降时处于静平衡位置，若将坐标原点取在绳被卡住瞬时重物所在位置，则t=0时有，$x_0=0\\quad \\dot x_0=v$ 于是带入振动方程： \\begin{align} x(t) &= x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)\\\\ &=\\dfrac{v}{\\omega_0} \\sin(\\omega_0t)=12.8\\sin(19.6t) (cm) \\end{align} 求绳子的最大张力，一定时是绳子在最底部时的。绳中最大张力等于静张力与因为振动引起动的张力之和： T_{max}=T_s+kA=W+kA\\\\ =1.47\\times10^5+0.74\\times10^5=2.21\\times10^5 动张力几乎是静张力的一半 由于$kA=k\\dfrac{v}{\\omega_0}=v\\sqrt{km}$ 为了减少振动引起的动张力，应当降低升降系统的刚度。尽管这样可能会造成A过大舒适性下降，但是由于加速度减小，安全性得到保证。 首先，取平衡位置，以梁承受重物静平衡位置为坐标原点（就像相当于将重物平稳的放在上面产生的静变形为$\\lambda$） 由材料力学得：$\\lambda=\\dfrac{mgl^3}{48EJ}$ 自由振动频率：$\\omega_0=\\sqrt{\\dfrac{g}{\\lambda}}=\\sqrt {\\dfrac{48EJ}{ml^3}}$ 撞击时刻为零时刻，则t=0 时，有：$x_0=-\\lambda\\quad\\dot x_0=\\sqrt{2gh}$ 自由振动振幅：$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}=\\sqrt{\\lambda^2+2h\\lambda}$ 梁的最大扰度：$\\lambda_{max}=A+\\lambda$ 由牛顿第二定律： I\\ddot \\theta(t)+k_\\theta \\theta(t)=0\\\\ \\ddot \\theta(t)+\\omega_0^2\\theta(t)=0 则扭振的固有频率为$\\omega_0=\\sqrt{\\dfrac{k_\\theta}{I}}$ 总结：由上例可看出，除坐标不同外，角振动与直线振动的数学描述完全相同。如果在弹簧质量系统中将m、k 称为广义质量及广义刚度，则弹簧质量系统的有关结论完全适用于角振动。以后不加特别声明时，弹簧质量系统是广义的。 从上两例还可看出，单自由度无阻尼系统总包含着惯性元件和弹性元件两种基本元件。 惯性元件是感受加速度的元件，它表现为系统的质量或转动惯量； 弹性元件是产生使系统恢复原来状态的恢复力的元件，它表现为具有刚度或扭转刚度的弹性体。 同一个系统中，若惯性增加，则使固有频率降低，而若刚度增加，则固有频率增大。 求复摆在平衡位置附近做微振动时的微分方程和固有频率。这里我们考虑的振动都是微振动（$\\sin \\theta \\approx \\theta$ )。 首先，由牛顿定律：$I_0\\ddot \\theta(t)+mga\\sin \\theta(t)=0$ 得出固有频率$\\omega_0=\\sqrt{\\dfrac{mga}{I_0}}$ 若已测出物体的固有频率，则可求出$\\omega_0$，再由移轴定理，可得物质绕质心的转动惯量：$I_c=I_0-ma^2$ 实验确定复杂形状物体的转动惯量的一个方法。 以静平衡位置为坐标原点建立坐标系，振动固有频率：$\\omega_0=\\sqrt{\\dfrac{K}{m}}=70rad/s$ 振动初始条件：$kx_0=mg\\times\\sin30° \\ \\Rightarrow x_0=-0.1cm$ 由题初始速度为$\\dot x_0=0$，则运动方程为$x(t)=-0.1\\cos(70t) cm$ 如果系统竖直放置，振动频率是否改变？不改变，因为质量是不变的，只有原长会改变。 能量法 对于不计阻尼即认为没有能量损失的单自由度系统，可利用能量守恒原理建立自由振动微分方程，或直接求出固有频率。 无阻尼系统为保守系统，其机械能守恒，即动能T 和势能V 之和保持不变，即：$T+V=const$ \\dfrac{d}{dt} (T+V)=0 当原点在静平衡位置的情况： 则总的势能为： V=-mgx+\\int_0^xk(\\lambda+x)\\,dx\\\\=-mgx+k\\lambda x+\\frac 1 2 k x^2 =\\frac 1 2 kx^2 则总的能量的为：$T+V=\\dfrac 1 2 k x^2+\\dfrac 1 2m \\dot x^2$ $\\dfrac{d}{dt} (T+V)=(m\\ddot x +kx)\\dot x=0 \\,\\Rightarrow \\, m\\ddot x(t)+kx(t)=0$ 能量法的步骤：(1)列方程，(2)求固有频率 如果将坐标原点不是取在系统的静平衡位置，而是取在弹簧为自由长时的位置，此时由能量之和的导数为零可得： $m\\ddot x \\dot x-mg\\dot x +kx \\dot x=0 \\, \\Rightarrow \\, m\\ddot x(t)+kx(t)=mg$ 设新的坐标$y=x-\\dfrac {mg} k =x- \\lambda \\ \\Rightarrow \\ m\\ddot y(t)+ky(t)=0$ 如果重力的影响仅是改变了惯性元件的静平衡位置，那么将坐标原点取在静平衡位置上，方程中就不会出现重力项。 由于$T+V=const$，则有$T_{max}= V_{max}\\Rightarrow\\frac 1 2m \\dot x_{max}^2=\\frac 1 2 k x_{max}^2$ 即有$\\dot x_{max}=\\omega_0x_{max}$，带入$x(t)= A \\sin (\\omega_0t+\\varphi) $，可得$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 对于转动：$\\dot \\theta_{max}=\\omega_0\\theta_{max}$ (1) 倒摆作微幅振动时的固有频率(2) 摆球$m=0.9kg$时，测得频率f为1.5HZ，$m=1.8kg$时，测得频率f为0.75HZ，问摆球质量为多少千克时恰使系统处于不稳定平衡状态？ 解法一：静平衡位置如左图，广义坐标为$\\theta$ 势能：由于是微振动，正弦遵循小角近似，但是余弦不遵循 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}-m g l(1-\\cos \\theta)\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}-m g l\\left(1-\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} \\theta^{2}-m g l \\theta^{2}\\right)=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 微分方程为：$T_{max}=U_{max} \\Rightarrow \\frac{1}{2} m l^{2} \\dot{\\theta}_{\\max }^{2}=\\dfrac{1}{2}\\left(k a^{2}-m g l\\right) \\theta_{\\max }^{2}$ 求固有频率：$\\dot \\theta_{max}=\\omega_0\\theta_{max} \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 这里我们将$ m l^{2}$视为等效质量，$\\left(k a^{2}-m g l\\right) $视为等效刚度。 解法二：静平衡位置如右图，广义坐标为$\\theta$ 势能：由于是微振动，这里用小角近似 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}+m g l\\cos \\theta\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}+m g l\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} -m g l \\right)\\theta^{2}+mgl \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 由于$\\frac{d}{d t}(T+U)=0 \\Rightarrow\\ 2 m l^{2} \\dot{\\theta} \\ddot{\\theta}+2 \\theta\\left(k a^{2}-m g l\\right) \\dot{\\theta}=0$ 则有：$2 m l^{2} \\ddot{\\theta}+2\\left(k a^{2}-m g l\\right) \\theta=0 \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 确定系统微振动的固有频率。 广义坐标：圆柱微转角$\\theta$，圆柱做一般运动， 由柯希尼定理，动能：$T=\\frac{1}{2}\\left(\\frac{3}{2} m R^{2}\\right) \\dot{\\theta}^{2}$ C点为瞬心 A点速度：$v_{A}=(R+a) \\dot{\\theta} \\ \\Rightarrow \\ x_{A}=(R+a) \\theta$ B点的速度：$v_{B}=(R-b) \\dot{\\theta}\\ \\Rightarrow \\ x_{B}=(R-b) \\theta$ 则势能为：$U=\\dfrac{1}{2}\\left(2 k_{1}\\right)(R+a)^{2} \\theta^{2}+\\dfrac{1}{2}\\left(2 k_{2}\\right)(R-b)^{2} \\theta^{2}$ 由于$T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{\\theta}_{\\max }=\\omega_{0} \\theta_{\\max }$ \\begin{align} \\omega_{0}^{2}&=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}\\\\ &=\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right] \\end{align}解得固有频率为：$\\omega_{0}=\\sqrt{\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right]}$ 坐标原点设在静平衡位置，因为计算势能的时候预先压缩造成的重力势能和弹性势能一定会被约掉，得出其次动力学方程。 因此，广义的坐标：质量块的垂直位移x 动能： \\begin{align} T&=\\frac{1}{2} m \\dot{x}^{2}+\\dfrac{1}{2} M\\left(\\dfrac{1}{2} \\dot{x}\\right)^{2}+\\frac{1}{2}\\left(\\dfrac{1}{2} M R^{2}\\right)\\left(\\dfrac{\\dot{x}}{2 R}\\right)^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{1}{4} M+\\frac{1}{8} M\\right) \\dot{x}^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{3}{8} M\\right) \\dot{x}^{2} \\end{align} 势能：$U=\\dfrac{1}{2} k_{2} x^{2}+\\dfrac{1}{2} k_{1}\\left(\\dfrac{1}{2} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{2}+\\dfrac{1}{4} k_{1}\\right) x^{2}$ 由能量守恒可知： $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max }$ 解得：$\\omega_{0}=\\sqrt{\\dfrac{2 k_{1}+8 k_{2}}{3 M+8 m}}$ 瑞利法利用能量法求解固有频率时，对于系统的动能的计算只考虑了惯性元件的动能，而忽略不计弹性元件的质量所具有的动能，因此算出的固有频率是实际值的上限。 这种简化方法在许多场合中都能满足要求，但有些工程问题中，弹性元件本身的质量因占系统总质量相当大的比例而不能忽略，否则算出的固有频率明显偏高。 当弹簧的质量的质量不是远小于小车的质量时，就无法忽略弹簧的质量，因此这里用等效的质量来分析。 系统最大的势能：$V_{\\max }=\\frac{1}{2} k x_{\\max }^{2}$ $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max } \\quad \\Rightarrow \\quad \\omega_{0}=\\sqrt{\\dfrac{k}{m+m_{t}}}$ 若忽略 $m_t$ ，则$\\omega_0$增大，因此忽略弹簧动能所算出的固有频率是实际值的上限。 瑞利法求解等效的质量是通过积分来求解的。 等效质量与等效阻尼方法一：能量法求解 选定广义位移坐标后，将系统得动能、势能写成如下形式：$T=\\dfrac{1}{2} M_{e} \\dot{x}^{2} ,\\, V=\\dfrac{1}{2} K_{e} x^{2}$ 当 $\\dot x,x$分别取最大值时：$T \\rightarrow T_{\\max }， \\ V \\rightarrow V_{\\max }$ ，可以得出：$\\omega_{0}=\\sqrt{\\dfrac{K_{e}} {M_e}}$ $K_e$：简化系统的等效刚度；$M_e$：简化系统的等效质量。 等效的含义是指简化前后的系统的动能和势能分别相等。 主要步骤： 选定广义坐标 将动能和势能写成标准形式 根据系数写出等效刚度和等效阻尼 动能：$T=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2} \\Rightarrow M_{e}=m l^{2}$ 势能：$V=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\Rightarrow K_{e}=k a^{2}-m g l$ 固有频率：$\\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 势能：$U=\\frac{1}{2}\\left[\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}\\right] \\theta^{2}$ 等效刚度：$K_{e}=\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}$ 则固有频率为：$\\omega_{0}^{2}=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}$ 方法二：定义法 等效刚度：使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 等效质量：使系统在选定的坐标上产生单位加速度而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效质量。 使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 串联弹簧的刚度的倒数是原来各个弹簧刚度倒数的总和 并联弹簧的刚度是原来各个弹簧刚度的总和。 求：系统对于坐标x 的等效质量和等效刚度。 方法1：能量法 动能：$T=\\dfrac{1}{2} m_{1} \\dot{x}^{2}+\\dfrac{1}{2} m_{2}\\left(\\dfrac{l_{2}}{l_{1}} \\dot{x}\\right)^{2}=\\dfrac{1}{2}\\left(m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}\\right) \\dot{x}^{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 势能：$V=\\dfrac{1}{2} k_{1} x^{2}+\\dfrac{1}{2} k_{2}\\left(\\dfrac{l_{3}}{l_{1}} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}\\right) x^{2}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 方法二：定义法 设使系统在x方向产生单位加速度需要施加力P，则在m1、m2上产生惯性力，对支座取矩： $P l_{1}=\\left(m_{1} \\cdot 1\\right) l_{1}+\\left(m_{2} \\cdot \\dfrac{l_{2}}{l_{1}}\\right) l_{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 画虚线是夸张化的m，其实其位移非常的为微小，在零时刻产生了单位加速度$\\ddot x=1$，$m_1,m_2$在平衡位置静平衡位置：重力和弹簧预变形相互抵消，因此弹力可以忽略。 设使系统在x坐标上产生单位位移需要施加力P，则在k1、k2处将产生弹性恢复力，对支点取矩： $P l_{1}=\\left(k_{1} \\cdot 1\\right) l_{1}+\\left(k_{2} \\cdot \\dfrac{l_{3}}{l_{1}}\\right) l_{3}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 等效质量(惯性力)：动态求解(达朗贝尔原理)； 等效刚度(静力平衡：静态求解(列静力学方程)。","link":"/2022/01/27/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E8%87%AA%E7%94%B1%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第五章 线性振动的近似计算方法 传递矩阵法","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是线性振动的近似计算方法中传递矩阵法，主要从圆盘的扭转振动和梁的横向振动来介绍，主要的思想就是将结构转化成为基本的集中质量的结构，进而求解传递矩阵，最后利用边界条件来求解固有频率。 传递矩阵法适用于计算链状结构的固有频率和主振型 多个圆盘的扭振，连续梁，气轮机和发电机的转轴系统 特征：可简化为无质量的梁上带有若干个集中质量的横向振动 如将汽轮机轴的质量简化到轮盘上面。 特点：将链状结构划分为一系列单元，每对单元之间的传递矩阵的阶数等于单元的运动微分方程的阶数，因此传递矩阵法对全系统的计算分解为阶数很低的各个单元的计算，然后加以综合，从而大大减少计算工作量 圆盘的扭转振动 轴不计质量，只计刚度，圆盘和轴自左至右编号 第 i-1 个和第 i 个圆盘以及连接两盘的轴段构成第 i 个单元 $J_{i-1}、J_{i}$ 圆盘转动惯量；$l_i$：轴段长度 ；$k_i$：轴段扭转刚度 \\begin{aligned} {\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{i}^{R} } &=\\left[\\begin{array}{cc}1 & 0 \\\\ -\\omega^{2} J_{i} & 1\\end{array}\\right]\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{i}^{L} \\quad \\boldsymbol{X}_{i}^{R}=\\boldsymbol{S}_{i}^{P} \\boldsymbol{X}_{i}^{L} \\\\ \\boldsymbol{S}_{i}^{P} &=\\left[\\begin{array}{cc}1 & 0 \\\\ -\\omega^{2} J_{i} & 1\\end{array}\\right] \\quad \\text { 点传递矩阵 } \\end{aligned}其中，$\\boldsymbol{X}=(\\theta,T)^T$为状态的变量。 第 i 个轴段来分析： \\begin{aligned} {\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{i}^{L} } &=\\left[\\begin{array}{cc}1 & 1/k_i \\\\ 0 & 1\\end{array}\\right]\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{i-1}^{R} \\quad \\boldsymbol{X}_{i}^{L}=\\boldsymbol{S}_{i}^{F} \\boldsymbol{X}_{i-1}^{R} \\\\ \\boldsymbol{S}_{i}^{F} &=\\left[\\begin{array}{cc}1 & 1/k_i \\\\ 0 & 1\\end{array}\\right] \\quad \\text { 场传递矩阵 } \\end{aligned} 第 i-1 个圆盘右侧到第 i 个圆盘右侧的状态变量传递关系： \\boldsymbol{X}_{i}^{R}=\\boldsymbol{S}_{i}^{P} \\boldsymbol{S}_{i}^{F} \\boldsymbol{X}_{i-1}^{R}=\\boldsymbol{S}_{i} \\boldsymbol{X}_{i-1}^{R} \\\\ S_{i}=S_{i}^{P} S_{i}^{F} \\Rightarrow 单元传递矩阵\\\\\\boldsymbol{S}_{i}=\\boldsymbol{S}_{i}^{P} \\boldsymbol{S}_{i}^{F}=\\left[\\begin{array}{cc}1 & 0 \\\\ -\\omega^{2} J_{i} & 1\\end{array}\\right]\\left[\\begin{array}{cc}1 & 1 / k_{i} \\\\ 0 & 1\\end{array}\\right]=\\left[\\begin{array}{cc}1 & 1 / k_{i} \\\\ -\\omega^{2} J_{i} & 1-\\omega^{2}\\left(J_{i} / k_{i}\\right)\\end{array}\\right]n 个圆盘的轴系，最左端和最右端状态变量传递关系：$\\boldsymbol{X}_n^R=S\\boldsymbol{X}_1^R$ S：第1至第n单元通路中所有单元传递矩阵的连乘积 $S=S_nS_{n-1}…S_1 \\ (\\omega)$的函数。 最后再去利用两端边界条件可确定固有频率和模态。 第一个圆盘左端状态：$\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{1}^{L} =\\left[\\begin{array}{c}1 \\\\ 0 \\end{array}\\right]$ 第一个圆盘右端状态：$\\left[\\begin{array}{l}\\theta \\\\ T\\end{array}\\right]_{1}^{R} =\\left[\\begin{array}{cc}1 &amp; 0 \\\\ -\\omega^{2} J &amp; 1\\end{array}\\right]\\left[\\begin{array}{c}1 \\\\ 0 \\end{array}\\right]=\\left[\\begin{array}{c}1 \\\\ -\\omega^2J \\end{array}\\right]$ 梁的横向弯曲振动系统 传递矩阵法可用于分析梁的横向弯曲振动； 梁上有 n-1 个集中质量，即只考虑质量，而不考虑其形状 ；梁段质量不计，只计刚度； 支座、梁段、集中质量自左向右分别编号； 第 i-1 个和第 i 个质量以及连接两质量的梁段构成第 i 个单元 梁段长$l_i$，抗弯刚度 $E_iI_i$，集中质量$m_{i-1}$、$m_i$ 状态变量构成：$\\boldsymbol{X} = (y \\quad \\theta\\quad M\\quad F_s)^T$ 分别对应的是：集中质量处梁的横向位移(挠度)、截面转角、弯矩和剪力 这几个是有一定对应的关系的，其中第一个$\\theta=\\partial y/\\partial x$ ，$F_s=\\partial M /\\partial x$ ，弯矩M和挠度y是二阶曲率的关系。 第i个质量受力分析 由于几种质量，因此可以不考虑形状特征，此时的挠度、转角和弯矩是相同的，但是由于其质量无法无法忽略，因此其存在惯性力。 当系统以频率 $\\omega$ 作简谐振动时 ：$\\ddot y_i=-\\omega^2y_i$ 质量左右两侧的传递关系：$\\boldsymbol{X}_{i}^{R}=\\boldsymbol{S}_{i}^{P} \\boldsymbol{X}_{i}^{L}$(点传递矩阵) \\left[\\begin{array}{c}y \\\\ \\theta \\\\ M \\\\ F_{s}\\end{array}\\right]_{i}^{R}=\\left[\\begin{array}{cccc}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ \\omega^{2} m_{i} & 0 & 0 & 1\\end{array}\\right]\\left[\\begin{array}{c}y \\\\ \\theta \\\\ M \\\\ F_{s}\\end{array}\\right]_{i}^{L} \\quad第 i 个梁段受力分析 由于两端没有质量，因此平衡的条件是两端的剪力相同。 同时，材料力学和振动力学涉及的都是微小的变形，微振。 对于转角，由材料力学有： \\begin{aligned}\\theta_{i}(x) &=\\theta_{i-1}^{R}+\\frac{1}{E_{i} I_{i}} \\int_{0}^{x} M_{i}(x) d x \\\\&=\\theta_{i-1}^{R}+\\frac{1}{E_{i} I_{i}} M_{i-1}^{R} x+\\frac{1}{2 E_{i} I_{i}} F_{s, i-1}^{R} x^{2}\\end{aligned}对于挠度，有材料力学得: y_{i}(x)=y_{i-1}^{R}+\\int_{0}^{x} \\theta_{i}(x) d x \\\\=y_{i-1}^{R}+\\theta_{i-1}^{R} x+\\frac{1}{2 E_{i} I_{i}} M_{i-1}^{R} x^{2}+\\frac{1}{6 E_{i} I_{i}} F_{s, i-1}^{R} x^{3}于是令$\\theta_i(x)^L,\\ y_i(x)^L,\\ M_i(x)^L$ 中的$x=l_i$： F_{s,i}^L=F_{s,i-1}^R\\\\ M_i^L=M_i^R+F_{s,i-1}^Rl_i\\\\ \\theta_{i}^L =\\theta_{i-1}^{R}+\\frac{1}{E_{i} I_{i}} M_{i-1}^{R}l_i+\\frac{1}{2 E_{i} I_{i}} F_{s, i-1}^{R} {l_i}^{2}\\\\ y_{i}^L=y_{i-1}^{R}+\\theta_{i-1}^{R} l_i+\\frac{1}{2 E_{i} I_{i}} M_{i-1}^{R} {l_i}^{2}+\\frac{1}{6 E_{i} I_{i}} F_{s, i-1}^{R} {l_i}^{3}结合梁段受力平衡方程，第 i 个梁段左右两端状态变量的传递关系： 第 i -1 个质量右侧至第 i个质量右侧的状态变量传递关系： \\boldsymbol{X}_{i}^{R}=\\boldsymbol{S}_{i}^{P} \\boldsymbol{S}_{i}^{F} \\boldsymbol{X}_{i-1}^{R}=\\boldsymbol{S}_{i} \\boldsymbol{X}_{i-1}^{R} \\\\ S_{i}=S_{i}^{P} S_{i}^{F} \\Rightarrow 单元传递矩阵\\\\对于带 n 个集中质量得梁，总能利用各单元传递矩阵的连乘积导出梁的最左端和最右端状态变量传递关系：$\\boldsymbol{X}_n^R=S\\boldsymbol{X}_1^R$ 最后两端边界条件可确定固有频率和振型 本节主要关注： 一个初始条件：先对模型进行分段，将确定两边的边界条件。 两次受力分析：一次对集中质量，一次对轴段和两端。 三个传递矩阵：点传递矩阵、场传递矩阵、单元传递矩阵。 引入无量纲量的目的是方便计算 之后使用传递矩阵法，计算每个两端和集中质量处的状态变量的值，最后我们将两边的结果代入即可。 两支座之间的状态关系：$ \\boldsymbol{X}_{3}^{L}=\\overline{\\boldsymbol{S}}_{0}^{R} \\quad \\overline{\\boldsymbol{S}}=\\overline{\\boldsymbol{S}}_{3}^{F} \\overline{\\boldsymbol{S}}_{2}^{P} \\overline{\\boldsymbol{S}}_{2}^{F} \\overline{\\boldsymbol{S}}_{1}^{P} \\overline{\\boldsymbol{S}}_{1}^{F} $ 在初始条件下 $y_0^R=0,\\ M_0^R=0$ 代入得到 $y_3^L,M_3^R$ 的表达式，在代入$y_3^L=0,\\ M_3^L=0$ \\overline{\\boldsymbol{S}}=\\left[\\begin{array}{llll}\\alpha_{11} & \\alpha_{12} & \\alpha_{13} & \\alpha_{14} \\\\ \\alpha_{21} & \\alpha_{22} & \\alpha_{23} & \\alpha_{24} \\\\ \\alpha_{31} & \\alpha_{32} & \\alpha_{33} & \\alpha_{34} \\\\ \\alpha_{41} & \\alpha_{42} & \\alpha_{43} & \\alpha_{44}\\end{array}\\right]\\Rightarrow\\left(\\begin{array}{c}\\bar{y} \\\\ \\theta \\\\ \\bar{M} \\\\ \\overline{\\bar{F}}\\end{array}\\right)_{3}^{L}=\\left[\\begin{array}{llll}\\alpha_{11} & \\alpha_{12} & \\alpha_{13} & \\alpha_{14} \\\\ \\alpha_{21} & \\alpha_{22} & \\alpha_{23} & \\alpha_{24} \\\\ \\alpha_{31} & \\alpha_{32} & \\alpha_{33} & \\alpha_{34} \\\\ \\alpha_{41} & \\alpha_{42} & \\alpha_{43} & \\alpha_{44}\\end{array}\\right]\\left(\\begin{array}{c}\\bar{y} \\\\ \\theta \\\\ \\bar{M} \\\\ \\overline{\\bar{F}}\\end{array}\\right)_{0}^{R}两端支座边界条件: \\left\\{\\begin{array}{l}\\alpha_{12} \\theta_{0}+\\alpha_{14} \\bar{F}_{s 0}=0 \\\\ \\alpha_{32} \\theta_{0}+\\alpha_{34} \\bar{F}_{s 0}=0\\end{array}\\right. 非零解条件: $\\quad \\Delta \\lambda(\\omega)=\\left|\\begin{array}{ll}\\alpha_{12} &amp; \\alpha_{14} \\\\ \\alpha_{32} &amp; \\alpha_{34}\\end{array}\\right|=0 \\quad $得出频率方程，求解可得系统的固有频率。 也可利用特征方程，采用数值方法求解固有频率。 频率和模态是由边界决定，因为手动在这些连续体上面的传递可以看作是一种波的传递过程，这就是传递矩阵法的意义所在。 下面看一个悬臂梁的例子。 边界条件： 最左边贴近固定端的一侧，其挠度和转角为0，允许有弯矩和剪力； 对于自由端，由于没有约束其转角和挠度不为0，剪力和弯矩由于没有相关的约束，因此为0。 最后的结果是第一阶模态的准确性还是可以的，但是第二阶就不准确了。 原因是对于之前的简支梁来说，其左右两边是被固定住的，因此肯定是无法发生位移的，集中质量假设对该模型来说影响不大，即简化前后的模态大体上是相近的情况。 但是对于悬臂梁而言，其有一个自由端，之前是一个均匀的悬臂梁的振型和集中质量简化后的求出的模态有在自由端上出现差异。","link":"/2022/03/15/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%8C%AF%E5%8A%A8%E7%9A%84%E8%BF%91%E4%BC%BC%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95-%E4%BC%A0%E9%80%92%E7%9F%A9%E9%98%B5%E6%B3%95/"},{"title":"第二章单自由度系统自由振动-第二部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍有阻尼自由振动和等效阻尼振动，包括库伦力但摩擦系统自由振动的精确分析。 阻尼自由振动理论知识 实际系统的机械能不可能守恒，存在各种各样的阻力 振动中将阻力称为阻尼：摩擦阻尼，电磁阻尼，介质阻尼和结构阻尼 尽管已经提出了许多数学上描述阻尼的方法，但是实际系统中阻尼的物理本质仍然极难确定 最常用的一种阻尼力学模型是粘性阻尼 例如：在流体中低速运动或沿润滑表面滑动的物体，通常就认为受到粘性阻尼 对于高速运动的物体，其受到的是高速阻尼力的影响，比如足球在空中高速的飞过其受到的阻尼力跟速度的二次方成正相关。 由于振动的存在，因此阻尼造成的延迟是广泛存在的。 粘性阻尼力与相对速度称正比，即： P_d = cv 其中，c:为粘性阻尼系数，或阻尼系数单位：$ N.s /m $ 建立平衡位置，并受力分析： 动力学方程： m\\ddot x(t) + c\\dot x(t) + kx(t) = 0 或者写成： \\ddot x(t) + 2\\zeta \\omega_0 \\dot x(t) + \\omega_0^2x(t) = 0\\\\ \\frac c m = 2 \\zeta\\omega_0 这里我们的固有频率：$\\omega_0 = \\sqrt {\\dfrac k m}$ ; 相对阻尼系数为 $\\zeta = \\dfrac c {2\\sqrt {km}}$ 使用特征根法来求解得： 这里只有欠阻尼才会引起振动，一般情况下，我们结构阻尼都在0.05以下。 过阻尼和临界阻尼会造成系统逐渐停止。 情况一：欠阻尼 $\\zeta &lt; 1$ 特征根：$\\lambda_{1,2} = -\\zeta\\omega_0 \\pm i\\omega_d$ 此时有两个复数根； 此时得振动方程解为：$ x(t)=e^{-\\zeta\\omega_0t}(c_1\\cos\\omega_dt + c_2\\sin\\omega_dt )$ 其中 $c_1,c_2:$初始条件确定； 有阻尼的自由振动频率 ： $\\omega_d = \\omega_0\\sqrt{1-\\zeta^2}$，从中得出，有阻尼情况下的振动周期更长，频率更慢。 此时的周期为$T_d = \\dfrac{2\\pi}{\\omega_0\\sqrt{1-\\zeta^2}} = \\dfrac{T_0}{\\sqrt{1-\\zeta^2}}$ 是初始条件：$x(0) = x_0 \\qquad \\dot x(0)=x_0$ 此时的振动界为：$x(t)=e^{-\\zeta\\omega_0t}(x_0\\cos\\omega_dt + \\dfrac {\\dot x_0 + \\zeta\\omega_0x_0} {\\omega_d}\\sin\\omega_dt ) $ 或简写成：$x(t)=e^{-\\zeta\\omega_0t}Asin(\\omega_d t + \\theta) $ 其中$A = \\sqrt{x_0^2+\\left (\\dfrac {\\dot x_0 + \\zeta\\omega_0x_0} {\\omega_d}\\right )^2}$ , $\\theta = tg^{-1} \\dfrac{x_0\\omega_d}{\\dot x_0 + \\zeta\\omega_0x_0}$ 如图为振动的图形： 欠阻尼为振幅逐渐衰减，周期不变的振动。 对比阻尼下的振动可知：在高频的振动下可以通过阻尼材料进行控制，但是对于低频材料来说阻尼材料的作用不大； 阻尼材料属于被动控制的一种，主要是振动的能量 减幅系数 $\\eta$ 评价阻尼对振幅衰减快慢的影响，定义为相邻两个振幅的比值： \\eta = \\dfrac {\\Delta_i} {\\Delta_{i+1}} = \\dfrac {Ae^{-\\zeta\\omega_0t}} {Ae^{-\\zeta\\omega_0{(t+T_d)}}}=e^{-\\zeta\\omega_0T_d} $\\eta$ 和 t 无关，任意两个相邻振幅之比均为$\\eta$ 衰减振动的频率为$\\omega_d$，振幅衰减的快慢取决于$\\zeta\\omega_0$，这两个重要的特征反映在特征方程的特征根的实部和虚部. 但是由于其含有指数项，不利于工程上的应用，因此实际中采用对数衰减率，$\\Lambda=\\ln \\eta = \\zeta\\omega_0T_d$ ,可以使用仪器测得。 实验测量： 利用相隔j 个周期的两个峰值进行求解： \\dfrac {\\Delta_i} {\\Delta_{i+j}} = \\dfrac {\\Delta_i} {\\Delta_{i+1}}\\dfrac {\\Delta_{i+1}} {\\Delta_{i+2}}\\dfrac {\\Delta_{i+2}} {\\Delta_{i+3}}\\dots\\dfrac {\\Delta_{i+j-1}} {\\Delta_{i+j}} 得：$\\Lambda=\\dfrac1 j\\ln \\eta = \\zeta\\omega_0 \\dfrac{2\\pi}{\\omega_0\\sqrt{1-\\zeta^2}} = \\dfrac{2\\pi\\zeta}{\\sqrt{1-\\zeta^2}} \\approx 2\\pi\\zeta$ 其中$\\zeta = \\dfrac{\\Lambda}{2\\pi}$ 情况二：过阻尼 $\\zeta &gt; 1$ 特征根：$\\lambda_{1,2} = -\\zeta\\omega_0 \\pm i\\omega_0\\sqrt{\\zeta^2-1}$ 此时有两个负实根； $\\omega^* = \\omega_0\\sqrt{\\zeta^2-1}$ 此时得振动方程解为：$ x(t)=e^{-\\zeta\\omega_0t}(c_1ch\\omega^*t + c_2sh\\omega^*t )$ 其中 $c_1,c_2:$初始条件确定； 是初始条件：$x(0) = x_0 \\qquad \\dot x(0)=x_0$ 此时的振动界为：$x(t)=e^{-\\zeta\\omega_0t}(x_0ch\\omega^*t + \\dfrac {\\dot x_0 + \\zeta\\omega_0x_0} {\\omega_d}sh\\omega^*t ) $ 响应的图形为： 一种按指数规律衰减的非周期蠕动，没有振动发生 情况三：临界阻尼 $\\zeta = 1$ 特征根：$\\lambda_{1,2} = -\\omega_0$ 此时有两个重根； 此时得振动方程解为：$ x(t)=e^{\\omega_0t}(c_1 + c_2t )$ 其中 $c_1,c_2:$初始条件确定； 是初始条件：$x(0) = x_0 \\qquad \\dot x(0)=x_0$ 此时的振动界为：$x(t)=e^{-\\zeta\\omega_0t}(x_0+ ({\\dot x_0 + \\omega_0x_0})t)$ 这里也是呈现指数衰减的，只是衰减的速度没有过阻尼快； 临界阻尼系数$c_{cr}$ ： $\\zeta = \\dfrac c {2\\sqrt {km}}$ 但是要注意的是，这里的c是等效阻尼，可能有系数，要整体来乘，最后得出$c_{cr} = 2\\sqrt{km}$ 欠阻尼是一种振幅逐渐衰减的振动 过阻尼是一种按指数规律衰减的非周期蠕动，没有振动发生 临界也是按指数规律衰减的非周期运动，但比过阻尼衰减快些 应用案例 由题知：$x(0) = x_0 \\qquad \\dot x(0)=x_0$ 此时的振动界为：$x(t)=e^{-\\zeta\\omega_0t}(x_0\\cos\\omega_dt + \\dfrac {\\dot x_0 + \\zeta\\omega_0x_0} {\\omega_d}\\sin\\omega_dt ) $ 求导可得：$\\dot{x}(t)=-\\frac{\\omega_{0}^{2} x_{0}}{\\omega_{d}} e^{-\\zeta \\omega_{0} t} \\sin \\omega_{d} t$ 设在时刻t1 质量越过平衡位置到达最大位移，此时速度： $\\dot{x}(t)=-\\frac{\\omega_{0}^{2} x_{0}}{\\omega_{d}} e^{-\\zeta \\omega_{0} t} \\sin \\omega_{d} t=0 \\Rightarrow t_1 = \\dfrac{\\pi}{\\omega_d}$ 即经过半个周期后出现第一个振幅x1 $x_{1}=x\\left(t_{1}\\right)=-x_{0} e^{-\\zeta \\omega_{0} t_{1}}=-x_{0} e^{-\\frac{\\pi \\zeta}{\\sqrt{1-\\zeta^{2}}}}$ 由题可知：$\\left|\\dfrac{x_{1}}{x_{0}}\\right|=e^{-\\frac{\\pi \\zeta}{\\sqrt{1-\\zeta^{2}}}}=10 \\%$ 解得：$\\zeta=0.59$ 这里建立广义坐标 $\\theta$，这里我们假设初始位置已经达到了静平衡位置了，因此不用分析重力和弹性力(因为已经抵消了)。 阻尼力的方向和速度的方向相反，弹性力和位移的方向相反。 由力矩平衡可得： m \\ddot{\\theta}(t) l \\cdot l+c \\dot{\\theta}(t) a \\cdot a+k \\theta(t) b \\cdot b=0\\\\ m l^{2} \\ddot{\\theta}(t)+c a^{2} \\dot{\\theta}(t)+k b^{2} \\theta(t)=0 则此时根据公式可求出无阻尼时的固有频率为：$\\omega_{0}=\\sqrt{\\dfrac{k b^{2}}{m l^{2}}}=\\dfrac{b}{l} \\sqrt{\\dfrac{k}{m}}$ $\\dfrac{c a^{2}}{m l^{2}}=2 \\xi \\omega_{0} \\Rightarrow \\xi=\\dfrac{c a^{2}}{2 m l^{2} \\omega_{0}}=\\dfrac{c a^{2}}{2 m l b} \\sqrt{\\dfrac{m}{k}}$ 于是，阻尼振动的固有频率为 $\\omega_{d}=\\omega_{0} \\sqrt{1-\\xi^{2}}=\\dfrac{1}{2 m l^{2}} \\sqrt{4 k m b^{2} l^{2}-c^{2} a^{4}}$ 进而得到临界阻尼系数为： $\\xi=1 \\quad \\Rightarrow \\quad c_{c r}=\\dfrac{2 b l}{a^{2}} \\sqrt{m k}$ 等效粘性阻尼 阻尼在所有振动系统中是客观存在的； 大多数阻尼是非粘性阻尼，其性质各不相同 非粘性阻尼的数学描述比较复杂，处理方法之一： 采用能量方法将非粘性阻尼简化为等效粘性阻尼 等效原则：等效粘性阻尼在一个周期内消耗的能量等于要简化的非粘性阻尼在同一周期内消耗的能量。 通常假设在简谐激振力作用$F=F_0\\sin\\omega t$\\ 下，非粘性阻尼系统的稳态响应仍然为简谐振动。 该假设只有在非粘性阻尼比较小时才是合理的，否则会造成大量的相位上的延迟。 粘性阻尼在一个周期内消耗的能量 $\\Delta E$ 可近似地利用无阻尼振动规律计算出： \\Delta E=-\\oint c \\dot{x} d x=-\\int_{0}^{T} c \\dot{x} d t=-c \\omega_{0}^{2} A^{2} \\int_{0}^{T} \\cos ^{2}\\left(\\omega_{0} t+\\theta\\right) d t=-\\pi c A^{2}目的是为了采用该式计算等效粘性阻尼系数 讨论以下几种非粘性阻尼情况： 干摩擦阻尼、平方阻尼(高速运动的物体)、结构阻尼 干摩擦阻尼 干摩擦阻尼又称库伦阻尼 其摩擦力：$F_{d}=-\\mu F_{N} \\operatorname{sgn} \\dot{x}(t)$ ， $\\operatorname{sgn} \\dot{x}(t)=\\left\\{\\begin{array}{ll}1, &amp; \\dot{x}(t)&gt;0 \\\\ 0, &amp; \\dot{x}(t)=0 \\\\ -1, &amp; \\dot{x}(t)&lt;0\\end{array}\\right.$ 其中$\\mu:$摩擦系数 $F_N:$正压力 $sgn\\dot x$：为符号函数 平方阻尼 工程背景：低粘度流体中以较大速度运动的物体时，阻尼力与相对速度的平方成正比，方向相反。 阻尼力：$F_{d}=-c_{d} \\dot{x}^{2}(t) \\operatorname{sgn} \\dot{x}(t)$ $c_d$：阻力系数 在运动方向不变的半个周期内计算耗散能量，再乘2： $\\Delta E=-\\oint c_{d} \\dot{x}^{2}(t) \\operatorname{sgn} \\dot{x}(t) d x=-2 \\int_{-T / 4}^{T / 4} c_{d} \\dot{x}^{3}(t) d t=-\\dfrac{8}{3} c_{d} \\omega_{0}^{2} A^{2}$ 等效粘性阻尼系数：$c_{e}=-\\dfrac{8}{3 \\pi} c_{d} \\omega_{0} A$ 结构阻尼 由于材料为非完全弹性，在变形过程中材料的内摩擦所引起的阻尼称为结构阻尼。 特征：应力－应变曲线存在滞回曲线加载和卸载沿不同曲线 内摩擦所耗散的能量等于滞回环所围的面积：$\\Delta E=-vA^2$ 等效粘性阻尼系数：$c_e=-\\dfrac {v} {\\pi\\omega_0}$ 库伦摩擦单自由度系统自由振动的精确分析有库伦力阻尼的一般振动系统在许多机械系统中，为了简单与方便经常采用库伦摩擦 $F=\\mu N$, 其中$\\mu$ : 动力学系数，N：法向力 摩擦自由振动问题： 动力学方程：$m\\ddot x+ kx = -\\mu N$ 是个二阶齐次的微分方程 通解：$x(t)=A_{1} \\cos \\omega_{0} t+A_{2} \\sin \\omega_{0} t-\\dfrac{\\mu N}{k}$ A1和A2为常数，由这半个周期的初始条件确定，$\\omega_0=\\sqrt{k/m}$ 为振动的固有频率。 动力学方程：$m\\ddot x+ kx = -\\mu N$ 是个二阶齐次的微分方程 通解：$x(t)=A_{1} \\cos \\omega_{0} t+A_{2} \\sin \\omega_{0} t-\\dfrac{\\mu N}{k}$ 动力学方程：$m\\ddot x+ kx = \\mu N$ 是个二阶齐次的微分方程 通解：$x(t)=A_{1} \\cos \\omega_{0} t+A_{2} \\sin \\omega_{0} t+\\dfrac{\\mu N}{k}$ A3和A4为常数，由这半个周期的初始条件确定 $\\mu$N / k 可以看做常力以静载荷方式作用在质量块上时弹簧产生的虚位移。 这两式同时表明，在每一个半周期中运动都是简谐的，只是对应的平衡位置从$\\mu$N / k变为$-\\mu$N / k。 合并可得：$m\\ddot x+ \\mu N sgn(\\dot x)kx = 0$ 是非线性方程，无解析解，可以分段求解。 由于开始的情况下，质量块是被拉到了最左端，然后释放，则此时的是从右向左运动的，满足情况2； 假定初始条件：$x(0)=x_0, \\dot x(0)=0$ $A_3=x_0-\\dfrac {\\mu N}{k} A_4=0$ $x(t)=\\left(x_{0}-\\dfrac{\\mu N}{k}\\right) \\cos \\omega_{0} t+\\dfrac{\\mu N}{k}$ , 在半周期内成立$t \\in [0, \\dfrac \\pi {\\omega_0}]$ 当$t=\\dfrac \\pi {\\omega_0}$时，质量快达到最左端位置： $x_{1}=x\\left(t=\\dfrac{\\pi}{\\omega_{0}}\\right)=\\left(x_{0}-\\dfrac{\\mu N}{k}\\right) \\cos \\omega_{0} t+\\dfrac{\\mu N}{k}=-\\left(x_{0}-\\dfrac{2 \\mu N}{k}\\right)$ 第二个半周期内，前一个半周期终止时刻的运动情况是这半个周期的初始条件： $x(0)=-(x_0-\\dfrac{2\\mu N}{k}), \\dot x(0)=0$ $\\Rightarrow$ $A_1=-x_0+\\dfrac {3\\mu N}{k} A_2=0$ $x(t)=\\left(x_{0}-\\dfrac{3\\mu N}{k}\\right) \\cos \\omega_{0} t-\\dfrac{\\mu N}{k}$ , 在半周期内成立$t \\in [\\dfrac \\pi {\\omega_0}, \\dfrac {2\\pi} {\\omega_0}]$ 在这半个周期的最后时刻的位移和速度：$x_2=x_0-\\dfrac{4\\mu N}{k}, \\dot x=0$ 在运动终止前，发生的半个周期的个数r 为：$x_{0}-r \\dfrac{2 \\mu N}{k} \\leq \\dfrac{\\mu N}{k} \\Rightarrow r \\geq \\dfrac{x_{0}-\\dfrac{\\mu N}{k}}{\\dfrac{2 \\mu N}{k}}$ 有库伦力阻尼的扭转振动系统 第2个半周期结束时振幅：$\\theta_{r}=\\theta_{0}-r \\dfrac{2 T}{k_{\\theta}}$ ,其中$\\theta_0$为t=0时的角位移(t=0时的$\\dot \\theta_0=0$) 当$r \\geq\\left(\\theta_{0}-\\dfrac{T}{k_{\\theta}}\\right) /\\left(\\dfrac{2 T}{k_{\\theta}}\\right)$时，会停止运动。 固有频率：$\\omega_{0}=\\sqrt{\\dfrac{k}{m}}=\\dfrac{2 \\pi}{T}=\\dfrac{2 \\pi}{0.4}(\\mathrm{rad} / s)=15.708(\\mathrm{rad} / s)$ 在一个周期内振幅减少量为：$\\dfrac{4 \\mu N}{k}=\\dfrac{4 \\mu m g}{k}$ 由初始条件得：$5\\times\\dfrac{4 \\mu m g}{k} = 0.10-0.01(m)=0.09(m)$ 摩擦系数：$\\mu=\\dfrac{0.09 k}{20 m g}=\\dfrac{0.09 \\omega_{0}^{2}}{20 g}=\\dfrac{0.09 \\times 15.708^{2}}{20 \\times 9.81}=0.1132$ $r \\geq \\dfrac{0.10472-\\dfrac{400}{49087.5}}{\\dfrac{800}{49087.5}}=5.926$ 因此其停止要经过的周期数为6个半周期的时间，其初始的位移 $\\theta_0=0.10472 rad$ 第r根半周期结束后的振幅为：$\\theta_{r}=\\theta_{0}-r \\dfrac{2 T}{k_{\\theta}}$ 经过6个半周期后滑轮的角位移为：$\\theta=0.10472-6 \\times 2 \\times \\dfrac{400}{49087.5}(\\mathrm{rad})=0.006935(\\mathrm{rad})=0.39724^{\\circ}$ 滑轮停止的位置与平衡位置的夹角0.397240°，且与初始角位移在平衡位置的同侧。","link":"/2022/03/05/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E8%87%AA%E7%94%B1%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"第五章 线性振动的近似计算方法 第一部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是线性振动的近似计算方法中邓克利法，瑞利法，里茨法。 在线性多自由度系统振动中，振动问题归结为刚度矩阵和质量矩阵的广义特征值问题 。缺点之一：当系统自由度较大时，求解计算工作量非常大 对于航天的帆板自由度有40万个，对于高铁过隧道时振动的自由度为上亿个。Ansys里面求解特征根是有其核心的算法的，和自己在Matlab里面自己编程求解的结果不同。 本章介绍几种近似计算方法，可作为实用的工程计算方法对系统的振动特性作近似计算 其中主要包括邓克利法，瑞利法，里茨法，传递矩阵法。 早些年计算设备不强大时主要使用上述的方法进行近似计算，而现在的计算方法和软件比较的发达，因此本章的方法只作为了解不是重点。 但是传递矩阵法是重点，现在也有人研究。 邓克利法 由邓克利（Dunkerley）在实验确定多圆盘的横向振动固有频率时提出的 便于作为系统基频的计算公式 上述方程求解得到的模态的结果是相同的，不会因为作用力方程和位移方程而有不同，其结果是相同的。 其中，这里的$a_1$是D矩阵的迹，即对角线元素之和。 M 阵一般是对角的，只有在集中质量和摆动耦合的情况下是对称非对角的. 物理意义：沿第 i 个坐标施加单位力时所产生的第 i 个坐标的位移 对于刚度：$F=kx \\Rightarrow k = \\dfrac F x$ 单位需要的力的大小；对于柔度：$\\dfrac 1 k=\\dfrac x F$ 单位力产生位移。 如果只保留第 i 个质量，所得单自由度系统的固有频率为： $\\bar{\\omega}$ 都是单自由度系统的频率。 \\sum_{i=1}^{n} \\frac{1}{\\omega_{i}^{2}}=\\sum_{i=1}^{n} f_{i i} m_{i} \\qquad \\bar{\\omega}_{i}^{2}=\\frac{k_{i}}{m_{i}}=\\frac{1}{f_{i i} m_{i}}\\\\ \\sum_{i=1}^{n} \\frac{1}{\\omega_{i}^{2}}=\\frac{1}{\\bar{\\omega}_{1}^{2}}+\\frac{1}{\\bar{\\omega}_{2}^{2}}+\\cdots+\\frac{1}{\\bar{\\omega}_{n}^{2}}当第二阶及以上固有频率远大于基频时，得到的基频是精确值的下限： \\frac{1}{\\omega_{1}^{2}} \\approx \\frac{1}{\\bar{\\omega}_{1}^{2}}+\\frac{1}{\\bar{\\omega}_{2}^{2}}+\\cdots+\\frac{1}{\\bar{\\omega}_{n}^{2}}邓克利法：利用单自由度固有频率近似求解多自由度系统基频的方法 \\frac{1}{\\omega_{1}^{2}}+a=b \\quad a=\\frac{1}{\\omega_{2}^{2}}+\\frac{1}{\\omega_{3}^{2}}+\\cdots+\\frac{1}{\\omega_{n}^{2}}\\\\ \\omega_{1}^{2}=\\frac{1}{b-a} \\quad b=\\frac{1}{\\bar{\\omega}_{1}^{2}}+\\frac{1}{\\bar{\\omega}_{2}^{2}}+\\cdots+\\frac{1}{\\bar{\\omega}_{n}^{2}}因在邓克利法中忽略了a，因此所得结果为基频下限 总结：邓克利法的主要是用来求解基频的，将用n个单自由度的频率来估计n自由度系统的基频的下限。 瑞利法 基于能量原理的一种近似方法 可用于计算系统的基频 算出的近似值为实际基频的上限 配合邓克利法算出的基频下限，可以估计实际基频的大致范围 \\phi=\\varphi=a_{1} \\boldsymbol{\\phi}_{N}^{(1)}+a_{2} \\boldsymbol{\\phi}_{N}^{(2)}+\\cdots+a_{N} \\boldsymbol{\\phi}_{N}^{(n)}=\\sum_{j=1} a_{j} \\boldsymbol{\\phi}_{N}^{(j)}=\\boldsymbol{\\Phi}_{N} \\boldsymbol{a}\\\\\\boldsymbol{\\Phi}_{N}=\\left[\\boldsymbol{\\phi}_{N}^{(1)}, \\boldsymbol{\\phi}_{N}^{(2)}, \\cdots, \\boldsymbol{\\phi}_{N}^{(n)}\\right] \\quad \\boldsymbol{a}=\\left[a_{1}, a_{2}, \\cdots, a_{n}\\right]^{T}\\\\R(\\varphi)=\\frac{\\boldsymbol{a}^{T} \\boldsymbol{\\Phi}_{N}^{T} \\boldsymbol{K} \\boldsymbol{\\Phi}_{N} \\boldsymbol{a}}{\\boldsymbol{a}^{T} \\boldsymbol{\\Phi}_{N}^{T} \\boldsymbol{M} \\boldsymbol{\\Phi}_{N} \\boldsymbol{a}}=\\frac{\\boldsymbol{a}^{T} \\boldsymbol{\\Lambda} \\boldsymbol{a}}{\\boldsymbol{a}^{T} \\boldsymbol{I} \\boldsymbol{a}}=\\sum_{j=1}^{n} a_{j}^{2} \\omega_{j}^{2} / \\sum_{j=1}^{n} a_{j}^{2}可以证明， $\\omega_1^2$ 和 $\\omega_n^2$分别为瑞利商的极小值和极大值。 \\omega_{1}^{2} \\leq R(\\varphi) \\leq \\omega_{n}^{2}分析：如果将$\\omega_j$换成$\\omega_1$，此时$\\omega_1$是最低阶固有频率 R(\\varphi)>\\sum_{j=1}^{n} a_{j}^{2} \\omega_{1}^{2} / \\sum_{j=1}^{n} a_{j}^{2}=\\omega_{1}^{2}由瑞利商公式知，当$\\varphi=\\phi^{(1)}$ 确为第一阶振型时：$R(\\varphi)=\\omega_1^2$ 因此，瑞利商的极小值为$\\omega_1^2$，同理可证明，瑞利商的极大值为$\\omega_{n}^2$ 代入瑞利商可得： R(\\varphi) \\approx \\omega_{k}^{2}+\\sum_{j=1}^{n}\\left(\\omega_{j}^{2}-\\omega_{k}^{2}\\right) \\varepsilon_{j}^{2} 因此，若 $\\varphi$与 $\\phi^{(k)}$ 的差异为一阶小量，则瑞利商与 $\\omega_k^2$ 的差别为二阶小量 对于基频的特殊情况，令k＝1，则由于 $\\omega_j^2-\\omega_1^2&gt;0 \\ (j=2,…,n)$ ，瑞利商在基频处取极大值 利用瑞利商估计系统的基频所得的结果必为实际基频的上限 愈接近系统的真实振型，算出的固有频率愈准确 在实际计算的时候，我们直接将静变形作为第一阶模态之后代入到上面式子中进行计算，得出基频的上限。 如果可以得出第二阶的模态，那么我们也可去很好的估计第二阶模态。 里茨法 里兹法是瑞利法的改进 用里兹法不仅可以计算系统的基频，还可以算出系统的前几阶频率和振型 瑞利法算出的基频的精度取决于假设的振型对第一阶主振型的近似程度，而且得到的基频总是精确值的上限 里兹法将对近似振型给出更合理的假设，从而使算出的基频值进一步下降 里兹法基于与瑞利法相同的原理，但将瑞利使用的单个假设振型改进为若干个独立的假设振型的线性组合： \\varphi=a_{1} \\boldsymbol{\\eta}^{(1)}+a_{2} \\boldsymbol{\\eta}^{(2)}+\\ldots+a_{r} \\boldsymbol{\\eta}^{(r)}=\\sum_{j=1} a_{j} \\boldsymbol{\\eta}^{(j)}=\\boldsymbol{\\Pi} \\boldsymbol{A} \\quad \\boldsymbol{\\eta}^{(i)} \\in R^{n \\times 1}\\\\ \\boldsymbol{\\Pi}=\\left[\\boldsymbol{\\eta}^{(1)}, \\boldsymbol{\\eta}^{(2)}, \\cdots, \\boldsymbol{\\eta}^{(r)}\\right] \\in R^{n \\times r} \\quad \\boldsymbol{A}=\\left[a_{1}, a_{2}, \\cdots, a_{r}\\right]^{T} \\in R^{r \\times 1}其中$\\eta^{(i)}$ 为假设模态，A中的元素数量时待定的。 R(\\varphi)=R(\\boldsymbol{\\Pi} \\boldsymbol{A})=\\frac{\\boldsymbol{A}^{T} \\boldsymbol{\\Pi}^{T} \\boldsymbol{K} \\boldsymbol{\\Pi} \\boldsymbol{A}}{\\boldsymbol{A}^{T} \\boldsymbol{\\Pi}^{T} \\boldsymbol{M} \\boldsymbol{\\Pi} \\boldsymbol{A}}=\\frac{\\boldsymbol{A}^{T} \\overline{\\boldsymbol{K}} \\boldsymbol{A}}{\\boldsymbol{A}^{T} \\overline{\\boldsymbol{M}} \\boldsymbol{A}}=\\bar{\\omega}^{2}\\\\ \\overline{\\boldsymbol{K}}=\\boldsymbol{\\Pi}^{T} \\boldsymbol{K} \\boldsymbol{\\Pi} \\in R^{r \\times r} \\quad \\overline{\\boldsymbol{M}}=\\boldsymbol{\\Pi}^{T} \\boldsymbol{M} \\boldsymbol{\\Pi} \\in R^{r \\times r}由于 $R(\\varphi)$ 在系统中的真实主振型处取驻值,所以 A 的各个元素应当从下式确定: \\frac {\\partial R}{\\partial a_j} = 0 \\quad (j=1,2,...,r) $\\dfrac {\\partial} {\\partial A}$ :为将函数分别对 A 各个元素依次求偏导，排成列向量。 同理, 有：$\\dfrac{\\partial}{\\partial A}\\left(A^{T} \\bar{M} A\\right)=2 \\bar{M} A$ \\frac{\\partial}{\\partial \\boldsymbol{A}}\\left(\\boldsymbol{A}^{T} \\overline{\\boldsymbol{K}} \\boldsymbol{A}\\right)-\\bar{\\omega}^{2} \\frac{\\partial}{\\partial \\boldsymbol{A}}\\left(\\boldsymbol{A}^{T} \\overline{\\boldsymbol{M}} \\boldsymbol{A}\\right)=\\mathbf{0}\\\\ \\Rightarrow \\left(\\overline{\\boldsymbol{K}}-\\bar{\\omega}^{2} \\overline{\\boldsymbol{M}}\\right) A=0 由于$\\bar{K}、\\bar{M}$ 阶数 r 一般远小于系统自由度数 n，上式矩阵特征值问题比原系统的矩阵特征值问题解起来容易得多 里兹法是一种缩减系统自由度求解固有振动的近似方法 频率求出即可，但是计算出的模态必须满足正交的要求。 下面证明正交性： 与我们假设的这个$\\varphi$ 是若干个独立的假设振型，因此可知A的不同分量间是线性独立的： i \\neq j \\text { 时 } \\boldsymbol{A}^{(i) T} \\overline{\\boldsymbol{M}} \\boldsymbol{A}^{(j)}=0, \\quad \\boldsymbol{A}^{(i) T} \\overline{\\boldsymbol{K}} \\boldsymbol{A}^{(j)}=0 \\quad \\text { 成立 } \\\\\\varphi^{(i) T} \\boldsymbol{M} \\varphi^{(j)} =\\boldsymbol{A}^{(i) T} \\boldsymbol{\\Pi}^{T} \\boldsymbol{M} \\boldsymbol{\\Pi} \\boldsymbol{A}^{(j)}=\\boldsymbol{A}^{(i) T} \\overline{\\boldsymbol{M}} \\boldsymbol{A}^{(j)}=0\\\\ \\varphi^{(i) T} \\boldsymbol{K} \\varphi^{(j)}=\\boldsymbol{A}^{(i) T} \\boldsymbol{\\Pi}^{T} \\boldsymbol{K} \\boldsymbol{\\Pi} \\boldsymbol{A}^{(j)}=\\boldsymbol{A}^{(i) T} \\overline{\\boldsymbol{K}} \\boldsymbol{A}^{(j)}=0得出的近似主振型式关于矩阵 M 和 K 相互正交 首先假设振型： \\boldsymbol{\\Pi}=\\left[\\begin{array}{ll}\\boldsymbol{\\eta}^{(1)} & \\boldsymbol{\\eta}^{(2)}\\end{array}\\right]=\\left[\\begin{array}{cc}1 & 1 \\\\2 & 2 \\\\3 & -1\\end{array}\\right]\\\\缩减后的新系统的刚度矩阵和质量矩阵： \\overline{\\boldsymbol{K}}=\\boldsymbol{\\Pi}^{T} \\boldsymbol{K} \\boldsymbol{\\Pi}=\\left[\\begin{array}{cc}4 k & -4 k \\\\-4 k & 20 k\\end{array}\\right] \\quad \\overline{\\boldsymbol{M}}=\\boldsymbol{\\Pi}^{T} \\boldsymbol{M} \\boldsymbol{\\Pi}^{T}=\\left[\\begin{array}{cc}23 m & -m \\\\-m & 7 m\\end{array}\\right]特征值问题: \\quad\\left[\\begin{array}{cc}4-23 \\alpha & -4+\\alpha \\\\ -4+\\alpha & 20-7 \\alpha\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right] \\quad \\alpha=\\frac{m \\bar{\\omega}^{2}}{k} \\begin{array}{c}\\alpha_{1}=0.139853 \\quad \\alpha_{2}=2.860147 \\\\\\boldsymbol{A}^{(1)}=\\left[\\begin{array}{ll}4.927547, & 1\\end{array}\\right]^{T} \\quad \\boldsymbol{A}^{(2)}=\\left[\\begin{array}{ll}-0.018449, & 1\\end{array}\\right]^{T}\\end{array} $\\beta_1$ 和 $\\beta_2$ 是主振型归一化时产生的常数，不必考虑 里兹法所得基频精度比瑞利法高，但第二阶固有频率精度欠佳，但是我们可以将估计出的值迭代多次逐渐逼近最优值。","link":"/2022/03/15/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%8C%AF%E5%8A%A8%E7%9A%84%E8%BF%91%E4%BC%BC%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第六章 连续系统的振动  一维波动方程","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是连续系统振动的一维波动方程部分，主要从动力学方程、固有频率和模态函数、常见的边界、主振型和正交性、杆的纵向受迫振动以及横向振动的典型例题等方面就行讲解。 本章主要的假设：1）本章讨论的连续体都假定为线性弹性体，即在弹性范围内服从虎克定律2）材料均匀连续；各向同性3）振动为微振 实际振动系统都是连续体，具有连续分布的质量与弹性，又称连续系统或分布参数系统。 确定连续体上无数质点的位置需要无限多个坐标，因此连续体是具有无限多自由度的系统。 连续体的振动要用时间和空间坐标的函数来描述，其运动方程不再像有限多自由度系统那样是二阶常微分方程组，它是偏微分方程。 在物理本质上，连续体系统和多自由度系统没有什么差别，连续体振动的基本概念与分析方法与有限多自由度系统是完全类似的。 动力学方程这里对于简单的系统来说是可以将上述的三种运动进行解耦分析的，但是对于大推力火箭而言，三种振动相互耦合，不可分开。 杆的纵向振动 $p(x,t)$：为单位长度杆上分布的纵向分布力 假定振动过程中各横截面仍保持为平面，忽略由纵向振动引起的横向变形 航天里面的悬臂结构，在向外伸长的时候，会产生一定的横向振动。 注意在太空中阻尼是可以忽略的 这里的$\\dfrac {\\partial^2u} {\\partial t^2} $ 代表的是微端的加速度；$\\rho Sdx$ 代表的是微端的质量。 横截面上内力：$ F=E S \\varepsilon=E S \\dfrac{\\partial u}{\\partial x} $ 达朗贝尔原理：$ \\rho S d x \\dfrac{\\partial^{2} u}{\\partial t^{2}}=\\left(F+\\dfrac{\\partial F}{\\partial x} d x\\right)-F+p(x, t) d x $ 这里我们使用的是最一般分布力来阐述，因为集中力可以看成是分布力的特殊情况。$F(t)=F_0\\delta(x-x_0)$ ，其中$x_0$为集中力的作用位置。 杆的纵向强迫振动方程为： \\rho S d x \\dfrac{\\partial^{2} u}{\\partial t^{2}}=\\left(F+\\dfrac{\\partial F}{\\partial x} d x\\right)-F+p(x, t) d x \\\\ \\rho S \\frac{\\partial^{2} u}{\\partial t^{2}}=\\frac{\\partial}{\\partial x}\\left(E S \\frac{\\partial u}{\\partial x}\\right)+p(x, t)等直杆ES 为常数： \\frac{\\partial^{2} u}{\\partial t^{2}}=a_{0}^{2} \\frac{\\partial^{2} u}{\\partial x^{2}}+\\frac{1}{\\rho S} p(x, t)其中，$a_0=\\sqrt {E/\\rho}$ 为弹性纵波沿杆的纵向传播速度 弦的横向振动 注意，这里是约等于，因为我们采用了$\\sin\\theta \\approx\\theta$ 的小角近似。 同理可得，弦的横向强迫振动方程： \\frac{\\partial^{2} y}{\\partial t^{2}}=a_{0}^{2} \\frac{\\partial^{2} y}{\\partial x^{2}}+\\frac{1}{\\rho } p(x, t)其中，$y(x,t)$：为弦上x 处横截面t 时刻的横向位移； $a_0$ ：为弹性横波的纵向传播速度 $\\rho$ ：为单位长度弦质量 如传送带皮带，由于传送带的纵向的运动会引起横向的振动问题。 轴的扭转振动 其中，T：为截面处的扭矩；$\\rho I_pdx$：为微端绕着轴线的转动惯量。 达朗贝尔原理： \\begin{array}{c}\\rho I_{p} d x \\dfrac{\\partial^{2} \\theta}{\\partial t^{2}}=\\left(\\mathbf{X}+\\dfrac{\\partial T}{\\partial x} d x\\right)-\\mathbf{K}+p d x \\\\\\rho I_{p} \\dfrac{\\partial^{2} \\theta}{\\partial t^{2}}=\\dfrac{\\partial T}{\\partial x}+p(x, t)\\end{array}材料力学中扭矩的公式可得： $T=G I_{p} \\dfrac{\\partial \\theta}{\\partial x} $ \\rho I_{p} \\frac{\\partial^{2} \\theta}{\\partial t^{2}}=\\frac{\\partial}{\\partial x}\\left(G I_{p} \\frac{\\partial \\theta}{\\partial x}\\right)+p(x, t)圆截面杆的扭转振动强迫振动方等直杆, 抗扭转刚度 $G I_{p} $ 为常数 \\frac{\\partial^{2} \\theta}{\\partial t^{2}}=a_{0}^{2} \\frac{\\partial^{2} \\theta}{\\partial x^{2}}+\\frac{1}{\\rho_{p}} p(x, t)其中，$a_0=\\sqrt{\\dfrac{ G} \\rho}$ ：为剪切弹性波的纵向传播速度 小结： 虽然它们在运动表现形式上并不相同，但它们的运动微分方程是类同的，都属于一维波动方程，因此分析得到的一些性质是可以共用的。 固有频率和模态函数 这里我们简化首先考虑自由振动的情况，此时设外部力的作用为0： \\frac{\\partial^{2} u}{\\partial t^{2}}=a_{0}^{2} \\frac{\\partial^{2} u}{\\partial x^{2}}假设杆的各点作同步运动：$u(x,t)=\\phi(x)q(t)$ 其中$q(t)$：为运动规律的时间函数； $\\phi(x)$：为杆上矩原点x处的截面的纵向振幅 \\frac{\\ddot{q}(t)}{q(t)}=a_{0}^{2} \\frac{\\phi^{\\prime \\prime}(x)}{\\phi(x)}=-\\lambda 解得： q(t)=a \\sin (\\omega t+\\theta) \\quad \\phi(x)=c_{1} \\sin \\frac{\\omega x}{a_{0}}+c_{2} \\cos \\frac{\\omega x}{a_{0}}其中，$c_1,c_2,\\omega$ 由杆的边界条件确定 ,$\\phi(x)$确定杆纵向振动的形态，称为振型。 杆的边界条件确定固有频率。 与有限自由度系统不同，连续系统的模态为坐标的连续函数，表示各坐标振幅的相对比值，由频率方程确定的固有频率$\\omega_i$有无穷多个 这里，固有频率和振动模态是一一对应的。 \\omega_i \\longleftrightarrow \\phi_i(x)第 i 阶主振动为：$u^{(i)}(x, t)=a_{i} \\phi_{i}(x) \\sin \\left(\\omega_{i} t+\\theta_{i}\\right), \\quad(i=1,2 \\cdots)$ 系统的自由振动是无穷多个主振动的叠加：$u(x, t)=\\sum_\\limits{i=1}^{\\infty} a_{i} \\phi_{i} \\sin \\left(\\omega_{i} t+\\theta_{i}\\right)$ 几种常见边界条件下的固有频率和模态函数固有频率的模态是由边界决定的。 求解频率方程可得：$\\omega_i=\\dfrac {i\\pi a_0}{l} \\quad (i=0,1,2,…)$ 无穷多组解。 此时的 i=0，对应的是刚体模态，但是题目两边是固定的，一定存在力，因此这个情况是不存在的。 将$\\omega_i$ 代入振型函数：$\\phi_i(x)=c_i\\sin\\dfrac {i\\pi x}{l} \\quad (i=0,1,2,…)$ 由于零固有频率对应的振型函数为零，因此零固有频率除去，但是对于导弹这种两边可以自由振动的系统，就可以存在这种频率为0的情况，此时对应的是刚体运动。 求解频率方程可得：$\\omega_i=\\dfrac {i\\pi a_0}{l} \\quad (i=0,1,2,…)$ 无穷多组解。 此时的 i=0，对应的是刚体模态。 将$\\omega_i$ 代入振型函数：$\\phi_i(x)=c_i\\cos\\dfrac {i\\pi x}{l} \\quad (i=0,1,2,…)$ 频率方程和固有频率两端固定杆的情况相同，零固有频率对应的常值振型为杆的纵向刚性位移。 边界条件中的第一行代表物理的边界，之后的第二行代表模态的边界。 求解频率方程可得：$\\omega_i=\\dfrac {(2i-1)\\pi a_0}{2l} \\quad (i=1,2,…)$或 $\\omega_i=\\dfrac {i\\pi a_0}{2l} \\quad (i=1,3,…)$ 无穷多组解。 将$\\omega_i$ 代入振型函数：$\\phi_i(x)=c_i\\sin\\dfrac {(2i-1)\\pi x}{2l} \\quad (i=1,2,…)$ 或 $\\phi_i(x)=c_i\\sin\\dfrac {i\\pi x}{2l}\\quad (i=1,3,…)$ 例：推导系统的频率方程 首先令系统的振动方程为：$u(x,t)=\\phi(x)q(t) \\quad \\phi(x)=c_{1} \\sin \\dfrac{\\omega x}{a_{0}}+c_{2} \\cos \\dfrac{\\omega x}{a_{0}}$ 代入边界条件可得： 对于左边界而言，其位移为0： u(0, t)=0 \\Rightarrow \\phi(0)=0 \\Rightarrow c_{2}=0对于去右边界，其受到的轴向力用弹簧的形变来抵消： k u(l, t)=-E S \\frac{\\partial u}{\\partial x}(l, t) \\Rightarrow k \\phi(l)=-E S \\frac{\\partial \\phi}{\\partial x}(l, t)\\\\ \\Rightarrow k \\sin \\frac{\\omega l}{a_{0}}=-E S \\frac{\\omega}{a_{0}} \\cos \\frac{\\omega l}{a_{0}}\\\\即得到频率方程为： \\Rightarrow \\frac{\\operatorname{tg}\\left(\\omega l / a_{0}\\right)}{\\omega l / a_{0}}=-\\frac{E S}{k l} \\equiv \\text { 常数 } 同样的，首先确定振动方程，之后代入到边界条件： u(0, t)=0\\\\M \\frac{\\partial^{2} u}{\\partial t^{2}}(l, t)=-E S \\frac{\\partial u}{\\partial x}(l, t) 总结： 连续体的频率和模态是由边界条件决定的，而多自由度问题的频率和模态是由其质量阵和刚度阵的特征根问题。 N自由度系统中有N个频率和N个模态，但是对于连续体问题的频率和模态是无穷的。 边界问题，上边讲述了三个简单的边界和两个复杂边界。 主振型的正交性只对具有简单边界条件的杆讨论主振型的正交性，杆可以是变截面或匀截面的 变截面：质量密度及截面积S等都可以是x 的函数 动力方程 : \\rho S \\dfrac{\\partial^{2} u}{\\partial t^{2}}=\\dfrac{\\partial}{\\partial x}\\left(E S \\dfrac{\\partial u}{\\partial x}\\right)+p(x, t) 这里由于是变截面的情况，因此将S放大偏微号之内。 自由振动方程： $ \\rho S \\dfrac{\\partial^{2} u}{\\partial t^{2}}=\\dfrac{\\partial}{\\partial x}\\left(E S \\dfrac{\\partial u}{\\partial x}\\right)$ 主振动 ：这里使用分离变量法 u(x, t)=\\phi(x) a \\sin (\\omega t+\\theta) \\\\\\left(E S \\phi^{\\prime}\\right)^{\\prime}=-\\omega^{2} \\rho S \\phi 这里可以对比多自由度系统的特征方程：$|K-\\omega^2M|=0$ 这里的$\\rho S$代表的是微元的质量，$ES$ 代表刚度微元项。 乘 $ \\phi_{j}(x) $ 并沿杆长积分: 由于这里的S可能是变截面的，因此S不能拿出来。 \\int_{0}^{l} \\phi_{j}\\left(E S \\phi_{i}^{\\prime}\\right)^{\\prime} d x=-\\omega_{i}^{2} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x分部积分: \\int_{0}^{l} \\phi_{j}\\left(E S \\phi_{i}^{\\prime}\\right)^{\\prime} d x=\\left.\\phi_{j}\\left(E S \\phi_{i}\\right)\\right|_{0} ^{l}-\\int_{0}^{l} E S \\phi_{i}^{\\prime} \\phi_{j}^{\\prime} d x 对于第一项而言，总有第一项为0，因为当其是简答边界时，第一项中的$\\phi_j$为0，但当其为自由边界时，$ES\\phi_i$为0，所以第一项总是0。 任一端上总有 $\\phi=0$ 或 $\\phi^{\\prime}=0$ 成立 \\quad \\int_{0}^{l} E S \\phi_{i}^{\\prime} \\phi_{j}^{\\prime} d x=\\omega_{i}^{2} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} dx 杆的主振型关于质量的正交性： \\left(\\omega_{i}^{2}-\\omega_{j}^{2}\\right) \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=0 \\\\i \\neq j \\text { 时 } \\ \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=0 \\Rightarrow\\omega_{i} \\neq \\omega_{j}杆的主振型关于刚度的正交性： \\int_{0}^{l} E S \\phi_{i}^{\\prime} \\phi_{j}^{\\prime} d x=-\\int_{0}^{l} \\phi_{j}\\left(E S \\phi_{i}^{\\prime}\\right)^{\\prime} d x=0 \\quad(i \\neq j) 当 $ i=j $ 时, 设第 i 阶模态主质量为$m_{pi}$ ： \\int_{0}^{l} \\rho S \\phi_{i}^{2} d x=m_{p i} 第 i 阶模态主刚度为$k_{pi}$： \\int_{0}^{l} E S\\left(\\phi_{i}^{\\prime}\\right)^{2} d x=-\\int_{0}^{l} \\phi_{i}\\left(E S \\phi_{i}^{\\prime}\\right)^{\\prime} d x=k_{p i}第 i 阶固有频率为 $\\omega_{i}$：$\\omega_{i}^{2}=k_{p i} / m_{p i}$ 对比多自由度系统的主模态和正则模态可得： 主振型归一化得出正则振型: $\\int_{0}^{l} \\rho S \\phi_{i}^{2} d x=m_{p i}=1$ 这里归一化的对象是模态函数前面的那个待定系数$c_1、c_2$ $\\phi(x)=c_{1} \\sin \\dfrac{\\omega x}{a_{0}}+c_{2} \\cos \\dfrac{\\omega x}{a_{0}}$ 则第 i 阶主刚度：$k_{p i}=\\omega_{i}^{2}$ 合写为: \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=\\delta_{i j} \\quad\\int_{0}^{l} E S \\phi_{i}^{\\prime} \\phi_{j}^{\\prime} d x=\\omega_{i}^{2} \\delta_{i j} \\\\ \\int_{0}^{l} \\phi_{i}\\left(E S \\phi_{j}^{\\prime}\\right)^{\\prime} d x=-\\omega_{i}^{2} \\delta_{i j} \\quad \\delta_{i j}=\\left\\{\\begin{array}{ll}1 & i=j \\\\ 0 & i \\neq j\\end{array}\\right.杆的纵向强迫振动 注意：这里的初始时刻是一个函数方程，表示初始状态下的形状分布函数。 其次，这里的$q_i(x)$不可以写成正弦了，因为现在讨论的是强迫振动。 \\rho S \\sum_{i=1}^{\\infty} \\phi_{i} \\ddot{q}=\\sum_{i=1}^{\\infty}\\left(E S \\phi_{i}^{\\prime}\\right)^{\\prime} q_{i}+p(x, t) 这里由于$q_i$是时间的函数，因此可以放到等式的外面。 并且由于正交性，$i \\ne j$的项全部被抵消了。 第j个正则模态坐标广义力：$\\ddot{q}_{j}+\\omega_{j}^{2} q_{j}=Q_{j}(t)$ 模态坐标初始条件求解 ： \\left \\{\\begin{array}{l} u(x, 0)=f_{1}(x)=\\sum_\\limits{i=1}^{\\infty} \\phi_{i}(x) q_{i}(0) \\\\ \\left.\\dfrac{\\partial u}{\\partial t}\\right|_{t=0}=f_{2}(x)=\\sum_\\limits{i=1}^{\\infty} \\phi_{i}(x) \\dot{q}_{i}(0)\\end{array}\\right.乘 $ \\rho S \\phi_{j}(x) $ 并沿杆长对 ( x ) 积分, 由正交性条件： \\left\\{\\begin{array}{ll}q_{j}(0)=\\int_{0}^{l} \\rho S f_{1}(x) \\phi_{j}(x) d x & \\text { 求得 } q_{j}(t) \\text { 后 } \\\\\\dot{q}_{j}(0)=\\int_{0}^{l} \\rho S f_{2}(x) \\phi_{j}(x) d x & \\text { 可得 } u(x, t)\\end{array}\\right.\\\\q_{j}(t)=q_{j}(0) \\cos \\omega_{j} t+\\frac{\\dot{q}_{j}(0)}{\\omega_{j}} \\sin \\omega_{j} t+\\frac{1}{\\omega_{j}} \\int_{0}^{l} Q_{j}(t) \\sin \\omega_{j}(t-\\tau) d \\tau 最后对初始条件的响应进行杜哈梅积分。 上面考虑的都是分布力作用时的情况，现在讨论集中力的情况： 当受到的力为集中力时：$p(x, t)=P(t) \\delta(x-\\xi)$ 正则坐标广义力： Q_{j}(t)=\\int_{0}^{l} P(t) \\delta(x-\\xi) \\phi_{j}(x) d x=P(t) \\phi_{j}(\\xi)横向振动的典型例题例：等直杆，自由端作用有：$P(t)=P_0\\sin\\omega t$ ，其中$P_0$为常数，求：杆的纵向稳态响应。 对于强迫振动还包括自由伴随，但是最后都会随着时间的推移而慢慢消失。这里求解的值稳态的情况，因此直接考虑稳态即可。 注意以下归一化，归一化的参数时模态方程的系数$C_i$ ，因此正则化的作用无非是确定模态方程的前面待定系数。 当外部力频率等于杆的任一阶固有频率时都会发生共振现象 基本的步骤： 由边界条件得到频率和模态函数； 求解模态广义力，即求解力在模态空间的表达式； 求解模态空间的解，即求解模态坐标$q_i(t)$，转换到物理空间。 例：一均质杆两端固定。假定在杆上作用有两个集中力，如图所示，试问：当这些力突然移去时，杆将产生什么样的振动？ 由于力去掉之后没有外部激励了，因此其振动的形式一定是简谐振动。 通过边界条件，即两边为固定端，可得其频率方程与位移方程。 边界条件上，在0时刻位移有一个分布函数，其实就是对应的应变分布。 系统的自由振动是无穷多个主振动的叠加： \\begin{aligned} u(x, t) &=\\sum_{i=1}^{\\infty} a_{i} \\phi_{i}(x) \\sin \\left(\\omega_{i} t+\\theta_{i}\\right) \\\\ &=\\sum_{i=1}^{\\infty}\\left\\{\\sin \\frac{i \\pi x}{l}\\left[B_{1 i} \\cos \\frac{i \\pi a_{0}}{l} t+B_{2 i} \\sin \\frac{i \\pi a_{0}}{l} t\\right]\\right\\} \\end{aligned}应用位移的初始条件 $u(x,0)=f(x)$ 代入到上述的方程中可得： f(x)=\\sum_\\limits{i=1}^{\\infty} B_{1i}\\sin \\frac{i \\pi x}{l}两边乘 $\\rho S\\phi_j(x)$ 并沿杆长积分，然后利用正交性条件： B_{1i}=\\frac 2 l \\int_0^1 f(x)\\sin \\frac{i \\pi x}{l}应用速度初始条件可得：$B_{2i}=0$ \\begin{aligned} B_{1 i}=& \\frac{2}{l} \\int_{0}^{l} f(x) \\sin \\frac{i \\pi x}{l} d x \\\\=& \\frac{2}{l} \\varepsilon_{0}\\left[\\int_{0}^{l / 4} x \\sin \\frac{i \\pi x}{l} d x+\\int_{l / 4}^{3 l / 4}\\left(\\frac{l}{2}-x\\right) \\sin \\frac{i \\pi x}{l} d x\\right.\\left.+\\int_{3 l / 4}^{l}(l-x) \\sin \\frac{i \\pi x}{l} d x\\right] \\\\=& \\frac{P_{0} l}{i^{2} \\pi^{2} E S}(-1)^{(i-2) / 4} \\qquad (i=2,6,10, \\ldots) \\end{aligned}将上述的待定系数，代入到物理空间的方程中解得系统的响应为： \\begin{aligned} u(x, t) &=\\sum_{i=1}^{\\infty}\\left\\{\\sin \\frac{i \\pi x}{l}\\left[B_{1 i} \\cos \\frac{i \\pi a_{0}}{l} t+B_{2 i} \\sin \\frac{i \\pi a_{0}}{l} t\\right]\\right\\} \\\\ &=\\frac{P_{0} l}{\\pi^{2} E S} \\sum_{i=2,6,10, \\ldots}^{\\infty} \\frac{(-1)^{(i-2) / 4}}{i^{2}} \\sin \\frac{i \\pi x}{l} \\cos \\frac{i \\pi a_{0}}{l} t \\end{aligned}这里，第二道例题是自由响应，因此可以将$q_i(t)=a_i\\sin(\\omega_it+\\theta_i)$ 来进行表示，代入边界条件求解待定系数，这种方法称为直接法。 相反，第一道例题的是受迫振动，无法使用直接法代入模态坐标$q_i(t)$的表达式，需要建立正则方程去求解。 思考题： 有一根以常速度v沿x轴运动的杆。如果杆的中点处突然被卡住停止，试求出所产生的自由振动表达式。 在此种情况下，可从杆的中点分开，分开的左右两部分的振动形式相同，因此只分析右半部分即可 边界条件：右半部分为一端固定、另一端自由的杆 杆的自由振动方程：$\\dfrac{\\partial^{2} u}{\\partial t^{2}}=a_{0}^{2} \\dfrac{\\partial^{2} u}{\\partial x^{2}}+\\dfrac{1}{\\rho S} p(x, t) \\quad a_0=\\sqrt{\\dfrac E \\rho}$ 边界条件为：$u(0,t)=0, \\quad \\left. \\dfrac{\\partial u}{\\partial x}\\right|_{x=\\frac l 2}=0$ 初始条件为：$u(x,0)=0, \\quad \\left. \\dfrac{\\partial u}{\\partial t}\\right|_{t=0}=0$ 例：有一根x=0 端为自由、x=l 端处为固定的杆，固定端承受支撑运动 $u_g(t)=d\\sin\\omega t$，d 为振动的幅值，试求杆的稳态响应 这里基础存在位移，参考基在动，因此这里的受力分析和之前不同。 此时$u^*$才是真正的杆的位移。 代入方程可得：$\\rho S\\ddot u^*-ES\\ddot u^*=-\\rho S\\ddot u_g=-\\rho Sd\\omega^2\\sin\\omega t$ 这里，尽管相对的参考系有所变化，但是由于边界条件不变，因此最后解得模态和频率不变，设为 u^{*}=\\sum_\\limits{i=1}^{\\infty} \\phi_{i}(x) q_{i}(t)\\\\ \\phi_{i}(x)=\\sqrt{\\frac{2}{l}} \\cos \\frac{i \\pi}{2 l} x, \\quad i=1,3,5, \\ldots其中 $\\phi_i(x)$为归一化的正则模态函数，$q_i(t)$ 为模态坐标， $u^{*}=u-u_{g}$ 将其代入到方程中，求解模态坐标去可得： \\sum_{i=1,3,5, \\ldots}^{\\infty}\\left(\\rho S \\ddot{q}_{i} \\phi_{i}-E S q_{i} \\phi_{i}\\right)=\\rho S d \\omega^{2} \\sin \\omega t用 $ \\phi_{j}(x) $ 乘上式, 并沿杆长积分：这里就是在利用正交性的特性来求解系数 以上式常规操作，建议记住 \\sum_{i=1}^{\\infty}\\left(\\ddot{q}_{i} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x-q_{i} \\int_{0}^{l} E S \\phi_{i}^{\\prime \\prime} \\phi_{j} d x\\right)=\\rho S d \\omega^{2} \\sin \\omega t \\int_{0}^{l} \\phi_{j}\\ dx利用正交性可得： \\ddot{q}_{i}+\\omega_{i}^{2} q_{i}=\\sqrt{\\frac{2}{l}} \\frac{2 l}{i \\pi}(-1)^{(i-1) / 2} d \\omega^{2} \\sin \\omega t模态坐标稳态解： $q_{i}=\\dfrac{\\omega^{2}}{\\omega_{i}^{2}} \\eta_{i} \\sqrt{\\dfrac{2}{l}} \\dfrac{2 l}{i \\pi}(-1)^{(i-1) / 2} d \\sin \\omega t $ 其中，$\\eta_{i}=\\dfrac{1}{1-\\left(\\omega / \\omega_{i}\\right)^{2}}$ 解得杆的变形方程为： u^{*}=\\frac{16 \\rho l^{2} \\omega^{2}}{\\pi^{3} E} \\sum_{i=1,3,5, \\ldots}^{\\infty} \\frac{(-1)^{(i-1) / 2}}{i^{3}} d \\eta_{i} \\cos \\frac{i \\pi x}{2 l} \\sin \\omega t\\\\最后求解参考基下的绝对位移： \\begin{aligned} u &=u^{*}+u_{g} \\\\ &=\\left[1+\\frac{16 \\rho l^{2} \\omega^{2}}{\\pi^{3} E} \\sum_{i=1,3,5, \\ldots .}^{\\infty} \\frac{\\eta_{i}}{i^{3}}(-1)^{(i-1) / 2} \\cos \\frac{i \\pi x}{2 l}\\right] d \\sin \\omega t \\end{aligned} u(x,t)为杆上面左右点的响应。 这里的基础振动就是参考系的振动。","link":"/2022/03/18/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%AF%E5%8A%A8-%E4%B8%80%E7%BB%B4%E6%B3%A2%E5%8A%A8%E6%96%B9%E7%A8%8B/"},{"title":"第六章 连续系统的振动  梁的弯曲振动","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是连续系统振动的近似求解方法部分本文主要介绍的是连续系统振动的一维波动方程部分，主要从动力学方程、固有频率和模态函数、振型函数和正交性以及梁的纵向受迫振动等方面就行讲解。 弯曲振动即横向振动，轴向的振动相比横向的振动时可以忽略的。 动力学方程 对于微振来说，其变形比较小，变形前后在轴向上的投影时相同的。 满足上述条件和假设的梁称为伯努利－欧拉梁（Bernoulli-Euler Beam）即长梁。对于短梁而言，就不能忽略剪切变形以及截面绕中性轴转动惯量的影响 著名的等截面假设：就是弯矩和挠度又二阶偏导的关系 变截面梁的动力学方程： \\frac{\\partial^{2}}{\\partial x^{2}}\\left[E I \\frac{\\partial^{2} y(x, t)}{\\partial x^{2}}\\right]+\\rho S \\frac{\\partial^{2} y(x, t)}{\\partial t^{2}}=f(x, t)-\\frac{\\partial}{\\partial x} m(x, t) $EI$项为刚度项，$\\rho S$项为惯性项，整体的量纲是力的量纲。 等截面梁的动力学方程： E I \\frac{\\partial^{4} y}{\\partial x^{4}}+\\rho S \\frac{\\partial^{2} y}{\\partial t^{2}}=f(x, t)-\\frac{\\partial}{\\partial x} m(x, t) 对于的截面而言，$I$ 是个定值，可以提出来。 固有频率和模态函数基本理论 在自由振动的条件下，我们可以将时间的函数(模态坐标)写成简谐的。 其中，$C_i(i=1,2,3,4)$ 和 $\\omega$ 应该满足的频率方程形式是由梁的边界条件确定的。 这里的$\\omega_i \\longleftrightarrow \\phi_i(x)$ 有无穷多个且一一对应。 第 $ i $ 阶主振动：$ \\quad y^{(i)}(x, t)=a_{i} \\phi_{i}(x) \\sin \\left(\\omega_{i} t+\\theta_{i}\\right) $ $a_{i}$ 和 $\\theta_{i}$ 由系统的初始条件确定系统的自由振动是无穷多个主振动的叠加： y(x, t)=\\sum_{i=1}^{\\infty} a_{i} \\phi_{i}(x) \\sin \\left(\\omega_{i} t+\\theta_{i}\\right)常见的约束和边界条件 对于固定端，由于固定的一端是不受约束的，因此固定的那一端上的转角和位移都是0. 对于简支端，由于其位移是别固定住的，因此位移是0，其次由于简支端是铰接的，可以随便的转动，因此弯矩是0。 对于自由端，其弯矩和剪力都是0。 首先，代入固定端的条件可得：$C_{1}=-C_{3} \\quad C_{2}=-C_{4}$ 之后，代入自由端的条件可得： \\left\\{\\begin{array}{l}C_{1}(\\cos \\beta l+\\cosh \\beta l)+C_{2}(\\sin \\beta l+\\sinh \\beta l)=0 \\\\ -C_{1}(\\sin \\beta l-\\sinh \\beta l)+C_{2}(\\cos \\beta l+\\cosh \\beta l)=0\\end{array}\\right. $ C_{1} 、 C_{2} $ 非零解条件: $ \\left|\\begin{array}{cc}\\cos \\beta l+\\cosh \\beta l &amp; \\sin \\beta l+\\sinh \\beta l \\\\ -\\sin \\beta l+\\sinh \\beta l &amp; \\cos \\beta l+\\cosh \\beta l\\end{array}\\right|=0 $ 等截面梁：$\\phi^{(4)}(x)-\\beta^{4} \\phi(x)=0 \\quad \\beta^{4}=\\dfrac{\\omega^{2}}{a_{0}^{2}} \\quad a_{0}^{2}=\\dfrac{E I}{\\rho S} $ 通解： $\\phi(x)=C_{1} \\cos \\beta x+C_{2} \\sin \\beta x+C_{3} \\cosh \\beta x+C_{4} \\sinh \\beta x $ 代入$\\beta^{4}=\\dfrac{\\omega^{2}}{a_{0}^{2}}$ 中可得，系统的各阶频率： \\omega_{i}=\\left(\\beta_{i} l\\right)^{2} \\sqrt{\\frac{E I}{\\rho S l^{4}}}, \\quad(i=1,2, \\cdots)对应的各阶振型函数： \\phi_{i}(x)=\\cos \\beta_{i} x-\\cosh \\beta_{i} x+\\underline{\\xi_{i}}\\left(\\sin \\beta_{i} x-\\sinh \\beta_{i} x\\right), \\quad(i=1,2, \\cdots) \\\\\\xi_{i}=\\frac{\\cos \\beta_{i} l+\\cosh \\beta_{i} l}{\\sin \\beta_{i} l+\\sinh \\beta_{i} l}, \\quad(i=1,2, \\cdots) \\quad \\beta^{4}=\\frac{\\omega^{2}}{a_{0}^{2}} \\quad a_{0}^{2}=\\frac{E I}{\\rho S}这里的 $\\xi_i$ 其实就是各阶模态下$C_1和C_3$的比值。 测量的传感器要避开节点的位置。 之后，代入边界条件可得：$C_{1}=C_{3}=0$ \\begin{array}{l} \\left\\{\\begin{array}{l}C_{2} \\sin \\beta l+C_{4} \\sinh \\beta l=0 \\\\-C_{2} \\sin \\beta l+C_{4} \\sinh \\beta l=0\\end{array} \\quad \\Longrightarrow \\quad C_{4}=0\\right.\\end{array}频率方程:：$\\sin \\beta l=0 \\quad \\Rightarrow \\quad \\beta_{i} l=i \\pi, \\quad(i=1,2, \\cdots) $ 固有频率: $\\quad \\omega_{i}=\\left(\\dfrac{i \\pi}{l}\\right)^{2} \\sqrt{\\dfrac{E I}{\\rho S}}, \\quad(i=1,2, \\cdots) $ 例：两端自由梁的固有频率和振型函数，背景：导弹飞行系统类别：半正定系统 、存在刚体模态。 注意：这里第二阶的模态和静平衡位置有所不同，由于存在大范围的因此其存在两个结点，对于静平衡的结构来说应该不存在这种结构。 之前是几个简单的结构，不存在重复约束的静定结构，下面我们来看一个静不定结构的例子。 例：试用数值确定一根一端固定另一端简支的梁的频率方程，并且绘出第一阶振型和第二阶振型的挠度曲线。 对于固定端来说，位移和转角的0；对于简支端来说，位移和弯矩为0，弯矩对于的是$M=EI\\dfrac {\\partial^2 y(x,t)} {\\partial x^2}$ 将边界条件代入到振型函数中去： \\phi(x)=C_{1} \\cos \\beta x+C_{2} \\sin \\beta x+C_{3} \\cosh \\beta x+C_{4} \\sinh \\beta x \\\\ \\phi(0)=0 \\Longrightarrow C_{1}+C_{3}=0 \\Longrightarrow C_{3}=-C_{1} \\\\ \\phi^{\\prime}(0)=0 \\Longrightarrow C_{2}+C_{4}=0 \\Longrightarrow C_{4}=-C_{2} \\\\ \\phi(l)=0 \\Longrightarrow C_{1}(\\cos \\beta l-\\cosh \\beta l)+C_{2}(\\sin \\beta l-\\sinh \\beta l)=0 \\\\ \\phi^{\\prime \\prime}(l)=0 \\Longrightarrow C_{1}(\\cos \\beta l+\\cosh \\beta l)+C_{2}(\\sin \\beta l+\\sinh \\beta l)=0 解得：$\\beta_1l=3.927,\\beta_2l=7.069$ 首先，设弯曲变形方程为$y(x,t)=\\phi(x)q(t)$ 边界条件: 固定端：挠度和截面转角为零 $\\phi(0)=0 \\quad \\phi^{\\prime}(0)=0$ 弹性支撑端：剪力、弯矩分别与直线弹簧反力、卷簧反力矩相等 剪力平衡条件：$ \\dfrac{\\partial}{\\partial x}\\left(E I \\dfrac{\\partial^{2} y(l, t)}{\\partial x^{2}}\\right)=k_{2} y(l, t) \\Rightarrow E I \\phi^{\\prime \\prime \\prime}(l)=k_{2} \\phi(l) $ 弯矩平衡条件：$E I \\dfrac{\\partial^{2} y(l, t)}{\\partial x^{2}}=-k_{1} \\dfrac{\\partial y(l, t)}{\\partial x} \\Rightarrow E I \\phi^{\\prime \\prime}(l)=-k_{1} \\phi^{\\prime}(l) $ 由弹性支撑固定端条件解得： \\begin{array}{l}C_{1}\\left[E I \\beta(\\cos \\beta l+\\cosh \\beta l)+k_{1}(\\sin \\beta l+\\sinh \\beta l)\\right]+ \\\\C_{2}\\left[E I \\beta(\\sin \\beta l+\\sinh \\beta l)-k_{1}(\\cos \\beta l-\\cosh \\beta l)\\right]=0 \\\\C_{1}\\left[E I \\beta^{3}(\\sin \\beta l-\\sinh \\beta l)-k_{2}(\\cos \\beta l-\\cosh \\beta l)\\right]- \\\\C_{2}\\left[E I \\beta^{3}(\\cos \\beta l+\\cosh \\beta l)+k_{2}(\\sin \\beta l-\\sinh \\beta l)\\right]=0\\end{array} $C_{1} 、 C_{2} $ 非零解条件导出频率方程： \\cos \\beta l \\cosh \\beta l+1=-\\frac{k_{1}}{E I \\beta}(\\cos \\beta l \\sinh \\beta l+\\sin \\beta l \\cosh \\beta l), \\quad\\left(k_{2}=0\\right) \\\\ \\cos \\beta l \\cosh \\beta l+1=-\\frac{k_{2}}{E I \\beta^{3}}(\\cos \\beta l \\sinh \\beta l-\\sin \\beta l \\cosh \\beta l), \\quad\\left(k_{1}=0\\right) $k_2=0$：代表没有直线弹簧只有扭簧的情况下，系统的振动方程。 $k_1=0$：代表没有扭簧只有直线弹簧的情况下，系统的振动方程。 讨论： 若k1、k2 同时为零，则退化为悬臂梁的情形。$\\cos\\beta l\\cosh \\beta l+1=0$ 若k1＝0、k2 无穷大，则退化为一端固定另一端简支的情形 $k_2=\\dfrac a b \\quad b=0 \\quad \\cos\\beta l\\sinh\\beta l-\\sin\\beta\\cosh \\beta l=0$ 所谓的有质量没尺寸的情况，此时集中质量没有弯矩。 说明： 考虑剪切变形使得梁的刚度降低，考虑转动惯量使得梁的惯性增加，这两个因素都会使梁的固有频率降低 总结：梁的固有频率和模态是由边界来决定的；复杂边界，就是在梁的自由端增加集中质量、直线弹簧和卷簧。 振型函数的正交性 于是设：$\\omega_i \\leftrightarrow \\phi_i(x)$， $\\omega_j \\leftrightarrow \\phi_j(x)$ 在梁的简单边界上，总有挠度$\\phi(x)$或剪力$\\phi^{\\prime\\prime\\prime}(x)$中的一个与转角或$\\phi^{\\prime}(x)$弯矩$\\phi^{\\prime\\prime}(x)$中的一个同时为零 简单边界：自由端，固定端，简支端。 代入边界条件可得：$\\int_{0}^{l} \\phi_{j}\\left(E I \\phi_{i}^{\\prime \\prime}\\right)^{\\prime \\prime} d x=\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime} \\phi_{j}^{\\prime \\prime} d x$ 代入 (3) 式：$\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime} \\phi_{j}^{\\prime \\prime} d x=\\omega_{i}^{2} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x$ 同理, (2)式两边乘 $ \\phi_{i} $ 并沿梁长积分： $ \\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime} \\phi_{j}^{\\prime \\prime} d x=\\omega_{j}^{2} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x $ 相减可得: $ \\quad\\left(\\omega_{i}^{2}-\\omega_{j}^{2}\\right) \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=0 $ 讨论： 当$ i \\neq j $ 时，主振型关于质量的正交性为： \\omega_{i} \\neq \\omega_{j} \\quad \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=0, \\quad i \\neq j主振型关于刚度的正交性为： \\int_{0}^{l} \\phi_{j}\\left(E I \\phi_{i}^{\\prime \\prime}\\right)^{\\prime \\prime} d x=\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime} \\phi_{j}^{\\prime \\prime} d x=0, \\quad i \\neq j当$i=j$ 时，第 j 阶主质量： \\int_{0}^{l} \\rho S \\phi_{j}^{2} d x=m_{p j}第 j 阶主刚度： \\int_{0}^{l} \\phi_{j}\\left(E I \\phi_{j}^{\\prime \\prime}\\right)^{\\prime \\prime} d x=\\int_{0}^{l} E I\\left(\\phi_{j}^{\\prime \\prime}\\right)^{2} d x=k_{p j}第 j 阶固有频率为： $ \\omega_{j}=k_{p j} / m_{p j} $ 主振型中的常数（$\\phi_j$的系数）按归一化条件确定 ：$\\int_{0}^{l} \\rho S \\phi_{j}^{2} d x=m_{p j}=1$ 正则振型的正交性：$\\int_{0}^{l} \\phi_{j}\\left(E I \\phi_{j}^{\\prime \\prime}\\right)^{\\prime \\prime} d x=\\int_{0}^{l} E I\\left(\\phi_{j}^{\\prime \\prime}\\right)^{2} d x=k_{p j}=\\delta_{ij}\\omega_j^2$ 梁横向振动的强迫响应 这边其实默认积分和求和时可以换位置的，因为振动的方程满足一致连续的条件。 得出$q_j(t)$之后，即可以得到梁的响应$y(x,t)$ 。 如果作用在梁上的载荷不是分布力矩，而是集中力和集中力矩。 Q_{j}(t)= \\int_{0}^{l}\\left[f(x, t) \\phi_{j}+m(x, t) \\phi_{j}^{\\prime}\\right] d x \\quad \\int_{0}^{t} f(t) \\delta(t-\\tau) d t=f(\\tau)将其代入到上面的表达式可得： \\begin{aligned} Q_{j}(t) &=\\int_{0}^{l}\\left[F_{0}(t) \\delta\\left(x-\\xi_{1}\\right) \\phi_{j}(x)+M_{0}(t) \\delta\\left(x-\\xi_{2}\\right) \\phi_{j}^{\\prime}(x)\\right] d x \\\\ &=F_{0}(t) \\phi_{j}\\left(\\xi_{1}\\right)+M_{0}(t) \\phi_{j}^{\\prime}\\left(\\xi_{2}\\right) \\\\ \\end{aligned} 解： 首先，由材力得初始条件： y(x, 0)=f_{1}(x)=\\left\\{\\begin{array}{ll}y_{s t}\\left[3\\left(\\dfrac{x}{l}\\right)-4\\left(\\dfrac{x}{l}\\right)^{3}\\right], & 0 \\leq x \\leq \\dfrac{l}{2} \\\\y_{s t}\\left[3\\left(\\dfrac{l-x}{x}\\right)-4\\left(\\dfrac{l-x}{l}\\right)^{3}\\right], & \\dfrac{l}{2} \\leq x \\leq l\\end{array}\\right.\\\\ \\left.\\frac{\\partial y}{\\partial t}\\right|_{t=0}=f_{2}(x)=0 \\quad y_{s t}=-\\frac{P l^{3}}{48 E I} \\quad 梁中点的静挠度 其次，可以边界条件求解固有频率和模态函数： 归一化条件: \\int_{0}^{l} \\rho S\\left(C_{i} \\sin \\frac{i \\pi x}{l}\\right)^{2} d x=\\frac{\\rho S l}{2} C_{i}^{2}=1 \\quad C_{i}=\\sqrt{\\frac{2}{\\rho A l}} 然后，根据初始条件求模态坐标 代入公式将外界广义力转化到模态坐标，这里的$f_1(x)$为初始条件下梁的变形曲线。 q_{j}(0)=\\int_{0}^{l} \\rho S f_{1}(x) \\phi_{j}(x) d x\\\\ \\dot{q}_{j}(0)=\\int_{0}^{l} \\rho S f_{2}(x) \\phi_{j}(x) d x模态坐标初始条件下，当作用力刚刚撤去受到的力产生的位移，即正则广义力为： \\begin{align} q_{i}(0) &=\\int_{0}^{\\frac{l}{2}} \\rho S y_{s t}\\left[3\\left(\\frac{x}{l}\\right)^{3}-4\\left(\\frac{x}{l}\\right)^{3}\\right] C_{i} \\sin \\frac{i \\pi x}{l} d x + \\int_{\\frac{l}{2}}^{l} \\rho S y_{s t}\\left[3\\left(\\frac{l-x}{l}\\right)-4\\left(\\frac{l-x}{l}\\right)^{3}\\right] C_{i} \\sin \\frac{i \\pi x}{l} d x \\\\&=-\\frac{P l^{4} \\rho S}{i^{4} \\pi^{4} E I} \\qquad i=1,3,5, \\cdots \\end{align} 这里根据积分的表达式可得：在 i 为偶数的情况下积分的结果可能为0。 初始条件下，由于外力是刚刚撤去的，因此此时的速度为0，没有激励，因此正则广义力为0： $\\dot{q}_{i}(0)=0 \\quad i=1,3,5, \\cdots $ 最后，代入求解在物理空间的响应 模态坐标响应: $ \\quad q_{i}(t)=q_{i}(0) \\cos \\omega_{i} t $ 物理空间上的梁响应： y(x, t)=\\sum_{i=1}^{\\infty} \\phi_{i}(x) q_{i}(t)=-\\frac{2 P l^{3}}{\\pi^{4} E I} \\sum_{i=1,3,5 \\cdots}^{\\infty} \\frac{(-1)^{\\frac{i-1}{2}}}{i^{4}} \\sin \\frac{i \\pi x}{l} \\cos \\omega_{i} t 例：简支梁，中点受力矩作$M_0\\sin\\omega t$ 用，求：梁的响应 上面的两个题目都是直接求解，固有频率、振型方程、广义正则力，之后得出正则方程，求解正则方程，最后将求解的结果代入得到物理空间，得出最后的模态。 上述两题的方法总结： 首先根据边界条件使用之前例题的一些结论直接得出固有频率和振型函数(刚才我们推导了不同边界下的振动过程) 之后根据外力的公式，直接积分得出正则广义力即模态坐标 最后根据模态函数和模态坐标相乘并累加 其实直接法和定义法是差不多的，但是使用定义法不容易出错。 求稳态强迫振动，以及梁自由端的响应。 两边乘 $ \\phi_{j} $ 并沿梁长对 x 积分： \\sum_{i=1}^{\\infty}\\left(q_{i} \\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime \\prime} \\phi_{j} d x+\\ddot{q}_{i} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x\\right)=P \\sin \\omega t \\int_{0}^{l} \\delta(x-l) \\phi_{j} d x利用正则振型正交性条件 : \\ddot{q}_{i}+\\omega_{i}^{2} q_{i}=P \\phi_{i}(l) \\sin \\omega t模态稳态解 : $q_{i}=\\dfrac{P \\phi_{i}(l)}{\\omega_{i}^{2}\\left[1-\\left(\\omega / \\omega_{i}\\right)^{2}\\right]} \\sin \\omega t, \\quad i=1,2, \\ldots $ 梁的响应： y(x, t) =\\sum_\\limits{i=1}^{\\infty} \\phi_{i}(x) q_{i}(t) =P \\sin \\omega t \\sum_\\limits{i=1}^{\\infty} \\dfrac{\\phi_{i}(l) \\phi_{i}(x)}{\\omega_{i}^{2}\\left[1-\\left(\\omega / \\omega_{i}\\right)^{2}\\right]}, \\quad i=1,2, \\ldots此时自由端的响应为： 令 $ x=l: \\quad y(l, t)=P \\sin \\omega t \\sum_\\limits{i=1}^{\\infty} \\dfrac{\\phi_{i}^{2}(l)}{\\omega_{i}^{2}\\left[1-\\left(\\omega / \\omega_{i}\\right)^{2}\\right]}, \\quad i=1,2, \\ldots $ \\left.\\phi_{i}(x)\\right|_{x=l}=\\cos \\beta_{i} l-\\cosh \\beta_{i} l+\\frac{\\cos \\beta_{i} l+\\cosh \\beta_{i} l}{\\sin \\beta_{i} l+\\sinh \\beta_{i} l}\\left(\\sin \\beta_{i} l-\\sinh \\beta_{i} l\\right), \\quad(i=1,2, \\cdots) \\\\ \\beta_{1} l=1.875 \\quad \\beta_{2} l=4.694 \\quad \\beta_{3} l=7.855 \\quad \\beta_{i} l \\approx \\frac{2 i-1}{2} \\pi, \\quad(i=3,4, \\cdots) \\\\ y(l, t)=\\frac{4 P l^{3}}{E I}\\left[\\frac{\\eta_{1}}{(1.875)^{4}}+\\frac{\\eta_{2}}{(4.694)^{4}}+\\frac{\\eta_{3}}{(7.855)^{4}}+\\ldots . .\\right] \\sin \\omega t \\\\ \\eta_{i}=\\frac{1}{1-\\left(\\omega / \\omega_{i}\\right)^{2}}, \\quad i=1,2, \\ldots例：简支梁，左端承受正弦支撑运动 $g(t)=y_0\\sin(\\omega t)$ 试求梁的响应。 $y_g(x,t)$ 为参考基的位移，$y-y_g$ 代表相对位移，就是假设基础不动是的位移。 以右截面上任一点为矩心，力矩平衡： \\left(M+\\frac{\\partial M}{\\partial x} d x\\right)-M-F_{s} d x+\\rho S d x \\frac{\\partial^{2} y}{\\partial t^{2}} \\frac{d x}{2}=0略去高阶无穷小量：$F_s=\\dfrac {\\partial M}{\\partial x}$ 材料力学的等截面假设，弯矩与挠度的关系： M(x, t)=E I \\dfrac{\\partial^{2}\\left[y(x, t)-y_{g}(x, t)\\right]}{\\partial x^{2}}于是可得梁的振动方程为： E I \\frac{\\partial^{4}\\left(y-y_{g}\\right)}{\\partial x^{4}}+\\rho S \\frac{\\partial^{2} y}{\\partial t^{2}}=0之后令 $y^{}=y-y_{g},\\quad y=y^{}+y_{g}$ ，并代入$y_g(x,t)$ 得： 代入方程： $E I y^{(4)}+\\rho S \\dot{y}^{}=-\\rho S \\dot{y}_{g}=-\\rho S \\omega^{2} y_{0} \\sin \\omega t\\left(1-\\dfrac{x}{l}\\right)$ 设解为: $y^{*}=\\sum_\\limits{i=1}^{\\infty} {\\phi_{i}(x) q_{i}(t)}$ 代入到方程中可得： \\quad \\sum_{i=1}^{\\infty}\\left(E I q_{i} \\phi_{i}^{\\prime \\prime \\prime}+\\rho S \\ddot{q}_{i} \\phi_{i}\\right)=\\rho S \\omega^{2} y_{0}\\left(1-\\frac{x}{l}\\right) \\sin \\omega t其中，归一化正则振型为： $ \\phi_{i}(x) =\\sqrt{\\dfrac{2}{l}} \\sin \\dfrac{i \\pi x}{l}$ 用 $\\phi_{j}(x)$ 乘上式, 并沿杆长积分: \\sum_{i=1}^{\\infty}\\left(q_{i} {\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime \\prime} \\phi_{j} d x}+{\\left.\\ddot{q}_{i} \\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x \\right)}=\\rho S \\omega^{2} y_{0} \\sin \\omega t \\int_{0}^{l} \\phi_{j}\\left(1-\\frac{x}{l}\\right) d x\\right.这里，$\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime \\prime} \\phi_{j} d x=\\omega_i^2$ , $\\int_{0}^{l} \\rho S \\phi_{i} \\phi_{j} d x=1$. 正交性: $\\quad \\ddot{q}_{i}+\\omega_{i}^{2} q_{i}=\\sqrt{\\dfrac{2}{l}} \\dfrac{l \\omega^{2} y_{0} \\sin \\omega t}{i \\pi}, \\quad i=1,2, \\ldots$ 模态坐标稳态解: q_{i}=\\sqrt{\\frac{2}{l}} \\frac{l \\omega^{2} y_{0} \\eta_{i}}{i \\pi \\omega_{i}^{2}} \\sin \\omega t =\\sqrt{\\frac{2}{l}} \\frac{l^{5} \\omega^{2} y_{0}}{i^{5} \\pi^{5} a_{0}^{2}} \\eta_{i} \\sin \\omega t, \\quad i=1,2, \\ldots\\\\ \\eta_{i}=\\frac{1}{1-\\left(\\omega / \\omega_{i}\\right)^{2}}简支梁固有频率：$\\omega_{i}=\\left(\\dfrac{i \\pi}{l}\\right)^{2} \\sqrt{\\dfrac{E I}{\\rho S}}, \\quad(i=1,2, \\cdots), \\quad a_{0}^{2}=\\dfrac{E I}{\\rho S}$$ y^{*}=\\frac{2 l^{4} \\omega^{2} y_{0} \\sin \\omega t}{\\pi^{5} a_{0}^{2}} \\sum_{i=1}^{\\infty} \\frac{\\eta_{i}}{i^{5}} \\sin \\frac{i \\pi x}{l}\\\\y=y^{*}+y_{g}=y_{0} \\sin \\omega t\\left[1-\\frac{x}{l}+\\frac{2 l^{4} \\omega^{2}}{\\pi^{5} a_{0}^{2}} \\sum_{i=1}^{\\infty} \\frac{\\eta_{i}}{i^{5}} \\sin \\frac{i \\pi x}{l}\\right]","link":"/2022/03/18/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%AF%E5%8A%A8-%E6%A2%81%E7%9A%84%E5%BC%AF%E6%9B%B2%E6%8C%AF%E5%8A%A8/"},{"title":"第六章 连续系统的振动 近似求解方法 第一部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是连续系统振动的近似求解方法部分，主要介绍其中的集中质量法、假设模态法、瑞利法以及里兹法。 连续系统的精确解仅适用于简单构件形状和边界条件，对于复杂构件来说只能求解数值解。 当构件形状复杂或边界条件复杂时可以采用近似解法 近似方法主要包括：集中质量法、假设振型法、有限元法 集中质量法是将连续系统的质量集中到有限个点或截面上，将连续的问题离散化后求解。 假设振型法是用有限个函数的线性组合来构造连续系统的解 有限元法兼有以上两种方法的特点 各种近似解法的共同特点：用有限自由度的系统对无限自由度的系统进行近似，这样可以将无限自由度的问题转化为有限自由度的多自由度系统求解问题。 集中质量法 工程系统的物理参数常常分布不均匀 惯性和刚性较大的部件可看作质量集中的质点和刚体 惯性小和弹性强的部件可抽象为无质量的弹簧，它们的质量可以不计或折合到集中质量上 如圆盘之间的轴或者滑块之间的弹簧。 物理参数分布均匀的系统，也可近似地分解为有限个集中质量 将悬臂梁等效为一些集中质量的组合 集中质量的数量取决于所要求的计算精度 等效的集中质量越密集个数越多，计算得到的精度就越高 连续系统离散为有限自由度系统后，可以采用多自由度系统的分析方法进行分析 这里，两端边界的质量对挠度不会产生影响，因此两端的质量可以去掉，最后等效万以后的总质量是0.75m，与原来的质量不同。 最终等效为，$m_1=m_2=m_3=\\dfrac m 4$ 的三自由度的系统。 多自由度系统分质量矩阵为$M=\\dfrac m 4 \\left[\\begin{array}\\\\ 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1 \\end{array}\\right]$ 三个质点之间的梁段具有相同的弹性性质，由材料力学，得柔度影响系数： f_{11}=f_{33}=\\dfrac {9l^3} {768EI}\\\\ f_{12}=f_{21}=f_{23}=f{32} =\\dfrac {11l^3} {768EI}\\\\ f_{22}=\\dfrac {16l^3} {768EI}\\\\ f_{13}=f_{31}=\\dfrac {7l^3} {768EI}\\\\可得柔度矩阵为：$F=\\dfrac {l^3} {768EI} \\left[\\begin{array}\\\\ 9 &amp; 11 &amp; 7\\\\ 11 &amp; 16 &amp; 11\\\\ 7 &amp; 11 &amp; 9 \\end{array}\\right]$ 连续体近似成了三自由度系统，也可将连续梁离散为两自由度或单自由度系统，在求得系统的质量矩阵和柔度矩阵后，可以计算出相应的系统固有频率： 随着自由度数目的增加，计算精度提高； 基频精度较高，但是其他的本来误差就比较大； 频率阶数增高，误差增大。 注：在采用集中质量法时，计算精度与边界条件有关，例如将同一模型用于悬臂梁系统，计算精度明显下降连续系统的振动 由于悬臂梁的右边是自由的，约束减少了。 假设模态法主要包括动力学方程、瑞利法和里兹法。 利用有限个已知的振型函数来确定系统的运动规律，在采用振型叠加法讨论连续系统的响应时，是将连续系统的解写作全部振型函数的线性组合： y(x, t)=\\sum_\\limits{i=1}^{\\infty} \\phi_{i}(x) q_{i}(t)其中，$\\phi_i(x)$ 为振型函数；$q_i(t)$ 为模态坐标。 若取前 n 个有限项作为近似解： y(x, t)=\\sum_\\limits{i=1}^{n} \\phi_{i}(x) q_{i}(t)其中，$\\phi_i(x)$：应该是系统的振型函数，但实际中由于无法得到等原因而代以假设模态，即满足部分或全部边界条件，但不一定满足动力学方程的试函数族。$q_i(t)$ ：与假设振型所对应的广义坐标。 动能： \\begin{align} T&=\\frac{1}{2} \\int_{0}^{l} \\rho S\\left(\\frac{\\partial y(x, t)}{\\partial t}\\right)^{2} d x=\\frac{1}{2} \\int_{0}^{l} \\rho S\\left(\\dot{\\boldsymbol{q}}^{T} \\boldsymbol{\\Phi}^{T}\\right)(\\boldsymbol{\\Phi} \\dot{\\boldsymbol{q}}) d x\\\\&=\\frac{1}{2} \\dot{\\boldsymbol{q}}^{T}\\left(\\int_{0}^{l} \\rho S \\boldsymbol{\\Phi}^{T} \\boldsymbol{\\Phi} d x\\right) \\dot{\\boldsymbol{q}}=\\frac{1}{2} \\dot{\\boldsymbol{q}}^{T} \\boldsymbol{M} \\dot{\\boldsymbol{q}} \\end{align} 势能： V=\\frac{1}{2} \\int_{0}^{l} E I\\left(\\frac{\\partial^{2} y(x, t)}{\\partial x^{2}}\\right)^{2} d x=\\frac{1}{2} \\int_{0}^{l} E I\\left(\\boldsymbol{q}^{T} \\boldsymbol{\\Phi}^{\\prime \\prime}\\right)\\left(\\boldsymbol{\\Phi}^{\\prime \\prime} \\boldsymbol{q}\\right) d x=\\frac{1}{2} \\boldsymbol{q}^{T} \\boldsymbol{K} \\boldsymbol{q}\\\\\\boldsymbol{K}=\\int_{0}^{l} E I \\boldsymbol{\\Phi}^{\\prime \\prime T} \\boldsymbol{\\Phi}^{\\prime \\prime} d x \\in R^{n \\times n} \\quad 刚度阵\\\\k_{i j}=k_{j i}=\\int_{0}^{l} E I \\phi_{i}^{\\prime \\prime}(x) \\phi_{j}^{\\prime \\prime}(x) d x \\quad 刚度阵为对称有激励存在的拉格朗日方程： \\frac{d}{d t}\\left(\\frac{\\partial T}{\\partial \\dot{q}_{i}}\\right)-\\frac{\\partial T}{\\partial q_{i}}+\\frac{\\partial V}{\\partial q_{i}}=Q_{i}\\\\ \\frac{d}{d t}\\left(\\frac{\\partial L}{\\partial \\dot{q}_{i}}\\right)-\\frac{\\partial L}{\\partial q_{i}}=Q_{i} \\quad L=T-V分布力的虚功: \\quad \\delta W(t)=\\int_{0}^{l} p(x, t) \\delta y d x=\\sum_\\limits{i=1}^{n}\\left({\\int_{0}^{l} p(x, t) \\phi_{i}(x) d x}\\right) \\delta q_{i}= \\sum_{i=1}^{n} Q_{i} \\delta q_{i} \\\\Q_{i}(t) =\\int_{0}^{l} p(x, t) \\phi_{i}(x) d x \\quad \\text { 广义力 }矩阵形式: $\\quad \\boldsymbol{Q}(t)=\\left[Q_{1}(t), Q_{2}(t), \\cdots, Q_{n}(t)\\right]^{T} \\in R^{n \\times 1}$ 拉格朗日方程矩阵形式： \\frac{d}{d t}\\left(\\frac{\\partial T}{\\partial \\dot{q}}\\right)-\\frac{\\partial T}{\\partial q}+\\frac{\\partial V}{\\partial \\boldsymbol{q}}=\\boldsymbol{Q} \\\\{M} \\ddot{q}+\\boldsymbol{K} \\boldsymbol{q}=\\boldsymbol{Q}(t)弹性体的受迫振动转换成了 n 自由度系统的强迫振动问题. 以上均质梁的动能和势能的表示函数。 如果均质上面有多余的卷簧和直线弹簧，则算法为以下所示。 典型例题 若对第三阶固有频率的精度要求不高，取 n＝3，但是一般求前三阶时我们会求前五阶的模态函数，这里对进度的要求不高就先求前三阶。 对于这种边界比较复杂的函数来讲，求解模态就比较复杂了，因此最好使用假设的比较简单的模态来近似逼近，这里我们时假设的是简支梁的模态$\\phi_i(x)=\\sin\\dfrac {i \\pi x}{l}$。 此时其振型的函数阵： 于是其对应的特征根问题为：$(K-\\omega^2M)\\Psi=0$ 解得固有频率为： \\omega_{1}=5.6825 \\sqrt{\\dfrac{E I}{\\rho S l^{4}}} \\quad \\omega_{2}=39.4784 \\sqrt{\\dfrac{E I}{\\rho S l^{4}}} \\quad \\omega_{3}=68.9944 \\sqrt{\\dfrac{E I}{\\rho S l^{4}}}正则化特征向量： $\\psi^{(1)}=\\sqrt{\\frac{2}{\\rho S l}}\\left[\\begin{array}{c}0.5742 \\\\ 0 \\\\ -0.0048\\end{array}\\right] \\psi^{(2)}=\\sqrt{\\frac{2}{\\rho S l}}\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0\\end{array}\\right] \\quad \\psi^{(3)}=\\sqrt{\\frac{2}{\\rho S l}}\\left[\\begin{array}{c}0.5199 \\\\ 0 \\\\ 0.7746\\end{array}\\right]$ 梁的稳态响应： y(x,t)=\\sum_\\limits{i=1}^3\\phi_i(x)q_i(x)=\\sum_\\limits{i=1}^3q_i(t)\\sin \\frac {i\\pi x}{l} 瑞利法连续系统的瑞利法是基于能量法的假设振型法，是多自由度系统的瑞利法的推广以梁的弯曲振动为例 假设梁以某阶振型函数作频率为 $\\omega$ 的自由振动：$y(x,t)=\\phi\\sin \\omega t$ 设系统为保守系统，机械能守恒，即$T_{max}=V_{max}$ 定义瑞利商：$R(\\phi)=\\dfrac {V_{max}} {T^{*}}=\\omega^2$ 当 $\\phi(x)$ 为准确的第 i 阶振型函数时，瑞利商即为相应的特征值，即第 i 阶固有频率$\\omega_i$ 。 若$\\phi(x)$是试函数，它满足梁的几何边界条件，但不满足动力学方程，则瑞利商是一个依赖于 $\\phi(x)$ 的标量。 试函数 $\\phi(x)$ 越接近某阶真实振型$\\Rightarrow$瑞利商越接近该阶固有频率。 与多自由度系统相同，瑞利商大于基频 $R(\\phi)&gt;\\omega_0^2$ 。 实际计算时可选择梁的静变形函数，或选择条件相近的梁的精确解作为试函数。比如，对于真实情况下的悬臂梁，我们使用标准的匀质，等截面的悬臂来梁来进行近似。 T^{*}=\\dfrac{1}{2}\\left[\\int_{0}^{l} \\rho S \\phi^{2}(x) d x+m \\phi^{2}\\left(x_{a}\\right)\\right] \\quad R(\\phi)=\\dfrac{V_{\\max }}{T^{*}} 选择等截面悬臂梁在均布载荷下的静挠度曲线作为试函数： \\phi(x)=A_{1}\\left(x^{4}-4 l x^{3}+6 l^{2} x^{2}\\right) \\Longrightarrow \\omega_{1}=1.1908 \\sqrt{\\dfrac{E I}{\\rho S l^{4}}} 选择端部集中质量作用下的静挠度曲线作为试函数： \\phi(x)=A_{2}\\left(3 l x^{2}-x^{3}\\right) \\quad \\Longrightarrow \\quad \\omega_{1}=1.1584 \\sqrt{\\frac{E I}{\\rho S l^{4}}} 因集中质量大于梁的分布质量，选用后一种试函数好 瑞利法理论是只要模态估计的好基本都可以很好的估计，尤其估计基频对应的曲线比较的容易，但是估计三阶或者更高阶的变形曲线就比较的困难了。 里茨法 里兹法是瑞利法的改进 瑞利法使用单个试函数，而里兹法使用若干个独立的试函数的线性组合： \\phi(x)=\\sum_\\limits{i=1}^{n} a_i \\eta_i(x) 里兹法的主要精髓就是如何选择参数$a_i\\quad (i=1,2,…,n)$ ，使得瑞利商取驻值： \\dfrac {\\partial R} {\\partial a_i}=0,\\quad (i=1,2,...,n)得到 $a_i$ 的齐次代数方程组，其非零解条件可用来计算系统的固有频率。 考虑梁的弯曲振动，其参考动能为： \\begin{align} T^{*}&=\\frac{1}{2} \\int_{0}^{l} \\rho S \\phi^{2}(x) d x=\\frac{1}{2} \\int_{0}^{l} \\rho S\\left[\\sum_{i=1}^{n} a_{i} \\eta_{i}(x)\\right]\\left[\\sum_{j=1}^{n} a_{j} \\eta_{j}(x)\\right] d x\\\\ &=\\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\tilde{m}_{i j} a_{i} a_{j}=\\frac{1}{2} \\boldsymbol{a}^{T} \\widetilde{\\boldsymbol{M}} \\boldsymbol{a} \\\\ &\\widetilde{m}_{i j}=\\frac{1}{2} \\int_{0}^{l} \\rho S \\eta_{i}(x) \\eta_{j}(x) d x, \\quad(i, j=1,2, \\cdots, n) \\quad \\\\&定义: \\tilde{\\boldsymbol{M}}=\\left[\\tilde{m}_{i j}\\right] \\in R^{n \\times n} \\quad \\boldsymbol{a}=\\left[a_{i}\\right] \\in R^{n \\times 1} \\end{align} 梁的弯曲振动，其最大势能： \\begin{align} V_{\\max } &=\\frac{1}{2} \\int_{0}^{l} E I \\phi^{\\prime \\prime 2}(x) d x=\\frac{1}{2} \\int_{0}^{l} E I\\left[\\sum_{i=1}^{n} a_{i} \\eta_{i}^{\\prime \\prime}(x)\\right]\\left[\\sum_{j=1}^{n} a_{j} \\eta_{j}^{\\prime \\prime}(x)\\right] d x\\\\ &=\\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\widetilde{k}_{i j} a_{i} a_{j} =\\frac{1}{2} \\boldsymbol{a}^{T} \\widetilde{\\boldsymbol{K}} \\boldsymbol{a}\\\\ \\tilde{k}_{i j} &=\\frac{1}{2} \\int_{0}^{l} E I \\eta_{i}^{\\prime \\prime}(x) \\eta_{j}^{\\prime \\prime}(x) d x, \\quad(i, j=1,2, \\cdots, n) \\end{align}定义: $ \\widetilde{\\boldsymbol{K}}=\\left[\\widetilde{k}_{i j}\\right] \\in R^{n \\times n} $ 固有频率的近似值： R(\\phi)=\\frac{\\boldsymbol{a}^{T} \\widetilde{\\boldsymbol{K}} \\boldsymbol{a}}{\\boldsymbol{a}^{T} \\widetilde{\\boldsymbol{M}} \\boldsymbol{a}}=\\widetilde{\\omega}^{2} 里兹法改善了瑞利法对基频的估计，还可计算高阶固有频率 n 愈大，计算精度愈高 计算精度也与基函数 $\\eta_i(i=1,2,…,n)$ 的选择有关，通常采用幂函数、三角函数、贝塞尔函数或条件相近的有精确解的梁的振型函数作为基函数 对于机械臂而言，我们可以直接使用一个一般的均质等截面梁的各阶模态作为基函数来进行函数逼近。 解：选取无集中质量时的梁的振型函数作为里兹基函数： 这里就是选用简支梁的模态函数来作为上述结构的里兹基。 \\eta_i(x)=\\sin \\dfrac {i\\pi x}{l},(i=1,2,...)基函数满足自然边界条件(两端挠度和弯矩为零)： \\eta_i(x)=0,\\eta_i^{\\prime \\prime}=0 \\quad (x=0\\,\\ or\\,\\ l)若对第三阶固有频率的精度要求不高，取 n＝3 振型试函数：$\\phi(x)=\\sum_\\limits{i=1}^{3} a_i \\eta_i(x)=\\sum_\\limits{i=1}^{3} a_i \\sin \\dfrac {i \\pi x} l$ 离散化强迫振动方程：$\\boldsymbol{M \\ddot q} + \\boldsymbol{Kq}=\\boldsymbol{Q(t)}$ 梁的振型函数近似解： \\begin{aligned} \\phi^{(1)}(x) &=\\sqrt{\\frac{2}{\\rho S l}}\\left(0.5742 \\sin \\frac{\\pi x}{l}-0.0048 \\sin \\frac{3 \\pi x}{l}\\right) \\\\ \\phi^{(2)}(x) &=\\sqrt{\\frac{2}{\\rho S l}} \\sin \\frac{2 \\pi x}{l} \\\\ \\phi^{(3)}(x) &=\\sqrt{\\frac{2}{\\rho S l}}\\left(0.5199 \\sin \\frac{\\pi x}{l}-0.7746 \\sin \\frac{3 \\pi x}{l}\\right) \\end{aligned} 用里兹法求基频。 有材料力学可得根部截面对中性轴的惯性矩为：$I_0=\\dfrac 1 {12} \\left({2b}\\right)^3$ 截面对中性轴的惯性矩：$I_0=\\dfrac 1 {12} \\left(\\dfrac {2bx} {l}\\right)^3=I_0\\dfrac {x^3} {l^3}$ 取基函数：$\\eta_i=\\left(1-\\dfrac x l\\right)^2\\left(\\dfrac x l\\right)^{i-1},(i=1,2,…,n)$ 可以验证，基函数满足所有位移边界条件和力边界条件： 这里我们取$n=2$可得： m_{i j}=\\frac{1}{2} \\int_{0}^{l} \\rho S \\eta_{i}(x) \\eta_{j}(x) d x \\quad k_{i j}=\\frac{1}{2} \\int_{0}^{l} E I \\eta_{i}^{\\prime \\prime}(x) \\eta_{j}^{\\prime \\prime}(x) d x \\left|\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right|=0 \\Longrightarrow \\omega_{1}=5.319 \\sqrt{\\frac{E I_{0}}{\\rho A_{0} l^{4}}} \\\\ \\text { 若取 } n=1: \\quad \\omega_{1}=5.477 \\sqrt{\\frac{E I_{0}}{\\rho A_{0} l^{4}}} \\\\ \\text { 精确解: } \\quad \\omega_{1}=5.315 \\sqrt{\\frac{E I_{0}}{\\rho A_{0} l^{4}}}","link":"/2022/03/18/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%AF%E5%8A%A8-%E8%BF%91%E4%BC%BC%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第六章 连续系统的振动 近似求解方法 第三部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是连续系统振动的近似求解方法部分，主要介绍其中的模态综合法的进一步分析和阐述、动态子结构方法的基本思想、自由界面模态综合法和固定模态综合法。本节内容是课本内容的深入和拔高。 模态综合法的进一步阐述 有限单元法可成功将一连续系统转化为一个多自由度系统问题。 可求得：系统的固有频率，振型，动力响应； 现代工程结构特征：庞大，复杂； 飞机，大型轮船，高层建筑，大型机械，航天器； 系统自由度成千上万阶，甚至几十万阶； 传统的动力特性和动力响应分析往往十分困难； 自由度过高，造成系统的控制比较困难。 对策：从量级上大幅缩减整体结构自由度而不改变问题的本质，在保证问题的主要特征的情况下进行减小问题的自由度。 本节是对模态综合法的补充，主要介绍的是模态综合法/动态子结构法/模型缩聚。 上世纪60年代初，人们为了解决大型复杂结构系统整体动力分析困难问题而提出了模态综合技术 Hurty和GladWell等人于上世纪60年代初奠定了模态综合技术的理论基础 60年代末至70年代间，Craig和Bampton、Rubin、Hou、Hintz等人先后从各个不同侧面对古典的模态综合技术进行了改进和总结 我国学者王文亮、王永岩、张汝清等人也做了大量研究工作，使模态综合方法得到了进一步发展 模态综合法主要分为固定界面模态综合法和自由界面模态综合法。 动态子结构方法的基本思想按照工程的观点或结构的几何轮廓，遵循某些原则要求，把完整的大型复杂结构人为地抽象成若干个子结构。首先对自由度少得多的各个子结构进行动态分析，然后经由各种方案，把它们的主要模态信息予以保留，以综合总体结构的动态特性 再现子结构：于整体结构中再现由模态坐标返回到物理坐标后的各子结构，以得到实际结构的主振型和位移及应力等动态响应 实际案例分析 每个子结构的自由度分为内部自由度${u_I}$和界面自由度${u_J}$： \\left\\{u^{a}\\right\\}=\\left\\{\\begin{array}{l}u_{I}^{a} \\\\u_{J}^{a}\\end{array}\\right\\}, \\quad\\left\\{u^{b}\\right\\}=\\left\\{\\begin{array}{l}u_{I}^{b} \\\\u_{J}^{b}\\end{array}\\right\\}根据界面连续性条件, 有: $\\quad\\left\\{u_{J}^{a}\\right\\}=\\left\\{u_{J}^{b}\\right\\}$ 由力的对接条件, 有: $\\left\\{f_{J}^{a}\\right\\}+\\left\\{f_{J}^{b}\\right\\}=\\{0\\}$ 界面内力合力为 这里$\\left\\{u_a \\right\\},\\left\\{u_b \\right\\}$ 为物理坐标，可以写成模态乘以模态坐标的形式，但是这里是近似求解，$\\left\\{u_a \\right\\},\\left\\{u_b \\right\\}$ 都有一定的截断，但是截断的位数不一定相等。 第一次坐标变换，将物理空间子结构的左边变化为模态坐标 T=T^{a}+T^{b}=\\frac{1}{2}\\left\\{\\dot{u}^{a}\\right\\}^{T}\\left[m^{a}\\right]\\left\\{\\dot{u}^{a}\\right\\}+\\frac{1}{2}\\left\\{\\dot{u}^{b}\\right\\}^{T}\\left[m^{b}\\right]\\left\\{\\dot{u}^{b}\\right\\}\\\\ V=V^{a}+V^{b}=\\frac{1}{2}\\left\\{u^{a}\\right\\}^{T}\\left[k^{a}\\right]\\left\\{u^{a}\\right\\}+\\frac{1}{2}\\left\\{u^{b}\\right\\}^{T}\\left[k^{b}\\right]\\left\\{u^{b}\\right\\}\\\\ T=\\frac{1}{2}\\left\\{\\dot{p}^{a}\\right\\}^{T}[M]^{a}\\left\\{\\dot{p}^{a}\\right\\}+\\frac{1}{2}\\left\\{\\dot{p}^{b}\\right\\}^{T}[M]^{b}\\left\\{\\dot{p}^{b}\\right\\}=\\frac{1}{2}\\{\\dot{p}\\}^{T}[M]\\{\\dot{p}\\}\\\\V=\\frac{1}{2}\\left\\{p^{a}\\right\\}^{T}[K]^{a}\\left\\{p^{a}\\right\\}+\\frac{1}{2}\\left\\{p^{b}\\right\\}^{T}[K]^{b}\\left\\{p^{b}\\right\\}=\\frac{1}{2}\\{p\\}^{T}[K]\\{p\\}\\\\{[M]^{a}=[\\Phi]^{a T}\\left[m^{a}\\right][\\Phi]^{a}, \\quad[M]^{b}=[\\Phi]^{b T}\\left[m^{b}\\right][\\Phi]^{b} }\\\\ [K]^{a}=[\\Phi]^{a T}\\left[k^{a}\\right][\\Phi]^{a}, \\quad[K]^{b}=[\\Phi]^{b T}\\left[k^{b}\\right][\\Phi]^{b}将a,b组集成为一个矩阵： [M]和[K]实际上是独立处理各子结构后得到的，而每个子结构的界面自由度${u_J^a}$、${u_J^b}$不是相互独立的，因此坐标${p}$中的元素不是相互独立的，不独立坐标的个数d恒等于界面自由度数，例如上图中d＝3 在界面上二者是重合的，因此需要将二者重叠的部分去掉一个，进而保证独立性成立。 新方程的阶数等于所选取的全部保留模态的总数减去对接自由度数。 系统的无阻尼自由振动的运动方程: \\begin{array}{c}{[M]^{*}\\{\\ddot{q}\\}+[K]^{*}\\{q\\}=\\{0\\}} \\\\{[M]^{*}=[S]^{T}[M][S], \\quad[K]^{*}=[S]^{T}[K][S]}\\end{array}对于一般的动力学分析问题, 也可以得到缩聚方程为: \\begin{array}{l}{[M]^{*}\\{\\ddot{q}\\}+[C]^{*}\\{\\dot{q}\\}+[K]^{*}\\{q\\}=\\{R\\}^{*}} \\\\{[C]^{*}=[S]^{T}[C][S], \\quad\\{R\\}^{*}=[S]^{T}\\{R\\}}\\end{array} 上述分析很容易推广到多个子结构组成的结构系统，困难的是如何构造和获取各子结构的保留模态来构成李兹基。各种不同的获取方法，便形成了不同的模态综合技术。 在模态综合法中，常常需取子结构低阶主振型来组成主振型矩阵[Фk]，以后称之为保留主振型，模态综合法正是因为舍去了子结构的高阶主振型而达到整体降阶的目的 于是解得解耦后的质量阵和刚度阵： 原结构第二阶频率具有中点不动的振型，它恰可由固定界面子结构的基本振型精确地组合，因此第二阶频率为精确解。 自由界面模态综合法 1968年SNHou和Goldman差不多同时提出的 将子结构从整体中分割出来后，解出全部约束，这与固定界面综合法完全不同 便于与试验相结合 自由界面模态综合法分析方法：将整体结构划分为自由界面的一系列子结构，然后完成每一子结构的模态析，以提出各子结构的主振型信息。用自由界面主振型中的保留主振型作为各子结构的假设振型参与综合，但是主振型数必须大于界面自由度数固定界面模态综合法很难与试验相结合，因为固定对界面在试验中很难实现 为与第二次变换中的变量顺序保持一致，修改第一次变换所得到了质量阵和刚度阵的顺序 第二次变换后的刚度阵和质量阵： 综合出的基频是精确解，原因：原结构的第一阶模态恰巧是由两个子结构的第一阶模态组成的，是反对称模态 典型例题 对于子结构3作同样处理，子结构3与子结构1、2对接，最终得到第二次变换： 得到第二次变换矩阵后，可以得到整体结构最终的质量阵和刚度阵，然后就可进行固有频率和振型分析。 长梁与每根短梁互相耦合4个自由度，所以减去8个自由度，最后建立的有限元模型为181阶方程。 采用自由界面模态综合法时，对每个子结构保留1/3左右正则主模态，最后得到利用自由界面模态综合法所建立的模型为63阶方程，可以看出经过局部降阶，即模态综合法建模，模型阶数已经较大程度的降低。","link":"/2022/03/19/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%AF%E5%8A%A8-%E8%BF%91%E4%BC%BC%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86/"},{"title":"第六章 连续系统的振动 近似求解方法 第二部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是连续系统振动的近似求解方法部分，主要以杆的纵向振动和梁的弯曲振动为例来介绍其中的模态综合法和有限元法。 模态综合法 对于由多个构件组成的复杂系统，很难找到适合于整个系统的假设模态。 对策：将复杂结构分解成若干个较简单的子结构，对每个子结构选定假设模态，然后根据对接面上的位移和力的协调条件，将各个子结构的假设振型综合成总体系统的振型函数。 实际工程问题中低阶模态占主要成分，因此对每个子结构只需要计算少量低阶模态，然后加以综合。 子结构的划分应使得子结构易于分析，并且对接面尽量缩小，以减少子结构之间的耦合。 模态综合法是计算机不发达时期主要产物，因为当是的算例和储存都达不到要求。 由于$o_3$为交界面，因此在$o_3$处的力、位移和转角都是一样的。 固定界面法：将两子结构的界面 $o_3 $加以固定，使两子结构成为两端固定的直梁。 自由界面法：将两个结构看做出成为两个悬臂梁。 此时满足几何边界条件的振型函数：$\\phi_1(x_i)=\\left(1-\\dfrac {x_i} l\\right)^2\\left(\\dfrac {x_i} l\\right)^{2}$ 满足在$x=0 /l$时的位移和转角都为0。 位移边界条件满足： \\phi_{1}\\left(x_{i}\\right)=\\left(\\frac{x_{i}}{l}\\right)^{2}\\left[1-\\left(\\frac{x_{i}}{l}\\right)\\right]^{2} \\\\x=0 \\text { 或 } l: \\quad \\phi_{1}\\left(x_{i}\\right)=0\\\\角位移边界条件满足： \\frac{\\partial \\phi_{1}\\left(x_{i}\\right)}{\\partial x_{i}}=\\left(\\frac{2 x_{i}}{l^{2}}\\right)\\left[1-\\left(\\frac{x_{i}}{l}\\right)\\right]^{2}+\\left(\\frac{x_{i}}{l}\\right)^{2}\\left[1-\\left(\\frac{x_{i}}{l}\\right)\\right]^{2}\\left(-\\frac{2}{l}\\right)\\\\ x=0\\ 或\\ l: \\frac{\\partial \\phi_{1}\\left(x_{i}\\right)}{\\partial x_{i}}=0当界面 $o_3 $产生角位移时，各子结构满足几何边界条件的模态称为约束振型，取为： \\phi_{2}\\left(x_{i}\\right)=\\left(\\frac{x_{i}}{l}\\right)^{2}\\left[1-\\left(\\frac{x_{i}}{l}\\right)\\right]根据相关的约束求导可得： \\frac{\\partial \\phi_{2}\\left(x_{i}\\right)}{\\partial x_{i}}=\\left(\\frac{2 x_{i}}{l^{2}}\\right)\\left[1-\\left(\\frac{x_{i}}{l}\\right)\\right]+\\left(\\frac{x_{i}}{l}\\right)^{2}\\left(-\\frac{1}{l}\\right)\\\\ x= l: \\frac{\\partial \\phi_{2}\\left(x_{i}\\right)}{\\partial x_{i}}=-\\frac 1 l于是我们把以上的两个模态作为基准： 于是计算系统的动能可得： T=\\frac{1}{2} \\int_{0}^{l} \\rho A\\left(\\left(\\frac{\\partial y_{1}\\left(x_{1}, t\\right)}{\\partial t}\\right)^{2}+\\left(\\frac{\\partial y_{2}\\left(x_{2}, t\\right)}{\\partial t}\\right)^{2}\\right) d x \\quad \\widetilde{\\boldsymbol{M}}=\\left[\\begin{array}{cc}\\widetilde{\\boldsymbol{M}}_{1} & \\\\ & \\widetilde{\\boldsymbol{M}}_{2}\\end{array}\\right] \\\\ =\\frac{1}{2} \\dot{\\boldsymbol{\\Psi}}_{1}^{T} \\widetilde{\\boldsymbol{M}}_{1} \\dot{\\boldsymbol{\\Psi}}_{1}+\\frac{1}{2} \\dot{\\boldsymbol{\\Psi}}_{2}^{T} \\widetilde{\\boldsymbol{M}}_{2} \\dot{\\boldsymbol{\\Psi}}_{2}=\\frac{1}{2} \\dot{\\boldsymbol{\\Psi}}^{T} \\widetilde{\\boldsymbol{M}} \\dot{\\boldsymbol{\\Psi}} \\quad \\boldsymbol{\\Psi}=\\left(\\begin{array}{llll}\\zeta_{1} & \\zeta_{2} & \\zeta_{3} & \\zeta_{4}\\end{array}\\right)^{T}计算系统的势能可得： V=\\frac{1}{2} \\int_{0}^{l} E I\\left(\\left(\\frac{\\partial^{2} y_{1}\\left(x_{1}, t\\right)}{\\partial x_{1}^{2}}\\right)^{2}+\\left(\\frac{\\partial^{2} y_{2}\\left(x_{2}, t\\right)}{\\partial x_{2}^{2}}\\right)^{2}\\right) d x =\\frac{1}{2} \\boldsymbol{\\Psi}^{T} \\widetilde{\\boldsymbol{K}} \\boldsymbol{\\Psi} \\\\ \\boldsymbol{\\Psi}=\\left(\\begin{array}{llll}\\zeta_{1} & \\zeta_{2} & \\zeta_{3} & \\zeta_{4}\\end{array}\\right)^{T} \\quad \\widetilde{\\boldsymbol{K}}=\\left[\\begin{array}{ll}\\widetilde{\\boldsymbol{K}}_{1} & \\\\ & \\widetilde{\\boldsymbol{K}}_{2}\\end{array}\\right] $\\Psi$ 只是单纯的组合排列，其中向量的独立性是未知的，其正交性或独立性需要进行分析和验证。 由上述的计算结果可知，向量的1、3不独立，2、4不独立，下面来分析以下1、2的独立性。 下面是$\\xi_1=\\xi_3,\\xi_2=\\xi_4$的独立性证明，使用了位移和弯矩的协调条件。 \\frac{\\partial y_{1}(l, t)}{\\partial x_{1}}=\\left.\\frac{\\partial \\phi_{1}\\left(x_{1}\\right)}{\\partial x_{1}}\\right|_{x=l} \\zeta_{1}(t)+\\left.\\frac{\\partial \\phi_{2}\\left(x_{1}\\right)}{\\partial x_{1}}\\right|_{x=l} \\zeta_{2}(t)=\\left(-\\frac{1}{l}\\right) \\zeta_{2}(t)\\\\ \\frac{\\partial y_{2}(l, t)}{\\partial x_{2}}=\\left.\\frac{\\partial \\phi_{1}\\left(x_{2}\\right)}{\\partial x_{2}}\\right|_{x=l} \\zeta_{3}(t)+\\left.\\frac{\\partial \\phi_{2}\\left(x_{2}\\right)}{\\partial x_{2}}\\right|_{x=l} \\zeta_{4}(t)=\\left(-\\frac{1}{l}\\right) \\zeta_{4}(t) 由弯矩的协调条件可得：$\\xi_1=\\xi_3$ 由位移的协调条件可得：$\\xi_2=\\xi_4$ 其中，$\\beta=\\left[\\begin{array}[c]\\ 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 1 &amp; 0\\\\ 0 &amp; 1 \\end{array}\\right]$ ，通过上述转换我们可以的得出一个相互独立的模态坐标，这里我们可以看出$y_2(x,t)$ 的模态坐标和 $y_1$是一样的。 总结： 将原系统合理的差分为若干个独立的子结构； 根据子结构，列出合理的质量阵和刚度阵，并得到系统的动力学方程； 然后根据协调条件，对动力学方程进行修改，使得模态坐标彼此独立， 得出新的系统动力学方程。 有限元法 20世纪五六十年代发展起来的方法 吸取了集中质量法与假设振型法的优点 将复杂结构分割成有限个单元，单元端点称为节点，将节点的位移作为广义坐标，并将单元的质量和刚度集中到节点上； 每个单元作为弹性体，单元内各点的位移用节点位移的插值函数表示(单元的假设模态)； 由于是仅对单元、而非整个结构取假设振型，因此振型函数可取得十分简单，并且可令各个单元的模态相同 有限元法是目前工程中计算复杂结构广泛使用的方法 以杆的纵向振动和梁的弯曲振动为例进行介绍 杆的纵向振动单元质量矩阵和刚度矩阵的求解 以上其实就是一个杆的一个微小的单元体，其实是很小的。 对于x位置截面的位移$u(x,t)$的表达式是： u(x, t)=\\sum_{i=1}^{2} N_{i}(x) u_{i}(t) \\\\ N_{1}(x)=1-\\frac{x}{l} \\quad N_{2}(x)=\\frac{x}{l} \\\\ u(x, t)=\\boldsymbol{N}^{T} \\boldsymbol{u}_{e} \\\\ u_{e}=[u_1(t),u_2(t)]^T,\\ N=\\left(1-\\dfrac x l,\\dfrac x l \\right)^T $u_e=[u_1(t),u_2(t)]^T$ 为广义坐标。 计算单元体的动能可得： T_{e}=\\frac{1}{2} \\int_{0}^{l} \\rho A\\left(\\frac{\\partial u(x, t)}{\\partial t}\\right)^{2} d x=\\frac{1}{2} \\dot{\\boldsymbol{u}}_{e}^{T} \\boldsymbol{m}_{e} \\dot{\\boldsymbol{u}} \\\\ m_{e}=\\int_{0}^{l} \\rho A \\mathbf{N} \\mathbf{N}^{T} d x=\\frac{\\rho A l}{6}\\left(\\begin{array}{ll}2 & 1 \\\\ 1 & 2\\end{array}\\right) \\\\其中，$m_e$ 为单元质量阵。 单元体的势能为: V_{e}=\\frac{1}{2} \\int_{0}^{l} E A\\left(\\frac{\\partial u(x, t)}{\\partial x}\\right)^{2} d x =\\frac{1}{2} \\boldsymbol{u}_{e}^{T} \\boldsymbol{k}_{e} \\boldsymbol{u}_{e} \\quad E: 弹性模量 \\\\ \\boldsymbol{k}_{e}=\\int_{0}^{l} E A \\boldsymbol{N}^{\\prime} \\boldsymbol{N}^{\\prime T} d x=\\frac{E A}{l}\\left(\\begin{array}{cc}1 & -1 \\\\ -1 & 1\\end{array}\\right) \\quad \\quad \\boldsymbol{N}^{\\prime}=\\left(\\begin{array}{ll}-\\dfrac{1}{l} & \\dfrac{1}{l}\\end{array}\\right)^{T} $f(x, t)$对虚位移 $\\delta u(x, t) $ 的虚功，由$u(x, t)=\\boldsymbol{N}^{T}\\boldsymbol{u}_{e}$ 可得： \\delta W=\\frac{1}{2} \\int_{0}^{l} f(x, t) \\delta u(x, t) d x=\\boldsymbol{F}_{e}^{T} \\delta \\boldsymbol{u}_{e}其中，$\\boldsymbol{F}_{e} $与节点坐标 $\\boldsymbol{u}_{e} $ 对应的单元广义力列阵为：$\\boldsymbol{F}_{e}=\\int_{0}^{l} f(x, t) \\boldsymbol{N} d x$ 如果轴向力为常值力，可得：$\\boldsymbol{F}_{e} =\\dfrac {fl} 2 (1 \\quad 1)^T$ 全系统的动力学方程 单元质量矩阵： $\\boldsymbol{m}_{e 1}=\\boldsymbol{m}_{e 2}=\\frac{\\rho A l}{3}\\left(\\begin{array}{ll}2 &amp; 1 \\\\ 1 &amp; 2\\end{array}\\right) \\quad \\boldsymbol{m}_{e 3}=\\frac{\\rho A l}{6}\\left(\\begin{array}{ll}2 &amp; 1 \\\\ 1 &amp; 2\\end{array}\\right) $ 单元刚度矩阵：$\\boldsymbol{k}_{e 1}=\\boldsymbol{k}_{e 2}=\\frac{2 E A}{l}\\left(\\begin{array}{cc}1 &amp; -1 \\\\ -1 &amp; 1\\end{array}\\right) \\quad \\boldsymbol{k}_{e 3}=\\frac{E A}{l}\\left(\\begin{array}{cc}1 &amp; -1 \\\\ -1 &amp; 1\\end{array}\\right) $ 这里保证我们的$q_1,q_2,q_3$是相互独立。 全系统的动能： T=\\sum_{i=1}^{3} T_{e i}=\\frac{1}{2} \\sum_{i=1}^{3} \\dot{\\boldsymbol{u}}_{e i}^{T} \\boldsymbol{m}_{e i} \\dot{\\boldsymbol{u}}_{e i}=\\frac{1}{2} \\dot{\\boldsymbol{U}}^{T} \\widetilde{\\boldsymbol{M}} \\dot{\\boldsymbol{U}}=\\frac{1}{2} \\dot{\\boldsymbol{q}}^{T} \\boldsymbol{M} \\dot{\\boldsymbol{q}}\\\\ T_{e}=\\frac{1}{2} \\dot{\\boldsymbol{u}}_{e}^{T} \\boldsymbol{m}_{e} \\dot{\\boldsymbol{u}}_{e} \\quad \\boldsymbol{U}=\\boldsymbol{\\beta} \\boldsymbol{q}其中，$ \\tilde{\\boldsymbol{M}}=\\left(\\begin{array}{ccc}\\boldsymbol{m}_{e 1} &amp; \\boldsymbol{0} &amp; \\boldsymbol{0} \\\\ \\boldsymbol{0} &amp; \\boldsymbol{m}_{e 2} &amp; 0 \\\\ \\boldsymbol{0} &amp; \\boldsymbol{0} &amp; \\boldsymbol{m}_{e 3}\\end{array}\\right) \\in R^{6 \\times 6} $，$\\boldsymbol{M}=\\boldsymbol{\\beta}^{T} \\tilde{\\boldsymbol{M}} \\boldsymbol{\\beta} \\in R^{3 \\times 3} $ M为进行坐标独立正交化之后的形式。 质量矩阵 M 也可直接利用单元质量矩阵组集而成 (叠加法)：将单元质量矩阵 $m_{e1}$、$m_{e2}$ 和 $m_{e3}$ 的各个元素统一按 $q_i(i=1,2,3)$ 的下标重新编号，放入M 中与编号相对应的行和列中 $q_{1}=u_{2}=u_{3}, \\quad q_{2}=u_{4}=u_{5}, \\quad q_{3}=u_{6}$ 这里$u_1=0$，因此对应的都是0 这里其实就是将原来的单元体(i=1,2,3,4,5,6)的质量阵使用广义坐标(1,2,3)重新进行编号，相同的地方直接相加。 和广义坐标 $q=(q_1\\quad q_2 \\quad q_3)^T$ 相对应的质量矩阵： \\boldsymbol{M}=\\left(\\begin{array}{lll}m_{11} & m_{12} & m_{13} \\\\m_{21} & m_{22} & m_{23} \\\\m_{31} & m_{32} & m_{33}\\end{array}\\right)=\\frac{\\rho A l}{6}\\left(\\begin{array}{ccc}{4+4} & 2 & 0 \\\\2 & 4+2 & 1 \\\\ 0 & 1 & 2\\end{array}\\right)全系统的势能： V=\\sum_{i=1}^{3} V_{e i}=\\frac{1}{2} \\sum_{i=1}^{3} \\boldsymbol{u}_{e i}^{T} \\boldsymbol{k}_{e i} \\boldsymbol{u}_{e i}=\\frac{1}{2} \\dot{\\boldsymbol{U}}^{T} \\widetilde{\\boldsymbol{K}} \\dot{\\boldsymbol{U}}=\\frac{1}{2} \\boldsymbol{q}^{T} \\boldsymbol{K} \\boldsymbol{q}\\\\ V_{e}=\\frac{1}{2} \\boldsymbol{u}_{e}^{T} \\boldsymbol{k}_{e} \\boldsymbol{u}_{e} \\quad \\boldsymbol{U}=\\boldsymbol{\\beta} \\boldsymbol{q} \\quad \\boldsymbol{K}=\\boldsymbol{\\beta}^{T} \\widetilde{\\boldsymbol{K}} \\boldsymbol{\\beta} \\\\ \\widetilde{\\boldsymbol{K}}=\\left(\\begin{array}{ccc}\\boldsymbol{k}_{e 1} & \\boldsymbol{0} & 0 \\\\ \\boldsymbol{0} & \\boldsymbol{k}_{e 2} & \\boldsymbol{0} \\\\ 0 & \\boldsymbol{0} & \\boldsymbol{k}_{e 3}\\end{array}\\right) \\in R^{6 \\times 6}其中，$\\boldsymbol{\\beta}=\\left(\\begin{array}{cccccc}0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\end{array}\\right)^{T} $ 也可以使用组集方法得：$\\boldsymbol{K}=\\frac{E A}{l}\\left(\\begin{array}{ccc}2+2 &amp; -2 &amp; 0 \\\\ -2 &amp; 2+1 &amp; -1 \\\\ 0 &amp; -1 &amp; 1\\end{array}\\right)$ 当杆上有常值轴向力作用时，三根杆的广义外力阵为： \\boldsymbol{F}_{e 1}=\\boldsymbol{F}_{e 2}=\\boldsymbol{F}_{e 3}=\\frac{f l}{2}\\left(\\begin{array}{ll}1 & 1\\end{array}\\right)^{T}系统的广义力阵：$\\boldsymbol{F}=\\left(\\begin{array}{lll}\\boldsymbol{F}_{e 1}^{T} \\quad \\boldsymbol{F}_{e 2}^{T} \\quad \\boldsymbol{F}_{e 3}^{T}\\end{array}\\right)^{T} \\in R^{6 \\times 1}$ 作用力的总虚功：$\\delta W=\\boldsymbol{F}^{T} \\delta \\boldsymbol{U}=\\boldsymbol{Q}^{T} \\delta \\boldsymbol{q} \\quad \\boldsymbol{U}=\\boldsymbol{\\beta} \\boldsymbol{q}$ 这里$Q=\\beta^TF$ 和广义的坐标$q$ 对应的广义力阵 (叠加法)也可将$F_{e1}$、$F_{e2}$和 $F_{e3}$ 的各个元素统一按 $q_i (i=1,2,3)$ 的下标重新编号，放入 Q 中与编号相对应的行和列中： \\boldsymbol{Q}=\\frac{f l}{2}(1+1 \\quad 1 \\quad 1)^{T}=\\frac{f l}{2}\\left(\\begin{array}{lll}2 & 1 & 1\\end{array}\\right)^{T}用广义坐标阵 q 表示的广义质量阵、广义刚度阵和广义外力阵： 用广义坐标阵 q 表示的全系统的动力学方程： \\boldsymbol{M} \\ddot{\\boldsymbol{q}}+\\boldsymbol{K} \\boldsymbol{q}=\\boldsymbol{Q}\\\\ \\frac{\\rho A l}{6}\\left(\\begin{array}{ccc}8 & 2 & 0 \\\\ 2 & 6 & 1 \\\\ 0 & 1 & 2\\end{array}\\right)\\left(\\begin{array}{l}\\ddot{q}_{1} \\\\ \\ddot{q}_{2} \\\\ \\ddot{q}_{3}\\end{array}\\right)+\\frac{E A}{l}\\left(\\begin{array}{ccc}4 & -2 & 0 \\\\ -2 & 3 & -1 \\\\ 0 & -1 & 1\\end{array}\\right)\\left(\\begin{array}{l}q_{1} \\\\ q_{2} \\\\ q_{3}\\end{array}\\right)=\\frac{f l}{2}\\left(\\begin{array}{l}2 \\\\ 1 \\\\ 1\\end{array}\\right) 其实有限元方法的基本步骤和模态叠加法基本类似： 首先，划分为有限个单元；之后，采用能量法来得到刚度阵和质量阵；最后，一节点的坐标为系统的广义坐标，来建立系统的动力学方程。 有限元方法建立的模型是有限自由度模型，广义坐标是节点的位移，是在物理空间上的，但是模态综合法建立的动力学方程的坐标是模态坐标，在模态空间上的。 梁的弯曲振动单元质量矩阵和刚度矩阵的求解 选为均质梁在端点常值位移作用下的静挠度曲线(多项式函数)： N_{i}(x)=a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}, \\quad(i=1,2,3,4) $N_{3}(0)=N_{3}^{\\prime}(0)=0,N_{3}(l)=1,N_3^{\\prime}(l)=1$ $N_{4}(0)=N_{4}^{\\prime}(l)=N_{4}(0)=0, \\quad N_{4}^{\\prime}(l)=1$ 上述边界条件的意义就是跟$u_i(t)$是对应的，比如$N_1(0)=1$ 是由于$u_1(t)$ 对应的是x=0处的位移，$N_2(0)^{\\prime}=0$ 是由于$u_2(t)$ 对应的是x=0处的转角，依次类推。 形函数列阵：$\\boldsymbol{N}=\\left[\\begin{array}{llll}N_{1}(x) &amp; N_{2}(x) &amp; N_{3}(x) &amp; N_{4}(x)\\end{array}\\right]^{T}$ 代入$y(x, t)=\\boldsymbol{N}^{T} \\boldsymbol{u}_{e}$ 可得单元的动能为： T_{e}=\\dfrac{1}{2} \\int_{0}^{l} \\rho A\\left(\\dfrac{\\partial y(x, t)}{\\partial t}\\right)^{2} d x=\\dfrac{1}{2} \\dot{\\boldsymbol{u}}_{e}^{T} \\boldsymbol{m}_{e} \\dot{\\boldsymbol{u}}_{e}其中，$\\rho$代表材料密度，A代表截面积。 同理代入可得单元的势能： V_{e}=\\frac{1}{2} \\int_{0}^{l} E I\\left(\\frac{\\partial y^{2}(x, t)}{\\partial x^{2}}\\right)^{2} d x=\\frac{1}{2} \\boldsymbol{u}_{e}^{T} \\boldsymbol{k}_{e} \\boldsymbol{u}_{e} \\quad E I:抗弯刚度 假设梁上有分布外力，$f(x, t)$对虚位移 $\\delta u(x, t) $ 的虚功，由$y(x, t)=\\boldsymbol{N}^{T}\\boldsymbol{u}_{e}$ 可得： \\delta W=\\frac{1}{2} \\int_{0}^{l} f(x, t) \\delta y(x, t) d x=\\boldsymbol{F}_{e}^{T} \\delta \\boldsymbol{u}_{e}其中，$\\boldsymbol{F}_{e} $与节点坐标 $\\boldsymbol{u}_{e} $ 对应的单元广义力列阵为：$\\boldsymbol{F}_{e}=\\int_{0}^{l} f(x, t) \\boldsymbol{N} d x$ 对于均布载荷，$f$为常数，可得：$\\boldsymbol{F}_{e} =\\dfrac {fl} 2 (1 \\quad \\dfrac 1 6 \\quad 1 \\quad -\\dfrac 1 6)^T$ 全系统的动力学方程以上对单元所作的分析必须进行综合，以扩展到总体结构 T=\\frac{1}{2} \\dot{\\boldsymbol{q}}^{T} \\boldsymbol{M} \\dot{\\boldsymbol{q}} \\quad \\boldsymbol{M}=\\boldsymbol{\\beta}^{T} \\tilde{\\boldsymbol{M}} \\boldsymbol{\\beta} \\\\\\boldsymbol{\\beta}=\\left(\\begin{array}{llllllll}0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\end{array}\\right)^{T} \\quad \\widetilde{\\boldsymbol{M}}=\\left(\\begin{array}{cc}\\boldsymbol{m}_{e 1} & \\boldsymbol{0} \\\\ 0 & \\boldsymbol{m}_{e 2}\\end{array}\\right)因此, 有 假设梁上有简谐变化的均布载荷 $f(x,t)=f_0\\sin\\omega t$ \\boldsymbol{F}_{e 1}^{T}=\\boldsymbol{F}_{e 2}^{T}=(1 \\quad \\dfrac 1 6 \\quad 1 \\quad -\\dfrac 1 6)^T\\dfrac {f_0l} 2\\sin\\omega t系统的广义力阵：$\\boldsymbol{F}=\\left(\\begin{array}{lll}\\boldsymbol{F}_{e 1}^{T} \\quad \\boldsymbol{F}_{e 2}^{T} \\end{array}\\right)^{T} \\in R^{4 \\times 1}$ 与节点坐标U对应的广义力阵 $\\boldsymbol{U}=\\left(\\begin{array}{llll}u_{1} &amp; u_{2} &amp; \\cdots &amp; u_{8}\\end{array}\\right)^{T}_{8 \\times1}$ 作用力的总虚功：$\\delta W=\\boldsymbol{F}^{T} \\delta \\boldsymbol{U}=\\boldsymbol{Q}^{T} \\delta \\boldsymbol{q}$ 这里$Q=\\beta^TF$ 和广义的坐标$q$ 对应的广义力阵 (叠加法)也可将$F_{e1}$、$F_{e2}$和 $F_{e3}$ 的各个元素统一按 $q_i (i=1,2,3)$ 的下标重新编号，放入 Q 中与编号相对应的行和列中： \\boldsymbol{Q}=(1 \\quad 0 \\quad \\dfrac1 2\\quad -\\dfrac l {12})^{T}\\dfrac {f_0l} 2\\sin\\omega t用广义坐标阵 q 表示的广义质量阵、广义刚度阵和广义外力阵： 用广义坐标阵 q 表示的全系统的动力学方程：$\\boldsymbol{M} \\ddot{\\boldsymbol{q}}+\\boldsymbol{K} \\boldsymbol{q}=\\boldsymbol{Q}$ 有限元方法的主要思想：是将结构划分为非常多的有限单元，每个单元都是弹性体，将单元的质量和刚度都向节点进行集中，最后以所有节点的位移为广义坐标，来建立一个有限多自由度系统的动力学方程。","link":"/2022/03/19/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%85%AD%E7%AB%A0-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%AF%E5%8A%A8-%E8%BF%91%E4%BC%BC%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"第四章 多自由度振动-多自由度系统的动力学方程 第一部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是多自由振动系统中动力学方程的第一部分，主要是介绍作用力方程、刚度矩阵与质量矩阵以及相关的系统，由于多自由度系统较为复杂，因此后续的分节不比较的细致。 建模方法1：将车、人等全部作为一个质量考虑，并考虑弹性和阻尼 优点：模型简单 缺点：模型粗糙，没有考虑人与车、车与车轮、车轮与地面之间的相互影响 建模方法2：车、人的质量分别考虑，并考虑各自的弹性和阻尼 优点：模型较为精确，考虑了人与车之间的耦合 缺点：没有考虑车与车轮、车轮与地面之间的相互影响 建模方法3：车、人、车轮的质量分别考虑，并考虑各自的弹性和阻尼 优点：分别考虑了人与车、车与车轮、车轮与地面之间的相互耦合，模型较为精确 问题：如何描述各个质量之间的相互耦合效应？ 对于航天领域的火箭，近似可以可以看作是刚体，因此频率方程有零根，对于飞船这样比较柔性的可以看作频率方程有重根。 作用力方程平动的案例例1：双质量弹簧系统，两质量分别受到激振力不计摩擦和其他形式的阻尼，试建立系统的运动微分方程 解：坐标原点：取 $m_1、m_2$ 的静平衡位置设某一瞬时：$m_1、m_2$上分别有位移 $x_1 、x_2$ , 加速度$\\ddot x_1、 、\\ddot x_2$ 受力分析： 建立动力学方程：(其主要的量纲为力量纲) \\left\\{\\begin{array}{l}m_{1} \\ddot{x}_{1}(t)+k_{1} x_{1}(t)+k_{2}\\left(x_{1}(t)-x_{2}(t)\\right)=P_{1}(t) \\\\ m_{2} \\ddot{x}_{2}(t)-k_{2}\\left(x_{1}(t)-x_{2}(t)\\right)+k_{3} x_{3}(t)=P_{2}(t)\\end{array}\\right. 将其准化为矩阵形式可得： \\left[\\begin{array}{cc}m_{1} & 0 \\\\ 0 & m_{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}k_{1}+k_{2} & -k_{2} \\\\ -k_{2} & k_{2}+k_{3}\\end{array}\\right]\\left[\\begin{array}{l}x_{1}(t) \\\\ x_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{c}P_{1}(t) \\\\ P_{2}(t)\\end{array}\\right]其中的$-k_2$ 为坐标间的耦合项，如果没有此项就变成了一个单自由度的系统了。 转动的案例例2：转动运动，外力矩为$M_1(t)\\ M_2(t)$ ，其转动惯量为$I_1、I_2$，轴的三段的扭转刚度为 $k_{\\theta_1}、k_{\\theta_2}、k_{\\theta_3}$ ，建立系统的动力学微分方程。 首先，建立坐标，设在某个瞬时的角位移为$\\theta_1\\ \\theta_2$, 对应的角加速度为 $\\ddot\\theta_1\\ \\ddot\\theta_2$ ，之后受力分析可得： 于是可得： \\left\\{\\begin{array}{l}I_{1} \\ddot{\\theta}_{1}(t)+k_{\\theta 1} \\theta_{1}(t)+k_{\\theta 2}\\left[\\theta_{1}(t)-\\theta_{2}(t)\\right]=M_{1}(t) \\\\ I_{2} \\ddot{\\theta}_{2}(t)+k_{\\theta 2}\\left[\\theta_{2}(t)-\\theta_{1}(t)\\right]+k_{3} \\theta_{3}(t)=M_{2}(t)\\end{array}\\right.改写成为矩阵形式可得： \\left[\\begin{array}{cc}I_{1} & 0 \\\\ 0 & I_{2}\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{\\theta}_{1}(t) \\\\ \\ddot{\\theta}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}k_{\\theta 1}+k_{\\theta 2} & -k_{\\theta 2} \\\\ -k_{\\theta 2} & k_{\\theta 2}+k_{\\theta 3}\\end{array}\\right]\\left[\\begin{array}{l}\\theta_{1}(t) \\\\ \\theta_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{c}M_{1}(t) \\\\ M_{2}(t)\\end{array}\\right] 多自由度系统的角振动与直线振动在数学描述上相同 如同在单自由度系统中所定义的，在多自由度系统中也将质量、刚度、位移、加速度及力都理解为广义的 对于倒立摆等结构，其M矩阵为质量和力矩耦合。 基于K矩阵来讲，反对角上的元素是相等的。 于是可以得出作用力的方程： 若系统有n个自由度，则各项的皆为n维矩阵或向量。 一般情况下M、K矩阵是二阶常微分的，如果再复杂一点可能是实变的。 对于连续体来说，其方程式偏微的，可以离散化的方法变为常微的 偏微分很难求解，因此要离散化近似。 刚度矩阵和质量矩阵当我们得到作用力方程时，只要M、K确定后，系统的动力可以完全确定，那么M、K要如何确定？ 刚度矩阵K的确定首先，先确定K，这里要排除外力以准静态方程的方式施加于系统，就是缓慢的加力，此时的加速度为零 $\\ddot X(t)=0$ 带入到作用力方程： 此时的$P(t)$ 为准静态外力列向量 。 假设作用于系统的是这样一组外力：它们使系统只在第 j 个坐标上产生单位的位移，而在其他各个坐标上不产生位移 即： 这里的理论基础就是 $F=kx$ \\boldsymbol{X}(t)=\\left[x_{1}(t), \\ldots, x_{j-1}(t), x_{j}(t), x_{j+1}(t), \\ldots, x_{n}(t)\\right]^{T}=[0, \\ldots, 0,1,0, \\ldots, 0]^{T} 其中得X矩阵只有第 j 项为1，其余都是0 带入得，（只有K矩阵第 j 列的数保留了下来） \\boldsymbol{P}(t)=\\left[\\begin{array}{l}P_{1}(t) \\\\ P_{2}(t) \\\\ \\vdots \\\\ P_{n}(t)\\end{array}\\right]=\\left[\\begin{array}{l}k_{11} \\ldots k_{1 j} \\ldots k_{1 n} \\\\ k_{21} \\ldots k_{2 j} \\ldots k_{2 n} \\\\ \\ldots \\ldots \\ldots \\ldots \\ldots . \\\\ k_{n 1} \\ldots k_{n j} \\ldots k_{n n}\\end{array}\\right]\\left[\\begin{array}{c}0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{l}k_{1 j} \\\\ k_{2 j} \\\\ \\vdots \\\\ k_{n j}\\end{array}\\right] 所施加的这组外力数值上正是刚度矩阵K 的第 j 列; 其中的$k_{ij} $ $(i=1,2,…n)$是在第 i 各坐标上面施加的力。 根据矩阵得性质可得，这组外力是唯一的。 结论：刚度矩阵K 中的元素 $k_{ij}$ 是使系统仅在第j 个坐标上产生单位位移而相应于第 i 个坐标上所需施加的力。 于是就将K矩阵确定，下面讨论M矩阵的确定。 质量矩阵M的确定之后，确定M矩阵，假设系统受到外力作用的瞬时，只产生加速度而不产生任何位移，这样可以使得$X(t)=0$ 假设作用于系统的是这样一组外力：它们使系统只在第 j 个坐标上产生单位加速度，而在其他各个坐标上不产生加速度。 这里的理论基础就是 $F=ma$ \\boldsymbol{P}(t)=\\left[\\begin{array}{l}P_{1}(t) \\\\ P_{2}(t) \\\\ \\vdots \\\\ P_{n}(t)\\end{array}\\right]=\\left[\\begin{array}{l}m_{11} \\ldots m_{1 j} \\ldots m_{1 n} \\\\ m_{21} \\ldots m_{2 j} \\ldots m_{2 n} \\\\ \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\\\ m_{n 1} \\ldots m_{n j} \\ldots m_{n n}\\end{array}\\right]\\left[\\begin{array}{c}0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{l}m_{1 j} \\\\ m_{2 j} \\\\ \\vdots \\\\ m_{n j}\\end{array}\\right]同理，最后就剩下了M矩阵的第 j 列，其含义就是其他坐标施加的外力。 结论：质量矩阵 M 中的元素$m_{ij}$是使系统仅在第 j 个坐标上产生单位加速度而相应于第 i 个坐标上所需施加的力 。 结论 刚度矩阵 K 中的元素 $k_{ij}$ 是使系统仅在第 j 个坐标上产生单位位移而相应于第 i 个坐标上所需施加的力; 质量矩阵 M 中的元素 $m_{ij}$ 是使系统仅在第 j 个坐标上产生单位加速度而相应于第 i 个坐标上所需施加的力; $m_{ij}、k_{ij}$又分别称为质量影响系数和刚度影响系数。根据它们的物理意义可以直接写出系统质量矩阵M和刚度矩阵K，从而建立作用力方程，这种方法称为影响系数方法. 经典例题 先考虑准静态的情况： 令 $X=[1\\quad 0\\quad 0]^T$ ,只使 $m_1$ 产生单位位移，$m_2$ 和 $m_3$ 不动，可以求出K阵的第一列； $k_{11}$ ——使 $m_1$ 产生单位位移所需施加的力：$k_{11}=k_1+k_2$ $k_{21}$ ——保持$m_2$不动所需施加的力：$k_{21}=-k_2$ $k_{31}$ ——保持$m_3$不动所需施加的力：$k_{31}=0$ 同理，令 $X=[0\\quad 1\\quad 0]^T$ ,只使 $m_2$ 产生单位位移，$m_1$ 和 $m_3$ 不动，可以求出K阵的第二列； $k_{22}$ ——使 $m_2$ 产生单位位移所需施加的力：$k_{22}=k_2+k_3+k_5+k_6$ $k_{12}$ ——保持$m_1$不动所需施加的力：$k_{21}=-k_2$ $k_{32}$ ——保持$m_3$不动所需施加的力：$k_{33}= -k_3$ 令 $X=[0\\quad 0\\quad 1]^T$ ,只使 $m_3$ 产生单位位移，$m_1$ 和 $m_2$ 不动，可以求出K阵的第三列； $k_{33}$ ——使 $m_3$ 产生单位位移所需施加的力：$k_{33}=k_3+k_4$ $k_{23}$ ——保持$m_2$不动所需施加的力：$k_{23}= -k_3$ $k_{13}$ ——保持$m_1$不动所需施加的力：$k_{13}= 0$ 只考虑动态的情况： 运动微分方程：此时的M阵是解耦的，K阵是耦合的。 \\left[\\begin{array}{ccc}m_{1} & 0 & 0 \\\\ 0 & m_{2} & 0 \\\\ 0 & 0 & m_{3}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t) \\\\ \\ddot{x}_{3}(t)\\end{array}\\right]+\\left[\\begin{array}{ccc}k_{1}+k_{2} & -k_{2} & 0 \\\\ -k_{2} & k_{2}+k_{3}+k_{5}+k_{6} & -k_{3} \\\\ 0 & -k_{3} & k_{3}+k_{4}\\end{array}\\right]\\left[\\begin{array}{c}x_{1}(t) \\\\ x_{2}(t) \\\\ x_{3}(t)\\end{array}\\right]=\\left[\\begin{array}{c}P_{1}(t) \\\\ P_{2}(t) \\\\ P_{3}(t)\\end{array}\\right]例：双混合摆，这里刚度的质量为$m_1,m_2$ ，质心为$c_1,c_2$ ，绕通过自身的质心的z轴的转动惯量为$I_1,I_2$，求以微小转角$\\theta_1,\\theta_2$为坐标，写出x-y平面内的摆动作用力方程。 问：刚体2的转角是相对于刚体1的、还是相对于参考系的？相对于参考系的 先求质量影响系数 令 $\\ddot \\theta_1=1,\\ddot \\theta_2=0$ ，则此时需要在两杆上施加力矩 $m_{11},m_{21}$ 下摆对A取矩：$m_{21}=m_{2} l h_{2}$ 整体对B取矩：$m_{11}=I_{1}+m_{1} h_{1}^{2}+m_{2} l\\left(l+h_{2}\\right)-m_{21}=I_{1}+m_{1} h_{1}^{2}+m_{2} l^{2}$ 为什么不考虑重力的影响，——因为我们考虑的是瞬时动态，也就是此时的系统还没来得及变形，因此重力在此时可以忽略不记。上面的图只是个示意图。 令 $\\ddot \\theta_1=0,\\ddot \\theta_2=1$ ，则此时需要在两杆上施加力矩 $m_{12},m_{22}$ 下摆对A取矩：$m_{22}=I_{2}+m_{2} h_{2}^{2}$ 整个对B取矩：$m_{12}=I_{2}+m_{2} h_{2}\\left(l+h_{2}\\right)-m_{22}=m_{2} l h_{2}$ 综上可得M矩阵为： 这里M为对阵矩阵，不是对角矩阵。 \\boldsymbol{M}=\\left[\\begin{array}{cc}I_{1}+m_{1} h_{1}^{2}+m_{2} l^{2} & m_{2} l h_{2} \\\\ m_{2} l h_{2} & I_{2}+m_{2} h_{2}^{2}\\end{array}\\right] 求刚度影响系数 由于恢复力是重力，所以实际上是求重力影响系数 令 $\\theta_1=1,\\theta_2=0$ ，则此时需要在两杆上施加力矩 $k_{11},k_{21}$ 下摆对A取矩：$k_{21}=0$ 此时为准静态，重力此时还没有产生恢复力矩 整体对B取矩：$k_{11}=m_{1} g h_{1}+m_{2} g l$ 令 $\\theta_1=0,\\theta_2=1$ ，则此时需要在两杆上施加力矩 $k_{12},k_{22}$ 下摆对A取矩：$k_{22}=m_2gh_2 $ 整体对B取矩：$k_{21}=m_{2} g h_{2}-k_{22}=0$ 综上，刚度矩阵为： \\boldsymbol{K}=\\left[\\begin{array}{cc}\\left(m_{1} h_{1}+m_{2} l\\right) g & 0 \\\\ 0 & m_{2} g h_{2}\\end{array}\\right] 得到运动方程为：(此时的弹性不存在耦合，惯性是耦合的) \\left[\\begin{array}{cc}I_{1}+m_{1} h_{1}^{2}+m_{2} l^{2} & m_{2} l h_{2} \\\\ m_{2} l h_{2} & I_{2}+m_{2} h_{2}^{2}\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{\\theta}_{1}(t) \\\\ \\ddot{\\theta}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}\\left(m_{1} h_{1}+m_{2} l\\right) g & 0 \\\\ 0 & m_{2} g h_{2}\\end{array}\\right]\\left[\\begin{array}{c}\\theta_{1}(t) \\\\ \\theta_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right] 例：双杆系统，每杆质量m，杆长度l，水平弹簧刚度k，弹簧距离固定端a，求以微小转角$\\theta_1,\\theta_2$为坐标，写出x-y平面内的摆动作用力方程 先求刚度影响系数 这里，由于是微小振动，因此$\\sin \\theta \\approx\\theta$ 得出刚度影响矩阵为： \\boldsymbol{K}=\\left[\\begin{array}{cc}\\dfrac{1}{2} m g l+k a^{2} & -k a^{2} \\\\ -k a^{2} & \\dfrac{1}{2} m g l+k a^{2}\\end{array}\\right]后求惯性影响系数 运动的微分方程为 \\left[\\begin{array}{cc}\\dfrac{1}{3} m l^{2} & 0 \\\\ 0 & \\dfrac{1}{3} m l^{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{\\theta}_{1}(t) \\\\ \\ddot{\\theta}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}\\dfrac{1}{2} m g l+k a^{2} & -k a^{2} \\\\ -k a^{2} & \\dfrac{1}{2} m g l+k a^{2}\\end{array}\\right]\\left[\\begin{array}{c}\\theta_{1}(t) \\\\ \\theta_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right]例：两自由度系统，摆长l，无质量，微摆动，求运动微分方程 首先求刚度影响系数 系统刚度矩阵：$\\boldsymbol{K}=\\left[\\begin{array}{cc}k_{1}+k_{2} &amp; 0 \\\\ 0 &amp; m_{2} g l\\end{array}\\right]$ 之后求惯性影响系数 系统水平方向力平衡：$m_{11}=\\left(m_{1}+m_{2}\\right) \\times \\ddot{x}=m_{1}+m_{2}$ 杆对A点力矩平衡：$m_{21}=\\left(m_{2} \\ddot{x}\\right) \\times l=m_{2} l$ 令 $\\ddot{x}=0 \\quad \\ddot{\\theta}=1$ 此时瞬时状态分析可得：$\\ddot{\\vec{x}}_{B}=\\ddot{\\vec{x}}_{A}+\\ddot{\\vec{\\theta}} l+\\vec{\\omega}^{2} l$ 这里的$\\ddot{\\vec{x}}_{A}、\\vec{\\omega}^{2} l$ 都为0。 水平方向力平衡：$m_{12}=m_2l$ 杆A点力矩平衡：$m_22=m_2l^2$ 质量矩阵：$\\boldsymbol{M}=\\left[\\begin{array}{cc}m_{1}+m_{2} &amp; m_{2} l \\\\ m_{2} l &amp; m_{2} l^{2}\\end{array}\\right]$ 运动方程为： \\left[\\begin{array}{cc}m_{1}+m_{2} & m_{2} l \\\\ m_{2} l & m_{2} l^{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}(t) \\\\ \\ddot{\\theta}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}k_{1}+k_{2} & 0 \\\\ 0 & m_{2} g l\\end{array}\\right]\\left[\\begin{array}{l}x(t) \\\\ \\theta(t)\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right]","link":"/2022/03/09/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E6%8C%AF%E5%8A%A8-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8A%A8%E5%8A%9B%E5%AD%A6%E6%96%B9%E7%A8%8B-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第四章 多自由度振动-多自由度系统的动力学方程 第二部分","text":"hljs.initHighlightingOnLoad(); 本文主要讲的是多自由振动系统中动力学方程的第二部分，主要介绍位移方程和柔度矩阵、质量矩阵与刚度矩阵的正定性质以及耦合与坐标变换。 位移方程和柔度矩阵基本理论 对于静定结构，有时通过柔度矩阵建立位移方程比通过刚度矩阵建立作用力方程来得更方便些 柔度定义为弹性体在单位力作用下产生的变形 这里和刚度是相反的，刚度的定义是单位变形下所需要的力的大小，而柔度是单位作用力/力矩下所产生的变形 物理意义及量纲与刚度恰好相反 集中质量——梁只有刚度，没有质量 求柔度矩阵 假设 $P_1、P_2$ 是常力 以准静态方式作用在梁上梁只产生位移(即挠度)，不产生加速度 取质量 $m_1 、m_2$ 的静平衡位置为坐标 $x_1、x_2$ 的原点 具体的计算可以参考材料力学的手册。 改写成矩阵形式可得： \\boldsymbol{X}=\\boldsymbol{F}\\boldsymbol{P}\\\\ \\boldsymbol{X}=\\left[\\begin{array}{l}x_{1} \\\\ x_{2}\\end{array}\\right] \\quad \\boldsymbol{F}=\\left[\\begin{array}{ll}f_{11} & f_{12} \\\\ f_{21} & f_{22}\\end{array}\\right] \\quad \\boldsymbol{P}=\\left[\\begin{array}{l}P_{1} \\\\ P_{2}\\end{array}\\right] 其中F被称为是柔度矩阵，和显然其就是K矩阵的倒数。 综上，等到柔度的物理意义是： 系统仅在第 j 个坐标受到单位力作用时，相应于第 i 个坐标上产生的位移 求刚度矩阵 当 $P_1$、$P_2$ 是动载荷时集中质量上有惯性力存在，这里通过达朗贝尔原理将其转化为惯性力施加在对于的质量上面。 考虑惯性力之后的位移方程： {\\left[\\begin{array}{l}x_{1} \\\\ x_{2}\\end{array}\\right]=\\left[\\begin{array}{ll}f_{11} & f_{12} \\\\ f_{21} & f_{22}\\end{array}\\right]\\left[\\begin{array}{c}P_{1}(t)-m_{1} \\ddot{x}_{1} \\\\ P_{2}(t)-m_{2} \\ddot{x}_{2}\\end{array}\\right] } 将上述方程分解可得： {\\left[\\begin{array}{l}x_{1} \\\\ x_{2}\\end{array}\\right]=\\left[\\begin{array}{ll}f_{11} & f_{12} \\\\ f_{21} & f_{22}\\end{array}\\right]\\left(\\left[\\begin{array}{l}P_{1}(t) \\\\ P_{2}(t)\\end{array}\\right]-\\left[\\begin{array}{cc}m_{1} & 0 \\\\ 0 & m_{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1} \\\\ \\ddot{x}_{2}\\end{array}\\right]\\right) } 得出最后的位移方程为： \\boldsymbol{X}=\\boldsymbol{F}(\\boldsymbol{P}-\\boldsymbol{M} \\ddot{\\boldsymbol{X}}) 作用力方程——左右两边都是力的量纲； 位移方程——左右两边都是位移的量纲。 要注意的问题： 对于允许刚体运动产生的系统(即具有刚体自由度的系统)，柔度矩阵不存在。即位移方程不适用于具有刚体自由度的系统。 即系统在特定的作用下有位移的平衡位置，整个系统和前面有一点的连接，但是如图所示，我们的施加力以后系统直接运动，其平衡位置相当于有无数个。 如左边的系统，其存在一个模态，弹簧是上面没有力，三个以系统的速度相同的加速度以同一个方向移动过去。 原因：在任意一个坐标上施加单位力，系统将产生刚体运动而无法计算各个坐标上的位移，此时系统的刚度矩阵K是奇异的。 典型例题例： 求图示两自由度简支梁横向振动的位移方程梁不计质量，抗弯刚度$EJ$ 由材料力学知，当B点作用有单位力时，A点的挠度为： f_{AB}=\\frac {ab} {6EJl} (l^2-a^2-b^2) 柔度影响系数为：$f_{11}=f_{22}=8f \\quad f_{21}=f_{12}=7f \\quad f=\\dfrac {l^3} {486EJ}$ 得出位移方程为： {\\left[\\begin{array}{l}x_{1} \\\\ x_{2}\\end{array}\\right]=\\left[\\begin{array}{ll}8f & 7f \\\\ 7f & 8f\\end{array}\\right]\\left(\\left[\\begin{array}{l}P_{1} \\\\ P_{2}\\end{array}\\right]-\\left[\\begin{array}{cc}m_{1} & 0 \\\\ 0 & m_{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1} \\\\ \\ddot{x}_{2}\\end{array}\\right]\\right) } 在坐标 $x_1$ 上对质量 $m_1$ 作用单位力系统在坐标$x_1$、$x_2$、$x_3$ 上产生位移: $f_{11}=f_{21}=f_{31}=\\dfrac 1 {k_1}$ 在坐标 $x_2$上对质量 $m_2$ 作用单位力 $ f_{12}=\\dfrac{1}{k_{1}} \\quad f_{22}=\\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} \\quad f_{32}=\\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} $ 在坐标 $x_3$上对质量 $m_3$ 作用单位力 $ f_{13}=\\dfrac{1}{k_{1}} \\quad f_{23}=\\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} \\quad f_{33}=\\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}}+\\dfrac{1}{k_{3}} $ 这里和之前求刚度矩阵有不同，之前求刚度和惯性矩阵时，只是让某个这里发生位移而其他的部分样施加相应的力来保证位移是0. 于是得出柔度矩阵为： F=\\left[\\begin{array}{ccc}\\dfrac{1}{k_{1}} & \\dfrac{1}{k_{1}} & \\dfrac{1}{k_{1}} \\\\ \\dfrac{1}{k_{1}} & \\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} & \\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} \\\\ \\dfrac{1}{k_{1}} & \\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}} & \\dfrac{1}{k_{1}}+\\dfrac{1}{k_{2}}+\\dfrac{1}{k_{3}}\\end{array}\\right] \\quad \\begin{array}{c}\\text { 可以验证，有 : } \\\\ \\boldsymbol{F}\\boldsymbol{K}=\\boldsymbol{I}\\end{array} 小结： 反命题，如果K阵为奇异的，此时一定为刚体运动。$\\omega^2=k/m$ 当K为0时一定有$\\omega=0$，系统不振动。 质量矩阵和刚度矩阵的正定性质n 阶方阵 A 正定，即 $A_{n\\times n}&gt;0$ , 对于任意的 n 维列向量 y，总有 $y^TA\\ y&gt;0$ (标量) 成立 并且等号仅在 $y=0$ 时才成立 如果 $y \\ne 0$ 时，等号也成立，那么称矩阵A是半正定的 $A \\ge0 $ 对于动能，动能始终是大于等于0的。 对于势能，振动系统的刚度矩阵至少为半正定。 理解：$\\omega^2=k/m$ 根据公式可得，对于一般的系统来说，k都是大于0的；对于随遇平衡系统，其K=0，因此可以为半正定。 振动问题中主要讨论（1）M阵正定、K 阵正定 $\\Leftrightarrow$ 正定振动系统（2）M阵正定、K 阵半正定 $\\Leftrightarrow$ 半正定振动系统 耦合与坐标变换基本理论 不出现惯性耦合时，一个坐标上产生的加速度只在该坐标上引起惯性力。 \\left[\\begin{array}{cc}m_{11} & 0 \\\\ 0 & m_{22}\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{1} \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{c}m_{11} \\ddot{x}_{1} \\\\ 0\\end{array}\\right] 出现惯性耦合时，一个坐标上产生的加速度还会在别的坐标上引起惯性力。 \\left[\\begin{array}{cc}m_{11} & m_{12} \\\\ m_{21} & m_{22}\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{1} \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{c}m_{11} \\ddot{x}_{1} \\\\ m_{21} \\ddot{x}_{1}\\end{array}\\right]同理，不出现弹性耦合时，一个坐标上产生的位移只在该坐标上引起弹性恢复力；而出现弹性耦合时，一个坐标上产生的位移还会在别的坐标上引起弹性恢复力。 耦合的表现形式取决于坐标的选择 选取D点的垂直位移$x_D$和绕D点的角位移 $\\theta_D$ 为坐标，写出车体微振动的微分方程。 解法一：(理论力学的方法） 由于杆是刚体，因此其上面的点上的角速度是处处相等的 $\\theta_C = \\theta_D$ 这里涉及到刚体上力如果从一个点平移到另一个点会产生一个伴随力偶来确保整个系统的力矩平衡。 这里的广义坐标的取得是D点。 同理对于势能来说有： \\begin{aligned} V= \\frac{1}{2} k_{1}\\left(x_{D}-a_{1} \\theta_{D}\\right)^{2} +\\frac{1}{2} k_{2}\\left(x_{D}+a_{2} \\theta_{D}\\right)^{2} \\end{aligned} 将动能和势能带入拉格朗日方程可得： m \\ddot{x}_{D}+m e \\ddot{\\theta}_{D}+\\left(k_{1}+k_{2}\\right) x_{D}+\\left(k_{2} a_{2}-k_{1} a_{1}\\right) \\theta_{D}=P_{D}\\\\m e \\ddot{x}_{D}+\\left(I_{C}+m e^{2}\\right) \\ddot{\\theta}_{D}+\\left(k_{1}+k_{2}\\right) x_{D}+\\left(k_{1} a_{1}^{2}+k_{2} a_{2}^{2}\\right) \\theta_{D}=M_{D}写成矩阵形式可得： 使用D点为广义坐标，求解出来的振动方程，质量和刚度矩阵同时耦合，下面我们使用影响系数法来求解。 解法二：（振动力学的方法） 首先求解刚度矩阵 之后求解质量矩阵 这里的C点是质心，瞬间的惯性的就作用在C上面，由于没有角加速度，因此只有惯性力而没有力偶。 为了保证力的平衡，要在D处相应的施加一个等大的力以及一个防止出现角速度的力偶。 产生达朗贝尔惯性力偶的同时也会产生对应的惯性力。 得出微分方程为： \\left[\\begin{array}{cc}m & m e \\\\ m e & I_{C}+m e^{2}\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{D} \\\\ \\ddot{\\theta}_{D}\\end{array}\\right]+\\left[\\begin{array}{cc}k_{1}+k_{2} & k_{2} a_{2}-k_{1} a_{1} \\\\ k_{2} a_{2}-k_{1} a_{1} & k_{1} a_{1}^{2}+k_{2} a_{2}^{2}\\end{array}\\right]\\left[\\begin{array}{c}x_{D} \\\\ \\theta_{D}\\end{array}\\right]=\\left[\\begin{array}{c}P_{D} \\\\ M_{D}\\end{array}\\right]解耦分析： 将弹性耦合进行解耦可得，此时右端项为所有的外力向D点简化的结果： 将惯性耦合进行解耦可得，此时右端项为所有的外力向C点简化的结果： 问：能否找到这样一种坐标使得系统的运动微分方程既不出现惯性耦合，也不出现弹性耦合？ 使系统运动微分方程的全部耦合项全部解耦的坐标称为主坐标,，此内容为下次课程模态这边的重点。 不同广义坐标下方程的联系讨论：能对同一个系统选取两个不同的坐标，它们所描述的运动微分方程之间有着怎样的联系？ 首先，寻找D点和C点之间的联系： 可以得到：$\\left[\\begin{array}{l}x_{D} \\\\ \\theta_{D}\\end{array}\\right]=\\left[\\begin{array}{cc}1 &amp; -e \\\\ 0 &amp; 1\\end{array}\\right]\\left[\\begin{array}{l}x_{C} \\\\ \\theta_{C}\\end{array}\\right]$ 力在移动以后会产生附加力偶 $-eP_D$ T为非奇异的，因此：$F_D=(T^T)^{-1}F_C$ 总结 模态叠加：将物理空间的耦合的问题可以通过某个转换的关系来，转化到另一个解耦的空间进而实现求解两个单自由度的系统，之后再转换回到原来的物理空间。 广义坐标的选择不同，不影响刚度和惯性矩阵的性质，如正定性和对称性。","link":"/2022/03/10/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E6%8C%AF%E5%8A%A8-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8A%A8%E5%8A%9B%E5%AD%A6%E6%96%B9%E7%A8%8B-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"第四章 多自由度系统振动 多自由度系统的自由振动 第一部分","text":"hljs.initHighlightingOnLoad(); 本文主要讲的是多自由振动系统中的多自由度系统的自由振动，主要介绍了固有频率的计算以及模态(主振型)的计算方法等。 固有频率 在考虑系统的固有振动时，最感兴趣的是系统的同步振动，即系统在各个坐标上除了运动幅值不相同外，随时间变化的规律都相同的运动 同步振动：系统在各个坐标上除了运动幅值不相同外，随时间变化的规律都相同的运动。 第一阶模态的任意时间及距离平衡位置的距离成满足一定的比例 一般来说，实际的振动时这三种主振动的线性叠加 注意：这里的常值列阵$\\Phi$ 代表运动的形状，$f(t)$ 为时间的函数。 随遇平衡的系统，只能建立半正定系统，此时可能没有平衡位置。 这里M的一定时大于0的，正定；但是K阵是不一定的，因为对于随遇平衡位置来说肯定是K阵的行列式为0，此时频率为0. (1) 正定系统 $\\omega&gt;0$ 只可能出现形如 $X(t)=\\Phi a\\sin(\\omega t+\\varphi)$ 的同步运动 系统在各个坐标上都是按相同频率及初相位作简谐振动 (2) 半正定系统 $\\omega \\ge 0$ 可能出现形如 $X(t)=\\Phi a\\sin(\\omega t+\\varphi)$ 的同步运动 也可能出现形如 $X(t)=\\Phi (a t+ b)$ 的同步运动（不发生弹性变形 ） 正定系统的主振动 \\left|\\begin{array}{cccc}k_{11}-\\omega^{2} m_{11} & k_{12}-\\omega^{2} m_{12} & \\cdots & k_{1 n}-\\omega^{2} m_{1 n} \\\\ k_{21}-\\omega^{2} m_{21} & k_{22}-\\omega^{2} m_{22} & \\cdots & k_{2 n}-\\omega^{2} m_{2 n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ k_{n 1}-\\omega^{2} m_{n 1} & k_{n 2}-\\omega^{2} m_{n 2} & \\cdots & k_{n n}-\\omega^{2} m_{n n}\\end{array}\\right|=0 这里特征根对于的是系统的固有频率，特征向量对于的是模态。 将特征方程化简可得： 结构建立起来之后固有频率就确定了，和是否振动时无关的。 采用位移方程求解固有频率 由此可得特征方程为：$|FM-\\lambda I|=0$ 特征根按照降序排列：$\\lambda_1\\ge\\lambda_2\\ge\\cdots\\ge\\lambda_n&gt;0 \\Rightarrow \\lambda_i=\\dfrac 1 {\\omega_i^2}$ 注意，这里一定要按照升序进行排列。 $\\omega_{1}=\\sqrt{k / m} \\quad \\omega_{2}=1.732 \\sqrt{k / m} \\quad \\omega_{3}=2 \\sqrt{k / m}$ 多自由度系统的模态(主振型)求解特征方程的特征根问题主要求解的是特征根，而求解特征向量就是求解模态(主振型)的过程。 间接法求模态 与特征根与特征方程类似，我们的这里的固有频率和模态也是一一对应的关系。 $\\omega_{i} 、 \\boldsymbol{\\phi}^{(i)}$ 代入到特征方程中可得：$\\left(\\boldsymbol{K}-\\omega_{i}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}^{(i)}=\\boldsymbol{0}$ 第 i 阶模态特征值问题 当 $\\omega_i$ 不是特征多项式重根时(即此时没有重根)，上式 n 个方程只有一个不独立 。 设最后一个方程不独立，把最后一行划去，并且把含有 $\\phi^{(i)} $ 的某个元素（例如$\\phi^{(i)}_n $）的项全部移到等号右端，即将最后一列元素放到等号的也右边，此时左边为一个$(n-1) \\times (n-1)$ 的矩阵。 为了简化计算，可以将$\\phi^{(i)}_n=1 $， $\\boldsymbol{\\phi}^{(i)}=\\left[\\begin{array}{lllll}\\phi_{1}^{(i)} &amp; \\phi_{2}^{(i)} &amp; \\cdots &amp; \\phi_{n-1}^{(i)} &amp; 1\\end{array}\\right]^{T}$ \\left[\\begin{array}{ccc}3-\\alpha & -1 & 0 \\\\ -1 & 2-\\alpha & -1 \\\\ 0 & -1 & 3-\\alpha\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2} \\\\ \\phi_{3}\\end{array}\\right]=0 \\quad \\alpha_{1}=1 \\quad \\alpha_{2}=3 \\quad \\alpha_{3}=4以 $\\alpha=1$ 为例进行说明，将其带入到方程中可得： $\\phi^{(i)}_n$的取值也可以取任意非零的常数$\\alpha_i$ 将其求解可得：$a_i\\phi^{(i)}$ (也可以是特征向量) 在特征向量中规定某个元素的值以确定其他各元素的值的过程称为归一化处理。 这里要注意，归一化以后，前面的方程不能为0 系统在各个坐标上都将以第 i 阶固有频率 $\\omega_i$ 做简谐振动，并且同时通过静平衡位置。 \\left[\\begin{array}{c}x_{1}^{(i)}(t) \\\\ x_{2}^{(i)}(t) \\\\ \\vdots \\\\ x_{n}^{(i)}(t)\\end{array}\\right]=\\left[\\begin{array}{c}\\phi_{1}^{(i)} \\\\ \\phi_{2}^{(i)} \\\\ \\vdots \\\\ \\phi_{n}^{(i)}\\end{array}\\right] a_{i} \\sin \\left(\\omega_{i} t+\\varphi_{i}\\right) \\Rightarrow\\\\ \\frac{x_{1}^{(i)}(t)}{\\phi_{1}^{(i)}}=\\frac{x_{2}^{(i)}(t)}{\\phi_{2}^{(i)}}=\\ldots \\ldots=\\frac{x_{n}^{(i)}(t)}{\\phi_{n}^{(i)}}=a_{i} \\sin \\left(\\omega_{i} t+\\varphi_{i}\\right) 第 i 阶特征向量$\\phi^{(i)}$中的一列元素，就是系统做第 i 阶主振动时各个坐标上位移（或振幅）的相对比值。 $\\phi^{(i)}$ 描述了系统做第 i 阶主振动时具有的振动形态，称为第 i 阶主振型，或是振型。 虽然各坐标上振幅的精确值并没有确定，但是所表现的系统振动形态已确定。 主振动仅取决于系统的M 阵、K 阵等物理参数，这一重要概念是单自由度系统所没有的。 将模态叠加可得：(n个模态的叠加，模态叠加法) \\begin{align} \\boldsymbol{X}(t)&=\\boldsymbol{\\phi}^{(1)} a_{1} \\sin \\left(\\omega_{1} t+\\varphi_{1}\\right)+\\boldsymbol{\\phi}^{(2)} a_{2} \\sin \\left(\\omega_{2} t+\\varphi_{2}\\right)+\\ldots+\\boldsymbol{\\phi}^{(n)} a_{n} \\sin \\left(\\omega_{n} t+\\varphi_{n}\\right)\\\\ &=\\sum_{i=1}^{n} \\boldsymbol{\\phi}^{(i)} a_{i} \\sin \\left(\\omega_{i} t+\\varphi_{i}\\right) \\qquad a_{i}, \\varphi_{i}(i=1 \\sim n): 初始条件决$ \\end{align} 由于各个主振动的固有频率不相同，多自由度系统的固有振动一般不是简谐振动，甚至不是周期振动 直接法求模态 \\left(\\boldsymbol{K}-\\omega_{i}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}^{(i)}=\\boldsymbol{0} \\quad \\boldsymbol{\\phi}^{(i)}=\\left[\\begin{array}{lll}\\phi_{1}^{(i)} & \\cdots & \\phi_{n}^{(i)}\\end{array}\\right]^{T} 注意这种方法只限于求解无重根情况下的，即特征矩阵的秩为矩阵的维数，或特征多项式的行列式为0。但是，其实在手算的情况下，伴随矩阵不是很好求的，一般还是用间接法。 例：两自由度弹簧－质量系统，求：固有频率和主振型 动力学方程: \\left[\\begin{array}{cc}m & 0 \\\\ 0 & 2 m\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}2 k & -k \\\\ -k & 3 k\\end{array}\\right]\\left[\\begin{array}{c}x_{1}(t) \\\\ x_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right]令主振动为： \\left[\\begin{array}{l}x_{1}(t) \\\\ x_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2}\\end{array}\\right] \\sin (\\omega t+\\varphi) \\\\ \\left(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0}最后解得： \\left[\\begin{array}{cc}2 k-m \\omega^{2} & -k \\\\ -k & 3 k-2 m \\omega^{2}\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right] 特征方程为： \\left|\\begin{array}{cc}2-\\alpha & -1 \\\\ -1 & 3-2 \\alpha\\end{array}\\right|=2 \\alpha^{2}-7 \\alpha+5=0 \\quad \\Rightarrow \\quad \\alpha_{1}=1, \\quad \\alpha_{2}=2.5 分别带入特征根，即特征频率，求解模态： 画图：横坐标表示静平衡位置，纵坐标表示主振型中各元素的值 两个质量以$\\omega_1$ 为振动频率，同时经过各自的平衡位置，方向相同，而且每一时刻的位移量都相同。 两个质量以 $ \\omega_2$为振动频率，同时经过各自的平衡位置，方向相反，每一时刻第一个质量的位移都第二个质量的位移的两倍。 如果传感器放在节点位置，则测量的信号中将不包含有第二阶模态的信息。 例：三自由度弹簧－质量系统，求：固有频率和主振型 动力学方程： \\left[\\begin{array}{ccc}m & 0 & 0 \\\\ 0 & m & 0 \\\\ 0 & 0 & m\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1} \\\\ \\ddot{x}_{2} \\\\ \\ddot{x}_{3}\\end{array}\\right]+\\left[\\begin{array}{ccc}3 k & -k & 0 \\\\ -k & 2 k & -k \\\\ 0 & -k & 3 k\\end{array}\\right]\\left[\\begin{array}{l}x_{1} \\\\ x_{2} \\\\ x_{3}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0\\end{array}\\right] 此时设主振动力： \\left[\\begin{array}{l}x_{1} \\\\ x_{2} \\\\ x_{3}\\end{array}\\right]=\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2} \\\\ \\phi_{3}\\end{array}\\right] \\sin (\\omega t+\\varphi) \\quad or \\quad\\left(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0} \\left[\\begin{array}{ccc}3 k-m \\omega^{2} & -k & 0 \\\\-k & 2 k-m \\omega^{2} & -k \\\\0 & -1 & 3 k-m \\omega^{2}\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{1} \\\\\\phi_{2} \\\\\\phi_{3}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\0 \\\\0\\end{array}\\right] 或者，我们求解特征矩阵的伴随矩阵可得： adj \\left[\\begin{array}{ccc}3-\\alpha & -1 & 0 \\\\ -1 & 2-\\alpha & -1 \\\\ 0 & -1 & 3-\\alpha\\end{array}\\right]=\\left[\\begin{array}{ccc}(3-\\alpha)(2-\\alpha)-1 & 3-\\alpha & 1 \\\\ 3-\\alpha & (3-\\alpha)^{2} & 3-\\alpha \\\\ 1 & 3-\\alpha & (3-\\alpha)(2-\\alpha)-1\\end{array}\\right]之后，将$\\alpha_{1}=1, \\quad \\alpha_{2}=3, \\quad \\alpha_{3}=4$ 分别代入到方程中： \\phi^{(1)}=\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 1\\end{array}\\right], \\quad \\phi^{(2)}=\\left[\\begin{array}{c}-1 \\\\ 0 \\\\ 1\\end{array}\\right], \\quad \\phi^{(3)}=\\left[\\begin{array}{c} 1\\\\ -1 \\\\ 1\\end{array}\\right] 第一节振型没有节点，第二阶振型有1 个节点，第三阶振型有2 个节点，这由主振型内元素符号变号的次数可以判断出 要设计传感器的位置，使得我们的测量的信息尽可能的全。 小结：","link":"/2022/03/13/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%87%AA%E7%94%B1%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"第四章 多自由度系统振动 多自由度系统的自由振动 第二部分","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是多自由振动系统中多自由度系统的自由振动部分，主要介绍模态的正交性、主质量和主刚度、模态叠加法的使用以及模态截断法的应用。 模态的正交性，主质量和主刚度 K \\phi^{(i)}=\\omega_{i}^{2} M \\phi^{(i)} \\Rightarrow \\phi^{(i)^{T}} K \\phi^{(j)}=\\omega_{i}^{2} \\phi^{(i)^{T}} M \\phi^{(j)} \\quad 标量 \\\\ K \\phi^{(j)}=\\omega_{i}^{2} M \\phi^{(j)} \\Rightarrow \\phi^{(i)^{T}} K \\phi^{(j)}=\\omega_{j}^{2} \\phi^{(i)^{T}} M \\phi^{(j)} \\quad 标量 \\\\ 当 $i \\ne j$ 时，$\\omega_i \\ne \\omega_j$ ,此时 $\\phi^{(i)^{T}} M \\phi^{(j)}=0 $ 即有质量的正交性； 同理带入原式中可得：$\\phi^{(i)^{T}} K \\phi^{(j)}=0 $ 此时刚度具有正交性。 当 $i=j$ 时， $\\phi^{(i)^{T}} M \\phi^{(j)}=m_{pi}$ 第 i 阶模态的主质量 $\\phi^{(i)^{T}} K \\phi^{(j)}=k_{pi} $ 第 i 阶模态的主刚度 第 i 阶固有频率：$\\omega_i=\\dfrac {k_{pi}} {m_{pi}} \\quad (i=1,2\\cdots n)$ 这里给模态乘以一个系数，让主质量变为1，主刚度也变成了固有频率的平方。 利用模态之间的正交性可以实现质量矩阵和刚度矩阵实现解耦。 对于主振型将 $ \\boldsymbol{\\phi}^{(i)}(i=1 \\sim n) $ 组成矩阵 $ \\boldsymbol{\\Phi}=\\left[\\begin{array}{lll}\\boldsymbol{\\phi}^{(1)} &amp; \\cdots &amp; \\boldsymbol{\\phi}^{(n)}\\end{array}\\right] \\in R^{n \\times n} $振型矩阵 \\left\\{\\begin{array}{ll}\\boldsymbol{\\Phi}^{T} \\boldsymbol{M} \\boldsymbol{\\Phi}=\\operatorname{diag}\\left(m_{p 1}, \\cdots, m_{p n}\\right)=\\boldsymbol{M}_{p} & \\text { 主质量矩阵 } \\\\ \\boldsymbol{\\Phi}^{T} \\boldsymbol{K} \\boldsymbol{\\Phi}=\\operatorname{diag}\\left(k_{p 1}, \\cdots, k_{p n}\\right)=\\boldsymbol{K}_{p} & \\text { 主刚度矩阵 }\\end{array}\\right. \\begin{align} \\boldsymbol{\\Phi}^{T} \\boldsymbol{M} \\boldsymbol{\\Phi}&=\\left[\\begin{array}{llll}\\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(n)}\\end{array}\\right]^{T} \\boldsymbol{M}\\left[\\begin{array}{lll}\\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(n)}\\end{array}\\right] \\\\ &=\\left[\\begin{array}{c}\\boldsymbol{\\phi}^{(1)^{T}} \\\\ \\vdots \\\\ \\boldsymbol{\\phi}^{(n)^{T}}\\end{array}\\right] \\boldsymbol{M}\\left[\\begin{array}{lll}\\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(n)}\\end{array}\\right] =\\left[\\begin{array}{c}\\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\\\ \\vdots \\\\ \\boldsymbol{\\phi}^{(n)^{T}} \\boldsymbol{M}\\end{array}\\right]\\left[\\begin{array}{lll}\\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(n)}\\end{array}\\right] \\\\ &=\\left[\\begin{array}{ccc}\\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(n)} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\boldsymbol{\\phi}^{(n)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(1)} & \\cdots & \\boldsymbol{\\phi}^{(n)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(n)}\\end{array}\\right]=\\left[\\begin{array}{ccc}m_{p 1} & & 0 \\\\ & \\ddots & \\\\ 0 & & m_{p n}\\end{array}\\right] \\end{align}对正则振型将 $ \\boldsymbol{\\phi}^{(i)}_N(i=1 \\sim n) $ 组成矩阵 $ \\boldsymbol{\\Phi}_N=\\left[\\begin{array}{lll}\\boldsymbol{\\phi}^{(1)}_N &amp; \\cdots &amp; \\boldsymbol{\\phi}^{(n)}_N\\end{array}\\right] \\in R^{n \\times n} $正则振型矩阵 \\left\\{\\begin{array}{ll}\\boldsymbol{\\Phi}^{T}_N \\boldsymbol{M} \\boldsymbol{\\Phi}_N=I & \\text { 单位矩阵 } \\\\ \\boldsymbol{\\Phi}^{T}_N \\boldsymbol{K} \\boldsymbol{\\Phi}_N= \\boldsymbol{\\Lambda}& \\text { 谱矩阵 }\\end{array}\\right.\\qquad \\boldsymbol{\\Lambda}=\\left[\\begin{array}{lll}\\omega_{1}^{2} & & \\\\ & \\ddots & \\\\ & & \\omega_{n}^{2}\\end{array}\\right] 依次取$i=1 \\sim n$ ，得到的 n 个方程，可合写为：$K \\Phi=M \\Phi \\Lambda$ 左乘 $\\boldsymbol{\\Phi}^{T}$ 可得: $\\boldsymbol{K}_{p}=\\boldsymbol{M}_{p} \\boldsymbol{\\Lambda} ,\\quad \\boldsymbol{\\Lambda}=\\boldsymbol{M}_{p}^{-1} \\boldsymbol{K}_{p}$ 不难验证, 有: $\\boldsymbol{\\Phi}_{N}^{T} \\boldsymbol{K} \\boldsymbol{\\Phi}_{N}=\\boldsymbol{\\Lambda} \\quad \\boldsymbol{\\Phi}_{N}^{T} \\boldsymbol{M}\\boldsymbol{\\Phi}_{N}=\\boldsymbol{I}$ 此时的正则振型矩阵为： \\boldsymbol{\\Phi}_{N}=\\left[\\frac{\\phi^{(1)}}{\\sqrt{m_{p 1}}}, \\frac{\\phi^{(2)}}{\\sqrt{m_{p 2}}}, \\frac{\\phi^{(3)}}{\\sqrt{m_{p 3}}}\\right]=\\frac{1}{\\sqrt{6 m}}\\left[\\begin{array}{ccc}1 & -\\sqrt{3} & \\sqrt{2} \\\\ 2 & 0 & -\\sqrt{2} \\\\ 1 & \\sqrt{3} & \\sqrt{2}\\end{array}\\right]\\\\正则振型和主振型之间的关系：$\\boldsymbol{\\phi}_{N}^{(i)}=\\dfrac{1}{\\sqrt{m_{p i}}} \\boldsymbol{\\phi}^{(i)} $ 模态叠加法主要的两种模态坐标两种主要的模态的坐标： 主模态坐标：$X_P=[x_{p1},x_{p2},\\cdots,x_{pn}]^T$； 正则模态坐标：$X_N=[x_{N1},x_{N2},\\cdots,x_{Nn}]^T$ 模态 $\\phi^{(i)} \\ (i=1 \\sim n)$ ，相互正交，表明它们是线性独立的，可用于构成n 维空间的基。 系统的任意 n 维自由振动可唯一地表示为各阶振型的线性组合 \\boldsymbol{X}=\\sum_{i=1}^{n} \\boldsymbol{\\phi}^{(i)} x_{p i} \\quad \\boldsymbol{X} \\in R^{n} \\quad \\boldsymbol{\\phi}^{(i)} \\in R^{n \\times 1} 系统在正则模态的坐标下，响应的表达式为： \\boldsymbol{X}=\\boldsymbol{\\Phi_N}X_N=\\sum_{i=1}^{n} \\boldsymbol{\\phi}^{(i)}_N x_{N i} \\quad \\boldsymbol{X} \\in R^{n} \\quad \\boldsymbol{\\phi}^{(i)} \\in R^{n \\times 1} 小结： 求解无阻尼系统对初始条件的响应求解的基本问题： \\left\\{\\begin{array}{l}\\boldsymbol{M} \\ddot{\\boldsymbol{X}}+\\boldsymbol{K} \\boldsymbol{X}=0 \\quad \\boldsymbol{X} \\in R^{n}\\\\ \\boldsymbol{X}(0)=\\boldsymbol{X}_{0}, \\dot{\\boldsymbol{X}}(0)=\\dot{\\boldsymbol{X}}_{0} \\quad \\boldsymbol{M} 、 \\boldsymbol{K} \\in R^{n \\times n}\\\\ \\end{array}\\right.\\\\ \\boldsymbol{X}_{0}=\\left[x_{1}(0), x_{2}(0), \\cdots, x_{n}(0)\\right]^{T} \\quad \\dot{\\boldsymbol{X}}_{0}=\\left[\\dot{x}_{1}(0), \\dot{x}_{2}(0), \\cdots, \\dot{x}_{n}(0)\\right]^{T}可分别采用两类模态坐标求解 主模态坐标求解 此时可以转换为n个单自由度的问题，即将物理空间耦合的问题，转化为模态空间的解耦的问题。 m_{p i} \\ddot{x}_{p i}+k_{p i} x_{p i}=0 \\quad(i=1 \\sim n)\\\\ x_{p i}=x_{p i}(0) \\cos \\omega_{i} t+\\frac{\\dot{x}_{p i}(0)}{\\omega} \\sin \\omega_{i} t \\quad(i=1 \\sim n)在求得 $x_{pi} (i=1,2,… n)$ 后，可利用 $\\boldsymbol{X}=\\boldsymbol{\\Phi}\\boldsymbol{X_P} $ 式求得原系统的解。 正则模态坐标求解 \\ddot{x}_{N i}+\\omega_{i}^{2} x_{N i}=0, \\quad(i=1 \\sim n)\\\\ x_{N i}=x_{N i}(0) \\cos \\omega_{i} t+\\frac{\\dot{x}_{N i}(0)}{\\omega_{i}} \\sin \\omega_{i} t, \\quad(i=1 \\sim n)在求得 $x_{Ni} (i=1,2,… n)$ 后，可利用 $\\boldsymbol{X}=\\boldsymbol{\\Phi}\\boldsymbol{X_N} $ 式求得原系统的解。 例题例：三自由度弹簧－质量系统，求：系统在初始条件下的响应。 首先，求解出动力学方程： \\left[\\begin{array}{ccc}m & 0 & 0 \\\\ 0 & m & 0 \\\\ 0 & 0 & m\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1} \\\\ \\ddot{x}_{2} \\\\ \\ddot{x}_{3}\\end{array}\\right]+\\left[\\begin{array}{ccc}3 k & -k & 0 \\\\ -k & 2 k & -k \\\\ 0 & -k & 3 k\\end{array}\\right]\\left[\\begin{array}{l}x_{1} \\\\ x_{2} \\\\ x_{3}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0\\end{array}\\right]固有频率：$\\omega_{1}=\\sqrt{k / m}、\\omega_{2}=\\sqrt{3 k / m}、\\omega_{3}=2 \\sqrt{k / m}$ 正则振型的矩阵：$\\boldsymbol{\\Phi}_N=\\dfrac 1 {\\sqrt{6m}}\\left[\\begin{array}{ccc}1 &amp; -\\sqrt 3 &amp; \\sqrt 2 \\\\ 2 &amp; 0 &amp; -\\sqrt 2 \\\\ 1 &amp; \\sqrt 3 &amp; \\sqrt 2\\end{array}\\right] $ 此时，带入模态坐标的初始条件： \\boldsymbol{X}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\boldsymbol{X}_{0}=\\sqrt{m / 6}\\left[\\begin{array}{c}6 \\\\ -2 \\sqrt{3} \\\\ 0\\end{array}\\right] \\quad \\dot{\\boldsymbol{X}}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\dot{\\boldsymbol{X}}_{0}=\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0\\end{array}\\right]代入公式得模态坐标的响应： \\boldsymbol{X}_{N}=\\left[\\begin{array}{c}x_{N 1} \\\\ {x_{N 2}} \\\\ {x_{N 3}}\\end{array}\\right]=\\sqrt{\\frac{m}{6}}\\left[\\begin{array}{c}6 \\cos \\omega_{1} t \\\\ -2 \\sqrt{3} \\cos \\omega_{2} t \\\\ 0\\end{array}\\right]\\\\x_{N i}=x_{N i}(0) \\cos \\omega_{i} t+\\frac{\\dot{x}_{N i}(0)}{\\omega_{i}} \\sin \\omega_{i} t此时原物理空间的响应为： \\begin{aligned} \\boldsymbol{X}(t) &=\\left[\\begin{array}{l}x_{1}(t) \\\\ x_{2}(t) \\\\ x_{3}(t)\\end{array}\\right]=\\boldsymbol{\\Phi}_{N} \\boldsymbol{X}_{N}=\\frac{1}{\\sqrt{6 m}}\\left[\\begin{array}{ccc}1 & -\\sqrt{3} & \\sqrt{2} \\\\ 2 & 0 & -\\sqrt{2} \\\\ 1 & \\sqrt{3} & \\sqrt{2}\\end{array}\\right] \\times \\sqrt{\\frac{m}{6}}\\left[\\begin{array}{c}6 \\cos \\omega_{1} t \\\\ -2 \\sqrt{3} \\cos \\omega_{2} t \\\\ 0\\end{array}\\right] \\\\ &=\\left[\\begin{array}{l}\\cos \\omega_{1} t+\\cos \\omega_{2} t \\\\ 2 \\cos \\omega_{1} t \\\\ \\cos \\omega_{1} t-\\cos \\omega_{2} t\\end{array}\\right] \\end{aligned} 小结： 这里的叠加其实就是将模态空间的振型分别于对于的转换矩阵相乘后叠加来求解最后在物理空间的振动情况。 模态截断法 对自由度数n 很大的复杂振动系统，不可能求出全部的固有频率和相应的主振型，然后用振型叠加法分析系统对激励的响应 当激励频率主要包含低频成分时，可以撇去高阶振型及固有频率对响应的贡献，而只利用较低的前面若干阶固有频率及主振型近似分析系统响应 受迫振动时，高阶频率的振动对系统的影响非常小，可以忽略。 对于n 自由度系统，将前 r 阶振型$\\Phi^{(r)} (i=1,2,…,r)$ 组成的截断振型矩阵记为 : $\\boldsymbol{\\Phi}^{*}=\\left[\\begin{array}{llll}\\boldsymbol{\\phi}^{(1)} &amp; \\boldsymbol{\\phi}^{(2)} &amp; \\ldots &amp; \\boldsymbol{\\phi}^{(r)}\\end{array}\\right] \\in R^{n \\times r}$ 这里$\\boldsymbol{\\Phi}^{*}$ 要和M相乘，这里M是$n\\times n$的. 截断的主质量矩阵和主刚度矩阵 系统的任意n 阶振动近似地表示为截断后的 r 阶模态的线性组合： \\boldsymbol{X}=\\sum_{i=1}^{r} \\boldsymbol{\\phi}^{(i)} \\boldsymbol{X}_{p i}=\\boldsymbol{\\Phi}^{*} \\boldsymbol{X}_{p}^{*}​ $ \\boldsymbol{X}_{p}^{*} $ 截断后的主坐标列阵 $\\quad \\boldsymbol{X}_{p}^{*}=\\left[\\begin{array}{llll}x_{p 1} &amp; x_{p 2} &amp; \\ldots &amp; x_{p r}\\end{array}\\right]^{T} $ 利用模态截断法可将n 自由度系统原有的n 个坐标变换成较少的前 r 个主坐标","link":"/2022/03/13/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%87%AA%E7%94%B1%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"第四章 多自由度系统振动 多自由系统的受迫振动","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是多自由振动系统中多自由度系统的受迫振动，主要介绍系统对简谐力激励的响应、动力吸振器和振型叠加法求解任意激励下响应。 系统对简谐力激励的响应回顾单自由度的简谐激励的情况： 多自由度系统受到外力激励所产生的运动为受迫运动 设 n 自由度系统沿各个广义坐标均受到频率和相位相同的广义简谐力的激励 受迫振动方程：$ \\boldsymbol{M} \\ddot{\\boldsymbol{X}}(t)+\\boldsymbol{K} \\boldsymbol{X}(t)=\\boldsymbol{F}_{0} e^{i \\omega t} \\quad \\boldsymbol{X} \\in R^{n} $ 稳态解：$\\boldsymbol{X}(t)=\\overline{\\boldsymbol{X}} e^{i \\omega t} \\quad \\overline{\\boldsymbol{X}} \\in R^{n} $ 振幅列向量 ：$ \\overline{\\boldsymbol{X}}=\\left[\\begin{array}{llll}\\bar{X}_{1} &amp; \\bar{X}_{2} &amp; \\ldots \\ldots &amp; \\bar{X}_{n}\\end{array}\\right]^{T} $ 最后可得： \\left(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right) \\overline{\\boldsymbol{X}}=\\boldsymbol{F}_{0} 此时记$H(\\omega)=\\left[\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right]^{-1}$ 多自由度系统的幅频响应矩阵 则有$\\overline{\\boldsymbol{X}}=HF_0 \\quad X(t)=HF_0e^{i\\omega t}$ 简谐激励下，系统稳态响应也为简谐响应，并且振动频率为外部激励的频率，但是各个自由度上的振幅各不相同。 在实际的工程中：阻抗矩阵$\\left(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right)$ ,导纳矩阵 $H(\\omega)=\\left[\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right]^{-1}$ $H_{ij}$的物理意义为仅沿 j 坐标作用频率为 $\\omega$ 的单位幅度简谐力时，沿 i 坐标所引起的受迫振动的复振幅。 H(\\omega)=\\left[\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right]^{-1}=\\dfrac {adj(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M})} {|\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}|}当外部激励频率接近系统任一阶固有频率时：$|\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}|=0$ ，受迫振动的振幅无限增大，产生共振。 如果系统又n个不同的固有频率，也就又n个共振点。 动力吸振器动力吸振器的基本原理许多机器或部件由于旋转部分的质量偏心而产生强迫振动，为减小这种振动有时可以采用动力吸振器 忽略主系统阻尼 ， 主系统固有频率：$\\omega_1=\\sqrt{\\dfrac {k_1}{m_1}}$ 为了抑制主系统的振动，在主系统上附加一个弹簧-质量系统 系统强迫振动的方程： \\left[\\begin{array}{cc}m_{1} & 0 \\\\ 0 & m_{2}\\end{array}\\right]\\left[\\begin{array}{l}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}c & -c \\\\ -c & c\\end{array}\\right]\\left[\\begin{array}{c}\\dot{x}_{1}(t) \\\\ \\dot{x}_{2}(t)\\end{array}\\right]+\\left[\\begin{array}{cc}k_{1}+k_{2} & -k_{2} \\\\ -k_{2} & k_{2}\\end{array}\\right]\\left[\\begin{array}{l}x_{1}(t) \\\\ x_{2}(t)\\end{array}\\right]=\\left[\\begin{array}{c}F_{0} \\sin \\omega t \\\\ 0\\end{array}\\right]以下为有阻尼的动力吸振器系统： 简化系统，去掉阻尼后的无阻尼吸振器： 对于简谐振动可以使用直接使用公式$\\left(\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right) \\overline{\\boldsymbol{X}}=\\boldsymbol{F}_{0}$ 来求解，但是对于一般的系统就不可以了。 \\left[\\begin{array}{c}\\bar{x}_{1} \\\\ \\bar{x}_{2}\\end{array}\\right]=\\left[\\begin{array}{cc}k_{1}+k_{2}-m_{1} \\omega^{2} & -k_{2} \\\\ -k_{2} & k_{2}-m_{2} \\omega^{2}\\end{array}\\right]^{-1}\\left[\\begin{array}{c}F_{0} \\\\ 0\\end{array}\\right]=\\frac{F_{0}}{\\Delta(\\omega)}\\left[\\begin{array}{c}{k_{2}-m_{2} \\omega^{2}} \\\\{k_{2}} \\end{array}\\right]其中，$\\Delta(\\omega) $: 系统特征多项式 $\\Delta(\\omega)=\\left|\\boldsymbol{K}-\\omega^{2} \\boldsymbol{M}\\right| $ \\begin{aligned} \\Delta(\\omega) &=\\left(k_{1}+k_{2}-m_{1} \\omega^{2}\\right)\\left(k_{2}-m_{2} \\omega^{2}\\right)-k_{2}^{2} \\\\ &=m_{1} m_{2} \\omega^{4}-\\left(k_{1} m_{2}+k_{2} m_{1}+k_{2} m_{2}\\right) \\omega^{2}+k_{1} k_{2} \\end{aligned}于是当$\\omega=\\sqrt{\\dfrac {k_2} {m_2}}$ 时，外部激励频率等于吸振器的固有频率，此时与有$\\bar{x}_1=0$ ,主系统不再振动，这种现象称为反共振。 此时，$\\Delta(\\omega)=-k_2^2$ 吸振器的振幅为 $\\bar{x}_2=-\\dfrac {F_0} {k_2}$ 主系统上受到的激振力恰好被来自吸振器的弹性恢复力平衡。 上图为时滞吸尘器，就是将反共振的频带放宽，之后反共振的范围就扩大到更广泛的频率上了，尽量减少由于激励的改变而造成的但不到反共振情况。 在建筑领域，一般在楼的顶层加装弹性小车充当动力吸振器，ATMD、TMD、MTMD(在每一层都加一个阻尼吸振器)，这样可以防震。 若机械在使用动力吸振器之前，在接近共振的情况下工作，即：$\\omega\\approx \\omega_1=\\sqrt{k_1/m_1}$ 因此若在设计吸振器时，使得$\\omega=\\sqrt{k_2/m_2}=\\sqrt{k_1/m_1}$ 。则当机械在它原始的共振频率下运行时，振幅将会为零。 此时，$k_2\\bar{x}_2=-F_0=m_2\\omega^2\\bar{x}_2$ , 其中$k_2，m_2$ 时由$\\bar{x}_2$的允许值决定，一般参数选为： \\frac {k_2} {k_1} = \\frac {m_2} {m_1}=\\mu使吸振器的固有频率和主系统的固有频率相等。 记 $\\omega_0=\\sqrt{k_1/m_1}=\\sqrt{k_2/m_2} \\quad s=\\omega/\\omega_0$ 于是带入到特征表达式可得：$\\Delta(\\omega)=k_1k_2[s^4-(2+\\mu)s^2+1]$ 于是可以推得： \\Delta(\\omega)=m_{1} m_{2} \\omega^{4}-\\left(k_{1} m_{2}+k_{2} m_{1}+k_{2} m_{2}\\right) \\omega^{2}+k_{1} k_{2}\\\\ \\frac{k_{2}}{k_{1}}=\\frac{m_{2}}{m_{1}}=\\mu, \\quad \\omega_{0}=\\sqrt{\\frac{k_{1}} {m_{1}}}=\\sqrt{\\frac{k_{2}} {m_{2}}}, \\quad s=\\frac{\\omega}{\\omega_0}\\\\ \\Rightarrow \\Delta(\\omega)=k_{1} k_{2}\\left[s^{4}-(2+\\mu) s^{2}+1\\right]详细的推导： \\Delta(\\omega)=k_{1} k_{2}\\left[\\frac{m_{1} m_{2} \\omega^{4}}{k_{1} k_{2}}-\\frac{\\left(k_{1} m_{2}+k_{2} m_{1}+k_{2} m_{2}\\right) \\omega^{2}}{k_{1} k_{2}}+1\\right]其中的第二项的化简为 \\frac{\\left(k_{1} m_{2}+k_{2} m_{1}+k_{2} m_{2}\\right) \\omega^{2}}{k_{1} k_{2}}=\\frac{\\left(\\mu k_{1} m_{1}+\\mu k_{1} m_{1}+\\mu^{2} k_{1} m_{1}\\right) \\omega^{2}}{\\mu k_{1} k_{1}} \\\\=\\frac{\\left(m_{1}+m_{1}+\\mu m_{1}\\right) \\omega^{2}}{k_{1}}=\\frac{(2+\\mu) \\omega^{2}}{k_{1} / m_{1}}=\\frac{(2+\\mu) \\omega^{2}}{\\omega_{0}^{2}}=(2+\\mu) s^{2} 将$\\Delta(\\omega)$ 代入，并且设主质量的静变形为：$\\bar{x}_0=F_0/k_1$ 于是可得： \\frac{\\bar{x}_{1}}{\\bar{x}_{0}}=\\frac{1-s^{2}}{s^{4}-(2+\\mu) s^{2}+1} \\quad \\frac{\\bar{x}_{2}}{\\bar{x}_{0}}=\\frac{1}{s^{4}-(2+\\mu) s^{2}+1} 出现反共振，但在反共振两旁存在两个共振点。 注意： (1) 若机械的运行速度在主系统固有频率附近，机械启动和制止时必然经过s1，这会引起大振幅。 (2) 因为吸振器时根据一个特定的激励频率设计的，只有当固有频率等于外部激励频率时主系统振幅才为零。如果机械在其他频率下运行或者机械上的力包含几个不同的频率成分，则其振幅也可能会很大。 为了允许激励频率$\\omega $ 在 s =1 附近有一定范围的变化，s1、s2 应当相距远些。需要$\\mu$ 的值很大，此时只需要将$k_2，m_2$的间距调大即可，但是这样会使得动力吸振器很笨拙，因此我们采用阻尼动力吸振器。 非线性动力吸振器 稳态响应振幅（复振幅）: \\begin{align} {\\left[\\begin{array}{l}\\bar{x}_{1} \\\\\\bar{x}_{2}\\end{array}\\right] \\left[\\begin{array}{cc}k_{1}+k_{2}-m_{1} \\omega^{2}+i c \\omega & -\\left(k_{2}+i c \\omega\\right) \\\\-\\left(k_{2}+i c \\omega\\right) & k_{2}-m_{2} \\omega^{2}+i c \\omega\\end{array}\\right]^{-1}\\left[\\begin{array}{c}F_{0} \\\\0\\end{array}\\right] } \\frac{F_{0}}{\\Delta(\\omega)}\\left[\\begin{array}{c}k_{2}-m_{2} \\omega^{2}+i c \\omega \\\\k_{2}+i c \\omega\\end{array}\\right] \\\\ \\end{align} \\begin{align} 其中: \\Delta(\\omega)&=\\left(k_{1}+k_{2}-m_{1} \\omega^{2}+i c \\omega\\right)\\left(k_{2}-m_{2} \\omega^{2}+i c \\omega\\right)-\\left(k_{2}+i c \\omega\\right)^{2} \\\\ &=\\left(k_{1}-m_{1} \\omega^{2}\\right)\\left(k_{2}-m_{2} \\omega^{2}\\right)-k_{2} m_{2} \\omega^{2}+i c \\omega\\left(k_{1}-m_{1} \\omega^{2}-m_{2} \\omega^{2}\\right) \\end{align}主系统复振幅： \\bar{x}_{1}=\\frac{F_{0}\\left(k_{2}-m_{2} \\omega^{2}+i c \\omega\\right)}{\\left(k_{1}-m_{1} \\omega^{2}\\right)\\left(k_{2}-m_{2} \\omega^{2}\\right)-k_{2} m_{2} \\omega^{2}+i c \\omega\\left(k_{1}-m_{1} \\omega^{2}-m_{2} \\omega^{2}\\right)} 转化为无量纲的形式可得： \\frac{\\bar{x}_{1}}{\\delta_{s t}}=\\frac{\\sqrt{\\left(s^{2}-\\alpha^{2}\\right)^{2}+\\left(2 \\xi_{s}\\right)^{2}}}{\\sqrt{\\left[\\mu s^{2} \\alpha^{2}-\\left(s^{2}-1\\right)\\left(s^{2}-\\alpha^{2}\\right)\\right]^{2}+\\left(2 \\xi{s}\\right)^{2}\\left(s^{2}-1+\\mu s^{2}\\right)^{2}}} 对上面图像在不同阻尼下的结果进行分析可得： 当 $\\xi=0$ 时， 系统中无阻尼，有两个共振频率点，s1=0.895,s2=1.12 在s=1时，发生反共振现象 当$\\xi=\\infty$ 时，系统 变成力一个单自由度系统，共振点为s=0.976 阻尼非常大，可以看作时主质量和吸振器焊接在一起了。 当 $\\xi=0.10$ 和 $\\xi=0.32$ 时，可见当 s＝1 时，主系统振幅并不为零，但是和无阻尼系统的两个共振振幅相比，共振振幅明显下降。 无论阻尼取多少，所有曲线都过 S、T 两点。实际设计有阻尼动力吸振器时，一般选取适当的 m2 与 k2，使曲线在 S 和 T点有相同的幅值，并且适当选取阻尼，使曲线在 S、T 两点具有水平切线 动力吸振器典型例题例: 一台重3000N的柴油机，安装在支架上。当其以6000 r/min转速工作时，可以观察到它的振动通过支架对周围环境造成了影响。试确定需要安装在支架上的吸振器的参数。激振力的幅值为250N，辅助质量的最大许可位移为2mm。 例: 一台电动机-发电机组，设计运行速度为2000-4000 r/min。但是由于转子存在微小的不平衡，该机械在运行速度为3000 r/min时发生剧烈振动。为此设计安装一个悬臂式集中质量吸振器来消除振动。当一个有2kg实验载荷的悬臂安装到机器上之后，所得系统的固有频率为2500 r/min和3500 r/min。设计吸振器的质量和刚度，使得整个系统的固有频率在电动机-发电机组的转速范围之外。 注意，这里的2kg时实验的载荷，最优的载荷需要我们求解。 根据实验载荷的质量以及共振频率，可以求出主质量的将质量，下面来计算所需的吸振器的刚度和主力。 这里设计时，先确定的是频率比的下限，由下限s1来求出质量比$\\mu$ ,之后带回来求解共振质量比的上限，并求解出共振频率，判断是是否满足要求，不满足则先确定上限后确定下限。 工程应用(调谐质量阻尼器) 调谐质量阻尼器（Tuned Mass Damper，TMD），最早的结构振动被动控制装置之一，在建筑、桥梁、车辆、船舶及机械领域均有广泛应用。 TMD三个基本单元： 吸收振动能量的质量块m、耗散能量的阻尼装置C，以及刚度单元K。 从能量角度说是一种能量转移，即将主系统的振动能量转移到TMD上。 TMD减振方法的优点： (1) 减振效果显著。只要TMD固有频率与主系统固有频率一致，理论上主系统的振动可完全消除，实际工程中也能达到80％以上。 (2) 结构设计灵活。可根据振动主系统结构特征和安装空间，将TMD外形结构设计成不同形状，如可设计成摆式TMD，悬臂式TMD或环形TMD。 TMD减振方法的缺点： (1) 最大缺点是减振频带较窄。只当TMD固有频率与被控对象激振频率一致或接近时，减振才有效，若偏离时便会产生两个新共振峰。因此，如果TMD使用不当，不但不能吸振，反而易产生新的共振，即＂频率失调＂现象。 (2) TMD－旦发生频率失调，主系统会因共振而产生更大振动。该现象在当TMD质量较小时更为明显，这对TMD固有频率的设计提出了更高要求。 (3) TMD启动速度具有一定滞后性，对冲击或突发载荷等无法迅速反应。由于TMD对调谐频率的敏感型，许多学者对其有效频带拓宽方法进行研究，出现了各种主动、半主动调谐质量阻尼器便调谐其目标频率。 对于风振有很好的抑制作用，但是对于地震就由一定的延迟。 几种最新的调谐质量阻尼器： 主动型调谐质量阻尼器(ATMD)：从20世纪90年代初期起由于现代控制理论的普及如PID控制、LQR控制等，得到广泛的研究。ATMD最有魅力的地方就是可利用一个TMD就可实现多个振动模态的控制。ATMD优于被动TMD，但ATMD需要提供额外能量来获得期望的减振效果。 发生地震会断电，没有能量来源基本就废了，跟被动的没什么区别。 半自动型调谐质量阻尼器(SATMD)：由于具有刚度和阻尼可调的能力，及较强的适应能力，自1980年被提出后便得到了广泛关注。SATMD维护简单，对外部能源需求比ATMD低，可靠性和鲁棒性好。相关文献指出，SATMD比TMD和ATMD更有效和更具有发展潜力。 振型叠加法 求解多自由度系统的问题的本质，就是求解一个模态矩阵，使得M、K矩阵可以实现正交，对角化。 振型叠加法可用于分析多自由度系统的受迫振动 前面讨论的外部激励为简谐激励，因此可采用$X(t)=\\bar{X}e^{i\\omega t} $ 直接法进行求解 当外部激励不是简谐激励时，则不能用直接法，此时可采用振型叠加法下面先用振型叠加法对简谐激励的多自由度系统的受迫振动进行求解，以进一步阐述多自由度系统的共振特性 然后采用振型叠加法对任意外部激励时系统的响应进行求解 简谐激励时的情况考虑简谐激励的情况，使用标准的模态叠加法求解，就是先将空间由物理空间转换为模态空间，分别求解之后在转化成为物理空间。 $ n $ 自由度系统: $\\boldsymbol{M} \\ddot{\\boldsymbol{X}}(t)+\\boldsymbol{K} \\boldsymbol{X}(t)=\\boldsymbol{F}_{0} e^{i \\omega t} \\quad \\boldsymbol{X} \\in R^{n} \\quad \\boldsymbol{F}_{0} \\in R^{n \\times 1} $ 将物理空间转换为模态空间可得： \\boldsymbol{X}(t)=\\boldsymbol{\\Phi} \\boldsymbol{X}_{p}(t) \\quad \\boldsymbol{M}_{p} \\ddot{\\boldsymbol{X}}_{p}(t)+\\boldsymbol{K}_{p} \\boldsymbol{X}_{p}(t)=\\boldsymbol{F}_{p} e^{i \\omega t} \\quad \\boldsymbol{F}_{p}=\\boldsymbol{\\Phi}^{T} \\boldsymbol{F}_{0} \\in R^{n \\times 1} \\\\m_{p j} \\ddot{x}_{p j}(t)+k_{p j} x_{p j}(t)={F_{p j} e^{i \\omega t}}\\quad j=1 \\sim n\\\\ F_{p j}=\\phi^{(j)^{T}} \\boldsymbol{F}_{0}作用力模态变换的具体解释: F_p=\\left[\\begin{array}{c}F_{p_{1}} \\\\ \\vdots \\\\ F_{p} \\\\ \\vdots \\\\ F_{p_{n}}\\end{array}\\right]=\\boldsymbol{\\Phi}^{T} \\boldsymbol{F}_{0}=\\left[\\begin{array}{lllll}\\phi^{(1)} & \\cdots & \\phi^{(j)} & \\cdots & \\phi^{(n)}\\end{array}\\right]^{T}\\left[\\begin{array}{c}F_{01} \\\\ \\vdots \\\\ F_{0 n}\\end{array}\\right]=\\left[\\begin{array}{c}\\phi^{(1)^{T}} \\\\ \\vdots \\\\ \\phi^{(j)^{T}} \\\\ \\vdots \\\\ \\phi^{(n)^{T}}\\end{array}\\right] \\boldsymbol{F}_{0}=\\left[\\begin{array}{c}\\phi^{(1)^{T}} \\boldsymbol{F}_{0} \\\\ \\vdots \\\\ \\phi^{(j)^{T}} \\boldsymbol{F}_{0} \\\\ \\vdots \\\\ \\phi^{(n)^{T}} \\boldsymbol{F}_{0}\\end{array}\\right]模态坐标解： x_{p j}(t)=\\frac{F_{p j}}{k_{p j}} \\cdot \\frac{1}{1-s_{j}^{2}} e^{i \\omega t}=\\frac{\\phi^{(j)^{T}} \\boldsymbol{F}_{0}}{k_{p j}\\left(1-s_{j}^{2}\\right)} e^{i \\omega t} 其中，外部激励频率与第 j 阶固有频率之比 :$ s_{j}=\\dfrac{\\omega}{\\omega_{j}}$ 各坐标的受迫振动规律完全类似于单自由度系统的受迫振动规律： \\boldsymbol{X}(t)=\\boldsymbol{\\Phi} \\boldsymbol{X}_{p}(t)=\\sum_{j=1}^{n} \\boldsymbol{\\phi}^{(j)} x_{p j}(t)=\\sum_{j=1}^{n} \\frac{\\phi^{(j)} \\phi^{(j)^{T}}}{k_{p j}\\left(1-s_{j}^{2}\\right)} \\boldsymbol{F}_{0} e^{i \\omega t}当 $\\omega \\rightarrow \\omega_j$ 时， $s_j \\rightarrow 1$ 于是就会发生共振。即第 j 阶主坐标的受迫振动幅度将急剧增大，导致第 j 阶频率的共振。 系统具有 n 个不相等的固有频率时，可以出现 n 种不同频率的共振 直接法就是将复数项去掉，直接建立模长$\\bar{X},\\bar{F_0}$ 的关系来求解。但是直接法的前提是必须是简谐激励。 例：三自由度系统 求：系统稳态响应 这里可以看出，其第二阶的固有频率和系统外部激励比较接近。 激振频率接近第二阶固有频率，在稳态响应中第二阶振型占主要成分。 任意外部激励时的情况$ n $ 自由度系统的动力学方程为： \\boldsymbol{M} \\ddot{\\boldsymbol{X}}(t)+\\boldsymbol{K} \\boldsymbol{X}(t)=\\boldsymbol{F}_{0}(t) \\quad \\boldsymbol{X} \\in R^{n} \\quad \\boldsymbol{X}(0), \\dot{\\boldsymbol{X}}(0) \\\\ \\boldsymbol{X}(t)=\\ddot{\\boldsymbol{\\Phi}}_{N} \\boldsymbol{X}_{N}(t) \\quad \\boldsymbol{\\Lambda} \\boldsymbol{X}_{N}(t)=\\boldsymbol{F}_{N}(t)正则振型矩阵: \\ddot{x}_{N i}(t)+\\omega_{i}^{2} x_{N i}(t)=F_{N i}(t), \\quad i=1 \\sim n \\quad 模态广义力\\\\ \\boldsymbol{F}_{N}=\\boldsymbol{\\Phi}_{N}^{T} \\boldsymbol{F}_{0}=\\left[F_{N 1}, F_{N 2}, \\cdots, F_{N n}\\right]^{T}模态坐标初始条件：$ \\boldsymbol{X}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\boldsymbol{X}(0) \\quad \\dot{\\boldsymbol{X}}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\dot{\\boldsymbol{X}}(0)$ \\\\ x_{N i}(t)=x_{N i}(0) \\cos \\omega_{i} t+\\frac{\\dot{x}_{N i}(0)}{\\omega_{i}} \\sin \\omega_{i} t+\\frac{1}{\\omega_{i}} \\int_{0}^{t} F_{N i}(\\tau) \\sin \\omega_{i}(t-\\tau) d \\tau \\quad (i=1 \\sim n)在得到 $\\boldsymbol{X}_{N}$后，利用 $\\boldsymbol{X}=\\boldsymbol{\\phi}_{N}\\boldsymbol{X}_{N}$得出原系统的解。 主振型矩阵： \\boldsymbol{M} \\ddot{\\boldsymbol{X}_p}(t)+\\boldsymbol{K} \\boldsymbol{X}_p(t)=\\boldsymbol{F}_{p}(t) \\\\ m_{p i} \\ddot{x}_{p i}(t)+k_{p i} x_{p i}(t)=F_{p i}(t), \\quad i=1 \\sim n \\quad \\\\ 模态广义力 \\quad\\boldsymbol{F}_{p}=\\boldsymbol{\\Phi}^{T} \\boldsymbol{F}_{0}=\\left[F_{p 1}, F_{p 2}, \\cdots, F_{p n}\\right]^{T}模态坐标初始条件: $ \\boldsymbol{X}_{p}(0)=\\boldsymbol{\\Phi}^{-1} \\boldsymbol{X}(0) \\quad \\dot{\\boldsymbol{X}}_{p}(0)=\\boldsymbol{\\Phi}^{-1} \\dot{\\boldsymbol{X}}(0) $ x_{P i}(t)=x_{P i}(0) \\cos \\omega_{i} t+\\frac{\\dot{x}_{P i}(0)}{\\omega_{i}} \\sin \\omega_{i} t+\\frac{1}{m_{p i} \\omega_{i}} \\int_{0}^{t} F_{P i}(\\tau) \\sin \\omega_{i}(t-\\tau) d \\tau在得到$ X_{p} $后, 利用 $\\boldsymbol{X}=\\boldsymbol{\\Phi} \\boldsymbol{X}_{p} $ 得出原系统的解。 例：四自由度系统，在第一个和第四个质量上作用有阶梯力F，零初始条件，求：系统响应。 解：由题可得动力方程为： {\\left[\\begin{array}{cccc}m & 0 & 0 & 0 \\\\ 0 & m & 0 & 0 \\\\ 0 & 0 & m & 0 \\\\ 0 & 0 & 0 & m\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t) \\\\ \\ddot{x}_{3}(t) \\\\ \\ddot{x}_{4}(t)\\end{array}\\right]+k\\left[\\begin{array}{cccc}1 & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 1\\end{array}\\right]\\left[\\begin{array}{c}x_{1}(t) \\\\ x_{2}(t) \\\\ x_{3}(t) \\\\ x_{4}(t)\\end{array}\\right]=\\left[\\begin{array}{l}F \\\\ 0 \\\\ 0 \\\\ F\\end{array}\\right]=F_{0}(t) } \\\\\\omega_{1}^{2}=0, \\quad \\omega_{2}^{2}=(2-\\sqrt{2}) \\frac{k}{m}, \\quad \\omega_{3}^{2}=\\frac{2 k}{m}, \\quad \\omega_{4}^{2}=(2+\\sqrt{2}) \\frac{k}{m} \\ddot{x}_{N i}(t)+\\omega_{i}^{2} x_{N i}(t)=F_{N i}(t), \\quad i=1 \\sim 4 \\\\ i=1: \\quad \\omega_{1}^{2}=0 \\quad \\Rightarrow \\quad \\ddot{x}_{N1}(t)=F_{Ni} \\quad \\Rightarrow \\quad x_{Ni}=\\frac 1 2F_{Ni}t^2 \\\\i \\neq 1: \\quad x_{N i}(t)=\\frac{1}{\\omega_{1}} \\int_{0}^{t} F_{N i} \\sin \\omega_{i}(t-\\tau) d \\tau=\\frac{F_{N i}}{\\omega_{i}^{2}}\\left(1-\\cos \\omega_{i} t\\right)\\\\矩阵形式: $\\quad \\boldsymbol{X}_{N}(t)=\\left[\\begin{array}{c}x_{N 1}(t) \\\\ x_{N 2}(t) \\\\ x_{N 3}(t) \\\\ x_{N 4}(t)\\end{array}\\right]=\\frac{F}{\\sqrt{m}}\\left[\\begin{array}{c}0.5 t^{2} \\\\ 0 \\\\ m\\left(1-\\cos \\omega_{3} t\\right) / 2 k \\\\ 0\\end{array}\\right]$ 原系统响应: \\boldsymbol{X}(t)= \\boldsymbol{\\Phi}_{N} \\boldsymbol{X}_{N}(t) =\\frac{F}{4 m}\\left[\\begin{array}{l}t^{2}+\\left(1-\\cos \\omega_{3} t\\right) m / k \\\\ t^{2}-\\left(1-\\cos \\omega_{3} t\\right) m / k \\\\ t^{2}-\\left(1-\\cos \\omega_{3} t\\right) m / k \\\\ t^{2}+\\left(1-\\cos \\omega_{3} t\\right) m / k\\end{array}\\right]","link":"/2022/03/14/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E5%A4%9A%E8%87%AA%E7%94%B1%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%97%E8%BF%AB%E6%8C%AF%E5%8A%A8/"},{"title":"第四章 多自由度系统振动 有阻尼的多自由度系统","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是多自由振动系统中有阻尼的多自由度系统的处理，主要介绍多自由度系统阻尼的求解以及一般粘性阻尼系统的响应。 多自由度系统的阻尼 实际机械系统中不可避免地存在着阻尼 材料的结构阻尼，介质的粘性阻尼等 阻尼力机理复杂，难以给出恰当的数学表达 在阻尼力较小时，或激励远离系统的固有频率时，可以忽略阻尼力的存在，近似地当作无阻尼系统 当激励的频率接近系统的固有频率，激励时间又不是很短暂的情况下，阻尼的影响是不能忽略的 一般情况下，可将各种类型的阻尼化作等效粘性阻尼 有阻尼的 n 自由度系统： \\boldsymbol{M} \\ddot{\\boldsymbol{X}}(t)+C \\dot{\\boldsymbol{X}}(t)+\\boldsymbol{K} \\boldsymbol{X}(t)=\\boldsymbol{F}(t) \\quad \\boldsymbol{X} \\in R^{n}其中，C为阻尼矩阵，元素 $c_{ij}$ ：阻尼影响系数 物理意义：使系统仅在第 j 个广义坐标上产生单位速度而相应于第 i 个坐标上所需施加的力。 阻尼力为广义速度的线性函数 : Q_{d i}(t)=-\\sum_{j=1}^{n} c_{i j} \\dot{x}_{j}(t)阻尼矩阵一般是正定或半正定的对称矩阵 阻尼矩阵的建模方法 这里C阵的建模方法是，先照抄K阵，之后将没有阻尼的地方的$c_i=0$即可，如上图所示，只有$c_1$存在因此保留，其余的全部为0. 虽然主质量矩阵与主刚度矩阵是对角阵，但阻尼矩阵一般非对角阵，因而主坐标Y下的强迫振动方程仍然存在耦合。 此时的C阵是不解耦的，因此模态叠加法就无法使用。 若 $C_p$ 非对角，则在无阻尼系统中介绍的主坐标方法或正则坐标方法都不再适用，振动分析将变得十分复杂。 对于实模态分析而言，非解耦的情况时无法分析的，但是可以用复模态分析的方法来处理。 为了能沿用无阻尼系统中的分析方法，工程中常采用下列近似处理方法 (1) 忽略$C_p$ 矩阵中全部的非对角线元素 其中$C_{Pi}$为第i阶主振型的阻尼矩阵，或第i阶振型的阻尼或模态阻尼 \\boldsymbol{C}_{P}=\\left[\\begin{array}{ccc}c_{p 1} & & \\\\ & \\ddots & \\\\ & & c_{p n}\\end{array}\\right] 但是当我们的阻尼很大，相比之下无法忽略。 其中，$\\xi_i$: 第i阶振型阻尼比或模态阻尼比 (2) 将矩阵 C 假设为比例阻尼 假设C由以下的形式：$C=aM+bK$ ，其中a、b为常数，C为物理空间的阻尼矩阵。 这边的a,b的确定需要进行实验，如航空航天的地面试验，通过测试不同的参数和最后的结果进行对比来验证。 代入 $C_{p}=\\boldsymbol{\\Phi}^{T} \\boldsymbol{C} \\boldsymbol{\\Phi}$ 中可得： \\boldsymbol{C}_{p}=\\boldsymbol{\\Phi}^{T}(a \\boldsymbol{M}+b \\boldsymbol{K}) \\boldsymbol{\\Phi}=a \\boldsymbol{M}_{p}+b \\boldsymbol{K}_{p} \\quad 对角阵相对阻尼系数: $\\quad \\xi_{i}=\\dfrac{c_{p i}}{2 \\omega_{i} m_{p i}}=\\dfrac{a m_{p i}+b k_{p i}}{2 \\omega_{i} m_{p i}}=\\dfrac{1}{2}\\left(\\dfrac{a}{\\omega_{i}}+b \\omega_{i}\\right)$ (3) 由实验测定n阶振型阻尼系数 $\\xi_i \\quad (i=1,2,…,n)$ 实验法在工程中使用的比较多。一般情况下低阶模态占了主要的成分，测量悬臂梁的模态时，一般对末端加一个激励得出振型为第一阶占了主要成分，对中间的结点给一个激励，得出的响应的第二阶为主要成分。 实验测量高阶很好测，但低阶得模态不易做。 一般粘性阻尼系统的响应当阻尼矩阵 C 不允许忽略非对角元素，并且阻尼无法简化为等效粘性阻尼（橡胶存在粘性滞回现象，无法进行等效处理），为以上近似方法不成立， 须用复模态进行求解。 2n 个特征值：$\\lambda_1,\\lambda_2,…,\\lambda_{2n},$ 这2n个特征根中，有复数也有实数 2n个特征向量：$\\phi^{(1)},\\phi^{(2)},…,\\phi^{(2n)}$ $\\phi^{(i)}\\in R^{n \\times 1}$ 因为特征方程的系数都是实的,所以特征值为复数时，必定以共轭形式成对出现。相应地，特征向量也是共轭成对的复向量复振型，这种现象为复模态或复振型。 这是一种具有相位关系的振型，不再具有原来主振型的意义。 之前的模态代表着一种振型的形状。 当特征值为具有负实部的复数时，每一对这样的共轭特征值对应系统中具有特定的频率和衰减系数的自由衰减振动。 这里通过补充一个方程，将原方程从一个二阶微分方程，转化为一个一阶状态方程。 讨论自由振动此时的状态方程为： \\hat{\\boldsymbol{M}} \\dot{\\boldsymbol{Y}}(t)+\\hat{\\boldsymbol{K}} \\boldsymbol{Y}(t)=\\mathbf{0} \\\\ \\text{初始条件为:} \\boldsymbol{X_0} ,\\boldsymbol{\\dot X_0} \\quad \\boldsymbol{Y}=\\left[\\begin{array}{l}\\dot{\\boldsymbol{X}} \\\\ \\boldsymbol{X}\\end{array}\\right] \\in R^{2 n} \\\\代入以下形式的解: $Y(t)=\\psi e^{\\lambda t}\\quad (\\psi\\in R^{2n \\times1})$ 特征值问题: $(\\hat{\\boldsymbol{K}}+\\lambda \\hat{\\boldsymbol{M}}) \\psi=0 $ 将方程转化成为状态方程之后，方程的维数和特征根的数目增加了一倍。 $2n$ 个特征向量: \\psi^{(1)}, \\psi^{(2)}, \\cdots, \\psi^{(2 n)} \\quad\\left(\\psi^{(i)} \\in R^{2 n \\times 1}\\right)\\\\ \\boldsymbol{\\Psi}=\\left[\\psi^{(1)}, \\psi^{(2)}, \\cdots, \\psi^{(2 n)}\\right] \\in R^{2 n \\times 2 n}求解出来的复模态具有正交性: \\boldsymbol{\\Psi}^{T} \\hat{\\boldsymbol{M}} \\boldsymbol{\\Psi}=\\hat{\\boldsymbol{M}}_{p} \\in R^{2 n \\times 2 n}=\\operatorname{diag}\\left(\\hat{m}_{p 1}, \\cdots, \\hat{m}_{p(2 n)}\\right) \\\\\\boldsymbol{\\Psi}^{T} \\hat{\\boldsymbol{K}} \\boldsymbol{\\Psi}=\\hat{\\boldsymbol{K}}_{p} \\in R^{2 n \\times 2 n}=\\operatorname{diag}\\left(\\hat{k}_{p 1}, \\cdots, \\hat{k}_{p(2 n)}\\right)复特征值列为对角阵(谱矩阵) : $ \\boldsymbol{\\Lambda}=\\operatorname{diag}\\left(\\lambda_{1}, \\cdots, \\lambda_{2 n}\\right) \\in R^{2 n \\times 2 n} $ 此时的动力学方程为： M \\ddot{X}(t)+\\boldsymbol{C} \\dot{\\boldsymbol{X}}(t)+\\boldsymbol{K} \\boldsymbol{X}(t)=\\boldsymbol{0} \\quad \\boldsymbol{X} \\in R^{n}代入得方程的特解: $\\boldsymbol{X}(t)=\\phi e^{\\lambda t} \\quad\\left(\\phi \\in R^{n \\times 1}\\right)$ 特征值问题： $\\left(M \\lambda^{2}+C \\lambda+\\boldsymbol{K}\\right) \\boldsymbol{\\varphi}=\\mathbf{0} $ $ \\psi$ 与 $\\phi$ 之间关系，即 $ \\Psi$ 与 $\\Phi$ 之间关系为： \\psi=\\left[\\begin{array}{c}\\lambda \\phi \\\\\\phi\\end{array}\\right] \\quad \\Psi=\\left[\\begin{array}{c}\\Phi\\Lambda \\\\\\Phi\\end{array}\\right]之后对Y进行变换 $Y=\\Psi Z$, 代入到原来的状态方程中可得： \\boldsymbol{\\Psi}^{T} \\hat{\\boldsymbol{M}} \\boldsymbol{\\Psi} \\dot{\\boldsymbol{Z}}(t)+\\boldsymbol{\\Psi}^{T} \\hat{\\boldsymbol{K}} \\boldsymbol{\\Psi} \\boldsymbol{Z}(t)=\\mathbf{0}\\\\ \\begin{array}{l}\\hat{m}_{p_{i}} \\dot{z}_{i}(t)+\\hat{k}_{p_{i}} z_{i}(t)=0, \\quad i=1 \\sim 2 n \\\\\\dot{z}_{i}(t)-\\lambda_{i} z_{i}(t)=0 \\quad z_{i}(t)=z_{i}(0) e^{\\lambda_{i} t}\\end{array}初始条件：$\\boldsymbol{Z}(0)=\\boldsymbol{\\Psi}^{-1} \\boldsymbol{Y}(0)$ 这里的c,阻尼矩阵的项被并入到 $\\hat{\\boldsymbol{M}}$ 中。 得$z_i(i=1,2,…,2n)$ 于是$Z、Y、X、\\dot X$ 就可以全部求出。 \\boldsymbol{\\psi}^{(i)^{T}} \\hat{\\boldsymbol{M}} \\boldsymbol{\\psi}^{(j)}=\\delta_{i j} \\hat{m}_{p i} \\quad \\boldsymbol{\\psi}^{(i)^{T}} \\hat{\\boldsymbol{K}} \\boldsymbol{\\psi}^{(j)}=\\delta_{i j} \\hat{k}_{p i} 对于$Z(0)$ 矩阵的来说，其第 i 个分量为： z_{i}(0)=\\frac{1}{\\hat{m}_{p i}} \\boldsymbol{\\Psi}^{T} \\hat{\\boldsymbol{M}} \\boldsymbol{Y}(0) =\\frac{1}{\\hat{m}_{p i}}\\left[\\begin{array}{ll}\\lambda_{i} \\phi_{i}^{T} & \\phi_{i}^{T}\\end{array}\\right]\\left[\\begin{array}{cc}\\boldsymbol{0} & \\boldsymbol{M} \\\\ \\boldsymbol{M} & \\boldsymbol{C}\\end{array}\\right]\\left[\\begin{array}{c}\\dot{\\boldsymbol{X}}_{0} \\\\ \\boldsymbol{X}_{0}\\end{array}\\right] \\\\ =\\frac{1}{\\hat{m}_{p i}} \\boldsymbol{\\phi}_{i}^{T}\\left(\\lambda_{i} \\boldsymbol{M} \\boldsymbol{X}_{0}+\\boldsymbol{M} \\dot{\\boldsymbol{X}}_{0}+\\boldsymbol{C} \\boldsymbol{X}_{0}\\right)求解完$z_i(0)$ 代入公式 $z_i(t)=z_i(0)e^{\\lambda_i t}$ 中来求解$z_i(t)$，进而得出$Z(t)$ ，将$Z(t)$ 代入到下列方程得： \\boldsymbol{Y}(t)=\\left[\\begin{array}{c}\\dot{\\boldsymbol{X}}(t) \\\\ \\boldsymbol{X}(t)\\end{array}\\right]=\\boldsymbol{\\Psi} \\boldsymbol{Z}(t)=\\left[\\begin{array}{c}\\boldsymbol{\\Phi} \\boldsymbol{\\Lambda} \\\\ \\boldsymbol{\\Phi}\\end{array}\\right] \\boldsymbol{Z}(t)\\\\ \\boldsymbol{X}(t)=\\boldsymbol{\\Phi} \\boldsymbol{Z}(t) \\quad \\dot{\\boldsymbol{X}}(t)=\\boldsymbol{\\Phi} \\boldsymbol{\\Lambda} \\boldsymbol{Z}(t)\\\\ \\boldsymbol{\\Lambda}=\\operatorname{diag}\\left(\\lambda_{1}, \\cdots, \\lambda_{2 n}\\right) \\in R^{2 n \\times 2 n} \\\\ \\boldsymbol{\\Phi}=\\left[\\boldsymbol{\\phi}^{(1)}, \\quad \\boldsymbol{\\phi}^{(2)}, \\cdots, \\quad \\boldsymbol{\\phi}^{(2 n)}\\right] \\in R^{n \\times 2 n} \\quad\\left(\\boldsymbol{\\phi}^{(i)} \\in R^{n \\times 1}\\right)最终解出$X(t)$的表达式为： \\boldsymbol{X}(t)=\\boldsymbol{\\Phi} \\boldsymbol{Z}(t)=\\sum_{i=1}^{2 n} \\boldsymbol{\\phi}_{i} z_{i}(t)=\\sum_{i=1}^{2 n} \\frac{e^{\\lambda_{i} t}}{\\hat{m}_{p i}} \\boldsymbol{\\phi}_{i} \\boldsymbol{\\phi}_{i}^{T}\\left(\\lambda_{i} \\boldsymbol{M} \\boldsymbol{X}_{0}+\\boldsymbol{M}_{0}\\dot{\\boldsymbol{X_0}}+{\\boldsymbol{C}}{\\boldsymbol{X}}_{0}\\right) 复模态不再具有主模态的意义，而是具有相位关系的振型，实部代表衰减率，虚部代表衰减系统的固有频率。 其模长才是真正的固有频率。 复模态分析的是一阶的状态方程，并且维度扩大了一倍。 典型例题 这里首先求出在正常情况下系统的固有频率和模态，注意这里解出的固有特征根和模态都是复数的形式，其真正的固有频率为特征根的模长。 之后，根据系统对初始状态下的响应可得，代入到刚才求出的表达式中。 \\boldsymbol{X}(t)=\\sum_{i=1}^{2 n} \\frac{e^{\\lambda_{i} t}}{\\hat{m}_{p i}} \\boldsymbol{\\phi}_{i} \\boldsymbol{\\phi}_{i}^{T}\\left(\\lambda_{i} \\boldsymbol{M} \\boldsymbol{X}_{0}+\\boldsymbol{M}_{0}\\dot{\\boldsymbol{X_0}}+{\\boldsymbol{C}}{\\boldsymbol{X}}_{0}\\right)\\\\ \\boldsymbol{X}(t)=\\sum_{i=1}^{4} \\frac{e^{\\lambda_{i} t}}{\\hat{m}_{p i}} \\boldsymbol{\\phi}_{i} \\boldsymbol{\\phi}_{i}^{T} \\boldsymbol{M} \\dot{\\boldsymbol{X}}_{0}=\\sum_{i=1}^{4} e^{\\lambda_{, t}} \\frac{\\left(\\boldsymbol{\\phi}_{i}^{T} \\boldsymbol{M} \\dot{\\boldsymbol{X}}_{0}\\right)}{\\hat{m}_{p i}} \\boldsymbol{\\phi}_{i} 2和4由共轭关系可以直接推导出： 虚部之间相互抵消可得最后的结果表达式。 使用忽略非对角项方法求解：","link":"/2022/03/15/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E6%9C%89%E9%98%BB%E5%B0%BC%E7%9A%84%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F/"},{"title":"第四章 多自由度系统振动 频率方程的零根和重根情形","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是多自由振动系统中频率方程的零根和重根的处理，主要介绍零根和重根的处理以及刚体模态的存在条件。 对于零根的情形K的逆不存在，此时模态矩阵的逆也是不存在的。对于重根的情形，其模态矩阵可能有两列是一致的。 本质都是对模态矩阵的存在性和模态矩阵的秩进行分析的，只要模态矩阵存在且满秩，就存在质量和刚度的正交性的转换，就可以用叠加法来求解。 频率方程零根的情形 \\omega=0 \\quad \\Rightarrow \\quad\\boldsymbol|{K}|=0 K 为奇异矩阵是零固有频率存在的充要条件，满足此条件时系统的刚度矩阵 K 是半正定的。 \\omega=0 \\quad \\Rightarrow \\quad\\boldsymbol{K}\\phi=0 当半正定系统按刚体振型运动时，不发生弹性变形，因此不产生弹性恢复力。 因此假定系统中,$\\omega_1=0$ 一般情况下只有一阶频率为0，因为一阶频率在其中是最小的，此时其对应的主坐标方程为： m_{p 1} \\ddot{x}_{p 1}(t)+k_{p 1} x_{p 1}(t)=0 \\Rightarrow \\ddot{x}_{p 1}(t)+\\omega_{1}^2 x_{p 1}(t)=0\\\\ \\Rightarrow \\ddot{x}_{p 1}(t)=0 \\Rightarrow {x}_{p 1}(t)=at+b其中，a,b是由初始条件决定的。 此时对应的模态矩阵$\\phi^{(1)}=[1 \\quad 1 \\quad 1]^T, $ 三个质量的运动是同步的，且没有相对的位移。 注意$\\omega=0$ 可以得到 $\\phi^{(1)}=[1 \\quad 1 \\quad 1]^T, $ 是不为0的，但是反之不一定成立。即根据频率可以判断模态的情况，但是无法根据模态判断频率。 表明此主振动为随时间匀速增大的刚体位移。 本节主要考虑的是在有零根和重根的条件下，如何来求解模态矩阵，使得其正交性存在。 系统的刚体自由度可以利用振型的正交性条件消除。 设 $\\phi^{(1)}$ 为与 $\\omega_1=0$ 对应的刚体位移振型，由于正交性条件 $\\boldsymbol{\\phi}^{(i) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(j)}=0(i \\neq j)$ 可得： \\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(i)}=0\\quad (i=2,3,...,n)其中$\\boldsymbol{\\phi}^{(j)}(i=2,3,…,n)$ 除刚体位移之外的其它振型。 ${x}_{p i}(t)(i=2,3,…,n)$ 为与 $\\boldsymbol{\\phi}^{(i)}(i=2,3,…,n)$ 所对应的主坐标 右乘${x}_{p i}(t)$ ：$\\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(i)}=0\\quad (i=2,3,…,n)$ 令$\\boldsymbol{X}=\\sum\\limits_{i=1}^{n} \\boldsymbol{\\phi}^{(i)} x_{p i} $系统消除刚体位移后的自由振动可得约束条件： \\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{X(t)}=0\\quad (i=2,3,...,n) 利用此约束条件可消去系统的一个自由度，得到不含刚体位移的缩减系统，缩减系统的刚度矩阵是非奇异的。 相当于站在$m_1$上看系统，单三者是刚体运动时从$m_1$上看就是那两个就是静止不动的。 例：四自由度系统，求系统响应。 方法一(根据实际情况分情况求解): 由系统可得动力方程为 : \\left[\\begin{array}{cccc}m & 0 & 0 & 0 \\\\ 0 & m & 0 & 0 \\\\ 0 & 0 & m & 0 \\\\ 0 & 0 & 0 & m\\end{array}\\right]\\left[\\begin{array}{c}\\ddot{x}_{1}(t) \\\\ \\ddot{x}_{2}(t) \\\\ \\ddot{x}_{3}(t) \\\\ \\ddot{x}_{4}(t)\\end{array}\\right]+k\\left[\\begin{array}{cccc}1 & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 1\\end{array}\\right]\\left[\\begin{array}{l}x_{1}(t) \\\\ x_{2}(t) \\\\ x_{3}(t) \\\\ x_{4}(t)\\end{array}\\right]=0固有频率为： \\omega_{1}^{2}=0 \\quad \\omega_{2}^{2}=(2-\\sqrt{2}) \\frac{k}{m} \\quad \\omega_{3}^{2}=2 \\frac{k}{m} \\quad \\omega_{4}^{2}=(2+\\sqrt{2}) \\frac{k}{m} 正则模态方程: \\ddot{\\boldsymbol{X}}_{N}(t)+\\boldsymbol{\\Lambda} \\boldsymbol{X}_{N}(t)=\\boldsymbol{0} \\quad \\boldsymbol{X}_{N}=\\left[\\begin{array}{llll}x_{N 1} & x_{N 2} & x_{N 3} & x_{N 4}\\end{array}\\right]^{T} \\\\ \\ddot{x}_{N i}(t)+\\omega_{i}^{2} x_{N i}(t)=0 \\quad(i=1 \\sim 4)将物理坐标初始化的条件带入到，模态坐标进行初始化: \\boldsymbol{X}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\boldsymbol{X}_{0}=\\left[\\begin{array}{llll}0 & 0 & 0 & 0\\end{array}\\right]^{T} \\\\ \\dot{\\boldsymbol{X}}_{N}(0)=\\boldsymbol{\\Phi}_{N}^{-1} \\dot{\\boldsymbol{X}}_{0}=\\sqrt{m} \\times v\\left[\\begin{array}{llll}1 & 0 & 1 & 0\\end{array}\\right]^{T} 物理空间响应: \\boldsymbol{X}(t)=\\boldsymbol{\\Phi}_{N} \\boldsymbol{X}_{N}(t)=\\frac{v}{2}\\left[\\begin{array}{c}t+\\frac{1}{\\omega_{3}} \\sin \\omega_{3} t \\\\t-\\frac{1}{\\omega_{3}} \\sin \\omega_{3} t \\\\t-\\frac{1}{\\omega_{3}} \\sin \\omega_{3} t \\\\t+\\frac{1}{\\omega_{3}} \\sin \\omega_{3} t\\end{array}\\right]方法二(以第一个为参考系减去一个自由度): 解出系统的固有频率为： \\omega_{2}^{2}=(2-\\sqrt{2}) \\frac{k}{m} \\quad \\omega_{3}^{2}=2 \\frac{k}{m} \\quad \\omega_{4}^{2}=(2+\\sqrt{2}) \\frac{k}{m} 两种方法的结果不同，因为法二是站在$m_1$ 上面看其他刚体的振动的，因此法二的结果中消除的刚体的振动。 此模型一样看成是刚体运动和简谐振动的叠加。 同样的方法可以来分析柔性机械臂的变形，先假设机械臂是刚性的，之后我们相对第一个刚体建立浮动基，其主要是相对于第一个刚性基变形的。 方法一的结果： 正两种方法对应的广义坐标和物理含义是不同的。 系统存在刚体模态的条件 系统存在刚体模态的条件： 某阶固有频率为零或刚度矩阵奇异 所对应的振型元素全相等 频率方程的重根情形 在前面引入振型矩阵（或模态矩阵）的概念时，曾假设所有的特征值都是特征方程的单根 复杂的系统中会出现某些特征根彼此很接近甚至相等的情况工程背景之一：柔性航天结构 例如：n自由度系统中 $\\omega_1=\\omega_2 \\quad \\Rightarrow \\quad \\phi^{(1)}=\\phi^{(2)}$ 刚度矩阵奇异。 假设 $\\omega_{1}$ 为 r 重根 $\\omega_{1}^{2}=\\omega_{2}^{2}=\\cdots=\\omega_{r}^{2} $ 其余 $\\omega_{r+1},…,\\omega_n$ 都是单根。 $\\omega^{2}=\\omega_{1}^{2}$ 带入到特征方程之中：$\\left(\\boldsymbol{K}-\\omega_{1}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0}$ 此时特征矩阵的秩为：$rank[\\boldsymbol{K}-\\omega_{1}^{2} \\boldsymbol{M}]=n-r$ 例如当 $\\omega_1^2$ 是单根时，$r=1$ , n 个方程中只有 n – 1 个是独立的为简单计，令$\\omega_1=\\omega_2$ ,$r=2$。 则计算 $\\omega_1$ 对应的振型时，$\\left(\\boldsymbol{K}-\\omega_{1}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0}$ 中有2个是不独立的方程 模态之间的正交性证明： 对$\\phi^{(1)}$ 满足：$ \\left(\\boldsymbol{K}-\\omega_{1}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0} \\Rightarrow \\boldsymbol{K}\\phi^{(1)}=\\omega_{1}^{2} \\boldsymbol{M}\\phi^{(1)}$ ,两边右乘 $\\phi^{(j)}$ 对$\\phi^{(j)} (j=3,4,…,n)$ 满足：$ \\left(\\boldsymbol{K}-\\omega_{j}^{2} \\boldsymbol{M}\\right) \\boldsymbol{\\phi}=\\boldsymbol{0} \\Rightarrow \\boldsymbol{K}\\phi^{(j)}=\\omega_{1}^{2} \\boldsymbol{M}\\phi^{(j)}$ ,两边左乘 $\\phi^{(1)^T}$ \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{K} \\boldsymbol{\\phi}^{(j)}=\\omega_{i}^{2} \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(j)} \\quad \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{K} \\boldsymbol{\\phi}^{(j)}=\\omega_{1}^{2} \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(j)} 整理可得： $(\\omega_{1}^{2}-\\omega_{j}^{2}) \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{M} \\boldsymbol{\\phi}^{(j)}=0$ 由于$\\omega_{1} \\ne \\omega_{j}$ 所以正交 此时，除了前两阶模态之外其余的模态的之间有正交的关系，下面来处理前两阶的模态关系。 这边的描述太过抽象，具体的理解参考下面的例题。 $ \\omega_{1}=\\omega_{2}\\left[\\begin{array}{l}\\phi_{n-1}^{(1)} \\\\ \\phi_{n}^{(1)}\\end{array}\\right]=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\quad\\left[\\begin{array}{l}\\phi_{n-1}^{(2)} \\\\ \\phi_{n}^{(2)}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right] \\quad \\boldsymbol{\\phi}_{i}^{(1)}, \\boldsymbol{\\phi}_{i}^{(2)} $ 为保证它们之间满足正交性条件令：$\\bar{\\phi}^{(2)}=\\phi^{(2)}+c\\phi^{(1)}$ ，则$\\bar{\\phi}^{(2)}$ 也为最后的结果。 为了保证正交性，要满足$\\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{K} \\boldsymbol{\\bar{\\phi}^{(2)}}=0 \\Rightarrow \\boldsymbol{\\phi}^{(1)^{T}} \\boldsymbol{K} (\\phi^{(2)}+c\\phi^{(1)})=0$ 解得： $ c=-\\dfrac{\\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(2)}}{\\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(1)}}=-\\dfrac{1}{m_{p 1}} \\boldsymbol{\\phi}^{(1) T} \\boldsymbol{M} \\boldsymbol{\\phi}^{(2)} $ 此时满足$\\bar{\\phi}^{(2)},\\phi^{(1)}$ 正交。 由于线性叠加原理，$\\bar{\\phi}^{(2)}$ 也是关于其他模态也是正交的。 例题 例：四自由度系统，求：系统振型矩阵。 首先，确定动力学方程以及固有频率。 划去后两个方程，将前两个方程写为： {\\left[\\begin{array}{ll}-1 & -1 \\\\ -1 & -2\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2}\\end{array}\\right]+\\left[\\begin{array}{cc}-1 & -1 \\\\ -1 & 0\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{3} \\\\ \\phi_{4}\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0\\end{array}\\right] } \\\\ {\\left[\\begin{array}{l}\\phi_{1} \\\\ \\phi_{2}\\end{array}\\right]=-\\left[\\begin{array}{ll}-1 & -1 \\\\ -1 & -2\\end{array}\\right]^{-1}\\left[\\begin{array}{cc}-1 & -1 \\\\ -1 & 0\\end{array}\\right]\\qquad \\left[\\begin{array}{l}\\phi_{3} \\\\ \\phi_{4}\\end{array}\\right]=\\left[\\begin{array}{cc}-1 & -2 \\\\ 0 & 1\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{3} \\\\ \\phi_{4}\\end{array}\\right] }\\\\ \\Rightarrow\\left[\\begin{array}{l}\\phi_{1}\\\\ \\phi_{2} \\\\ \\phi_{3} \\\\ \\phi_{4}\\end{array}\\right]=\\left[\\begin{array}{cc}-1 & -2 \\\\ 0 & 1\\\\ 1 &0 \\\\ 0 & 1\\end{array}\\right]\\left[\\begin{array}{l}\\phi_{3} \\\\ \\phi_{4}\\end{array}\\right]于是由于前两阶的模态没有重根，直接求解可得出前两阶的模态为：$\\phi_{1}=[1 \\quad 1 \\quad 1\\quad 1]^T$,$\\phi_{2}=[0 \\quad -1 \\quad 0 \\quad 1]^T$ 。 根据刚才的求解可得后两阶模态为：$\\phi_{3}=[-1 \\quad 0 \\quad 1\\quad 0]^T$,$\\phi_{2}=[-2 \\quad 1 \\quad 0 \\quad 1]^T$ 不是正交的，其对应的主振型为： 零根的情形：（1）零根只有一个；（2）对应的是存在刚体自由度； 重根的情形：（1）重根可以有很多个；（2）对应的是柔性航天器。","link":"/2022/03/14/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%A4%9A%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E9%A2%91%E7%8E%87%E6%96%B9%E7%A8%8B%E7%9A%84%E9%9B%B6%E6%A0%B9%E5%92%8C%E9%87%8D%E6%A0%B9%E6%83%85%E5%BD%A2/"},{"title":"AlexNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); 本文首先详解AlexNet网络，计算每一层网络的维度并且整理了花数据集。之后，通过Pytorch对网络进行复现，主要从模型搭建、设置GPU、数据预处理、加载数据、配置损失函数和优化器、模型保存、模型训练验证与测试等方面进行实现。 AlexNet的详解AlexNet是2012年ISLVRC 2012 (lmageNet Large Scale Visual RecognitionChallenge）竞赛的冠军网络，分类准确率由传统的70%+提升到80%+。它是由Hinton和他的学生Alex Krizhevsky设计的。也是在那年之后，深度学习开始迅速发展。 AlexNet网络简介ISLVRC 2012训练集:1,281,167张已标注图片；验证集:50,000张已标注图片；测试集:100,000张未标注图片。 AlexNet的结构图 该网络的亮点在于: 首次利用GPU进行网络加速训练。 使用了ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数。 因为Sigmoid函数会出现梯度消失，梯度爆炸。 使用了LRN局部响应归一化。 在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。 过拟合：根本原因是特征维度过多，模型假设过于复杂，参数过多，训练数据过少，噪声过多，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。过度的拟合了训练数据，而没有考虑到泛化能力。 使用Dropout的方式在网络正向传播过程中随机失活一部分神经元。 回顾：经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1网络分层计算 第一层（Conv1）： 这里是运用了GPU的并行计算的功能，将96层分成了两部分进行计算。 通道数：input_channels = 3；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 11; stride = 4; padding = [1,2] 输入输出的尺寸数：input_size=[224,224,3]; output_size=[55,55,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(224-11+(1+2))}{4}+1=55 第二层（Maxpool1）：只是改变高度宽度，不改变深度。 通道数：input_channels = 96；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[55,55,96]; output_size=[27,27,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(55-3+0)}{2}+1=27 第三层（Conv2）： 通道数：input_channels = 96；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 5; stride = 1; padding = 2 输入输出的尺寸数：input_size=[27,27,96]; output_size=[27,27,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-5+4)}{1}+1=27 第四层（Maxpool2）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[27,27,256]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-3+0)}{2}+1=13 第五层（Conv3）： 通道数：input_channels = 256；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 384；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第七层（Conv5）： 通道数：input_channels = 384；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,384]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第八层（Conv6）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[13,13,256]; output_size=[6,6,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+0)}{2}+1=6 后三层接了三个全连接层，注意最后数据集有1000类，因此最后一个全连接层有1000个节点，如果我们的数据集有10类，最后的全连接层就10个节点。 layer_name kernel_size output_channels padding stride Conv1 11 96 [1,2] 4 Maxpool1 3 None 0 2 Conv2 5 256 [2,2] 1 Maxpool2 3 None 0 2 Conv3 3 384 [1,1] 1 Conv4 3 384 [1,1] 1 Conv5 3 256 [1,1] 1 Maxpool3 3 None 0 2 FC1 2048 None None None FC2 2048 None None None FC3 1000 None None None 数据集(flowers) （1）在data_set文件夹下创建新文件夹”flower_data” （2）点击链接下载花分类数据集 （3）解压数据集到flower_data文件夹下 （4）执行”split_data.py”脚本自动将数据集划分成训练集train和验证集val 1234├── flower_data ├── flower_photos（解压的数据集文件夹，3670个样本） ├── train（生成的训练集，3306个样本） └── val（生成的验证集，364个样本） AlexNet网络的pytorch实现模型的搭建 对于网络层比较多的结构来说，一般用在网络比较多的时候，且网络结构比较简单，没有跳跃连接等复杂的结构。 padding=tuple/int：如果tuple(1,2),代表上下方各补一行0，左右补两列0。但是，如果出现上述的计算出来的下一层的[H,W]不为0时，自动舍弃一行或一列零来满足最后结果为整数。 1nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2) 如果要左侧补一列，右侧补两列，上侧补一行，右侧补两行。要使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True): 减小使用内存，提高性能的参数。 self.modules()：返回一个迭代器，遍历网络中所有的模块； 关于初始化，目前版本的pytorch其实是可以自动进行初始化的。初始化时，对于卷积层使用恺明初始化，对于一般的全连接层使用正态分布初始化，偏差全部初始化为0。 1234567891011121314def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) 对于展开成为全连接层来说，保证第0位batch不变, start_dim=1$[batch\\ , channel\\ , weight\\ , height] \\rightarrow [batch\\ , num]$ 1x = torch.flatten(x, start_dim=1) # 也可以用view 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weight=False): super(AlexNet, self).__init__() # 卷积层合集 self.feature = nn.Sequential( # input [3,224,224] nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2), # output [48,55,55] # 如果出现上述的计算出来的下一层的[H,W]不为0时， # 自动舍弃一行零来满足最后结果为整数 # 或者使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [48,27,27] nn.Conv2d(48, 128, kernel_size=5, padding=2), # output [128,27,27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,13,13] nn.Conv2d(128, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 128, kernel_size=3, padding=1), # output [128,13,13] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,6,6] ) # 全连接层合集 self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(128*6*6, 2048), nn.ReLU(inplace=True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), nn.ReLU(inplace=True), nn.Linear(2048, num_classes), ) if init_weight: self._initialize_weights() # 一般情况下时自动进行初始化的 def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) def forward(self, x): x = self.feature(x) x = torch.flatten(x, start_dim=1) # [batch channel weight height] start_dim=1 # 就是保证第0位batch不变-&gt;[batch num] # 也可以用view x = self.classifier(x) return x 设置GPU设备1device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 数据预处理12345678910111213data_transform = { &quot;train&quot;: transforms.Compose([ transforms.RandomResizedCrop(224), # 随机截取大小为224的图片 transforms.RandomHorizontalFlip(), # 随机翻转 transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]), &quot;val&quot;: transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])} 这里我们将预处理部分分成“train”和”val”两部分，将其封装称为一个字典。 transforms.RandomResizedCrop(224)：随机截取一定大小的图片。 transforms.RandomHorizontalFlip()：对图片数据进行随机反转。 transforms.ToTensor()：将数据转化为Tensor，维度按照torch要求的排列$[batch\\ , channel\\ , weight\\ , height]$。 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))：将图片数据标准化。 加载数据1234567891011# 获得绝对路径data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))# os.getcwd()获得当前位置的目录# ./.代表返回上一层目录 ../..代表返回上两层目录# 获得花的数据data_root = os.path.abspath(os.getcwd())image_path = data_root + &quot;/data_set/flower_data/&quot;train_dataset = datasets.ImageFolder(root=image_path + &quot;/train&quot;, transform=data_transform[&quot;train&quot;])# 求数据即得数据个数train_num = len(train_dataset) os.getcwd()：获得当前位置的目录。 ./.代表返回上一层目录； ../..代表返回上两层目录 os.path.join(os.getcwd(), “../..”)：代表返回上两层目录，其中join()的作用就是将内部路径进行合并，也可以进入当前目录的下的某个文件，join(os.getcwd(), “/xxx/xxx”) ImageFolder：用来以一定方式整理图片的类。 123456789# flower_list得到字典，但是得出的结果是反的flower_list = train_dataset.class_to_idx# 是的字典的val和key交换为位置的一种方法cla_dict = dict((val, key) for key, val in flower_list.items())# 将字典写入到Json文件中json_str = json.dumps(cla_dict, indent=4)with open('class_indices.json', 'w') as json_file: json_file.write(json_str) train_dataset.class_to_idx：得到类别和索引值的字典，此处预测得到的是索引值，想要得到花的名字就需要将key（名称）和value（索引值）交换位置。 json.dumps(cla_dict, indent=4)：将字典值写入到json文件中。 1234567{ &quot;0&quot;: &quot;daisy&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;} 数据的导入和加载123456789101112batch_size = 32train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)val_dataset = datasets.ImageFolder(root=image_path + &quot;val&quot;, transform=data_transform[&quot;val&quot;])val_num = len(val_dataset)val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0) 这边和上一章相同，此处不在赘述。 损失函数的计算与优化器配置12345678net = AlexNet(num_classes=5, init_weight=True)net.to(device) # 启动GPUloss_function = torch.nn.CrossEntropyLoss()optimizer = optim.Adam(net.parameters(), lr=0.0002)save_path = '.AlexNet.pth'best_acc = 0.0 # 设置保存最高准确率所对应的参数 模型的训练与验证 net.train(),net.eval()：主要的作用是用来管理Dropout层和BN层，在训练的过程启用上述层，但是在预测的时候还是正常计算，不进行随机失活和BN操作。 训练过程 t1 = time.perf_counter()：用来记录训练的时间。 用来打印进度条的程序。其中，end=’’空字符。 123456# 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 以下是训练过程的代码实现。 123456789101112131415161718192021222324for epoch in range(15): net.train() # 主要针对的Dropout方法 running_loss = 0.0 t1 = time.perf_counter() for step, data in enumerate(train_loader, start=0): images, labels = data images, labels = images.to(device), labels.to(device) # 将梯度初始化为0 optimizer.zero_grad() outputs = net(images) loss = loss_function(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() # 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 print() print(time.perf_counter()-t1) 验证过程1234567891011121314151617# 直接接在上一个for循环中net.eval()acc = 0.0with torch.no_grad(): for data_test in val_loader: test_images, test_labels = data_test test_images, test_labels = test_images.to(device), test_labels.to(device) outputs = net(test_images) predict_y = torch.max(outputs, dim=1)[1] print(predict_y == test_labels) acc += (predict_y == test_labels).sum().item() accurate_test = acc / val_num # 只保存最好的结果 if accurate_test &gt; best_acc: best_acc = accurate_test torch.save(net.state_dict(), save_path) print('[epoch %d] train_loss: %.3f test_accuracy: %3f' % (epoch + 1, running_loss/step, acc / val_num)) 模型测试导入数据1234567891011121314151617181920data_transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# load imageimg = Image.open(&quot;4.jpg&quot;)plt.imshow(img)# [N C H w]img = data_transform(img)# 增加一个维度img = torch.unsqueeze(img, dim=0)# 读取字典try: json_file = open('./class_indices.json', 'r') class_indict = json.load(json_file)except Exception as e: print(e) exit(-1) 导入模型12345678910111213141516# 建立模型model = AlexNet(num_classes=5)# load 权重model_weigh_path = &quot;.AlexNet.pth&quot;model.load_state_dict(torch.load(model_weigh_path))model.eval()with torch.no_grad(): # predict class output = torch.squeeze(model(img)) # 降低维度，将batch一维去掉 predict = torch.softmax(output, dim=0) predict_cla = torch.argmax(predict).numpy()print(class_indict[str(predict_cla)], predict[predict_cla].item())plt.show()","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/AlexNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"GoogLeNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); GoogLeNet详解简介GoogLeNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task (分类任务)第一名，本文主要从模型的搭建以及pytorch实现上进行介绍。 网络中的亮点： 引入了Inception结构（融合不同尺度的特征信息) 使用1x1的卷积核进行降维以及映射处理 添加两个辅助分类器帮助训练 AlexNet和VGG都只有一个输出层，GoogLeNet有三个输出层(其中两个辅助分类层) 丢弃全连接层，使用平均池化层（大大减少模型参数) Inception结构 如图为原始的一种Inception结构； 主要的区别是之前的VGG主要采取串联的结构，增加模型的深度， Inception主要采取并行的结构，增加的是模型的宽度。 注意：每个分支所得的特征矩阵的高和宽必须是相同的。 如图为改进之后的网络图，这里1$\\times$1的卷积核的主要作用是用来降维的。 这里降维就是将深度降低，即channels数，通过减少深度，进而减少参数量，减少计算量。 辅助分类器(Auxiliary Classifier)The exact structure of the extra network on the side, including the auxiliary classifier, is as follows: An average pooling layer with 5x5 filter size and stride 3, resulting in an 4x4×512 outputfor the (4a), and 4×4×528 for the (4d) stage. $input_{size}=14,\\ output_{size}=\\dfrac{14-5+0}{3}+1=4$ A 1×1 convolution with 128 filters for dimension reduction and rectified linear activation.· A fully connected layer（全连接层） with 1024 units and rectified linear activation（RELU). A dropout layer with 70% ratio of dropped outputs. A linear layer with softmax loss as the classifier (predicting the same 1000 classes as themain classifier, but removed at inference time). 在3$\\times$3卷积之前要进行一个1$\\times$1卷积的降维处理。 上图为下面表格中对于的结构在网络中的位置。 如图，在实际的操作过程中，LocalRespNorm(LPN)层的作用不大，因此可以去掉。 如图相比之下发现，VGG的参数参数过多，是GoogLeNet的20倍。 但VGG的模型搭建简单，并且GoogLeNet辅助分类器的使用和修改比较麻烦，不容易调试，因此一般来说VGG的使用较多。 GoogLeNet的pytorch实现模型搭建因为GoogLeNet的一些结构块的代码复用比较多，因此这里首先创建几个模板文件，以方便之后模型的搭建。 基本卷积块12345678910class BasicCon2vd(nn.Module): def __init__(self, in_channels, out_channels, **kwargs): super(BasicCon2vd, self).__init__() self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, **kwargs) self.relu = nn.ReLU(inplace=True) def forward(self, x): x = self.conv(x) x = self.relu(x) return x 由于卷积层都是伴随着ReLU激活函数来使用的，因此首先建立将二者合并的模板。 通过使用模板搭建的方式，使得网络得结构一目了然，很清晰。 Inception模板的搭建 1234567891011121314151617181920212223242526272829class Inception(nn.Module): def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj): super(Inception, self).__init__() self.branch1 = BasicCon2vd(in_channels, ch1x1, kernel_size=1) self.branch2 = nn.Sequential( BasicCon2vd(in_channels, ch3x3red, kernel_size=1), BasicCon2vd(ch3x3red, ch3x3, kernel_size=3, padding=1) # 将padding=1 使得branch的输入和输出是相同的 ) self.branch3 = nn.Sequential( BasicCon2vd(in_channels, ch5x5red, kernel_size=1), BasicCon2vd(ch5x5red, ch5x5, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) self.branch4 = nn.Sequential( nn.MaxPool2d(kernel_size=3, stride=1, padding=1), BasicCon2vd(in_channels, pool_proj, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) def forward(self, x): branch1 = self.branch1(x) branch2 = self.branch2(x) branch3 = self.branch3(x) branch4 = self.branch4(x) output = [branch1, branch2, branch3, branch4] return torch.cat(output, 1) # 在维度1上面进行叠加和整合, 即在channel上进行拼接 通过不同的padding参数，保证每个branch的输入和输出总是相同的。 最后，在维度dim=1上面进行叠加和整合, 即在channel上进行拼接。 辅助分类器的搭建123456789101112131415161718192021222324252627class InceptionAux(nn.Module): def __init__(self, in_channels, num_classes): super(InceptionAux, self).__init__() self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3) self.conv = BasicConv2d(in_channels, 128, kernel_size=1) # output[batch, 128, 4, 4] self.fc1 = nn.Linear(2048, 1024) self.fc2 = nn.Linear(1024, num_classes) def forward(self, x): # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 x = self.averagePool(x) # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4 x = self.conv(x) # N x 128 x 4 x 4 x = torch.flatten(x, 1) # [batch channel width height] 1 代表在1的维度下进行展平 x = F.dropout(x, 0.5, training=self.training) # self.training model.train()模式下为true 在model.eval()下为False # N x 2048 x = F.relu(self.fc1(x), inplace=True) x = F.dropout(x, 0.5, training=self.training) # N x 1024 x = self.fc2(x) # N x num_classes return x 开始时，在平均池化下采样和卷积之前，一个辅助分类器与第二个辅助分类器的深度是不同的。 dropout层的随机概率p=0.7，但是实际的效果不一定好，因此我们将调整为p=0.5。 当我们实例化个模型model后，可以通过model.train()和model.eval()来控制模型的状态。在model.train()模式下self.training=True，在model.eval()模式下self.training=False GoogLeNet搭建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class GoogLeNet(nn.Module): def __init__(self, num_classes=1000, aux_logits=True, init_weight = False): super(GoogLeNet, self).__init__() self.aux_logits = aux_logits self.conv1 = BasicCon2vd(3, 64, kernel_size=7, stride=7, padding=3) # 计算默认为下取整 该层的作用是将H,W缩小为原来的一半 self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True) # ceil_mode=True时 取整方式变为了上取整 self.conv2 = BasicCon2vd(64, 64, kernel_size=1) self.conv3 = BasicCon2vd(64, 192, kernel_size=3, padding=1) self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32) self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64) self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64) self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64) self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64) self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128) self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128) self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128) if self.aux_logits: self.aux1 = InceptionAux(512, num_classes) self.aux2 = InceptionAux(528, num_classes) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # (1, 1) 这里的(1, 1) &lt;=&gt; (width, Height) 无论输入是多少 输出都为1*1 self.dropout = nn.Dropout(p=0.4) self.fc = nn.Linear(1024, num_classes) if init_weight: self._initialize_weights() def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) def forward(self, x): # N x 3 x 224 x 224 x = self.conv1(x) # N x 64 x 112 x 112 x = self.maxpool1(x) # N x 64 x 56 x 56 x = self.conv2(x) # N x 64 x 56 x 56 x = self.conv3(x) # N x 192 x 56 x 56 x = self.maxpool2(x) # N x 192 x 28 x 28 x = self.inception3a(x) # N x 256 x 28 x 28 x = self.inception3b(x) # N x 480 x 28 x 28 x = self.maxpool3(x) # N x 480 x 14 x 14 x = self.inception4a(x) # N x 512 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux1 = self.aux1(x) x = self.inception4b(x) # N x 512 x 14 x 14 x = self.inception4c(x) # N x 512 x 14 x 14 x = self.inception4d(x) # N x 528 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux2 = self.aux2(x) x = self.inception4e(x) # N x 832 x 14 x 14 x = self.maxpool4(x) # N x 832 x 7 x 7 x = self.inception5a(x) # N x 832 x 7 x 7 x = self.inception5b(x) # N x 1024 x 7 x 7 x = self.avgpool(x) # N x 1024 x 1 x 1 x = torch.flatten(x, 1) # N x 1024 x = self.dropout(x) x = self.fc(x) # N x 1000 (num_classes) if self.training and self.aux_logits: # eval model lose this layer return x, aux2, aux1 return x self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)：ceil_mode=True时 取整方式变为了上取整。 nn.AdaptiveAvgPool2d((1, 1)) ：自适应的池化下采样操作，其中输入参数为一个元组，大小为目标输出的[H,w]值。 模型的训练但部分还是和之前的模型相似的，以下为不同的部分。 1234net = GoogLeNet(num_classes=5, aux_logits=True, init_weights=True) net.to(device) loss_function = nn.CrossEntropyLoss() optimizer = optim.Adam(net.parameters(), lr=0.0003) 首先是定义的模型为GoogLeNet与原来不同。 123456789101112131415for step, data in enumerate(train_bar): images, labels = data optimizer.zero_grad() logits, aux_logits2, aux_logits1 = net(images.to(device)) loss0 = loss_function(logits, labels.to(device)) loss1 = loss_function(aux_logits1, labels.to(device)) loss2 = loss_function(aux_logits2, labels.to(device)) loss = loss0 + loss1 * 0.3 + loss2 * 0.3 loss.backward() optimizer.step() # print statistics running_loss += loss.item() train_bar.desc = &quot;train epoch[{}/{}] loss:{:.3f}&quot;.format(epoch + 1, epochs, loss) 其次是治理的损失函数用三个，训练时分别辅助分类器进行计算，之后再将计算得到的辅助分类器的值进行加权处理。 在训练是，会去计算各种辅助分类器的输出，计算损失函数，之后在验证和测试过程中，就不会再去计算辅助分类器了。 模型测试1234567# create modelmodel = GoogLeNet(num_classes=5, aux_logits=False).to(device)# load model weightsweights_path = &quot;./googleNet.pth&quot;assert os.path.exists(weights_path), &quot;file: '{}' dose not exist.&quot;.format(weights_path)missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device), strict=False) 这里，我们在训练过程中是保存了辅助分类器的参数的，但是在测试时，没有定义辅助分类器，因此将strict=False，默认为True，此时model.load_state_dict() 会返回两个结果，unexpected_keys保留的是之前辅助分类器的层。 最好的结果达到了86%左右。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"ResNeXt网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); ResNeXt网络详解论文题目为Aggregated Residual Transformations for Deep Neural Networks，主要的创新点在于更新了block. 在宽度和深度上性能有了一定的提升。 ResNeXt网络在相同的计算量的情况下相比ResNet来说，错误率更小。 组卷积 本质上是将输入$C_{in}$划分为g个组，每个组$C_{in}/g$层，每个组通过卷积层之后将产生$n/g$层的一个卷积，再将g个组的卷积再拼接以下，就得出了n层的卷积网络。 极端情况$g=C_{in},n=C_{in}$，此时就是DW Conv. (c)首先$1 \\times 1$对进行降维处理，256-&gt;128；之后用组卷积group=32进行卷积，最后$1 \\times 1$进行升维，再和输入进行相加。 (b)先分组，分成32个组，每组channel=4，进行$1 \\times 1$卷积之后，再将每个组进行$3 \\times 3$的组卷积，归并之后其他跟(c)相同。 (a)前面和(b)相同，后面用一个相加来代替归+卷积操作。 理论上三者是等价的，(b)和(c)的等价比较显然，与(a)的等价不好理解。 相加的规则如下图所示，kernel=[1,2]卷积的运算结果如绿线所示。 分组卷积再相加的结果和直接卷积的结果相同。 利用组卷积代替他一般的卷积，得出ResNeXt网络的基本框架。下图的(32$\\times$4d)代表成32个组，每个组conv2_channel=4 如下图所示，作者通过实验来验证为什么要选分组数为32. 这里尽量保持计算量相同的情况下，通过改变不同的分组数和conv_channel，右图设计了几个不同的分组组合。 左面的图代表50和101层网络中，不同分组组合对应得错误率。 对于浅层得block来讲，效果没有很大的提升。 ResNeXt网络的pytorch实现网络的搭建基本和ResNet相同，基本是在ResNet上面的改进。 如右图所示，网络的框架的是相同的，改进主要发生在基本的block上面： 第二个卷积成换成了group=32的组卷积。 第一个卷积层的输入channel是原来ResNet的2倍。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Bottleneck(nn.Module): &quot;&quot;&quot; 注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2， 这么做的好处是能够在top1上提升大概0.5%的准确率。 可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch &quot;&quot;&quot; expansion = 4 def __init__(self, in_channel, out_channel, stride=1, downsample=None, groups=1, width_per_group=64): super(Bottleneck, self).__init__() width = int(out_channel * (width_per_group / 64.)) * groups self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width, kernel_size=1, stride=1, bias=False) # squeeze channels self.bn1 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups, kernel_size=3, stride=stride, bias=False, padding=1) self.bn2 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion, kernel_size=1, stride=1, bias=False) # unsqueeze channels self.bn3 = nn.BatchNorm2d(out_channel*self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) out += identity out = self.relu(out) return out width = int(out_channel \\ (width_per_group / 64.)) * groups*计算的是翻倍以后的ResNeXt网络的out_channel数，如图所示，ResNeXt网络的第一层out_channel=128是ResNet的2倍，根据计算公式 width=(64*(32/64))*32=128 out_channel代表的是残差块的out_channel数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class ResNet(nn.Module): def __init__(self, block, blocks_num, num_classes=1000, include_top=True, groups=1, width_per_group=64): super(ResNet, self).__init__() self.include_top = include_top self.in_channel = 64 self.groups = groups self.width_per_group = width_per_group self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(self.in_channel) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, blocks_num[0]) self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) if self.include_top: self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # output size = (1, 1) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') def _make_layer(self, block, channel, block_num, stride=1): downsample = None if stride != 1 or self.in_channel != channel * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channel * block.expansion)) layers = [] layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride, groups=self.groups, width_per_group=self.width_per_group)) self.in_channel = channel * block.expansion for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) if self.include_top: x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x 相比之前的ResNet增加了groups=1, width_per_group=64 参数，在_make_layer()函数以及初始化的部分都增加上述参数，其余不变。 123456789def resnext50_32x4d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth groups = 32 width_per_group = 4 return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group) 这里我们采用第三种方法，仅仅训练最后一层全连接层的权重。 param.requires_grad = False 这样将前面的参数视之为不可训练的，这样就可以仅仅之训练最后一层的参数了，因为最后一层是重新定义的。 12345678net.load_state_dict(torch.load(model_weight_path, map_location=device))for param in net.parameters(): param.requires_grad = False # change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 数据预测 数据的打包过程，这里的我们的首先将图片名称放到一个list中，之后使用batch_img = torch.stack(img_list, dim=0) 将list里面的图片打包成一个batch中。","link":"/2022/02/03/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ResNeXt%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"Pytorch入门教程及LeNet网络","text":"hljs.initHighlightingOnLoad(); 本篇为Pytorch入门教程，使用的网络为LeNet(1998)网络。主要从网络搭建、导入数据、定义损失函数与优化器、训练与验证模型、模型测试与保存方面进行展示。 建立LeNet网络模型123456789101112131415161718192021222324252627import torchimport torch.nn as nnimport torch.nn.functional as Fclass LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5) self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(32 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) # pytorch [batch, channel, height, width] def forward(self, x): #input(3,32,32) N=(32-5+0)/1+1=28 x = F.relu(self.conv1(x)) #output(16,28,28) N=28/2=14 x = self.pool1(x) #output(16,14,14) N=(14-5+0)/1+1=10 x = F.relu(self.conv2(x)) #output(32,10,10) N=10/2=5 x = self.pool2(x) #output(32,5,5) x = x.view(-1, 32*5*5) #output=32*5*5=800 x = F.relu(self.fc1(x)) #output=120 x = F.relu(self.fc2(x)) #output=84 out = F.relu((self.fc3(x)))#output=10 return out 经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1以下我们进行模型的测试和调试： 12345678910111213141516# 模型的测试import torchX = torch.rand(size=(32, 3, 32, 32), dtype=torch.float32)model = LeNet()print(model)# 打印的结果如下：LeNet( (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (fc1): Linear(in_features=800, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 导入数据 这里我们使用的CIFAR-10数据集，一共由10类。 首先，下载数据集。 torchvision.datasets.xxx() 里面有我们需要很多数据集。 123456# 下载训练数据trainset = torchvision.datasets.CIFAR10( root=&quot;./data&quot;, #数据集下载的位置 train=True, #是否为训练集 transform=transforms,#图像处理函数 download=True) #是否下载 图像的处理函数集 1234transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) Compose([ ])函数的作用是将所有的处理函数合并、打包。 ToTensor()函数的作用是将图片数据转换为张量，维度转化为pytorch标准的维度，同时数据的范围由原来的$[0,255]\\rightarrow[0.0,1.0]$。 Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))的作用是将图片的张量数据进行标准化。 之后，导入数据集。 123456# 导入训练数据trainloader = utils.data.DataLoader( trainset, # 总的训练数据集 batch_size=50, # 一个batch里的样本数 shuffle=True, # 是否打乱顺序 num_workers=0) # 线程数 由于一次训练不可能将训练集所有的参数都选进来进行反向传播，因此我们把一次喂入数据的个数称为batch_size。 数据的测试，使用迭代器获得数据集中的图片和标签。 1234567891011121314151617181920test_data_iter = iter(test_loader)# 迭代器，用来获取test_image, test_label = test_data_iter.next()# 用来获取下一个参数# 显示函数def imshow(img): img = img / 2 + 0.5 # unnormalize 反标准化 npimg = img.numpy() # 转化为numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # 由于ToTensor()改变了数据的维度排列，转化为原来的维度排列 plt.show()# # get some random training imagesdataiter = iter(trainloader)images, labels = dataiter.next()# show imagesimshow(torchvision.utils.make_grid(images))# print labelsprint(' '.join('%5s' % classes[labels[j]] for j in range(4))) 定义损失函数12# 定义损失函数为交叉熵损失函数loss_function = nn.CrossEntropyLoss() 如图，在CrossEntropyLoss()里面已经包含了交叉熵的计算公式，因此就不在需要在网络里定义softmax()层了。 定义优化器这里使用的Adam() 优化器。 1234# 定义优化器（训练参数，学习率）optimizer = optim.Adam(net.parameters(), lr=0.01)# 可变学习率scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1) 训练模型1234567891011121314151617181920212223242526272829303132for epoch in range(5): # 一个epoch即对整个训练集进行一次训练,这里对训练集循5轮 running_loss = 0.0 # 训练误差初始化为0 for step, train_data in enumerate(trainloader, start=0): inputs, labels = train_data inputs, labels = inputs.to(device), labels.to(device) # 清除历史梯度,每一轮训练都要 optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) # 正向传播 loss = loss_function(outputs, labels) # 计算损失 loss.backward() # 反向传播 optimizer.step() # 优化器更新参数 # 打印训练结果 running_loss += loss.item() accuray = 0 test_image, test_label = test_image.to(device), test_label.to(device) if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 enumerate(trainloader, start=0)：返回的是数据集和对应的步数。 关于optimizer.zero_grad() 进行梯度的清零。 12345678910# 传统的方法for i, (image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2. backward optimizer.zero_grad() # reset gradient loss.backward() optimizer.step() 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； optimizer.zero_grad() 清空过往梯度； loss.backward() 反向传播，计算当前梯度； optimizer.step() 根据梯度更新网络参数 1234567891011121314151617# 梯度累加方法for i,(image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2.1 loss regularization loss = loss / accumulation_steps # 2.2 back propagation loss.backward() # 3. update parameters of net if (i+1) % accumulation_steps == 0: # optimizer the net optimizer.step() # update parameters of net optimizer.zero_grad() # reset gradient 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； loss.backward() 反向传播，计算当前梯度； 多次循环步骤 1-2，不清空梯度，使梯度累加在已有梯度上； 梯度累加了一定次数后，先optimizer.step() 根据累计的梯度更新网络参数，然后optimizer.zero_grad() 清空过往梯度，为下一波梯度累加做准备； 总结来说：梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空，不断累加，累加一定次数后，根据累加的梯度更新网络参数，然后清空梯度，进行下一次循环。对于一些GPU内存不足的实验室，这是一个可以扩大batch_size的trick。 模型测试12345678910111213141516# 打印训练结果running_loss += loss.item()accuray = 0# 使用GPUtest_image, test_label = test_image.to(device), test_label.to(device)if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] # _,predit_y = torch.max(outputs, dim=1) # max()返回的是两个维度，首先的最大值，之后是index accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 with torch.no_grad():这里的with是一个上下文管理器，其中的作用是下面的代码都遵循torch.no_grad()。 其次，在预测过程中，不用进行梯度计算，用了反而内存不够，因此使用torch.no_grad()。 tensor.item()：用来获取tensor的数值。 保存模型12save_path = './LeNet.pth'torch.save(net.state_dict(), save_path) 模型测试 首先，对图片进行处理。 123456789101112# 数据预处理transform = transforms.Compose( [transforms.Resize((32, 32)), # 首先需resize成跟训练集图像一样的大小 transforms.ToTensor(), # 转换为torch的对的张量维度 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下im = Image.open('4.jpg')im = transform(im) # 转换成[C, H, W]im = torch.unsqueeze(im, dim=0) # 对数据增加一个新维度，# 因为tensor的维度是[batch, channel, height, width] torch.unsqueeze(im, dim=0)：对数据增加一个新维度，即加一个batch的维度。 之后，实例化网络 123# 实例化网络，加载训练好的模型参数net = LeNet()net.load_state_dict(torch.load('Lenet.pth')) 最后，预测类别 1234567# 预测classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')with torch.no_grad(): outputs = net(im) predict = torch.max(outputs, dim=1)[1].data.numpy()print(classes[int(predict)]) 这里，我们将outputs丢进torch.softmax() ，可得到属于每个类别的概率。 1234567predict = torch.softmax(outputs, dim=1)# dim=1的原因，是因为outputs为两维的，dim=0只有一个# outputs = tensor([[0.0000, 0.0000, 5.4191, 0.4988, 0.0000, 1.3599, 0.0000, 0.2233, 0.0000, 0.0000]])print(predict)# 输出:tensor([[0.0042, 0.0042, 0.9464, 0.0069, 0.0042, 0.0163, 0.0042, 0.0052, 0.0042, 0.0042]])","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Pytorch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8F%8ALeNet%E7%BD%91%E7%BB%9C/"},{"title":"ResNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); ResNet详解ResNet在2015年由微软实验室提出，斩获当年lmageNet竞赛中分类任务第一名，目标检测第一名。获得coco数据集中目标检测第一名，图像分割第一名。 网络中的亮点: 超深的网络结构(突破1000层) 提出residual模块 使用Batch Normalization加速训练(丢弃dropout) 随着网络的不断加深：梯度消失和梯度爆炸、退化问题。 通过残差结构可以很好的解决上述问题。 residual结构 如图，1x1的卷积层的主要作用是改变channel个数，即进行升维和降维； 注意，求和是时主分支和shoutcut的特征矩阵的形状[H,W]和深度channel必须相同。 左边这副图原本是以输入channel为64，3x3卷积层卷积核数也是64为例的，这里为了方便对比都改成了256。 表格中的乘积代表堆叠几层 下图所示，残差块的结构中残差有实线也有虚线。 实线连接和虚线连接的区别 其中的实线代表相加的二者形状和维度相同，即残差块的输入channel和输出的channel相同； 虚线表示残差块的输入channel和输出channel不同。因为虚线块首先要进行一个维度变化，导致input和shoutcut的维度不同，因此需要一个$kernel\\ size=1\\times1 \\, ,stride = 2$的卷积层来缩减矩阵形状，并且改变通道数来保证形状和维度相同。 一般在迭代的时候，将虚线层放在每次迭代的第一层来改变宽度和维度，第二层以后都为实线层，主要是用来将迭代，不改变任何参跨度和维度。 同理，另一个卷积的结构也适用。 注意原论文中，右侧虚线残差结构的主分支上，第一个1x1卷积层的步距是$stride=2$，第二个3x3卷积层步距是$stride=1$。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是$stride=1$，第二个3x3卷积层步距是$stride=2$，这样能够在ImageNet的top1上提升大概0.5%的准确率。详细可参考Resnet v1.5 综上，我们的残差块的主要的功能是降维缩减为原来的一半，之后将通道数变为原来的两倍。 Batch Normalization详解 Batch Normalization是google团队在2015年论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》提出的。通过该方法能够加速网络的收敛并提升准确率。 Batch Normalization 的目的是使得我们一批(Batch)的feature map满足均值为0，方差为1的规律。 Batch Normalization原理 我们在图像预处理过程中通常会对图像进行标准化处理，这样能够加速网络的收敛，如下图所示。 对于Conv1来说输入的就是满足某一分布的特征矩阵，但对于Conv2而言输入的feature map就不一定满足某一分布规律了（注意这里所说满足某一分布规律并不是指某一个feature map的数据要满足分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律）。 也就是说，卷积Conv1输入以前的满足归一化，输出后不一定还满足之前输入的归一化。同时数据的Normalization是针对feature map的每一个维度在整个训练集上的数据进行的。 Batch Normalization的目的就是使我们的feature map满足均值为0，方差为1的分布规律。 “对于一个拥有d维的输入x，我们将对它的每一个维度进行标准化处理。” 假设我们输入的x是RGB三通道的彩色图像，那么这里的d就是输入图像的channels即d=3，$x^{(1)}$代表的是图片R通道的特征矩阵，依次类推分别是G通道和B通道的。 x = (x^{(1)}, x^{(2)}, x^{(3)}) 标准化处理也就是分别对我们的R通道，G通道，B通道进行处理。上面的公式不用看，原文提供了更加详细的计算公式如下： 由于Normalization后归一化成[0,1]并非是最好的结果，因此这里选择了引入$\\gamma;\\beta$两个超参数一个是 让feature map满足某一分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律，也就是说要计算出整个训练集的feature map然后在进行标准化处理，对于一个大型的数据集明显是不可能的，所以论文中说的是Batch Normalization，也就是我们计算一个Batch数据的feature map然后在进行标准化（batch越大越接近整个数据集的分布，效果越好）。 使用BN时需要注意的问题（1）训练时要将traning参数设置为True，在验证时将trainning参数设置为False。在pytorch中可通过创建模型的model.train()和model.eval()方法控制。 （2）batch size尽可能设置大点，设置小后表现可能很糟糕，设置的越大求的均值和方差越接近整个训练集的均值和方差。 （3）建议将BN层放在卷积层（Conv）和激活层（例如Relu）之间，且卷积层不要使用偏置bias，因为没有用，参考下图推理，即使使用了偏置bias求出的结果也是一样的. 总结如下 迁移学习迁移学习的优势 能够快速训练出一个理想的结果。 当数据集较少时也能训练出理想的效果。传统情况下，网络越深，数据越少，越容易造成过拟合。 迁移学习可以将别人预训练好的模型拿来使用，大大的加速训练的过程。 注意：在使用别人的预训练模型参数时，要注意别人的预处理方式。自己的预处理的方式要与预训练模型的相同。 浅层网络的学习到的信息具有通用性，可以直接迁移到比较复杂的网络中使用，大大减小的训练的时间。 迁移学习的主要目的是，将预训练好的浅层网络的通用的识别信息迁移到我们的要训练的模型里去，使得新的网络也拥有识别底层通用特征得能力。 常见的迁移学习方式：1．载入权重后训练所有参数；2．载入权重后只训练最后几层参数；3．载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层(由于我们最后的一层输出的结点数和类别数可能不等于，因此最后加一层)。 一般情况下，第一种方法的效果是最好的，但相比第二和第三种方法，需要的运算资源较长、花费的时间也较长。 Resnet的pytorch实现模型搭建基本骨架的搭建18和34层结构上的主分支操残差结构的两层卷积网络是一模一样的，50、101、152层的残差结构中的三个卷积网络都不同。 这里现从基本的18层和34层的网络开始搭建。 1234567891011121314151617181920212223242526272829class BasicBlock(nn.Module): expansion = 1 # 通道数的变化，输出是输入的几倍 def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channel) self.relu = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channel) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out += identity out = self.relu(out) return out downsample的作用是区分结果是否为虚线上的的残差结构。 out_channel为主分支上的通道数。 bias=False使用BN层时，偏置是不需要的，设为False. expansion输出是输入的几倍的参数。 以下是50层、101层和152层网络的搭建： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Bottleneck(nn.Module): &quot;&quot;&quot; 注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2， 这么做的好处是能够在top1上提升大概0.5%的准确率。 可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch &quot;&quot;&quot; expansion = 4 def __init__(self, in_channel, out_channel, stride=1, downsample=None, groups=1, width_per_group=64): super(Bottleneck, self).__init__() width = int(out_channel * (width_per_group / 64.)) * groups self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width, kernel_size=1, stride=1, bias=False) # squeeze channels self.bn1 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups, kernel_size=3, stride=stride, bias=False, padding=1) self.bn2 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False) # unsqueeze channels self.bn3 = nn.BatchNorm2d(out_channel * self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) out += identity out = self.relu(out) return out ResNet基本框架1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class ResNet(nn.Module): def __init__(self, block, blocks_num, groups=1, num_classes=1000, include_top=True, width_per_group=64): super(ResNet, self).__init__() self.include_top = include_top self.in_channel = 64 self.groups = groups self.width_per_group = width_per_group self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(self.in_channel) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, blocks_num[0]) self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) if self.include_top: self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # output size = (1, 1) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') def _make_layer(self, block, channel, block_num, stride=1): downsample = None if stride != 1 or self.in_channel != channel * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channel * block.expansion)) layers = [] layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride, groups=self.groups, width_per_group=self.width_per_group)) self.in_channel = channel * block.expansion for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) if self.include_top: # include_top的主要的作用是对于需要在ResNet基础上做扩展的网络，则要将 # include_top设置为False x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x _make_layer(self, block, channel, block_num, stride=1): 输入为block(基本骨架)，channel(输入通道数)，block_num(基本骨架循环的层数) if stride != 1 or self.in_channel != channel $\\times$ block.expansion: 此处的判断逻辑是stride!=1(有H,W的改变)或者输入维度与输出维度不相等(不满足in_channel = channel $\\times$ block.expansion就代表不是第一层)，对于每一个残差结构的第一个来说，其改变的宽度和深度，因此要用考虑虚线连接。之后，几层为一般的实线的结构，不需要if分支设计虚线层。 设计堆叠的实线的残差层。第一层为实线，后几层都为实线。 12345for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) nn.Sequential(\\layers)* 返回值为非关键字参数。 第一个残差层不改变[H,W]，因此stride设计为1. 12345self.layer1 = self._make_layer(block, 64, blocks_num[0]) # 第一个残差层不改变[H,W]，因此stride设计为1 self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) 1234567891011121314151617181920212223242526272829303132333435def resnet34(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet34-333f7ec4.pth return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)def resnet50(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet50-19c8e357.pth return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)def resnet101(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)def resnext50_32x4d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth groups = 32 width_per_group = 4 return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group)def resnext101_32x8d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth groups = 32 width_per_group = 8 return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group) 定义不同类型的网络。 模型训练迁移学习1import torchvision.models.resnet ctrl+左键进入后可以直接看源码。可以下载预训练参数进行的前迁移学习，网址如下： 1234567891011model_urls = { 'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth', 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth', 'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth', 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth', 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth', 'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth', 'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth', 'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth', 'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',} 数据增强处理123456789data_transform = { &quot;train&quot;: transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), &quot;val&quot;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])} 载入预训练模型的方法12345678910111213net = resnet34()# load pretrain weights# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pthmodel_weight_path = &quot;./resnet34-pre.pth&quot;assert os.path.exists(model_weight_path), &quot;file {} does not exist.&quot;.format(model_weight_path)net.load_state_dict(torch.load(model_weight_path, map_location=device))# for param in net.parameters():# param.requires_grad = False# change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 首先，定义网络net = resnet34(); 之后，导入预训练的数据集 12model_weight_path = &quot;./resnet34-pre.pth&quot;net.load_state_dict(torch.load(model_weight_path, map_location=device)) 最后，改变模型最后一层结构。 1234# change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 也可以先载入到内存里面，之后将全连接层删去，将其载入到模型中去。 12torch.load(model_weight_path, map_location=device)# 载入到内存 其余的部分跟之前一样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import osimport jsonimport torchimport torch.nn as nnimport torch.optim as optimfrom torchvision import transforms, datasetsfrom tqdm import tqdmfrom model import resnet34def main(): device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(&quot;using {} device.&quot;.format(device)) data_transform = { &quot;train&quot;: transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), &quot;val&quot;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])} data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;)) # get data root path image_path = os.path.join(data_root, &quot;data_set&quot;, &quot;flower_data&quot;) # flower data set path assert os.path.exists(image_path), &quot;{} path does not exist.&quot;.format(image_path) train_dataset = datasets.ImageFolder(root=os.path.join(image_path, &quot;train&quot;), transform=data_transform[&quot;train&quot;]) train_num = len(train_dataset) # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4} flower_list = train_dataset.class_to_idx cla_dict = dict((val, key) for key, val in flower_list.items()) # write dict into json file json_str = json.dumps(cla_dict, indent=4) with open('class_indices.json', 'w') as json_file: json_file.write(json_str) batch_size = 16 nw = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 8]) # number of workers print('Using {} dataloader workers every process'.format(nw)) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=nw) validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, &quot;val&quot;), transform=data_transform[&quot;val&quot;]) val_num = len(validate_dataset) validate_loader = torch.utils.data.DataLoader(validate_dataset, batch_size=batch_size, shuffle=False, num_workers=nw) print(&quot;using {} images for training, {} images for validation.&quot;.format(train_num, val_num)) net = resnet34() # load pretrain weights # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth model_weight_path = &quot;./resnet34-pre.pth&quot; assert os.path.exists(model_weight_path), &quot;file {} does not exist.&quot;.format(model_weight_path) net.load_state_dict(torch.load(model_weight_path, map_location=device)) # for param in net.parameters(): # param.requires_grad = False # change fc layer structure in_channel = net.fc.in_features net.fc = nn.Linear(in_channel, 5) net.to(device) # define loss function loss_function = nn.CrossEntropyLoss() # construct an optimizer params = [p for p in net.parameters() if p.requires_grad] optimizer = optim.Adam(params, lr=0.0001) epochs = 3 best_acc = 0.0 save_path = './resNet34.pth' train_steps = len(train_loader) for epoch in range(epochs): # train net.train() running_loss = 0.0 train_bar = tqdm(train_loader) for step, data in enumerate(train_bar): images, labels = data optimizer.zero_grad() logits = net(images.to(device)) loss = loss_function(logits, labels.to(device)) loss.backward() optimizer.step() # print statistics running_loss += loss.item() train_bar.desc = &quot;train epoch[{}/{}] loss:{:.3f}&quot;.format(epoch + 1, epochs, loss) # validate net.eval() acc = 0.0 # accumulate accurate number / epoch with torch.no_grad(): val_bar = tqdm(validate_loader) for val_data in val_bar: val_images, val_labels = val_data outputs = net(val_images.to(device)) # loss = loss_function(outputs, test_labels) predict_y = torch.max(outputs, dim=1)[1] acc += torch.eq(predict_y, val_labels.to(device)).sum().item() val_bar.desc = &quot;valid epoch[{}/{}]&quot;.format(epoch + 1, epochs) val_accurate = acc / val_num print('[epoch %d] train_loss: %.3f val_accuracy: %.3f' % (epoch + 1, running_loss / train_steps, val_accurate)) if val_accurate &gt; best_acc: best_acc = val_accurate torch.save(net.state_dict(), save_path) print('Finished Training')if __name__ == '__main__': main() 视频参考","link":"/2022/02/03/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ResNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"VGG网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); VGG网络详解简述VGG在2014年由牛津大学著名研究组VGG (Visual GeometryGroup)提出，斩获该年ImageNet竞赛中Localization Task (定位任务)第一名和Classification Task (分类任务)第二名。本文从模型的搭建与pytorch的实现进行具体的介绍。 VGG网络的几种配置 一般使用的时候，多用D网络。 网络中的亮点: 通过堆叠多个3x3的卷积核来替代大尺度卷积核——(减少所需参数) 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核，代替后拥有相同的感受野。 CNN的感受野在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野(receptive field)。通俗的解释是，输出feature map上的一个单元对应输入层上的区域大小。 感受野的计算公式： F(i)=(F(i+1)-1)\\times Stride+K_{size} $F(i)$为第i层感受野，$Stride$为第i层的步距，$K_{size}$为卷积核或采样核尺寸。 Pool1：Size=2$\\times$2，Stride=2；Conv1：size=3$\\times$3，Stride=2 Feature map：$F=1$ Pool1：$F=(1-1)\\times2+2=2$ Conv1：$F=(2-1)\\times2+3=5$ 验证两个3$\\times$3的卷积核可以代替一个7$\\times$7(Stride=1): Feature map：$F=1$ Conv3$\\times$3(3)：$F=(1-1)\\times1+3=3$ Conv3$\\times$3(2)：$F=(3-1)\\times1+3=5$ Conv3$\\times$3(1)：$F=(5-1)\\times1+3=7$ 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核。使用7x7卷积核所需参数，与堆叠三个3x3卷积核所需参数(假设输入输出channel为C) $7\\times7\\times C \\times C = 49C^2$ $3\\times3\\times C \\times C+3\\times3\\times C \\times C+3\\times3\\times C \\times C=27C^2$ 卷积层的作用是用来提取特征，全连接层的作用的用来分类。 VGG的pytorch实现模型搭建123456cfgs = { 'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], 'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],} 配置VGG的模型list，里面的数字代表Conv层的channel数，“M”代表Maxpool层。 其中cfg为一个dict的数据，Key为不同VGG的类型，Value为list即不同的VGG网络的配置参数。 卷积层的实现12345678910111213def make_features(cfg: list): layers = [] in_channels = 3 for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) layers += [conv2d, nn.ReLU(True)] # 每个卷积函数跟ReLU激活函数都是绑定在一起的。 in_channels = v # 下一层的输入为本层的输出 return nn.Sequential(*layers) 该代码是用来读取配置文件的，由于输入为一张图片，因此输入的in_channels=3。 nn.Sequential(layers)*：实例化非关键字参数实现的。 全连接层的实现12345678910111213self.classifier = nn.Sequential( # 第一个全连接层 nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), # 第二个全连接层 nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), # 第三个全连接层 nn.Linear(2048, class_num) ) 全部的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738class VGG(nn.Module): def __init__(self, features, class_num=1000, init_weights=False): super(VGG, self).__init__() self.features = features self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), nn.Linear(2048, class_num) ) if init_weights: self._initialize_weights() def forward(self, x): # N x 3 x 224 x 224 x = self.features(x) # N x 512 x 7 x 7 # 展平操作，和之前相似 x = torch.flatten(x, start_dim=1) # N x 512*7*7 x = self.classifier(x) return x def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') nn.init.xavier_uniform_(m.weight) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) # nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 模型的实例化123456789def vgg(model_name=&quot;vgg16&quot;, **kwargs): try: cfg = cfgs[model_name] # 得出配置列表参数 except: print(&quot;Warning: model number {} not in cfgs dict!&quot;.format(model_name)) exit(-1) model = VGG(make_features(cfg), **kwargs) return model \\*kwargs*：代表可变字典长度的参数。 模型的训练训练的过程，基本和ALexNet相同。这里由于VGG网络的参数多，训练所需要的数据大，而现实过程中我们的参数不足，因此需要迁移学习的方法来解决比较好。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"论文写作指导","text":"hljs.initHighlightingOnLoad(); 本文为伍老师给博士的写作指导课，主要简述的是科研论文写作的注意事项、IEEE的相关规范以及Latex的使用技巧等。 论文撰写基本语法 标题和关键字 摘要 简介 相关工作 问题和方法 实验和分析 总结 参考文献 这里不一定要按照上述的顺序，但是该有的结构一定要有。这样便于信息的定位和内容的完备。 语义 要让读者读的舒服为目的。 建议： 必要让评委和审稿人去猜 临近相同的区域避免同一个词的重复出现 避免句子以“And”开头 避免过长的句子 避免使用过于生晦的词汇 具体内容部分 标题 标题要精炼、突出 让编委和评委快速了解论文的方向，吸引读者 摘要 主编会看的部分，评委和读者的入口 就是主编通过看摘要来判断论文的方向，进而选择合适的副编，之对于最后的能否录用很关键。 必须描述论文主要的创新和贡献，内容要有足够的吸引性 不要有公式，不要冗长，就是不要写多段。 简介 陈述问题的背景和意义 简述过去在这个方向都做了什么工作 指出之前工作的不足之处(要委婉一点，万一审稿人就是之前工作的作者)，也就是提交的Motivation和拟解决的主要问题 简介工作的主要创新点 简介要针对前述问题的创新方法，让人感觉可以解决前述问题 不要过长，更具体地信息要留在后面来写，简介主要突出关键点 方便编委快速确认论文的方向，针对性地挑选编委 吸引读者阅读论文 相关工作 注重对调研工作的质量 从评委和主编的角度来看，调研工作的质量决定了你的品味，进而影射了你工作的质量和水准。 其实就是文献综述的时候不要引用太差劲的期刊上的水文，要跟顶刊和顶会看齐。 相关工作也是对过去领域内相关工作的调研和整理 概述过去工作的主要贡献 突出过去工作的不足之处 凸显提交工作的”先进性“ 确保你的工作有效地针对了当前工作的不足之处，并由卓有成效的推进 确保你工作的能够打动评委，能够吸引期刊的读者 很像一个读书笔记，不像是一个相关工作 问题和方法 问题陈述 比摘要和简介中进一步的陈述 问题要让人容易理解，在可能的情况下，举例说明会更清晰 一般的计算机顶会会有一张图，来介绍本文的思路，现在的审稿人会直接先看有没有那张图。 创新方法 ”为什么why“比“怎么how”还重要 why-&gt;how-&gt;what 聚焦于“怎么”做的容易陷入技术报告，缺乏逻辑上的串联 聚焦于“为什么”，这样会吸引评委和读者思考（从而认同），并且能够自然的带出“怎么做的”。 对这个方法多讨论，避免现如技术报告 实验与分析 在论文实验部分，牢记“实验是对所提方案的验证”，有三个要素不可缺少。一是可重复性，要有公认的实验场景和配置；二是可解释性，图片清晰，避免出现图片“误用”；三是要可分析性，即佐证结论。 公认的实验场景和配置 可参考相关领域的定会顶刊所发表的实验设置 实验要针对所研究的问题和目标 相关工作的对比，要state-of-the-art (呼应:相关工作) 对于自己的数据集最好要公开数据和代码 实验图表现要专业、清晰 尽可能使用专业的绘图工具python、Matlab 清晰度、字体的大小适当 可学习相关领域顶会顶刊的图标 实验结果的分析 分析不是简单地陈述实验结果，重点是内 解释为什么提升了 消融性的分析，三个条件缺少了某个会造成什么样的后果 灵敏度分析，对超参数进行敏感性分析 多读论文 不仅仅凸显所提出方案的有优势，更能凸显为什么有优势（呼应：为什么比怎么做还重要） 左侧的图片可解释性不是很强，因为齐亨佐那个坐标的标题栏以及图片的比例都不是很好，有点空。 其次是没有图例，legend的标注。 对比清晰，可以不是和state of the art进行比较，至少要让读者感觉你对自己的方法有信心；用了专业的作图工具，且考虑了黑白打印的效果。 总结 像摘要，但是又不是摘要 总结向另一个更形象的词：takeaway 是读者在阅读完论文的一个回应 在进一步理解的基础上再次总结论文的主要贡献(拔高) 展望(可选)，在现有的工作的基础上，指出下一步工作的方向和重点 这里展望要有理有据，不是瞎说 其次不要过渡的否决自己的工作，防止被拒稿或者打回来修改 实事求是 展望，不是猜想，也要有理有据 避免变成对提交工作的否决 排版 尽量使用LaTeX进行排版 专业、漂亮、对公式友好 换投时，修改格式方便快捷 使用指定的论文模板 IEEE for IEEE Springer for Springer 否则，主编可以直接拒稿。 定理最后的方框代表是否证明结束，这里面证明结束的方框是没有对齐的。 审稿回复 逐条阅读并且理解审稿让人的意见 逐条撰写回应，一方面解释，另一方面直接陈述论文相应怎么改的 遇到审稿人的意见方向不对的要怎么办？ 先从自身找原因： 逻辑不清，审稿人没有找到？ 没有表述清楚，引发歧义？ 忽略了，引起误解？ 多方证实，确实是审稿人的意见不对，就礼貌地回应。 写回复地时候也是要委婉的说是自己写的不好引起了您的误解。 之前的部分为过敏意老师的内容，之后的为伍老师自己总结的内容。 其他注意事项单复数、时态 不可数名词：equirment、research、faculty、noise。 可数名词：(这里就是要注意以上名词的单复数) Datum $\\rightarrow$ data Statistic $\\rightarrow$ Statistics Criterion $\\rightarrow$ Criteria Analysis $\\rightarrow$ Analyses Spectrum $\\rightarrow$ Spectra 在欧洲一般表达都用被动语态，但是在美国可以接受被动语态，因此这方面大可放心。 就算只有一个作者，也要用We 而不是 I 实验部分一般用过去时态 介绍别人的方法，一般用现在时，而不是过去式 related work 上面表述别人的方法，要使用一般现在时态，而不是过去时态 其他的注意事项 首先还是不要过分夸大自己而贬低别人 图、表、伪代码等应出现在正文以后(要先图，然后再文中出现figx.)，居中对齐，不要跨页，标题不要分离。 图的清晰度要高，字体不要太大或太小 不要出现错别字(then &amp; than) 每一段话也比要太长，多用短句，每段话也不宜过长。 每条参考文献都要在正文中得到引用 每个符号都要定义，(让别人帮忙检查) 尽量不要缩写，伍老师的经验来看少于5次就不要用缩写了 论断不要太绝对：may、could 表示转折用whereas 而非 while 表示其他用 Additionally / In addition 而非 Besides Principal component analysis , 而不是Principle 一般用approach , 而非method(比较口语化和低端) If 后面的从句最好加 then(英语为母语的人比较习惯) ; although 后面一定不加but Compared with … ,而非 Comparing with; 区分compared with(实验方法最比较) 和 compared to(做时会用). It ‘s worth doing $Latex$ 中的左引号”是``(数字1旁边的那个点) 不是正常的” 冠词的使用，主要是根据实际的发音来定的 An hour , an 8-hour delay , an SVM(这里是因为S的发音) an FS , &lt;-&gt; a fuzzy set a Euclidean space :zap:Defend 的意思 Defend : 保护、保佑， e.g. ,God Defend New Zealand Defend against : 抵御、防御，e.g. ,defend againist adversarial attacks 句子不要以And 开头 句子要写完整，When the number of labeled instances is in few-shot TL setting ,i.e.,each category with instances less than 10 3个或以上的作者才用et al. A proposed … ; A and B proposed … ; A et al. proposed … 公式后的标点符号 公式之后的逗号是因为后面的是前面的补充，这一句还没说完。 其次公式之间的等号要对齐。 这里的公式有逗号是由于，(13)(14)是下一句的一部分，因此没有标点符号。 学术规范IEEE规定：投稿有时候我们感觉审稿的希望不大时，我们可以选择撤回稿件，在去投别的期刊，但是一定要得到确认文章被撤回的信息才能下一轮投稿。 有些期刊比较反感axiv，因此在投稿的时候要提前声明，防止其追究一稿多投的责任。 IEEE规定：参考和引用图片的规定，如果文章已经发表，那么文章的版权归出版社所有，就算要引用自己论文里的图片，也要和出版社打招呼，征求同意。 因此我们对于以前自己的图还是重新画一下吧。 IEEE规定：论文抄袭&gt;50%的判定及处罚决定 这里对抄袭的规定有两种： 其一，全文抄袭，这里包括直接使用了他人的文章里的句子没有引用。(比较严重) 其二，50% 可以是一篇全问抄袭了50%，或者是同一个作者连投两篇论文，一共50%. IEEE规定：论文抄袭&gt;50%的处罚决定 包括在IEEE公开的数据库里写道歉信； 情节严重者会5年内不许投稿IEEE，就是直接拒稿。 连续两次会被终身拒稿。 IEEE规定：论文抄袭20-50%的判定及处罚决定 基本的判定和上面一样。 处罚不同的是，3年之内禁止发论文； 也要写处罚决定； 其次就是再投的文章或者已接受但未发表的文章直接拒稿。 IEEE规定：论文抄袭&lt;20%的判定及处罚决定 基本的判定规则还是一样的，一篇&lt;20%或者是同作者的同时投的文章&lt;20%。 不用被禁投 但是要写处罚决定 IEEE规定：不正确引用情况1：整段整句的引用 直接抄要将文字变为斜体，并加上参考文献。 要是用自己的话来描述别人的思路，那直接给出参考文献即可。 如果被认为是抄袭，要要在数据库道歉，并给对方的作者和期刊的主编道歉 情况2：大篇幅的引用 相当于是剽窃思路这类的； 道歉并且在本期刊发表撤稿声明 IEEE规定：不引用已有的文献 这种问题主要是，有一个和自己很相关的工作，但是效果不如人家的好，又怕别嘲讽没有意义，所以故意不去引用。 初犯通常主编直接警告处理，多次出现要写检讨。 IEEE规定：一稿多投 给主编写道歉信，并公开。 经验技巧理工科写论文的技巧建议使用Latex ，美观、高效、格式切换方便 MikTex,https://miktex.org，后台引擎 WinEdt，https://www.winedt.com，前端编辑 JabRef，https://www.jabref.org，参考文献管理 Latex里的公式 这里伍老师推荐使用align环境来排版 不带编号的公式的排版可以使用align*或者是使用\\nonumber 这里的\\[ *** \\]的作用和align环境相同。 Latex里的图片 对于插图一般是使用的是\\usepackeage{graphic,subfigure} 尽量是使用最简单的命令，防止无法运行成功。 图片的格式最好使用.eps矢量图，因为矢量图放大后不会变糊，而位图会变糊。 [htbp] -option参数，代表有限放到当前的位置h，否则地方不不够，会放到下一列的最顶端t，其次放到整体页面的两列的下方b。 clip: 代表直接裁掉边缘的空白。 产生EPS图像 这里伍老师建议还是再ppt中画图比较好，进本可以满足我们的基本要求，下载Visio比较麻烦，别人想让编辑还要再下载一个Visio。 PPT图像转EPS: PPT中选中图像，右键另存为jpg或png，然后用wxbmpp https://lsourceforge.net/p/dktools/wiki/wxbmpp 转EPS Matlab中定制图像大小和缺省字体: 12figure('Position',[100 100 400 300]);set(gcf，'DefaulttextFontName'，'times new roman'，'DefaultaxesFontName','times new roman' , 'defaultaxesfontsize', 11); Matlab 中定制 legend列数和位置: 1H = legend(CSP-LDA’,'CSP-CLDA’, 'location', 'eastoutside' , 'numcolumns'，1);set(h, 'fontsize', 9, 'position', get(h,'position')+[0.13 0.1 0 0]); Matlab 中存彩色EPS图像: 12saveas(gcf, 'name.eps' , 'epsc2');# epsc2 中的c代表color，如果不写c会存成黑白图片 Latex中的表格 使用的是\\usepackage{multirow}包。 Latex中的伪代码 使用的是\\usepackage[linked, ruled]{algorithm2e}包 这个例子还是全的，包括了代码的注释、if-end，while-end，if-then. 很有代表性，仔细参考。 参考文献参考文献管理 LaTex的参考文献建议用JabRef来创建和管理bib文件 假定 bib文件名为drwubib.bib，需要的时候只要在文章结尾\\end {document}之前加入:\\bibliographystyle{IEEEtran} \\bibliography {drwubib}即可以自动处理参考文献 \\Bibliographystyle {IEEEtranS}是把文献按第一作者 last name(姓)音序排列，IEEEtran是按照参考文献在正文中出现的顺序排列。 要使所有 .tex 文件都能找到公用的 bib 文件，而不是手动在每个 .tex 文件目录里面copy一份 bib 文9件，可以把公用的bib 文件 copy到MikTex 的对应目录下，比如C:Program Files\\LaTex\\MiKTeX2.9\\bibtexlbibldrwubib 对于老版本的 WinEdt，在菜单选择Tex→MikTex → Options → General → Refresh FNDB, MikTex以后就可以自动找到bib文件 对于新版本的WinEdt，可能菜单里面没有上述选项，或者不可用。解决办法是在开始菜单里面搜索MikTex Console，Tasks 菜单里面有Refresh file name database 特殊的对于中文的参考文献 要在JabRef中使用中文参考文献，需要设置:Options →Preference → General → Default Encoding → UTF8Options → Preference → Appearance → Set table font → MicrosoftYaHei 否则中文可能是乱码Preference设置好之后可export保存，以后装新版本时直接import进去Preference文件是不同版本通用的 一般要求 一般参考文献之间使用的是 and 连接, 因为逗号有其特殊的含义。 { } 的作用是防止编译器将其自动变成小写。 参考文献格式期刊论文Article Volume(卷)、issue(期)、pages都不能少 IEEE Transactions on XXX一般简写为{IEEE}Trans. on XXX 注意Trans后面有个点，期刊名首字母大写 花括号里面的文字在输出时大小写不变，这样可防止编译后IEEE变成Ieee 文章标题中有特殊字符需要大写的话，也用花括号包起来 会议论文 inproceedings 会议月份、地点都不能少 有时候没有页码，就不输入 Proceedings的简写是Proc. International的简写是Int’l Conference的简写是 Conf. 注意后面的点，全议名首字母大写 在美国开的会议，要写出主办城市和州的缩写，NV内华达州 Latex文档的Track Change 安装latexdiff： https://ctan.org/pkg/latexdiff?lang=enlatexdiff —math-markup=0 old.tex new.tex &gt; diff.tex 如果检查数学公式有无变化出问题，可设置—math-markup=0,不检查公式更新 Latexdiff不是完美的，产生的tex文件里面可能有错误,无法编译，对数学命令和表格命令会出错 最常见是在表中，可用新文档中的表格源码直接覆盖diff.tex中对应的部分，即表格就不track change了 因为期刊审稿的过程中会要求提交新老版本之间的区别。这样操作比较的方便。 蓝色为新添加的内容，红色为修改删去的内容。 PDF字体嵌入 IEEE会议文章为什么要求字体embedded? 有些文章用了特殊的字体(德语韩语如果没有装可能无法显示)，读者计算机上面可能没有安装，导致文章无法正常显示。把字体embed 到文章中去，就相当于编译程序时把所有依赖的包都打包进去，这样没有安装该字体的读者也能正常阅读 IEEE会议文章为什么要求字体subset? 一个字体包括很多字母和符号，体积可能很大，而文章中用到的可能只有几个字符。Subset就是只打包这几个用到的字符，从而避免文章体积过大 （期刊文章后期会有对于的编辑帮我们处理，而会议论文没有人帮我们后期处理） IEEE期刊文章为什么不要求字体embedded subset? IEEE的期刊文章都会经过编辑部重新排版整理，他们会处理这些东西不需要作者考虑。会议文章是作者上传最终版，所以责任在作者 字体嵌入的方法 PPT内使用Latex: lguanaTexhttp://www.jonathanleroux.org/software/iguanatex 但是，这个仅仅是个插件，不可以将一整个命令都copy过来。 在生成的公式是以一个图的形式插入在ppt中，不管怎样放大都很清晰。 而且这个公式的很方便编辑，而且就算别人的电脑里没有这个插件也是可以正常显示的。 Matlab中使用LaTex 如上图所示，'interpreter','latex'表示解析latex的命令。 使用latex的字符会更加的美观。","link":"/2022/03/03/%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%8C%87%E5%AF%BC/"},{"title":"第0章绪论","text":"hljs.initHighlightingOnLoad(); 本章主要介绍控制理论的性质、发展、应用以及控制动态系统的几个基本步骤，为以后现代控制理论的学习做铺垫。 0.1 控制理论的性质控制理论的两个目标： 了解基本控制原理； 以数学表达它们，使它们最终能用以计算进入系统的输入，或用以设计自动控制系统。 两个主题：自动控制领域中有两个不同的但又相互联系的主题。 反馈的概念。 最优控制的概念。 0.2 控制理论的发展 20世纪20年代到40年代，马克斯威尔对装有调速器的蒸汽机系统动态特性的分析、马诺斯基对船舶驾驶控制的研究都是控制理论的开拓性工作。 20世纪40年代至50年代，维纳对控制理论作出了创造性的贡献。 20世纪50年代后期到60年代初期是控制理论发展的转折时期。 苏联学者在20世纪50年代对包含非线性特性、饱和作用和受到限制的控制等因素的系统的最优瞬态的研究表现出很大的兴趣。这些学者的研究讨论导致了庞特里亚金的“极大值原理”。 显示控制理论转折时期的另一个里程碑是20世纪50年代后期卡尔曼(卡尔曼——布西)滤波器的发现。 最近25年线性系统理论的研究非常活跃。 20世纪60年代后期和70年代早期，将线性二次型理论推广到无穷维系统(即以偏微分方程、泛函微分方程、积分微分方程和在巴拿赫空间的一般微分方程描述的系统)的工作得到很大进展。 目前研究的是以线性偏微分方程或相对简单的迟延方程描述的只能在空间的边界上加以观察和控制的系统。 20世纪70年代末80年代初，反馈控制的设计问题经历了一个重新修正的过程。随着人工智能的发展和引入了新的计算机结构，控制理和计算机科学的联系愈来愈密切。 0.3控制理论的应用控制系统之所以能得到如此普遍的应用，要归功于 现代仪表化(完备的传感器和执行机构) 便宜的电子硬件 控制理论有处理其模型和输出信号所具有的不确定性动态系统的能力 在控制理论中已完善的各种方法愈来愈得到普遍应用的同时，先进的理论概念的应用却仍集中在像空间工程那样的高技术方面。当然，由于计算机技术的飞速发展和世界性的激烈的工业竞争，这种情况将会改变。 控制概念得到主要应用的一个领域是石油化工生产过程。钢铁行业中热轧厂是最早成功地采用计算机控制的工厂。 0.4 控制一个动态系统的几个基本步骤简单地说，控制一个动态系统有下列四个基本步骤： 建模：为一个系统选择一个数学模型是控制工程中最重要的工作。 系统辨识： 定义为用在一个动态系统上观察到的输入与输出数据来确定它的模型的过程。 当前系统辨识方面的研究集中在下列诸基本问题上：辨识问题的可解性和问题提出的恰当性、对各类模型的参数估计方法。 信号处理：控制理论外面的独立的一门学科，但这两学科之问有许多重叠之处，而控制界曾对信号处理作出了重要贡献，特别是在滤波和平滑的领域。 控制的综合：为控制系统生成控制规律。这些过程的复杂性导致了各种控制研究课题，主要有：","link":"/2022/02/08/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E7%AC%AC0%E7%AB%A0%E7%BB%AA%E8%AE%BA/"},{"title":"Transformer原理及其PyTorch源码讲解（一）","text":"hljs.initHighlightingOnLoad(); 本文主要是初步的熟悉了一下Transformer机制，以及熟悉了一下Pytorch的官方代码，对于一些遗留的问题和mask、位置编码代码的书写将放到以后的文章里。 基本原理概述 首先来看CNN 权重共享：这个其实和滑动窗口有比较紧密的联系，通过权重共享可以实现平移不变性，就是说窗口无论从左到右还是从右到左，其结果是不变的，没有前后关联性。于是这种结构就便于并行计算的实现。 滑动窗口：主要以来的假设就是局部关联性建模，如果想要对全局进行建模就需要将我们的卷积层进行叠加，这样可以增加原来的感受野，进而实现对全局长程信息的把握。 基于刚才的局部建模假设，因此CNN有对相对的位置比较敏感，对于绝对的位置不是很敏感的特点。 之后看RNN 有序递归建模：其在本时刻的输出要依赖上一时刻的出入和本时刻的输入。 对顺序敏感：序列颠倒顺序后计算的结果不一样。 串行计算：根据其有序递归建模的性质可得，其运算的顺序是串行的，下一时刻的输入需要上一时刻的输出。 复杂度：单步的复杂度其实都是一样的，但是总体的复杂度是跟序列的长度成正相关的。 基于有序建模的特性可得，其对于相对位置和绝对位置都是敏感的，而且对于长程建模还是需要叠加网络。 最后就是transformer 无局部假设：这样就可以实现并行计算，但是其对于相对位置也不敏感因为其不是对局部进行的建模，其主要是看位置编码来实现对位置信息的感知。 没有有序假设：不会像RNN那样还要等待上一时刻的及结果才可以实现本步的计算。因此这样对于绝对位置也不是很敏感。这里对位置的感知基本要靠的位置编码。 任意字符都可以建模：小到两个字符，大到一篇文章都可以来建模，但是自注意力机制的缺点就是计算地复杂度是$O(n^2)$。 transformer基本原理 从总体是来看，分为左边的encoder和右边的decoder，encoder部分，其输入的是要输入的词语编码，decoder部分的输入为上一时刻的输出的字符，中间部分又加入encoder的输出。 对于encoder而言，其是由$N_x$个相同的层叠加而成的，(It is composed of a stack of $N_x$ identical layer) 。 同时每个block 上面又有两个小的模块，一个是mult-head self-attention mechanism的layer ，另一个是全连接MLP layer 。 这两个sublayer又配置了残差连接 residual connection，之后进行layerNorm。 对于decoder而言，也是其是由$N_x$个相同的层叠加而成的，(It is composed of a stack of $N_x$ identical layer) 。 但是，这里的mult-head self-attention mechanism是带有因果mask的，这样就可以保证保证输入i时刻的内容，不会看到i+1时刻的内容，保证因果和训练与预测的一致性。 之后将mask mult -head attention 的输出的query，而encoder将key 和 value 输入尽量计算attention 的值。 这3个sublayer又配置了残差连接 residual connection，之后进行layerNorm。 位置编码，由于attention机制对于全局和局部都是不敏感的，因此加入位置编码。 通过残差网络使得位置信息一直存在，不会梯度消失。 通过以下的结构来详解tranformer结构： input word embedding ：其实就是将一个高维的one-hot编码[0,1,0,0,…,0] 通过一个全连接层$Linear(len,num) \\quad num&lt;len$ 转成一个比较稠密的连续的向量，这样可以节约内存。 position encoding：主要的假设，由以下几点： 基于下面的假设，我们的位置编码通过sin/cos来表征： 每个位置确定，因为传统的[0,1]等距编码方式，如果输入一个单词，序列的长度不一样了，向量又要重新编码，于是又要无法保证位置不变性。(即两个不同长度的序列上第二个位置上的位置编码是相同的) 不同句子中的相对距离保持一致，就是无论句子的总长是多少，相对距离为3的两词的位移编码差总是相同的。 位置编码可以推广到更差的句子。 pe(pos+k)可以写成pe(pos)的线性组合，就是如果测试几何中的句子更长，我们依然可以将其位置编码写成短句子位置编码的线性组合。 $ pe(pos+k)=\\alpha_1pe(pos)+\\alpha_2pe(pos) $ 满足上述性质的最好的就是三角函数了，这要可以实现将测试中的句子进行推广。 通过残差连接实现位置信息可以流入更深层的网络。 multi-head self-attention：多头的自注意力机制有较强的建模能力和表征空间； 而且其有多组Query,Key,Value，进而实现每组都计算一个attention，之后拼接成为一个向量。 就得到的attention向量输入到FFN(全连接网络)中得到最后的结果。 同时如果原来向量是512维的，输入有8个head，每个head就有64维，保证整体的运算量同步。 feed-forward network：只是考虑对每个单独的位置进行建模 不同位置上的参数是共享的。 类似于1*1的卷积，其实和单一的线性层；在图像上是考虑单一的pixel，但是在NLP中是只考虑单独的一个单词。 但是1*1卷积的作用不仅仅如此，在图像领域其作用是图像的通道融合，但是在语言上是将Embedding的维度进行压缩和融合。 这里decoder大部分都和encoder是相似的，因此不在赘述。 decoder这边其实是一个自回归的预测。 代码讲解以下讲解的主要是官方的源码链接如下：Transform源码 调用的实例： 1234&gt;&gt;&gt; transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)&gt;&gt;&gt; src = torch.rand((10, 32, 512))&gt;&gt;&gt; tgt = torch.rand((20, 32, 512))&gt;&gt;&gt; out = transformer_model(src, tgt) Transformer大类初始化函数 上述是初始化部分，这里有几个重要的参数： d_model：默认为512，其实表示的是输入的特征的维度。 nhead：默认为8，表示的是multi-head 中head数。 num_encoder_layers：默认为6，代表在encoder中的$N_x=6$ ，即layer的重复block次数。 num_decoder_layers：默认为6，代表在decoder中的$N_x=6$ ，即layer的重复block次数。 dim_feedforward：默认为2048，即在编码的时候，先映射到一个大的映射空间，然后再映射回来。 相关layer的实例化： 12345encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, **factory_kwargs)encoder_norm = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm) 这里的建模思路是将两部分TransformerEncoderLayer和LayerNorm分别建好然后分别整合到一个大类TransformerEncoder中，这里应该是LayerNorm层是通篇公用的。 前向传播函数 123memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask) mask=src_mask：代表样本的长度，对于短的样本，可以将后面的无效样本置为$-\\infty$ ，于是softmax预测值为0了。 输入的大样本其实是一些个句子，但是这些句子长短不一，所以我们进行要给一个mask参数，使其知道这个样本的长度。 tgt：目标句子，依次喂入一句话。 memory ：就是encoder的输出，将其输出到后面的交叉注意力机制中。 tgt_mask=tgt_mask：自回归的解码过程，每次预测后面一个，因此这个mask其实是一个上三角的矩阵。 output embedding的输入为tgt，但是我们不可将其全部不可见，否则成抄答案的了，预测出来的下一位个output里的下一位进行对比，不断学习。 input embedding 的输入为用来预测的句子。 memory_mask=memory_mask：其实就是当前这句换的长度。 TransformerEncoderLayer子类初始化函数 d_model：即模型的维度；nhead：同上是head数；dim_feedforward：是第一个全连接层的层数。 第二个全连接层的全连接层的输入和输出是相等的，因为有残差连接。 自定义的层 前向传播函数 参数只有：src和src_mask 之前经过了，这里不在赘述。 1234567x = srcif self.norm_first: x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask) x = x + self._ff_block(self.norm2(x)) else: x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask)) x = self.norm2(x + self._ff_block(x)) TransformerEncoder子类 主要是定义了一下，中间有多少堆叠的层。 比如这里_get_clones()的定义如下： 12def _get_clones(module, N): return ModuleList([copy.deepcopy(module) for i in range(N)]) 就是返回一个网络内层结构的深度拷贝。 src：为原句子的编码； mask：原句子长度构成的矩阵。 TransformerDecoderLayer子类 d_model：在整个的模型中一直都是512，代表的是模型的维度。 nhead：decoder中的head数。 dim_feedforward：代表的是第一个FFN的输入维度。 首先，出现两个multi-head self-attention ，第一个是mask 的，第二个是交叉的。 之后，出现两个线性层，第一个是将target 映射到更高维的空间上，然后第二个层就是将其映射回d_model维。 前向传播函数，第一层不加残差，之后的第二层和要加上残差并且按照图中的顺序进行计算。 以下，两个multi-head 的具体实现，两者除了输入其他的部分都是相同的。 TransformerDecoder子类 multi-head attention的原理 attention的计算的结果就是权重之和，其中Key和Query的相似度为每个key对于value的一个权重。 Attention(Q,K,V)=softmax(\\frac {QK^T}{\\sqrt {d_k}})V 首先，Q和K进行矩阵的内积； 之后，除以$\\sqrt {d_k}$ 进行缩放； 然后，乘以掩码mask矩阵，去掉一些未知部分； 最后，softmax归一化，并且和value向量做内积。 1234567891011def attention(query, key, value, mask=None, dropout=None): &quot;Compute 'Scaled Dot Product Attention'&quot; d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) \\ / math.sqrt(d_k) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) p_attn = F.softmax(scores, dim = -1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attn scores = scores.masked_fill(mask == 0, -1e9)将没有的字符的值赋值为$-\\infty$ .这样softmax之后就是0了。 位置编码 PE_{(pos,2i)}=sin(pos/1000^{2i/d_{model}})\\\\ PE_{(pos,2i)}=cos(pos/1000^{2i/d_{model}})在接下来的直播中up主准备进行手写位置编码部分、word embedding和mask的代码。 Q&amp;A如何提高模型的泛化能力，以一个是使用知识蒸馏，另一个是使用集成学习。 由于decoder是自回归的解码，主要是进行自回归的生成，用的不是很多；CV主要是对encoder的部分进行改造的。","link":"/2022/03/21/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/Transformer%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6PyTorch%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"图神经网络的通俗理解-GNN基本结构","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的GNN的基本网络实现，以及一些网络更新和学习的机理。 博客的参考网址：A Gentle Introduction to Graph Neural Networks (distill.pub)：https://distill.pub/2021/gnn-intro/ 视频的参考地址：https://www.bilibili.com/video/BV1iT4y1d7zP/?spm_id_from=333.788.recommend_more_video.0 既然图的描述是排列不变的矩阵格式，我们将使用图神经网络(GNN)来描述以解决图预测任务。GNN是对图的所有属性(节点、边、全局上下文)的一种可优化的转换，它保持了图的对称性(排列不变性)。 我们将使用Gilmer等人提出的消息传递神经网络框架来构建GNN，使用Battaglia等人介绍的图网架构示意图。 GNN采用一种“图入图出”的体系结构，这意味着这些模型类型接受一个图作为输入，将信息加载到它的节点、边和全局上下文中，并逐步转换这些嵌入，而不改变输入图的连接性。 相当于学习的过程优化的是边和顶点的权重，不会对连通性造成改变。 The simplest GNN使用上面构建的图的数字表示(使用向量而不是标量)，我们现在可以构建GNN了。我们将从最简单的GNN架构开始，在这个架构中，我们学习所有图属性(节点、边、全局)的新嵌入，但我们还没有使用图的连接性。 为简单起见，前面的图使用标量来表示图的属性;在实践中，特征向量或嵌入更有用。 该GNN使用一个独立的多层感知器(MLP)(或喜欢的模型) 作用在图的每个组件上；我们称之为GNN层。对于每个节点向量，我们应用MLP并得到一个学习后的节点向量。我们对每条边做同样的操作，学习每条边的嵌入，对全局向量也做同样的操作，学习整个图的单个嵌入。 你也可以叫它GNN块。因为它包含多个操作/层(像ResNet块)。 与神经网络模块或层一样，我们可以将这些GNN层堆叠在一起。 由于GNN不更新输入图的连通性，我们可以用与输入图相同的邻接表和相同数量的特征向量来描述GNN的输出图。但是，输出图更新了嵌入，因为GNN更新了每个节点、边和全局内容的表示向量。 GNN Predictions by Pooling Information我们已经构建了一个简单的GNN，但是我们如何在上面描述的任何任务中进行预测呢? 我们将考虑二元分类的情况，但这个框架可以很容易地扩展到多类或回归的情况。如果任务是对节点进行二分类预测，而图中已经包含了节点信息，那么这种方法很简单——对于每个节点的嵌入编码向量，应用一个线性分类器。这里的$C_{v_{i,n}}$ 代表一个分类网络，所有的节点共享一个分类网络。 然而，事情并不总是那么简单。例如，您可能在图中有存储在边中的信息，但在节点中没有信息，但仍然需要对节点进行预测。我们需要一种方法从边收集信息，并将它们交给节点进行预测。我们可以通过合并来实现。集中收益分两个步骤： 对于要汇集的每个项，将它们的每个嵌入集合起来，并将它们连接到一个矩阵中。 然后，通常通过求和操作对收集到的嵌入向量进行聚合。 我们用字母ρ表示汇集操作，并表示我们正在收集从边到节点的信息$p_{En→Vn}$。 如图所示，将和节点向量的边向量和全局内容的向量相加来。 因此，如果我们只有边的特征，并试图预测二进制节点信息，我们可以使用汇集操作，将信息汇集到它需要去的地方。 如果我们只有节点的特征，并试图预测二分类的边的信息，那么模型看起来是这样的。其实就是将一条边连接着的顶点的向量直接相加即可。 如果我们只有节点级别的特性，并且需要预测二分类的全局属性，那么我们需要将所有可用的节点信息汇聚在一起，并对它们进行聚合。这类似于CNN中的全局平均池层。对于边也可以这样做。 在我们的例子中，分类模型c可以很容易地用任何可微分模型替换，或者使用广义线性模型适应多类分类。 现在，我们已经演示了我们可以构建一个简单的GNN模型，并通过在图的不同部分之间信息传递来进行二分类预测。这种信息汇聚技术将作为构建更复杂的GNN模型的基础。如果我们有新的图形属性，我们只需要定义如何将信息从一个属性传递到另一个属性。 就目前的情况而言，在GNN blocks层中并没有考虑图的连接信息 请注意，在这个最简单的GNN公式中，我们根本没有在GNN层中使用图的连通性。每个节点、每条边以及全局上下文都是独立处理的。我们只在将信息用于预测时使用连接。 Passing messages between parts of the graph通过在GNN层中使用汇集操作，我们可以做出更复杂的预测，以使我们学到图的连接性的信息。我们可以使用消息传递来实现这一点，其中相邻节点或边交换信息并相互影响。 消息传递工作分为三个步骤： 对于图中的每个节点，收集所有的相邻节点嵌入向量的信息，即上面描述的g函数。 通过聚合函数(如sum)，汇聚所有消息。 所有汇集的消息都通过一个更新函数传递，通常是一个学习过的神经网络。 还可以1)收集消息，3)更新消息，2)聚合消息，并且仍然具有置换不变操作 正如汇聚操作可以应用于节点或边一样，消息传递机制也可以发生在节点或边之间。 这些步骤是利用图的连接性的关键。我们将在GNN层中构建更复杂的消息传递变体，从而产生具有更高表现力和功能的GNN模型。 总之就是将节点的编码向量+与其有连接节点的编码向量-&gt;激活函数-&gt;下一层节点 如果应用一次，这个操作序列就是消息传递GNN层的最简单类型。 这让人想起了标准卷积：从本质上讲，消息传递和卷积都是聚合和处理元素邻居信息以更新元素值的操作。在图形中，每个元素就是一个节点，而在图像中，每个元素是一个像素。然而，图中相邻节点的数量可以是可变的，不像在图像中，每个像素都有一组相邻元素。 而且，卷积操作相当于其和一帮相邻的元素之间进行加权和操作，但是图网络的操作其实实际上时权重都为1的加权和。 通过将传递GNN层的消息叠加在一起，一个节点最终可以整合来自整个图的信息：经过三层后，一个节点就拥有了距离它三步远的节点的信息。 只要多迭代几层，一个节点就可能整合所有图的信息。 我们可以更新我们的架构图来包含这个新的节点信息源： Learning edge representations 上面主要讲的是点和点，边和边信息的汇聚问题，下面主要讲解的是点的信息如何向边汇聚以及边的信息如何向顶点汇聚。 我们的数据集并不总是包含所有类型的信息(节点、边缘和全局上下文)。当我们想要对节点进行预测，但我们的数据集只有边的信息时，我们在上面展示了如何使用汇聚操作来将边的信息汇聚到节点上，但这步操作只在模型的最终预测进行。我们可以使用消息传递在GNN层的节点和边之间共享信息。 类似之前吸收相邻节点的信息，我们将使用同样的方法来处理邻边的信息，首先将边缘信息合并到一起，用一个更新函数对其进行转换，然后存储它。 然而，存储在图中的节点和边的信息不一定是相同的大小或形状，因此，如何将它们组合起来还不是立即就清楚的。其实可以如果维度不一样可以进行编码和投影操作来使得二者统一。一种方法是学习从边空间到节点空间的线性映射，反之亦然。或者，可以在更新函数之前将它们连接在一起。 如图所示就是将先将信息聚合，然后更新并存储在节点上，之后将节点上面的信息再次聚合回到节点上面。 在构造GNN时，我们更新哪些图属性以及更新它们的顺序是需要进行一个设计决策。我们可以选择是否在边的编码信息之前更新节点编码，或者反之。 这是一个具有多种解决方案的开放研究领域——例如，我们可以以“编织”的方式进行更新。其中，我们有四种更新后的表示形式，它们组合成新的节点和边表示形式：节点到节点(线性)、边到边(线性)、节点到边(边层)、边到节点(节点层)。 有实验证实，node-&gt;edge-&gt;node 和 edge-&gt;node-&gt;edge 两种方式去更新节点得到的结果是不同的，因此可以两种方式交叉进行的方法来更新。 Adding global representations下面介绍全局信息是如何交换并且为何定义整个全局的信息。 到目前为止，我们所描述的网络存在一个缺陷：图中彼此相距较远的节点可能永远无法有效地相互传递信息，即使我们应用了多次消息传递。对于一个节点，如果我们有k层，信息将在最多k步的距离传播。在预测任务依赖于距离很远的节点或节点组的情况下，这可能是个问题。在预测任务依赖于距离很远的节点或节点组的情况下，这可能是个问题。 一种解决方案是让所有节点都能够互相传递信息。不幸的是，对于大的图来说，这很快就会增加计算成本 (尽管这种被称为“虚边”的方法已经被用于小的图，如分子)。 本来是没有边提供连接的，但是虚拟的设了一个边。 解决这个问题的另一种方法是使用图(U)的全局表示，它有时被称为主节点或上下文向量。这个全局上下文向量连接到网络中所有其他的节点和边，作为它们之间传递信息的桥梁，建立了整个图的表示。这将创建一个更丰富、更复杂的图形表示，而不是通过其他方法来学习。 可以看作是跟resnet类似，本来是要过好几个节点，全局主节点像是直接来了个跳跃连接。 这个主节点照常参与信息的汇集。 在这个视图中，所有的图形所有属性(node,edge,global context) 都学习到对应的向量，所以我们可以在汇集的过程中利用它们，方法是将我们感兴趣的属性的信息与其他属性的信息相比较。 例如，对于一个节点，我们可以考虑来自相邻节点、连通边和全局主节点的信息。此外，我们还可以通过线性映射将它们映射到相同的空间上，并添加应用特征层或者是直接将其进行相加操作，这可以被认为是一种特征型注意机制。 这里其实就是将所有相关的消息都拿过来使用，于是就形成了一个类似于自注意力机制的东西。 词汇积累 embeddings 嵌入向量 leverage n.影响力 v.充分利用 elaborate adj. 复杂的，详尽的；精心制作的 reminiscent adj. 和…相似的 essence n.本质，要素 propagate v. 散播,宣传(观点,信仰等); 传播(运动,光线,声音等) concatenate v. 连接 adj. 连接的 imbue v. 灌入，浸入 myriad adj. 大量的，无数的","link":"/2022/03/30/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3-GNN%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/"},{"title":"图神经网络的通俗理解-图的基本知识","text":"hljs.initHighlightingOnLoad(); 神经网络在处理问题是会使用到图结构。本篇文章文章我们尝试去探索一些图结构的组成，及其背后所隐含的道理。本文主要介绍图的一些基本知识以及实际的应用案例。 博客的参考网址：A Gentle Introduction to Graph Neural Networks (distill.pub)：https://distill.pub/2021/gnn-intro/ 视频的参考地址：https://www.bilibili.com/video/BV1iT4y1d7zP/?spm_id_from=333.788.recommend_more_video.0 原网页为一个交互的图，如图所示，该节点的值时由上一层的该节点及其邻居结点的加权值构成的。 斜体字，非正文的内容。 我们周围到处都是图表；现实世界的对象通常是根据它们与其他事物的联系来定义的。一组对象，以及它们之间的联系，自然地用图形表示出来。研究人员已经开发出基于图形数据的神经网络(称为图形神经网络，或GNN)超过10年了。最近的发展提高了它们的能力和表达能力。我们开始看到它在抗菌药物发现[3]、物理模拟[4]、假新闻检测[5]、流量预测[6]和推荐系统[7]等领域的实际应用。 也就是说，GNN现在猜刚刚有简单的落地实例，之前基本上是科学的研究，并没有很多的应用。 这篇博客主要解释和探索现代的图网络结构。我们把这项工作分成四个部分。 首先，我们看看什么样的数据可以自然地用图表表达，以及一些常见的例子。 其次，我们将探讨是什么使图不同于其他类型的数据，以及在使用图时必须做出的一些特殊选择。 第三，我们构建一个现代GNN，从该领域的历史建模创新开始，遍历模型的每个部分。我们逐步从一个最基本的实现过渡到最先进的GNN模型。 第四，也是最后，我们提供了一个GNN playground，在这里您可以使用一个实字任务和数据集来构建一个更强的直觉，了解GNN模型的每个组件如何对其所做的预测做出贡献。 什么是图图表示实体(节点)集合之间的关系(边)。 V：代表整个结点所含的信息； E：代表边与边之间的所含的信息； U：代表全局的图及其所含的信息。 为了进一步描述每个节点、边或整个图，我们可以在图的每个部分中存储信息。 这里，结点使用的是一个长度为6的向量来表示，而边使用的是一个长度为8的向量，全局信息使用的是长度为五的向量。 图一般有两种，无向图如好友关系一般是双向的，但是关注于被关注的关系是一个有向图。 图是非常灵活的数据结构，如果现在看起来很抽象，我们将在下一节中通过示例使其具体化。 您可能已经熟悉了某些类型的图表数据，比如社交网络。然而，图形是一种非常强大的通用数据表示，我们将展示两种类型的数据，您可能认为它们无法建模为图形：图像和文本。尽管有悖直觉，但通过将图像和文本视为图形，可以了解更多关于它们的对称性和结构的信息，并建立一种直觉，有助于理解其他不太像网格的图形数据，我们将在后面讨论。 图来表示图像我们通常认为图像是带有图像通道的矩形网格，用数组表示它们(例如，244x244x3浮点数)。另一种将图像看作具有规则结构的图，其中每个像素代表一个节点，并通过一条边与相邻像素连接。每个无边界像素正好有8个邻居，每个节点上存储的信息是表示像素RGB值的三维向量。 可视化图的连接性的一种方法是通过它的邻接矩阵。我们对节点进行排序，在本例中，在一个简单的5x5笑脸图像中每个节点为25个像素，如果两个节点共享一条边，则用一个条目填充一个由$n_{nodes} \\times n_{nodes}$组成的矩阵。请注意，下面这三种表示都是同一段数据的不同视图。 其实就是一个邻接矩阵，来表示其连接与否。 图来表示文本我们可以将索引关联到每个字符、单词或标记，并将文本表示为这些索引的序列，从而对文本进行数字化。这创建了一个简单的有向图，其中每个字符或索引都是一个节点，并通过一条边连接到它后面的节点。 这种表示(字符标记序列)指的是文本通常在RNN中表示的方式；其他模型，如transformer，可以将文本视为一个完全连接的图，我们可以从中了解标记之间的关系。详细的而可以参考下面博客 Graph Attention Networks. 当然，在实践中，文本和图像通常不是这样编码的:这些图表示是多余的，因为所有的图像和文本都有非常规则的结构。例如，图像在其邻接矩阵中有一个带状结构，因为所有节点(像素)都连接在一个网格中。文本的邻接矩阵只是一条对角线，因为每个单词只与前一个单词连接，并与下一个单词连接。 图来表示分子结构图是描述您可能已经熟悉的数据的有用工具。让我们来看看结构更加异构的数据。在这些示例中，每个节点的邻居数量是可变的(与图像和文本的固定邻居大小相反)。除了图表，我们很难用其他任何方式来表达这些数据。 分子图形。分子是物质的基石，是由三维空间中的原子和电子构成的。所有的粒子都在相互作用，但当一对原子彼此之间保持稳定的距离时，我们说它们共享一个共价键。不同的原子和键对有不同的距离(如单键、双键)。这是一个非常方便和常见的抽象来描述这个三维对象作为一个图形，其中节点是原子，边是共价键。这是两种常见的分子及其相关的图形。 图来表示人物关系社交网络就是图表。社交网络是研究人们、机构和组织的集体行为模式的工具。我们可以通过将个体建模为节点，将他们的关系建模为边，来构建一个表示人群的图。 图表示其他网络结构引文网络是图表。科学家在发表论文时经常引用其他科学家的研究成果。我们可以将这些引用网络形象化为一个图，其中每一篇论文都是一个节点，每一条有向边都是一篇论文和另一篇论文之间的引用。此外，我们可以在每个节点中添加关于每篇论文的信息，例如摘要的单词嵌入。 注意：引用的关系图是一个有向图。 其他的例子。在计算机视觉中，我们有时希望在视觉场景中标记对象。然后，我们可以通过将这些对象视为节点，将它们的关系视为边来构建图。机器学习模型、编程代码和数学方程也可以表示为图形，其中变量是节点，边是将这些变量作为输入和输出的操作。您可能会在这些上下文中看到术语“数据流图”。 真实世界的图的结构在不同类型的数据之间可能有很大的差异，一些图有许多节点，但它们之间的连接很少，反之亦然。图数据集在节点、边的数量和节点的连接性方面可能有很大的差异(在给定的数据集内和数据集之间)。 什么样的问题可以使用图结构我们已经描述了一些图形的示例，但是我们希望对这些数据执行什么任务呢？在图上有三种一般类型的预测任务：图级、节点级和边缘级。 在图级任务中，我们预测整个图的单个属性。对于节点级任务，我们预测图中每个节点的一些属性。对于边级任务，我们希望预测图中边的属性或存在。 对于上面描述的三个级别的预测问题(图级、节点级和边级)，我们将说明以下所有问题都可以通过单个模型类GNN来解决。但首先，让我们更详细地浏览一下这三类图预测问题，并提供每种问题的具体示例。 Graph-level task在图级任务中，我们的目标是预测整个图的属性。例如，对于一个用图表表示的分子，我们可能想要预测这个分子的气味，或者它是否会与一种与疾病有关的受体结合。 比如有些任务是检测药物分子里是否存在环结构，如下图所示，但是检测环结构其实并不一定要GNN，一般的图搜索算法其实就可以。 这类似于MNIST和CIFAR的图像分类问题，在这些问题中，我们希望将一个标签关联到整个图像。对于文本，一个类似的问题是情绪分析，我们想要一次性确定整个句子的情绪或情绪。 对于监督学习中的分类问题，建立label和Image之间的关系，其实就是一个简单的问题图级别的问题。 Node-level task节点级任务与预测图中每个节点的标识或角色有关。 这边我个人感觉可能跟目标检测和语义分割一样，主要是用来理解图片是每一个单元的label，就比如目标检测中，理解车、障碍、行人以及背景。 节点级预测问题的一个经典例子是Zach的空手道俱乐部。该数据集是一个单一的社交网络图，由在政治分歧后宣誓效忠于两个空手道俱乐部之一的个人组成。 随着故事的发展，Mr. Hi(教练)和John H(管理员)之间的世仇在空手道俱乐部造成了分裂。节点代表每个空手道练习者，边缘代表空手道之外这些成员之间的互动。 预测的问题是区分一个给定的成员在不和之后是忠于Mr. Hi还是John H。在这种情况下，节点到讲师或管理员之间的距离与此标签高度相关。 Edge-level task图的剩余预测问题是边缘预测。 边缘水平推理的一个例子是图像场景理解。除了识别图像中的物体，深度学习模型还可以用来预测它们之间的关系。我们可以将其描述为边级分类：给定代表图像中对象的节点，我们希望预测这些节点中哪些节点共享一条边，或者那条边的值是多少。 如果我们想要发现实体之间的连接，我们可以认为图是完全连通的，并根据它们的预测值剪枝边来得到一个稀疏图。 这边其实就是语义分割之后的结果进行理解，将每个节点之间的关系进行理解，比如观众和台上面人的关系是Watching，其余人背景的关系是standing 等。 神经网络用在图上面的挑战那么，我们如何用神经网络来解决这些不同的图形任务呢？第一步是考虑如何表示与神经网络兼容的图结构。 机器学习模型通常采用矩形或网格状阵列作为输入。因此，如何用一种与深度学习兼容的格式来表示它们并不是一种直观的方法。图有多达四种类型的信息，我们可能希望使用它们来进行预测：节点、边、全局上下文和连接性。 前三个是相对简单的：例如，通过节点我们可以形成一个节点特征矩阵N，每个节点(node)索引为 i变为一个特征$node_i \\in N$存储到矩阵中 ，其实就是每个节点代表矩阵的一个维度。尽管这些矩阵的所包含的特征的数量是变化的(这里我理解的是维度是变化的)，但是照样可以使用一般化的方法来处理。 然而，表示图的连接性要复杂得多。许最明显的选择是使用邻接矩阵，因为它很容易张量化。但是，这种表示方式有一些缺点。 从示例数据集表中，我们可以看到图中的节点数可以达到数百万的量级，每个节点的对于的边数可以是高度可变的。 这通常会导致稀疏的邻接矩阵，这是空间低效的。 这里，在传统的图模型里面，一般是用邻接矩阵的方式来进行存储的，但是当数据比较多时，矩阵的维数会出奇的大，对设备的存储有一定的要求。 当然，也许会有稀疏矩阵的方式来进行存储，但是稀疏矩阵没办法使用GPU设备。 另一个问题是，有许多邻接矩阵可以编码相同的连通性，并且不能保证这些不同的矩阵会在深度神经网络中产生相同的结果(也就是说，它们不是置换不变的)。 例如，前面的奥赛罗图可以用这两个邻接矩阵等价地描述。它也可以用所有其他可能的节点排列来描述。其实就是两个行随便换位值之后其实连接的关系都是一样的，但是矩阵同，这样就会有二义性。 下面的例子展示了每个可以描述这个4个节点的小图的邻接矩阵。这已经是相当多的邻接矩阵了——对于更大的例子，如Othello，这个数字是站不住脚的。 视觉上不一样，但是结果确实一样的。$A_4^4=4 \\times 3 \\times 2 \\times 1 =24$ 于是去数据结构里找了一个图的有一种存储的方式，邻接表。 表示稀疏矩阵的一种优雅且内存有效的方法是邻接表。这些描述了边缘$e_k$在节点 $n_i$ 和 $n_j$ 之间的连通性作为邻接表第k个条目的元组$(i,j)$。 由于我们期望边的数量比邻接矩阵($n^2_{nodes}$)的条目数量要少得多，因此我们避免在图的不连通部分上进行计算和存储。 为了使这个概念更具体，我们可以看到不同图表中的信息在这个规范下是如何表示的： 之前邻接矩阵是主要存储节点，邻接表主要存储边，当边比较少的时候，矩阵比较稀疏，此时适合使用邻接表，但是如果存储的边比较多时，那么邻接矩阵比较合算。 应该注意的是，图在每个节点/边/全局中使用标量值，但是大多数实际的张量表示在每个图属性中都有向量。我们将处理大小为$[n_{nodes},node_{dim}]$的节点张量，而不是$[n_{nodes}]$的节点张量。其他图形属性也是如此。 词汇积累 rift n.(人际关系)不和，分歧；裂缝，裂口；地堑，裂谷 feud n. 不和；争执；封地;（部落或家族间的）世仇 vi. 长期不和；长期争斗 interaction n.相互作用；相互交流 intuitive adj. 直觉的；有直觉力的；易懂的，使用简便的 compatible adj. 兼容的，可共存的 assign v. 分派，布置 adjacency matrices 邻接矩阵 sparse adj. 稀疏的 equivalently adv. 相等地；相当于 permutation n. [数] 排列；[数] 置换","link":"/2022/03/30/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3-%E5%9B%BE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"title":"图神经网络的通俗理解-实验和相关技术","text":"hljs.initHighlightingOnLoad(); 本文主要结合相关的实验来对GNN进行分析，同时几何一些相关的各种来分析目前应用的问题和挑战。 博客的参考网址：A Gentle Introduction to Graph Neural Networks (distill.pub)：https://distill.pub/2021/gnn-intro/ GNN playground 实验部分主要是一个基于GNN预测分子结构的案例，本文的作者将程序嵌入到 js 网页里面。并且直接去可以去实时的调节网络来进行预测。 主要是预测给定的分子结构闻起来是否刺鼻，这是一个二分类的模型。我们将每个分子表示为一个图，其中原子是包含一个单热编码(碳、氮、氧、氟)的节点，而键是包含一个单热编码(单热、双热、三热或芳香族)的键类型的边。 这个问题的通用模板将使用顺序的GNN层构建，然后使用一个用于分类的sigmoid激活的线性模型。 GNN层数，又称深度。 更新时每个属性的维度。更新函数是一个具有relu激活函数和激活规范化层规范的单层MLP。 在池中使用的聚合函数:max, mean或sum 被更新的图属性或消息传递的样式:节点、边和全局表示。我们通过布尔开关(开或关)来控制这些。基线模型将是一个独立于图的GNN(所有消息传递)，它在最后将所有数据聚合到一个全局属性中。切换所有消息传递函数会生成一个GraphNets体系结构。 Some empirical GNN design lessons在下图中，我们通过几个主要的设计选择来探索GNN架构的空间和该任务的性能:消息传递的风格、嵌入的维数、层数和聚合操作类型。 散点图中的每个点代表一个模型：x轴是可训练变量的数量，y轴是性能。将鼠标悬停在一个点上可以看到GNN架构参数。 整张图讲的是参数的数量和最后预测结果的AUC之间的关系。首先要注意的是，令人惊讶的是，参数数量越多，性能越好。GNN是一种非常高效的参数模型类型:即使是少量的参数(3k)，我们已经可以找到高性能的模型。 接下来，我们可以查看基于不同图形属性的学习表示的维数聚合的性能分布。 箱型图，min 25% 50% 75% max，中值越改越好，bar不要太长，否则会很敏感，如图这些参数的方差太大了，比较的敏感。 我们可以注意到，模型的维数越高，其均值和下界性能越好，但最大值没有出现相同的趋势。对于较小的维度，可以找到一些性能最好的模型。由于更高的维数也将涉及更多的参数，这些观察结果与前面的图是一致的。 接下来，我们可以看到基于GNN层数的性能分解。 如图所示为不同层数间准确性的预测AUC的分布，可以看出对着层数的增加中位数也在增加，但是方差也在增加，也就是如果随着参数的增长，只要参数调的不好测试效果依然不好，表现在图中就是相互耦合的情况。 箱形图也显示了类似的趋势，虽然平均性能随着层数的增加而增加，但性能最好的模型不是三层或四层，而是两层。此外，性能的下界随着层的增加而降低。这种效应之前已经观察到，具有较多层数的GNN将以更高的距离传播信息，并可能在许多连续迭代中使其节点表示被“稀释”。 我们的数据集有首选的聚合操作吗?下图按照聚合类型对性能进行了分解。 基本上就是没有什么区别。 总的来说，sum似乎对平均性能有非常轻微的改善，但max或mean可以给出同样好的模型。在查看聚合操作的区分/表达能力时，这对于将其置于背景中非常有用。 之前的探索给出了复杂的信息。我们可以发现复杂程度越高，性能越好的平均趋势，但我们也可以发现参数越少、层数越少或维数越少的明显反例。一个更明显的趋势是相互传递信息的属性的数量。 这里，我们将根据消息传递的风格对性能进行分解。在这两种极端情况下，我们考虑的模型在图实体(“none”)之间不通信，而模型在节点、边和全局之间传递消息。 总的来说，我们看到交流的图属性越多，平均模型的性能就越好。我们的任务以全局表示为中心，因此明确地学习这个属性也有助于提高性能。我们的节点表示似乎也比边表示更有用，这是有意义的，因为在这些属性中加载了更多的信息。 为了获得更好的性能，你可以从很多方面着手。我们希望突出两个方向，一个与更复杂的图算法有关，另一个与图本身有关。 GNN研究的前沿领域之一不是制造新的模型和架构，而是“如何构造图”，更精确地说，为图注入可以利用的额外结构或关系。正如我们所看到的，图形属性的交流越多，我们的模型就越好。在这种特殊情况下，我们可以考虑通过添加节点之间的额外空间关系、添加非键的边或子图之间的显式可学习关系，使分子图的特征更加丰富。 Into the Weeds 相关的技术接下来，我们将用几节讨论与GNN相关的大量图形相关主题。 Other types of graphs (multigraphs, hypergraphs, hypernodes, hierarchical graphs)例如，我们可以考虑多边图或多重图，其中一对节点可以共享多种类型的边，当我们希望根据节点的类型对节点之间的交互进行不同的建模时，就会发生这种情况。例如，对于社交网络，我们可以根据关系类型(熟人、朋友、家人)指定边缘类型。对于每个边的类型，可以使用不同类型的消息传递步骤来调整GNN。 我们也可以考虑嵌套图，例如一个节点表示一个图，也称为超节点图。嵌套图对于表示层次信息是有用的。例如，我们可以考虑一个分子网络，其中一个节点代表一个分子，如果我们有一种方法(反应)将一个分子转化为另一个分子，则两个分子共享一条边。在这种情况下，我们可以通过一个GNN在分子级和反应网络级学习表示，并在训练期间交替学习表示，从而在嵌套图上学习。 Sampling Graphs and Batching in GNNs训练神经网络的一种常见做法是用训练数据的随机常数大小(批量大小)子集(小批量)计算出的梯度来更新网络参数。受到内存的限制们这里也需要进行取样，对这个小的batch进行计算梯度。 主要的方法有一下四种： 随机节点取样法是随机抽样一个均匀数目的节点，然后添加与节点集相邻的距离为k的相邻节点，包括它们的边。每个邻域可以被认为是一个单独的图，并且可以在这些子图的批量上训练GNN。 随机游走取样法。从一个节点开始，随机选择一个相邻的节点作为下一个节点进行计算，规定一定的随机游走的步数。 随机取样+游走法。随机走3步，之后将这三步经过的结点全部找出。 宽度遍历法，将其1、2、3近邻往前走步之后进行一个宽度遍历。 取样的选择需要根据实际的图形来进行选择，其次就是这样取样之后的得到的子图结点的数的大小是不同的，如何统一是一个有挑战性的问题。 Inductive biases在构建模型以解决特定类型数据上的问题时，我们希望将模型专门化，以利用该数据的特征。当这一点成功地完成时，我们通常会看到更好的预测性能，更低的训练时间，更少的参数和更好的泛化。 任何的机器学习模型都要一定的假设，对于卷积神经网络其主要的假设是空间不变性，循环神经网络的假设是时序的连续性。GNN的假设是保持了图的对称性。 Comparing aggregation operations选择和设计最优聚合操作是一个开放的研究课题。 聚合操作的一个理想属性是，类似的输入提供类似的聚合输出，反之亦然。一些非常简单的候选置换不变运算是和、均值和最大值。像方差这样的汇总统计也是可行的。所有这些都接受数量可变的输入，并提供相同的输出，无论输入顺序如何。让我们探讨一下这些操作之间的区别。 如图上面MAX聚合之后的结果，两种网络是一样的结构，但是使用Mean之后则右图的两个结果又是一样的，因此没有那个显著的优于另外的两个。 没有一种操作是一致的最佳选择。当节点的邻居数量高度可变时，或者需要对局部邻居的特征进行规范化处理时，均值操作非常有用。当您想要突出局部社区的单个显著特征时，最大操作可能很有用。Sum通过提供特性的局部分布的快照，在这两者之间提供了一种平衡，但是因为它不是标准化的，所以也可以突出显示离群值。在实践中，通常使用sum。 集合上的集合运算设计是一个与机器学习交叉的开放研究问题。新的方法，如主邻域聚合考虑几个聚合操作，将它们连接起来，并添加一个依赖于实体的连接性程度的扩展函数来进行聚合。同时，还可以设计特定于领域的聚合操作。一个例子就是“四面体手性”聚集算子。 GCN as subgraph function approximators GCN带了汇聚的图神经网络，第k层的结点显然是汇聚了其K步近邻的结构之后的结果，将其回推可以得到一个个子图，将每个子图求Embedding的结果和聚合相似。 Edges and the Graph Dual 边的结点进行互换实现图得对偶操作，对偶前后是相同的。 需要注意的一点是，边缘预测和节点预测虽然看起来不同，但往往归结为同一个问题:图G上的边缘预测任务可以被描述为G对偶上的节点级预测。 为了得到G的对偶，我们可以将节点转换为边(将边转换为节点)。图及其对偶包含相同的信息，只是表示方式不同而已。有时，这个特性使得在一种表示法中解决问题比在另一种表示法中容易，比如傅里叶空间中的频率。简而言之，为了解决G上的边缘分类问题，我们可以考虑在G的对偶上进行图卷积(这和在G上学习边缘表示是一样的)，这个想法是在双原图卷积网络中发展起来的。 Graph convolutions as matrix multiplications, and matrix multiplications as walks on a graph主要的想法就是将图卷积看作是邻接矩阵之间的矩阵相乘问题，早期的PageRank算法利用的就是这个思想。 具体的细节可以参考原文。 Graph Attention Networks 传统的卷积的权重是和位置相关，但是在图中，我们的GNN里面的卷积和位置无关，而且结点时可以随意打乱顺序的。我们可以参考注意力机制中权重和结点之间的关系相关，在注意力机制是通过Q K进行矩阵乘法计算相似度的。 Graph explanations and attributions 在部署GNN时，我们可能会关心模型的可解释性，以建立可信性、调试或科学发现。我们要解释的图概念因上下文的不同而不同。例如，对于分子，我们可能关心特定子图的存在与否，而在引文网络中，我们可能关心文章的连通性程度。由于图概念的多样性，有许多方法来构建解释。GNNexplainer将此问题转换为提取对任务重要的最相关的子图。归因技术为图中与任务相关的部分分配排序重要值。由于可以综合生成现实且具有挑战性的图问题，因此gnn可以作为评估归因技术的严格且可重复的测试平台。 Generative modelling对图的结构进行拓扑建模。 Final thoughts图是一种功能强大且丰富的结构化数据类型，它的优势和挑战与图像和文本非常不同。在本文中，我们概述了研究人员在构建基于处理图形的神经网络模型时所提出的一些里程碑。我们已经讨论了在使用这些架构时必须做出的一些重要设计选择，希望GNN操场能够直观地了解这些设计选择的经验结果是什么。近年来GNN的成功为一系列新问题创造了巨大的机遇，我们很高兴看到该领域将带来什么。","link":"/2022/03/30/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3-%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/"},{"title":"Ch3 三维空间的刚体运动 第一部分","text":"hljs.initHighlightingOnLoad(); 本文主要是讲解三维刚体运动的第一部分，包括点和向量坐标系与旋转矩阵的内容，之后还有一个Eigen的编程练习。 上节课中，我们主要讲了SLAM的一个主要的框架，和两个主要的数学方程，以及三个主要的问题，那么本节课我们主要讲解的是第一个，如何估计自身的(或相机)位姿，即三维空间的刚体运动。 点与坐标系 点、向量和坐标系的定义对于刚体来说，不仅要考虑其位置，也要考虑其当前的姿态，如上面的二维扫地机器人，出来考虑位置信息的$(x,y)$，还要考虑使用一个角度$\\theta \\in (0,2\\pi)$ ，来描述其当前的姿态信息。 三维空间也是一样的，我们引入点和向量来对空间进行描述。 点是最基本的元素，没有体积没有长度，仅仅刻画位置信息。 向量是从一个点指向另外一个点的箭头。 坐标 $\\ne$ 向量，坐标必须依赖于坐标系才能存在，而向量一直都存在，只有给定了坐标系后才能讨论向量在坐标系下的坐标。 定义了坐标系后，向量可以由$R^3$的坐标来表示。 a=\\left[e_1,e_2,e_3\\right]\\left[\\begin{array} & a_1 \\\\ a_2 \\\\a_3 \\end{array}\\right]=a_1e_1+a_2e_2+a_3e_3 这里$[e_1,e_2,e_3]$ 为一组基，$(a_1,a_2,a_3)^T$为向量$a$在这组基下的一个坐标。 因此向量对于的坐标不仅和自身有关，还和坐标系/基的选择有关。 坐标系：由三个正交的轴组成，其实可以是非正交的基，但是不常用。 构成线性空间的一组基 主要分为左手系和右手系。 向量的运算向量的运算可以使用坐标的运算来表达，对于加减和数乘比较的简单，此处不在赘述，下面主要介绍内积和外积的计算： 内积的计算公式如下： $\\langle\\boldsymbol{a}, \\boldsymbol{b}\\rangle$ 代表的是向量之间的夹角； 内积还可以表示向量之间的投影关系： \\boldsymbol{a} \\cdot \\boldsymbol{b}=\\boldsymbol{a}^{T} \\boldsymbol{b}=\\sum_{i=1}^{3} a_{i} b_{i}=|\\boldsymbol{a}||\\boldsymbol{b}| \\cos \\langle\\boldsymbol{a}, \\boldsymbol{b}\\rangle. 外积的计算的公式如下： 其运算的结果为一个方向垂直于向量组成的平面的一个向量； 大小为$|\\boldsymbol{a}||\\boldsymbol{b}| \\sin \\langle\\boldsymbol{a}, \\boldsymbol{b}\\rangle$ ,等价于两个向量张成平行四边型的面积。 \\boldsymbol{a} \\times \\boldsymbol{b}=\\left[\\begin{array}{ccc}\\boldsymbol{i} & j & k \\\\ a_{1} & a_{2} & a_{3} \\\\ b_{1} & b_{2} & b_{3}\\end{array}\\right]=\\left[\\begin{array}{c}a_{2} b_{3}-a_{3} b_{2} \\\\ a_{3} b_{1}-a_{1} b_{3} \\\\ a_{1} b_{2}-a_{2} b_{1}\\end{array}\\right]=\\left[\\begin{array}{ccc}0 & -a_{3} & a_{2} \\\\ a_{3} & 0 & -a_{1} \\\\ -a_{2} & a_{1} & 0\\end{array}\\right] \\boldsymbol{b} \\triangleq \\boldsymbol{a}^{\\wedge} \\boldsymbol{b} . 于是定义了反对称矩阵$\\boldsymbol a^\\^$ 为： \\boldsymbol a^\\^=\\left[\\begin{array}{ccc}0 & -a_{3} & a_{2} \\\\ a_{3} & 0 & -a_{1} \\\\ -a_{2} & a_{1} & 0\\end{array}\\right]这里反对称矩阵有一个重要的性质：$\\boldsymbol A ^T=-\\boldsymbol A$ 通过引入反对称矩阵，进而将外积转化为一个线性操作。 注意上述的运算公式是建立在坐标存在的基础上，但是如果坐标是不存在，那么上述的运算依然可以通过其几何含义来实现，所以说向量运算的结果是和坐标的选择无关。 刚体运动在实际的应用中，我们会定义各种各样的坐标系。比如在机器人研究中，我们会分别定义一个惯性坐标系(或世界坐标系)和一个移动坐标系。 惯性坐标系：可以看作是不动的。 移动坐标系：用来刻画相机或(移动机器人)当前的位置的坐标系。 机器人的移动坐标系是随着机器人的运动在不断的变化，产生新的坐标系。 于是引出了一个问题：坐标系之间是如何转化的，知道在一个坐标系下的坐标们如何在另一个坐标系下进行表示。 上述坐标系之间通过一次旋转加一次平移即可得到，于是定义为刚体运动。相机和机器人的运动就是典型的刚体运动。 刚体运动的特点： 运动的过程中的空间位置和姿态可能在一直改变； 但是其向量的夹角和长度是不变的。 此时刚体运动过程中，坐标系之间的变化可以看作是欧式变换。 旋转矩阵旋转直观来看，刚体的运动是可以看作是原点间的平移和三个轴之间的旋转组成，其中平移可以看作是加上一个向量，旋转可以看作是乘以一个旋转矩阵。 设单位正交基$(e_1,e_2,e_3)$ 发生一次旋转变换变成了 $(e_1^{\\prime},e_2^{\\prime},e_3^{\\prime})$ . 对于固定的向量$\\boldsymbol a$ (向量的旋转不随坐标系旋转)，它的坐标变换前后为$[a_1,a_2,a_3]$ 和 $[a_1^{\\prime},a_2^{\\prime},a_3^{\\prime}]$ . 于是得出： \\left[\\boldsymbol{e}_{1}, \\boldsymbol{e}_{2}, \\boldsymbol{e}_{3}\\right]\\left[\\begin{array}{l}a_{1} \\\\ a_{2} \\\\ a_{3}\\end{array}\\right]=\\left[\\boldsymbol{e}_{1}^{\\prime}, \\boldsymbol{e}_{2}^{\\prime}, \\boldsymbol{e}_{3}^{\\prime}\\right]\\left[\\begin{array}{c}a_{1}^{\\prime} \\\\ a_{2}^{\\prime} \\\\ a_{3}^{\\prime}\\end{array}\\right]由单位正交基的性质可得： \\left[\\begin{array}{c}a_{1} \\\\ a_{2} \\\\ a_{3}\\end{array}\\right]=\\left[\\begin{array}{ccc}\\boldsymbol{e}_{1}^{T} \\boldsymbol{e}_{1}^{\\prime} & \\boldsymbol{e}_{1}^{T} \\boldsymbol{e}_{2}^{\\prime} & \\boldsymbol{e}_{1}^{T} \\boldsymbol{e}_{3}^{\\prime} \\\\ \\boldsymbol{e}_{2}^{T} \\boldsymbol{e}_{1}^{\\prime} & \\boldsymbol{e}_{2}^{T} \\boldsymbol{e}_{2}^{\\prime} & \\boldsymbol{e}_{2}^{T} \\boldsymbol{e}_{3}^{\\prime} \\\\ \\boldsymbol{e}_{3}^{T} \\boldsymbol{e}_{1}^{\\prime} & \\boldsymbol{e}_{3}^{T} \\boldsymbol{e}_{2}^{\\prime} & \\boldsymbol{e}_{3}^{T} \\boldsymbol{e}_{3}^{\\prime}\\end{array}\\right]\\left[\\begin{array}{c}a_{1}^{\\prime} \\\\ a_{2}^{\\prime} \\\\ a_{3}^{\\prime}\\end{array}\\right] \\triangleq \\boldsymbol{R} \\boldsymbol{a}^{\\prime} 这里矩阵$\\boldsymbol R$ 称为旋转矩阵，其每个分量为各个坐标基之间的内积。 主要的性质： $\\boldsymbol R$ 是一个正交矩阵； $\\boldsymbol R$ 的行列式为 1。 通过上述的性质，定义上述两条性质的矩阵为旋转矩阵。 于是将n维旋转矩阵的几何定义为一个特殊正交群： \\mathcal {SO}(n)=\\{\\boldsymbol R \\in \\mathbb R^{n\\times n} | \\boldsymbol R\\boldsymbol R^T=\\boldsymbol I,\\det(\\boldsymbol R)=1\\}. 旋转矩阵描述了同一个向量在两个坐标系之间的坐标变换关系。 比如：$a_1=\\boldsymbol R_{12}a_2$，反之为：$a_2=\\boldsymbol R_{21}a_1$ 于是可得：$\\boldsymbol R_{21}=\\boldsymbol R_{12}^{-1}=\\boldsymbol R_{12}^T$ 进一步对于三个坐标系有：$a_3=\\boldsymbol R_{32}a_2=\\boldsymbol R_{32}\\boldsymbol R_{21}a_1=\\boldsymbol R_{31}a_1$ 平移这里平移的刻画是一个向量 $t_{12}$ ： a_1=\\boldsymbol R_{12}a_2+t_{12}这里对公式的理解： 对于旋转矩阵 $\\boldsymbol R_{12}$ ，其下标是从右向左来读的，代表的含义是把坐标系2的向量转化为坐标系1上。 对于平移向量 $t_12$，其下标是还是从左向右，代表的是从坐标系1指向坐标系2的向量，但是向量的在坐标系1下取得坐标。 在向量的几何层面有$t_{12}=-t_{21}$; 但是在坐标层面，由于两者所在的坐标系不同，因此$t_{12}\\ne-t_{21}$ 变换矩阵和齐次坐标对于刚才的的欧氏变换，其并非一个线性关系： b=\\boldsymbol R_1 a + t_1, c=\\boldsymbol R_2 b + t_2 \\Rightarrow c=\\boldsymbol R_2 (\\boldsymbol R_1 a + t_1) + t_2于是引入了齐次变换： \\left[\\begin{array}{c}\\boldsymbol{a}^{\\prime} \\\\ 1\\end{array}\\right]=\\left[\\begin{array}{cc}\\boldsymbol{R} & \\boldsymbol{t} \\\\ \\mathbf{0}^{T} & 1\\end{array}\\right]\\left[\\begin{array}{c}\\boldsymbol{a} \\\\ 1\\end{array}\\right] \\triangleq \\boldsymbol{T}\\left[\\begin{array}{c}\\boldsymbol{a} \\\\ 1\\end{array}\\right] . 这里记$\\tilde a=\\left[\\begin{array}{c}\\boldsymbol{a}^{\\prime} \\\\ 1\\end{array}\\right]$ 为齐次坐标，于是上面的坐标变换可以转化称为： \\tilde{b}=\\boldsymbol{T}_{1} \\tilde{\\boldsymbol{a}}, \\tilde{\\boldsymbol{c}}=\\boldsymbol{T}_{2} \\tilde{\\boldsymbol{b}} \\quad \\Rightarrow \\tilde{\\boldsymbol{c}}=\\boldsymbol{T}_{2} \\boldsymbol{T}_{1} \\tilde{\\boldsymbol{a}} 这种四个数表达三维向量的方法称为齐次坐标，原来的三维向量就为非齐次坐标。 引入齐次坐标之后，可以将旋转和平移放到同一个矩阵里面，其矩阵称为变换矩阵。 对于形容变换矩阵的一类矩阵称为特殊欧氏群： \\mathcal{SE}(3) =\\left\\{\\boldsymbol{T}=\\left[\\begin{array}{ll}\\boldsymbol{R} & \\boldsymbol{t} \\\\ \\mathbf{0}^{T} &1\\end{array}\\right] \\in \\mathbb{R}^{4 \\times 4} \\mid \\boldsymbol{R} \\in \\mathcal{SO}(3), \\boldsymbol{t} \\in \\mathbb{R}^{3}\\right\\} 同样，该变换的逆运算矩阵为： \\boldsymbol{T}^{-1}=\\left[\\begin{array}{cc}\\boldsymbol{R}^{T} & -\\boldsymbol{R}^{T} t \\\\ \\mathbf{0}^{T} & 1\\end{array}\\right]\\ 例子：在SLAM中，定义世界坐标系$\\boldsymbol T_w$ 和机器人坐标系 $\\boldsymbol T_R$ ，一个点的世界坐标为$p_w$，机器人的坐标为$p_R$ ，那么满足关系是：$p_R=\\boldsymbol T_{Rw}p_w$ 在实际的编程中，可以使用$\\boldsymbol T_{Rw}$和$\\boldsymbol T_{wR}$来描述机器人的位姿，其中$\\boldsymbol T_{wR}$ 的平移向量代表的是从世界坐标系指向机器人坐标系在世界坐标系下的向量坐标。 Eigen矩阵建立和变换的实践安装Eigen：sudo apt-get install libeigen3-dev 由于Eigen里面只有头文件没有库文件，因此只要进行添加头文件include_directories()即可不用添加库文件add_library()和target_link_libraries()。 在添加头文件是要添加一下头文件需要寻找头文件的位置： 12sudo updatedblocate eigen3 打开Clion之后首先新建一个CMakeList.txt 123456789cmake_minimum_required(VERSION 3.21)project(useEigen)set(CMAKE_BUILD_TYPE &quot;Release&quot;)set(CMAKE_CXX_FLAGS &quot;-O3&quot;)# 添加Eigen头文件include_directories(&quot;/usr/include/eigen3&quot;)add_executable(eigenMatrix eigenMatrix.cpp) 之后新建源文件eigenMatrix.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#include &lt;iostream&gt;using namespace std;#include &lt;ctime&gt;// Eigen 核心部分#include &lt;Eigen/Core&gt;// 稠密矩阵的代数运算（逆，特征值等）#include &lt;Eigen/Dense&gt;using namespace Eigen;#define MATRIX_SIZE 50/***************************** 本程序演示了 Eigen 基本类型的使用****************************/int main(int argc, char **argv) { // Eigen 中所有向量和矩阵都是Eigen::Matrix，它是一个模板类。它的前三个参数为：数据类型，行，列 // 声明一个2*3的float矩阵 Matrix&lt;float, 2, 3&gt; matrix_23; // 同时，Eigen 通过 typedef 提供了许多内置类型，不过底层仍是Eigen::Matrix // 例如 Vector3d 实质上是 Eigen::Matrix&lt;double, 3, 1&gt;，即三维向量 Vector3d v_3d; // 这是一样的 Matrix&lt;float, 3, 1&gt; vd_3d; // Matrix3d 实质上是 Eigen::Matrix&lt;double, 3, 3&gt; Matrix3d matrix_33 = Matrix3d::Zero(); //初始化为零 // 如果不确定矩阵大小，可以使用动态大小的矩阵 Matrix&lt;double, Dynamic, Dynamic&gt; matrix_dynamic; // 更简单的 MatrixXd matrix_x; // 这种类型还有很多，我们不一一列举 // 下面是对Eigen阵的操作 // 输入数据（初始化） matrix_23 &lt;&lt; 1, 2, 3, 4, 5, 6; // 输出 cout &lt;&lt; &quot;matrix 2x3 from 1 to 6: \\n&quot; &lt;&lt; matrix_23 &lt;&lt; endl; // 用()访问矩阵中的元素 cout &lt;&lt; &quot;print matrix 2x3: &quot; &lt;&lt; endl; for (int i = 0; i &lt; 2; i++) { for (int j = 0; j &lt; 3; j++) cout &lt;&lt; matrix_23(i, j) &lt;&lt; &quot;\\t&quot;; cout &lt;&lt; endl; } // 矩阵和向量相乘（实际上仍是矩阵和矩阵） v_3d &lt;&lt; 3, 2, 1; vd_3d &lt;&lt; 4, 5, 6; // 但是在Eigen里你不能混合两种不同类型的矩阵，像这样是错的 // Matrix&lt;double, 2, 1&gt; result_wrong_type = matrix_23 * v_3d; // 应该显式转换 Matrix&lt;double, 2, 1&gt; result = matrix_23.cast&lt;double&gt;() * v_3d; cout &lt;&lt; &quot;[1,2,3;4,5,6]*[3,2,1]=&quot; &lt;&lt; result.transpose() &lt;&lt; endl; Matrix&lt;float, 2, 1&gt; result2 = matrix_23 * vd_3d; cout &lt;&lt; &quot;[1,2,3;4,5,6]*[4,5,6]: &quot; &lt;&lt; result2.transpose() &lt;&lt; endl; // 同样你不能搞错矩阵的维度 // 试着取消下面的注释，看看Eigen会报什么错 // Eigen::Matrix&lt;double, 2, 3&gt; result_wrong_dimension = matrix_23.cast&lt;double&gt;() * v_3d; // 一些矩阵运算 // 四则运算就不演示了，直接用+-*/即可。 matrix_33 = Matrix3d::Random(); // 随机数矩阵 cout &lt;&lt; &quot;random matrix: \\n&quot; &lt;&lt; matrix_33 &lt;&lt; endl; cout &lt;&lt; &quot;transpose: \\n&quot; &lt;&lt; matrix_33.transpose() &lt;&lt; endl; // 转置 cout &lt;&lt; &quot;sum: &quot; &lt;&lt; matrix_33.sum() &lt;&lt; endl; // 各元素和 cout &lt;&lt; &quot;trace: &quot; &lt;&lt; matrix_33.trace() &lt;&lt; endl; // 迹 cout &lt;&lt; &quot;times 10: \\n&quot; &lt;&lt; 10 * matrix_33 &lt;&lt; endl; // 数乘 cout &lt;&lt; &quot;inverse: \\n&quot; &lt;&lt; matrix_33.inverse() &lt;&lt; endl; // 逆 cout &lt;&lt; &quot;det: &quot; &lt;&lt; matrix_33.determinant() &lt;&lt; endl; // 行列式 // 特征值 // 实对称矩阵可以保证对角化成功 SelfAdjointEigenSolver&lt;Matrix3d&gt; eigen_solver(matrix_33.transpose() * matrix_33); cout &lt;&lt; &quot;Eigen values = \\n&quot; &lt;&lt; eigen_solver.eigenvalues() &lt;&lt; endl; cout &lt;&lt; &quot;Eigen vectors = \\n&quot; &lt;&lt; eigen_solver.eigenvectors() &lt;&lt; endl; // 解方程 // 我们求解 matrix_NN * x = v_Nd 这个方程 // N的大小在前边的宏里定义，它由随机数生成 // 直接求逆自然是最直接的，但是求逆运算量大 Matrix&lt;double, MATRIX_SIZE, MATRIX_SIZE&gt; matrix_NN = MatrixXd::Random(MATRIX_SIZE, MATRIX_SIZE); matrix_NN = matrix_NN * matrix_NN.transpose(); // 保证半正定 Matrix&lt;double, MATRIX_SIZE, 1&gt; v_Nd = MatrixXd::Random(MATRIX_SIZE, 1); clock_t time_stt = clock(); // 计时 // 直接求逆 Matrix&lt;double, MATRIX_SIZE, 1&gt; x = matrix_NN.inverse() * v_Nd; cout &lt;&lt; &quot;time of normal inverse is &quot; &lt;&lt; 1000 * (clock() - time_stt) / (double) CLOCKS_PER_SEC &lt;&lt; &quot;ms&quot; &lt;&lt; endl; cout &lt;&lt; &quot;x = &quot; &lt;&lt; x.transpose() &lt;&lt; endl; // 通常用矩阵分解来求，例如QR分解，速度会快很多 time_stt = clock(); x = matrix_NN.colPivHouseholderQr().solve(v_Nd); cout &lt;&lt; &quot;time of Qr decomposition is &quot; &lt;&lt; 1000 * (clock() - time_stt) / (double) CLOCKS_PER_SEC &lt;&lt; &quot;ms&quot; &lt;&lt; endl; cout &lt;&lt; &quot;x = &quot; &lt;&lt; x.transpose() &lt;&lt; endl; // 对于正定矩阵，还可以用cholesky分解来解方程 time_stt = clock(); x = matrix_NN.ldlt().solve(v_Nd); cout &lt;&lt; &quot;time of ldlt decomposition is &quot; &lt;&lt; 1000 * (clock() - time_stt) / (double) CLOCKS_PER_SEC &lt;&lt; &quot;ms&quot; &lt;&lt; endl; cout &lt;&lt; &quot;x = &quot; &lt;&lt; x.transpose() &lt;&lt; endl; return 0;}","link":"/2022/04/02/SLAM/ch3-%E4%B8%89%E7%BB%B4%E7%A9%BA%E9%97%B4%E7%9A%84%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"Ch3 三维空间的刚体运动 第二部分","text":"hljs.initHighlightingOnLoad(); 本文主要是三维刚体运动的第二部分，包括旋转向量欧拉角和四元数的内容，最后是Eigen的几何模块的实践以及一个小的例题。 旋转向量和欧拉角旋转向量问题： 旋转矩阵和变换矩阵的方法需要的参数量太大，SO(3)里面涉及的9个参数表示3个自由度，SE(3)里16个参数描述6个自由度。 其次，两种群的约束过多使得求解变得困难。 因此我们使用一个三个自由度的向量来表示旋转，其中向量的方向为旋转轴的方向，向量的长度为旋转的角度，称这种向量为旋转向量，又称角轴/轴角。 \\boldsymbol \\omega=\\theta \\boldsymbol n 角轴和旋转矩阵的不同： 旋转矩阵：有九个量，且满足正交性的约束和行列式的值为1的约束。 角轴：三个量，没有约束。 注意上述二者只是表达方式不同，但是表达的东西是相同的。 这里的角轴表示就是在第四章要介绍的李代数问题。 二者的转换关系： 角轴-&gt;旋转矩阵：罗德里格斯公式 \\boldsymbol R=\\cos\\theta \\boldsymbol I +(1-\\cos \\theta)\\boldsymbol n \\boldsymbol n^T +\\sin\\theta\\boldsymbol n^\\^ 旋转矩阵-&gt;角轴 角度：$\\theta=\\arccos \\left( \\dfrac {tr(\\boldsymbol R)-1} {2}\\right)$ 轴向量：$\\boldsymbol R \\boldsymbol n =\\boldsymbol n$ 这里可以看作是将旋转轴绕自身旋转后结果不变，其实也就是旋转矩阵的特征值1对于的旋转向量。 欧拉角相比旋转矩阵和旋转向量并不是很直观的体现旋转的情况，这里使用欧拉角来更为直观的显示，但是欧拉角在实际编程中很少看到。 这里欧拉角是将，一次旋转分解为绕三个轴的旋转，通过三个分离的转角来表示。 因为人对绕单个轴的一次旋转过程比较容易理解。 但是，分解的情况有很多种，比如： 按照轴的旋转次序：可以分为XYZ，ZYX，ZYZ三种，其中ZYX使用的比较多。 按照每次旋转的轴是否固定：可以分为定轴旋转和动轴旋转，这两种主要区别是旋转矩阵的右乘还是左乘。 这里做常见是yaw-pitch-roll (偏航-俯仰-滚转)。 绕物体的Z轴旋转，得到偏航角yaw； 绕旋转之后的Y轴旋转，得到俯仰角pitch； 绕旋转之后的X轴旋转，得到滚转角roll。 万向锁问题 按照ZYX的顺序，如果Pitch为正负90°，则第三次和第一次是绕的同一个轴进行的，就会减少一个自由度，产生奇异的问题。 由于万向锁的存在，欧拉角不适合插值或迭代，多用于人机交互中。 可以证明：仅用三个实数表达旋转时，不可避免地存在奇异性问题。 旋转向量其实也会出现一样的奇异问题。 SLAM中亦很少用欧拉角表达姿态。 四元数四元数的定义四元数是一种扩展的复数，它参考了一般的复数可以很好的表示旋转的特点进行改造的，使得其同时具有紧凑性和非奇异性，尽管其依旧不是很直观。 四元数据具有三个虚部，可以表达三维空间中的旋转： \\boldsymbol q=q_0+q_1i+q_2j+q_3k其中，$i,j,k$ 为四元数的虚部，这里其运算满足以下的性质： \\left\\{\\begin{array} &i^2=j^2=k^2=-1 \\\\ ij=k,ji=-k\\\\ jk=i,kj=-i\\\\ ki=j,ik=-j \\end{array}\\right. 自己和自己的运算像复数，自己和别人运算像叉乘。 但是这里无法用复数的乘以一个$i$代表旋转了90°来理解，具体的理论查一下深入的资料，这里不再细讲。 有时四元数也被直接表达成： \\boldsymbol q=[\\boldsymbol s,\\boldsymbol v],s=q_0\\in \\mathbb R^3\\\\ v=[q_!,q_2,q_3]^T\\in\\mathbb R^3四元数的运算主要的运算为以下的几种： 加减法：$\\boldsymbol q_a \\pm \\boldsymbol q_b=[s_a\\pm s_b,v_a\\pm v_b].$ 乘法： $\\boldsymbol q_a\\boldsymbol q_b=[s_as_b-v_a^Tv_b,s_av_b+s_bv_a+v_a\\times v_b].$ 共轭： $\\boldsymbol q_a=s_a-x_ai-y_aj-z_ak=[s_a,-v_a].$ 模长： $||\\boldsymbol q_a||=\\sqrt{s_a^2+x_a^2+y_a^2+z_a^2}$ 逆： $\\boldsymbol q^{-1}=\\boldsymbol q^*/||\\boldsymbol q||$ 数乘： $k \\boldsymbol q=[ks, kv].$ 点乘： $\\boldsymbol q_a \\cdot \\boldsymbol q_b=s_as_b+x_ax_bi+y_ay_bj+z_az_bk$ 这里数乘是不可以随意的交换位置。 使用四元数进行旋转设点$p$ 经过一次以 $q$ 表示的旋转之后，得到了$p^{\\prime}$，则 将 $p$ 的坐标用四元数表示(虚四元数) ：$\\boldsymbol p=[0,x,y,z=[0,v].$ 旋转之后的关系为：$\\boldsymbol p^{\\prime} = \\boldsymbol q\\boldsymbol p \\boldsymbol q^{-1}=\\boldsymbol R\\boldsymbol p.$ 这里可以证明其旋转前后都是虚四元数。 下面来看四元数向其他两种旋转表示间的转化. 首先，是向旋转矩阵的转化： 和之前处理变换矩阵的方法一样，将非线性化的运算线性化： \\boldsymbol{q}^{+}=\\left[\\begin{array}{cc}s & -\\boldsymbol{v}^{\\mathrm{T}} \\\\ \\boldsymbol{v} & s \\boldsymbol{I}+\\boldsymbol{v}^{\\wedge}\\end{array}\\right], \\quad \\boldsymbol{q}^{\\oplus}=\\left[\\begin{array}{cc}s & -\\boldsymbol{v}^{\\mathrm{T}} \\\\ \\boldsymbol{v} & s \\boldsymbol{I}-\\boldsymbol{v}^{\\wedge}\\end{array}\\right]\\\\ \\boldsymbol{q}_{1}^{+} \\boldsymbol{q}_{2}=\\left[\\begin{array}{cc}s_{1} & -\\boldsymbol{v}_{1}^{\\mathrm{T}} \\\\ \\boldsymbol{v}_{1} & s_{1} \\boldsymbol{I}+\\boldsymbol{v}_{1}^{\\wedge}\\end{array}\\right]\\left[\\begin{array}{l}s_{2} \\\\ \\boldsymbol{v}_{2}\\end{array}\\right]=\\left[\\begin{array}{c}-\\boldsymbol{v}_{1}^{\\mathrm{T}} \\boldsymbol{v}_{2}+s_{1} s_{2} \\\\ s_{1} \\boldsymbol{v}_{2}+s_{2} \\boldsymbol{v}_{1}+\\boldsymbol{v}_{1}^{\\wedge} \\boldsymbol{v}_{2}\\end{array}\\right]=\\boldsymbol{q}_{1} \\boldsymbol{q}_{2}于是可得：$\\boldsymbol{q}_{1} \\boldsymbol{q}_{2}=\\boldsymbol{q}_{1}^{+} \\boldsymbol{q}_{2}=\\boldsymbol{q}_{2}^{\\oplus} \\boldsymbol{q}_{1}$ 将上述的旋转变换可以转化为：$\\boldsymbol{p}^{\\prime}=\\boldsymbol{q} \\boldsymbol{p} \\boldsymbol{q}^{-1}=\\boldsymbol{q}^{+} \\boldsymbol{p}^{+} \\boldsymbol{q}^{-1}=\\boldsymbol{q}^{+} \\boldsymbol{q}^{-1^{\\oplus}} \\boldsymbol{p}$ \\boldsymbol{q}^{+}\\left(\\boldsymbol{q}^{-1}\\right)^{\\oplus}=\\left[\\begin{array}{cc}s & -\\boldsymbol{v}^{\\mathrm{T}} \\\\ \\boldsymbol{v} & s \\boldsymbol{I}+\\boldsymbol{v}^{\\wedge}\\end{array}\\right]\\left[\\begin{array}{cc}s & \\boldsymbol{v}^{\\mathrm{T}} \\\\ -\\boldsymbol{v} & s \\boldsymbol{I}+\\boldsymbol{v}^{\\wedge}\\end{array}\\right]=\\left[\\begin{array}{cc}1 & -\\boldsymbol{0} \\\\ \\boldsymbol{0}^{\\mathrm{T}} & \\boldsymbol{v}\\boldsymbol{v}^{T}+s^2 \\boldsymbol{I}+2s\\boldsymbol{v}^{\\wedge}+(\\boldsymbol{v}^{\\wedge})^2\\end{array}\\right]由于旋转前后都是一个虚四元数，因此四元数的旋转矩阵为： \\boldsymbol{R}=\\boldsymbol{v} \\boldsymbol{v}^{\\mathrm{T}}+s^{2} \\boldsymbol{I}+2 s \\boldsymbol{v}^{\\wedge}+\\left(\\boldsymbol{v}^{\\wedge}\\right)^{2}之后，是向旋转向量转化： 根据之前得出的旋转矩阵可得： \\operatorname{tr}(\\boldsymbol{R})=\\operatorname{tr}\\left(\\boldsymbol{v} \\boldsymbol{v}^{\\mathrm{T}}+3 s^{2}+2 s \\cdot 0+\\operatorname{tr}\\left(\\left(\\boldsymbol{v}^{\\wedge}\\right)^{2}\\right)\\right.=4s^2-1有角轴和旋转矩阵的转化关系可得： \\theta=\\arccos \\left( \\dfrac {tr(\\boldsymbol R)-1} {2}\\right)=\\arccos(2s^2-1)可得：$\\cos\\theta=2s^2-1=2\\cos^2(\\dfrac \\theta 2)-1 \\ \\Rightarrow s=\\cos(\\dfrac \\theta 2) $ 同时$\\boldsymbol{p}^{\\prime}=\\boldsymbol{q} \\boldsymbol{p} \\boldsymbol{q}^{-1}$ 中，使用$q$代替$p$ ，得出旋转后一样，因此可知$q$ 为旋转轴，于是其虚部就为旋转轴的坐标。 综上其转化的关系为： \\left\\{\\begin{array}{l}\\theta=2 \\arccos q_{0} \\\\ {\\left[n_{x}, n_{y}, n_{z}\\right]^{\\mathrm{T}}=\\left[q_{1}, q_{2}, q_{3}\\right]^{\\mathrm{T}} / \\sin \\dfrac{\\theta}{2}}\\end{array}\\right.因此一般对应轨迹的存储我们还是使用四元数来进行储存。 Eigen几何模块的使用这里其他的地方和上面的实践基本相同，这里不在赘述。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;#include &lt;Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;using namespace Eigen;// 本程序演示了 Eigen 几何模块的使用方法int main(int argc, char **argv) { // Eigen/Geometry 模块提供了各种旋转和平移的表示 // 3D 旋转矩阵直接使用 Matrix3d 或 Matrix3f Matrix3d rotation_matrix = Matrix3d::Identity(); // 旋转向量使用 AngleAxis, 它底层不直接是Matrix，但运算可以当作矩阵（因为重载了运算符） AngleAxisd rotation_vector(M_PI / 4, Vector3d(0, 0, 1)); //沿 Z 轴旋转 45 度 cout.precision(3); cout &lt;&lt; &quot;rotation matrix =\\n&quot; &lt;&lt; rotation_vector.matrix() &lt;&lt; endl; //用matrix()转换成矩阵 // 也可以直接赋值 rotation_matrix = rotation_vector.toRotationMatrix(); // 用 AngleAxis 可以进行坐标变换 Vector3d v(1, 0, 0); Vector3d v_rotated = rotation_vector * v; cout &lt;&lt; &quot;(1,0,0) after rotation (by angle axis) = &quot; &lt;&lt; v_rotated.transpose() &lt;&lt; endl; // 或者用旋转矩阵 v_rotated = rotation_matrix * v; cout &lt;&lt; &quot;(1,0,0) after rotation (by matrix) = &quot; &lt;&lt; v_rotated.transpose() &lt;&lt; endl; // 欧拉角: 可以将旋转矩阵直接转换成欧拉角 Vector3d euler_angles = rotation_matrix.eulerAngles(2, 1, 0); // ZYX顺序，即yaw-pitch-roll顺序 cout &lt;&lt; &quot;yaw pitch roll = &quot; &lt;&lt; euler_angles.transpose() &lt;&lt; endl; // 欧氏变换矩阵使用 Eigen::Isometry Isometry3d T = Isometry3d::Identity(); // 虽然称为3d，实质上是4＊4的矩阵 T.rotate(rotation_vector); // 按照rotation_vector进行旋转 T.pretranslate(Vector3d(1, 3, 4)); // 把平移向量设成(1,3,4) cout &lt;&lt; &quot;Transform matrix = \\n&quot; &lt;&lt; T.matrix() &lt;&lt; endl; // 用变换矩阵进行坐标变换 Vector3d v_transformed = T * v; // 相当于R*v+t cout &lt;&lt; &quot;v tranformed = &quot; &lt;&lt; v_transformed.transpose() &lt;&lt; endl; // 对于仿射和射影变换，使用 Eigen::Affine3d 和 Eigen::Projective3d 即可，略 // 四元数 // 可以直接把AngleAxis赋值给四元数，反之亦然 Quaterniond q = Quaterniond(rotation_vector); cout &lt;&lt; &quot;quaternion from rotation vector = &quot; &lt;&lt; q.coeffs().transpose() &lt;&lt; endl; // 请注意coeffs的顺序是(x,y,z,w),w为实部，前三者为虚部 // 也可以把旋转矩阵赋给它 q = Quaterniond(rotation_matrix); cout &lt;&lt; &quot;quaternion from rotation matrix = &quot; &lt;&lt; q.coeffs().transpose() &lt;&lt; endl; // 使用四元数旋转一个向量，使用重载的乘法即可 v_rotated = q * v; // 注意数学上是qvq^{-1} cout &lt;&lt; &quot;(1,0,0) after rotation = &quot; &lt;&lt; v_rotated.transpose() &lt;&lt; endl; // 用常规向量乘法表示，则应该如下计算 cout &lt;&lt; &quot;should be equal to &quot; &lt;&lt; (q * Quaterniond(0, 1, 0, 0) * q.inverse()).coeffs().transpose() &lt;&lt; endl; return 0;} 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;using namespace std;using namespace Eigen;int main(int argc, char** argv) { Quaterniond q1(0.35, 0.2, 0.3, 0.1), q2(-0.5, 0.4, -0.1, 0.2); q1.normalize(); q2.normalize(); Vector3d t1(0.3, 0.1, 0.1), t2(-0.1, 0.5, 0.3); Vector3d p1(0.5, 0, 0.2); Isometry3d T1w(q1), T2w(q2); T1w.pretranslate(t1); T2w.pretranslate(t2); Vector3d p2 = T2w * T1w.inverse() * p1; cout &lt;&lt; endl &lt;&lt; p2.transpose() &lt;&lt; endl; return 0;}","link":"/2022/04/03/SLAM/ch3-%E4%B8%89%E7%BB%B4%E7%A9%BA%E9%97%B4%E7%9A%84%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"},{"title":"Ch5 相机和图像","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是视觉SLAM中的相机和图像问题，其中相机主要介绍的是简单的针孔相机模型，之后介绍了畸变的形成，然后介绍的RGBD相机和双目相机的简答原理。 相机模型针孔相机模型 现实生活中存在大量的照片 照片记录了真实世界在成像平面上的投影； 这个过程丢弃了“距离”维度上的信息； 普通相机可以用针孔模型很好地近似。 小孔成像模型，如图所示，主要的位置点有相机的中心O，焦距f，真实世界的点P，以及相机投影点P‘。 这里原始的成像关系为： \\dfrac Z f=-\\dfrac X {X'}=-\\dfrac Y {Y'} 这里我们为很实际的情况接轨，我们将其符号舍去，等价的吧成像平面对称的放到相机的前方，和三维的空间点在同一侧。 \\dfrac Z f=\\dfrac X {X'}=\\dfrac Y {Y'} 将上面的式子进行整理可得： X^{\\prime}=f\\dfrac X Z\\\\ Y^{\\prime}=f\\dfrac Y Z\\\\ 上面f的单位是米，但是实际上我们的照片都是以像素为单位的，于是这里涉及到像素坐标的转换关系，于是引入两个坐标系： 一个是物理空间的相机的坐标系O-X-Y ，其原点再光心O的位置，对应的是相机坐标$[X,Y]$和成像的坐标$[X^{\\prime},Y^{\\prime}]$。 另一个是像素空间的像素坐标系o-u-v ，其原点照片的左上角o的位置，对应的坐标为$[u,v]$。 像素坐标系和真实的物理坐标系之间相差一个缩放： \\left\\{ \\begin{array} &u=\\alpha X^{\\prime}+c_x\\\\ v=\\alpha Y^{\\prime}+c_y \\end{array}\\right.继续代入得到真实世界的物理坐标，将$\\alpha f \\rightarrow f_x$，$\\beta f \\rightarrow f_y$， \\left\\{ \\begin{array} &u=f_x\\dfrac X Z+c_x\\\\ v=f_y\\dfrac X Z+c_y \\end{array}\\right.这里$f_x,f_y,c_x,c_y$的像素，转化称为齐次坐标可得： \\left(\\begin{array}{l}u \\\\ v \\\\ 1\\end{array}\\right)=\\frac{1}{Z}\\left(\\begin{array}{ccc}f_{x} & 0 & c_{x} \\\\ 0 & f_{y} & c_{y} \\\\ 0 & 0 & 1\\end{array}\\right)\\left(\\begin{array}{l}X \\\\ Y \\\\ Z\\end{array}\\right) \\triangleq \\frac{1}{Z} \\boldsymbol{K} \\boldsymbol{P} 左侧为齐次坐标，右侧为非齐次坐标。 中间的矩阵K为相机的内参数矩阵，一般生产出厂就是给定了。 对相片进行的一些变换，那就是直接左内参矩阵上进行即可。 传统的写法是将Z写在前面，因为不管Z写在哪里，根据齐次坐标公式，最后的成像结果都是在同一个位置。 改变Z时，投影点仅为同一个点，因此还原只可以了解其投影距离，但是其距离信息未知。 Z\\left(\\begin{array}{l}u \\\\ v \\\\ 1\\end{array}\\right)=\\left(\\begin{array}{ccc}f_{x} & 0 & c_{x} \\\\ 0 & f_{y} & c_{y} \\\\ 0 & 0 & 1\\end{array}\\right)\\left(\\begin{array}{l}X \\\\ Y \\\\ Z\\end{array}\\right) \\triangleq \\boldsymbol{K} \\boldsymbol{P} 除内参外，相机坐标系与世界坐标系还相差一个变换： Z \\boldsymbol{P}_{u v}=Z\\left[\\begin{array}{l}u \\\\ v \\\\ 1\\end{array}\\right]=\\boldsymbol{K}\\left(\\boldsymbol{R} \\boldsymbol{P}_{\\mathrm{w}}+\\boldsymbol{t}\\right)=\\boldsymbol{K} \\boldsymbol{T} \\boldsymbol{P}_{\\mathrm{w}}先把P从世界坐标变到相机坐标系下，此时这里的$R,t$或者$T$称为相机的外参，内参一般标定后不变，外参会随着运动不断变化，外参时SLAM估计的目标。 注意，式子的右侧包含了一个非齐次到齐次的变换。 $\\left(\\boldsymbol{R} \\boldsymbol{P}_{\\mathrm{w}}+\\boldsymbol{t}\\right) \\rightarrow [x,y,z]^T \\rightarrow [x/z,y/z,1]^T$ 世界$\\rightarrow$相机$\\rightarrow$归一化平面$\\rightarrow$ 像素 相机的畸变造成畸变的几个原因： 透镜自身的形状对光线传播的影响，对应的是径向畸变。 在机械组装过程中，透镜和成像平面不可能完全平行，这也会使的光线穿过透镜到成像面时的位置发生变化，对应的畸变是切向畸变。 径向畸变：主要有两种形式，桶形畸变和枕形畸变。 主要特点：越靠近图像的边缘就变形越明显，表现是从直线变为了曲线，畸变呈现中心对称性。 桶形畸变：随着与光轴距离的增加，放大率逐渐减少。 枕形畸变：随着与光轴距离的减小，放大率逐渐变大。 可以看出，四个角的放大率要比中间的边缘大/小，因为其到光轴的距离要比中间边缘小。 切向畸变：因为透镜的安装位置造成的。 畸变的数学表述 径向畸变的数学表述如下： x_{\\text {distorted }}=x\\left(1+k_{1} r^{2}+k_{2} r^{4}+k_{3} r^{6}\\right)\\\\y_{\\text {distorted }}=y\\left(1+k_{1} r^{2}+k_{2} r^{4}+k_{3} r^{6}\\right)其中，$[x,y]^T$ 表示的是归一化坐标系的上的一点 p ，$[r,\\theta]$ 表示的是p点在极坐标的坐标，通常我们使用多项式来进行拟合。 切向畸变的数学表达： x_{\\text {distorted }}=x+2 p_{1} x y+p_{2}\\left(r^{2}+2 x^{2}\\right)\\\\y_{\\text {distorted }}=y+p_{1}\\left(r^{2}+2 y^{2}\\right)+2 p_{2} x y其中，$p_1,p_2$ 为修正系数。 实际使用时，我们需要5个参数就可以进行修正： 将三维空间点投影到归一化平面。设它的归一化坐标的为$[x,y]^T$。 对归一化的平面上的点进行计算径向畸变和切向畸变。 \\left\\{\\begin{array}{l}x_{\\text {distorted }}=x\\left(1+k_{1} r^{2}+k_{2} r^{4}+k_{3} r^{6}\\right)+2 p_{1} x y+p_{2}\\left(r^{2}+2 x^{2}\\right) \\\\ y_{\\text {dstorted }}=y\\left(1+k_{1} r^{2}+k_{2} r^{4}+k_{3} r^{6}\\right)+p_{1}\\left(r^{2}+2 y^{2}\\right)+2 p_{2} x y\\end{array}\\right. 将畸变后的点通过相机内参矩阵投影到像素平面，得到该点在图像上的正确位置。 \\left\\{ \\begin{array} &u=f_xx_{\\text {distorted }}+c_x\\\\ v=f_yy_{\\text {distorted }}+c_y \\end{array}\\right. 小结 双目相机模型原理：通过两个相机之间的视差来估计每个像素的深度。 双目相机的成像模型。$O_L,O_R$为左右光圈中心，方框为成像平面，f 为焦距。$u_L$和$u_R$为成像平面的坐标。请注意，按照图中坐标定义，$u_R$应该是负数，所以图中标出的距离为$-u_R$ 。 在左右双目相机中，我们可以把两个相机都看作针孔相机。它们是水平放置的，意味着两个相机的光圈中心都位于x轴上。两个相机的光圈之间的距离称为双目相机的基线（记作b)，是双目相机的重要参数。 根据几何关系$\\triangle PP_LP_R \\ \\sim \\ \\triangle PO_LO_R$ 可得： \\dfrac {z-f}{z} = \\dfrac {b-u_L+u_R}{b} \\Rightarrow z=\\dfrac {fd}{d},d\\triangleq u_L- u_R其中d定义为左右图的横坐标之差，称为视差。 视差越大的距离越近。 由于最小视差为一个像素，于是双目相机的深度存在一个理论的最大值，由$fb$ 来确定。 基线b越长，双目可以测到的最大距离就越远。 主要的困难时，如何分辨左图上的某的特征在右图的什么位置上面，一般要由很好的纹理特征才可以实现。 RGBD相机模型RGBD相机主要有两种，一种时基于红外结构光的，另一种时基于飞行时间ToF的，起主要的原理为： 红外结构光的原理：给定一种具有特定形状的光，如直线形状，当其照射到一般的圆柱面并反射回来时，会出现形状的改变，通过形状的变化情况来确定距离。反射前后之间的对比需要计算。 ToF的原理：其实和激光传感器类似，都是发射激光，测量返回时间进而根据距离$d=2c\\Delta t$ 来进行计算。不同的是，ToF发射的是面光源，而激光传感器是点光源。 相机在出厂的时候会将产生的深度图和彩色图进行配对和标定。 之后我们可以对图像读取器彩色和深度信息，计算其像素的3D位置，生成点云数据。 RGBD相机的缺点： 对环境的要求比较高，只能在室内使用，因为日光和其他的传感器会互相干扰。 对于透明材质，如玻璃会透射反射光，和一些会吸收反射光的材料，是无法测到其点云数据的。 图像如果有过使用Opencv基础的，本节的内容将会简单。 首先，相机在成完像之后就生成的图像。 之后，就是图像的存储，一般图像在计算机中的储存形式为二维数组的形式。 对于一个灰度图来说，$I(x,y)$表示x列y行的像素对于的灰度，有8位。 注意 X -&gt; 列数 -&gt; 宽度，Y -&gt; 行数 -&gt; 高度。 对于深度图来说，每个位置上的存储量不足，因此要扩大存储量到16位。 对于彩色图来说，有三个通道RGB，需要24位。 需要对感光度量化成数值，例如0~255之间的整数（彩色图像还有通道） 存储图像，首先记住每个像素的具体位数，其次记住每个像素的RGBDA的排列方式。 代码实践Opencv的安装1sudo apt-get ... 使用apt-get安装，速度很快，但是缺点是： 其一是版本可能受到系统的限制会很老，不是最新版； 其二就是apt-get是将源码直接编译好了来用的，没有源文件，只有生成好的二进制文件。 使用sourse来安装，最后保存的位置是自己定义文件的位置，而apt-get保存到系统指定的位置去了。https://opencv.org/releases/ 到Opencv的官网上下载源代码，然后自己cmake，之后再make -j4. 缺点就是编译时间过于的长。 相关的参考资料：https://docs.opencv.org/4.5.4/d9/df8/tutorial_root.html 实践之前首先改好CMakeList.txt文件 123456789project(imageBasics)add_executable(imageBasics imageBasics.cpp)# 链接OpenCV库target_link_libraries(imageBasics ${OpenCV_LIBS})add_executable(undistortImage undistortImage.cpp)# 链接OpenCV库target_link_libraries(undistortImage ${OpenCV_LIBS}) 实践1：图片的读取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;int main(int argc, char **argv) { // 读取argv[1]指定的图像 cv::Mat image; image = cv::imread(argv[1]); //cv::imread函数读取指定路径下的图像 // 判断图像文件是否正确读取 if (image.data == nullptr) { //数据不存在,可能是文件不存在 cerr &lt;&lt; &quot;文件&quot; &lt;&lt; argv[1] &lt;&lt; &quot;不存在.&quot; &lt;&lt; endl; return 0; } // 文件顺利读取, 首先输出一些基本信息 cout &lt;&lt; &quot;图像宽为&quot; &lt;&lt; image.cols &lt;&lt; &quot;,高为&quot; &lt;&lt; image.rows &lt;&lt; &quot;,通道数为&quot; &lt;&lt; image.channels() &lt;&lt; endl; cv::imshow(&quot;image&quot;, image); // 用cv::imshow显示图像 cv::waitKey(0); // 暂停程序,等待一个按键输入 // 判断image的类型 if (image.type() != CV_8UC1 &amp;&amp; image.type() != CV_8UC3) { // 图像类型不符合要求 cout &lt;&lt; &quot;请输入一张彩色图或灰度图.&quot; &lt;&lt; endl; return 0; } // 遍历图像, 请注意以下遍历方式亦可使用于随机像素访问 // 使用 std::chrono 来给算法计时 chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); for (size_t y = 0; y &lt; image.rows; y++) { // 用cv::Mat::ptr获得图像的行指针 unsigned char *row_ptr = image.ptr&lt;unsigned char&gt;(y); // row_ptr是第y行的头指针 for (size_t x = 0; x &lt; image.cols; x++) { // 访问位于 x,y 处的像素 unsigned char *data_ptr = &amp;row_ptr[x * image.channels()]; // data_ptr 指向待访问的像素数据 // 输出该像素的每个通道,如果是灰度图就只有一个通道 for (int c = 0; c != image.channels(); c++) { unsigned char data = data_ptr[c]; // data为I(x,y)第c个通道的值 } } } chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast &lt; chrono::duration &lt; double &gt;&gt; (t2 - t1); cout &lt;&lt; &quot;遍历图像用时：&quot; &lt;&lt; time_used.count() &lt;&lt; &quot; 秒。&quot; &lt;&lt; endl; // 关于 cv::Mat 的拷贝 // 直接赋值并不会拷贝数据 cv::Mat image_another = image; // 修改 image_another 会导致 image 发生变化 image_another(cv::Rect(0, 0, 100, 100)).setTo(0); // 将左上角100*100的块置零 cv::imshow(&quot;image&quot;, image); cv::waitKey(0); // 使用clone函数来拷贝数据 cv::Mat image_clone = image.clone(); image_clone(cv::Rect(0, 0, 100, 100)).setTo(255); cv::imshow(&quot;image&quot;, image); cv::imshow(&quot;image_clone&quot;, image_clone); cv::waitKey(0); // 对于图像还有很多基本的操作,如剪切,旋转,缩放等,限于篇幅就不一一介绍了,请参看OpenCV官方文档查询每个函数的调用方法. cv::destroyAllWindows(); return 0;} 实践2：畸变去除123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;opencv2/opencv.hpp&gt;#include &lt;string&gt;using namespace std;string image_file = &quot;./distorted.png&quot;; // 请确保路径正确int main(int argc, char **argv) { // 本程序实现去畸变部分的代码。尽管我们可以调用OpenCV的去畸变，但自己实现一遍有助于理解。 // 畸变参数 double k1 = -0.28340811, k2 = 0.07395907, p1 = 0.00019359, p2 = 1.76187114e-05; // 内参 double fx = 458.654, fy = 457.296, cx = 367.215, cy = 248.375; cv::Mat image = cv::imread(image_file, 0); // 图像是灰度图，CV_8UC1 int rows = image.rows, cols = image.cols; cv::Mat image_undistort = cv::Mat(rows, cols, CV_8UC1); // 去畸变以后的图 // 计算去畸变后图像的内容 for (int v = 0; v &lt; rows; v++) { for (int u = 0; u &lt; cols; u++) { // 按照公式，计算点(u,v)对应到畸变图像中的坐标(u_distorted, v_distorted) double x = (u - cx) / fx, y = (v - cy) / fy; double r = sqrt(x * x + y * y); double x_distorted = x * (1 + k1 * r * r + k2 * r * r * r * r) + 2 * p1 * x * y + p2 * (r * r + 2 * x * x); double y_distorted = y * (1 + k1 * r * r + k2 * r * r * r * r) + p1 * (r * r + 2 * y * y) + 2 * p2 * x * y; double u_distorted = fx * x_distorted + cx; double v_distorted = fy * y_distorted + cy; // 赋值 (最近邻插值) if (u_distorted &gt;= 0 &amp;&amp; v_distorted &gt;= 0 &amp;&amp; u_distorted &lt; cols &amp;&amp; v_distorted &lt; rows) { image_undistort.at&lt;uchar&gt;(v, u) = image.at&lt;uchar&gt;((int) v_distorted, (int) u_distorted); } else { image_undistort.at&lt;uchar&gt;(v, u) = 0; } } } // 画图去畸变后图像 cv::imshow(&quot;distorted&quot;, image); cv::imshow(&quot;undistorted&quot;, image_undistort); cv::waitKey(); return 0;} 实践3：双目相机的拼接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;opencv2/opencv.hpp&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;Eigen/Core&gt;#include &lt;pangolin/pangolin.h&gt;#include &lt;unistd.h&gt;using namespace std;using namespace Eigen;// 文件路径string left_file = &quot;./left.png&quot;;string right_file = &quot;./right.png&quot;;// 在pangolin中画图，已写好，无需调整void showPointCloud( const vector&lt;Vector4d, Eigen::aligned_allocator&lt;Vector4d&gt;&gt; &amp;pointcloud);int main(int argc, char **argv) { // 内参 double fx = 718.856, fy = 718.856, cx = 607.1928, cy = 185.2157; // 基线 double b = 0.573; // 读取图像 cv::Mat left = cv::imread(left_file, 0); cv::Mat right = cv::imread(right_file, 0); cv::Ptr&lt;cv::StereoSGBM&gt; sgbm = cv::StereoSGBM::create( 0, 96, 9, 8 * 9 * 9, 32 * 9 * 9, 1, 63, 10, 100, 32); // 神奇的参数 cv::Mat disparity_sgbm, disparity; sgbm-&gt;compute(left, right, disparity_sgbm); disparity_sgbm.convertTo(disparity, CV_32F, 1.0 / 16.0f); // 生成点云 vector&lt;Vector4d, Eigen::aligned_allocator&lt;Vector4d&gt;&gt; pointcloud; // 如果你的机器慢，请把后面的v++和u++改成v+=2, u+=2 for (int v = 0; v &lt; left.rows; v++) for (int u = 0; u &lt; left.cols; u++) { if (disparity.at&lt;float&gt;(v, u) &lt;= 0.0 || disparity.at&lt;float&gt;(v, u) &gt;= 96.0) continue; Vector4d point(0, 0, 0, left.at&lt;uchar&gt;(v, u) / 255.0); // 前三维为xyz,第四维为颜色 // 根据双目模型计算 point 的位置 double x = (u - cx) / fx; double y = (v - cy) / fy; double depth = fx * b / (disparity.at&lt;float&gt;(v, u)); point[0] = x * depth; point[1] = y * depth; point[2] = depth; pointcloud.push_back(point); } cv::imshow(&quot;disparity&quot;, disparity / 96.0); cv::waitKey(0); // 画出点云 showPointCloud(pointcloud); return 0;}void showPointCloud(const vector&lt;Vector4d, Eigen::aligned_allocator&lt;Vector4d&gt;&gt; &amp;pointcloud) { if (pointcloud.empty()) { cerr &lt;&lt; &quot;Point cloud is empty!&quot; &lt;&lt; endl; return; } pangolin::CreateWindowAndBind(&quot;Point Cloud Viewer&quot;, 1024, 768); glEnable(GL_DEPTH_TEST); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); pangolin::OpenGlRenderState s_cam( pangolin::ProjectionMatrix(1024, 768, 500, 500, 512, 389, 0.1, 1000), pangolin::ModelViewLookAt(0, -0.1, -1.8, 0, 0, 0, 0.0, -1.0, 0.0) ); pangolin::View &amp;d_cam = pangolin::CreateDisplay() .SetBounds(0.0, 1.0, pangolin::Attach::Pix(175), 1.0, -1024.0f / 768.0f) .SetHandler(new pangolin::Handler3D(s_cam)); while (pangolin::ShouldQuit() == false) { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); d_cam.Activate(s_cam); glClearColor(1.0f, 1.0f, 1.0f, 1.0f); glPointSize(2); glBegin(GL_POINTS); for (auto &amp;p: pointcloud) { glColor3f(p[3], p[3], p[3]); glVertex3d(p[0], p[1], p[2]); } glEnd(); pangolin::FinishFrame(); usleep(5000); // sleep 5 ms } return;} 实践4：RGBD123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;boost/format.hpp&gt; // for formating strings#include &lt;pangolin/pangolin.h&gt;#include &lt;sophus/se3.hpp&gt;using namespace std;typedef vector&lt;Sophus::SE3d, Eigen::aligned_allocator&lt;Sophus::SE3d&gt;&gt; TrajectoryType;typedef Eigen::Matrix&lt;double, 6, 1&gt; Vector6d;// 在pangolin中画图，已写好，无需调整void showPointCloud( const vector&lt;Vector6d, Eigen::aligned_allocator&lt;Vector6d&gt;&gt; &amp;pointcloud);int main(int argc, char **argv) { vector&lt;cv::Mat&gt; colorImgs, depthImgs; // 彩色图和深度图 TrajectoryType poses; // 相机位姿 ifstream fin(&quot;./pose.txt&quot;); if (!fin) { cerr &lt;&lt; &quot;请在有pose.txt的目录下运行此程序&quot; &lt;&lt; endl; return 1; } for (int i = 0; i &lt; 5; i++) { boost::format fmt(&quot;./%s/%d.%s&quot;); //图像文件格式 colorImgs.push_back(cv::imread((fmt % &quot;color&quot; % (i + 1) % &quot;png&quot;).str())); depthImgs.push_back(cv::imread((fmt % &quot;depth&quot; % (i + 1) % &quot;pgm&quot;).str(), -1)); // 使用-1读取原始图像 double data[7] = {0}; for (auto &amp;d:data) fin &gt;&gt; d; Sophus::SE3d pose(Eigen::Quaterniond(data[6], data[3], data[4], data[5]), Eigen::Vector3d(data[0], data[1], data[2])); poses.push_back(pose); } // 计算点云并拼接 // 相机内参 double cx = 325.5; double cy = 253.5; double fx = 518.0; double fy = 519.0; double depthScale = 1000.0; vector&lt;Vector6d, Eigen::aligned_allocator&lt;Vector6d&gt;&gt; pointcloud; pointcloud.reserve(1000000); for (int i = 0; i &lt; 5; i++) { cout &lt;&lt; &quot;转换图像中: &quot; &lt;&lt; i + 1 &lt;&lt; endl; cv::Mat color = colorImgs[i]; cv::Mat depth = depthImgs[i]; Sophus::SE3d T = poses[i]; for (int v = 0; v &lt; color.rows; v++) for (int u = 0; u &lt; color.cols; u++) { unsigned int d = depth.ptr&lt;unsigned short&gt;(v)[u]; // 深度值 if (d == 0) continue; // 为0表示没有测量到 Eigen::Vector3d point; point[2] = double(d) / depthScale; point[0] = (u - cx) * point[2] / fx; point[1] = (v - cy) * point[2] / fy; Eigen::Vector3d pointWorld = T * point; Vector6d p; p.head&lt;3&gt;() = pointWorld; p[5] = color.data[v * color.step + u * color.channels()]; // blue p[4] = color.data[v * color.step + u * color.channels() + 1]; // green p[3] = color.data[v * color.step + u * color.channels() + 2]; // red pointcloud.push_back(p); } } cout &lt;&lt; &quot;点云共有&quot; &lt;&lt; pointcloud.size() &lt;&lt; &quot;个点.&quot; &lt;&lt; endl; showPointCloud(pointcloud); return 0;}void showPointCloud(const vector&lt;Vector6d, Eigen::aligned_allocator&lt;Vector6d&gt;&gt; &amp;pointcloud) { if (pointcloud.empty()) { cerr &lt;&lt; &quot;Point cloud is empty!&quot; &lt;&lt; endl; return; } pangolin::CreateWindowAndBind(&quot;Point Cloud Viewer&quot;, 1024, 768); glEnable(GL_DEPTH_TEST); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); pangolin::OpenGlRenderState s_cam( pangolin::ProjectionMatrix(1024, 768, 500, 500, 512, 389, 0.1, 1000), pangolin::ModelViewLookAt(0, -0.1, -1.8, 0, 0, 0, 0.0, -1.0, 0.0) ); pangolin::View &amp;d_cam = pangolin::CreateDisplay() .SetBounds(0.0, 1.0, pangolin::Attach::Pix(175), 1.0, -1024.0f / 768.0f) .SetHandler(new pangolin::Handler3D(s_cam)); while (pangolin::ShouldQuit() == false) { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); d_cam.Activate(s_cam); glClearColor(1.0f, 1.0f, 1.0f, 1.0f); glPointSize(2); glBegin(GL_POINTS); for (auto &amp;p: pointcloud) { glColor3d(p[3] / 255.0, p[4] / 255.0, p[5] / 255.0); glVertex3d(p[0], p[1], p[2]); } glEnd(); pangolin::FinishFrame(); usleep(5000); // sleep 5 ms } return;}","link":"/2022/04/03/SLAM/ch5-%E7%9B%B8%E6%9C%BA%E5%92%8C%E5%9B%BE%E5%83%8F/"},{"title":"Ch6 非线性优化 基础理论部分","text":"hljs.initHighlightingOnLoad(); 在之前ch3、ch4中，主要介绍了运动方程的具体的形式，之后的ch5中主要基于针孔相机模型建立了一种观测模型，既然两个模型都已经建立完整。 \\boldsymbol x_{k+1}=f(\\boldsymbol x_k,\\boldsymbol u_k,\\boldsymbol \\omega_k) \\\\ \\boldsymbol z_{k,j}=h(\\boldsymbol x_k,\\boldsymbol y_j,\\boldsymbol v_{k,j})于是本讲开始主要介绍如何对非线性的状态空间进行状态估计，但是由于噪声的影响，对于状态的估计需要一定的优化的基础，因此本节主要介绍非线性优化以及状态估计的内容，并且介绍两个在非线性优化中比较常用的两个库，Ceres和g2o库。 状态估计问题批量估计和最大后验估计问题表述首先，我们回顾第二讲中那个经典的SLAM模型，由一个运动方程和一个观测方程组成： \\boldsymbol x_{k+1}=f(\\boldsymbol x_k,\\boldsymbol u_k)+\\boldsymbol \\omega_k \\\\ \\boldsymbol z_{k,j}=h(\\boldsymbol x_k,\\boldsymbol y_j)+\\boldsymbol v_{k,j}其中，这里的 $\\boldsymbol x_k$ 代表相机的真实位姿，一般使用$SE(3)$ 来表示，运动方程其实对于视觉SLAM来说，都一般的方程差不多，暂时书里也没说太详细。 观测方程就针孔模型的方程，这里假设 $\\boldsymbol x_k$ 处对路标的 $\\boldsymbol y_j$ 进行一次观测，对于在图像上的位置$\\boldsymbol z_{k,j}$ ，此时观测方程为： s\\boldsymbol z_{k,j}=\\boldsymbol K(\\boldsymbol R_k \\boldsymbol y_j+\\boldsymbol t_k)其中，这里的通过第五讲可知是个归一化的参数(第五讲中是Z，但是这里Z已经用过了，就用s)。K是内参矩阵。 对于上述的问题有两种可能的情况： 最简单的情况：线性系统，高斯噪声；kalmen filter 可以很好的解决这一类的问题。 复杂的情况：非线性系统，非高斯噪声；这个问题很难解决，但也最贴近最真实的情况，而且控制专业会讲解这里包含的很多的情况。 一般情况下，还是假设两个的噪声满足高斯分布： \\boldsymbol \\omega_k \\sim \\mathcal N(\\boldsymbol 0,\\boldsymbol R_k)\\ ,\\boldsymbol v_k \\sim \\mathcal N(\\boldsymbol 0,\\boldsymbol Q_{k,j}), 因此状态估计问题就是通过带有噪声的数据$\\boldsymbol z, \\boldsymbol u$来估计位姿$\\boldsymbol x$ 和地图$\\boldsymbol y$ 。 求解方法主要的求解方法由两种，一个是增量(incremental)的方法，另一个是批量(batch)的方法。 增量法又叫滤波器，其满足组马尔可夫性(其实卡尔曼滤波器就是线性高斯模型，就是HMM隐马尔可夫模型)，现在用的比较少了。 批量法就是通过攒数据，一起处理，预测的是这一段时间内的情况。极端情况就是sfm里，将将所有的情况全部取完之后再进行估计。 但是SLAM还是要一定的实时性，因此采取滑动窗口法，对当前时刻一定的历史数据进行优化。 下面主要介绍的是批量的方法，滤波法见第十章。 首先，考虑从1到N的所有时刻，其中包含有一些M个路标信息。 \\boldsymbol x=\\{ x_1, x_2,...,x_N\\},\\ \\boldsymbol y=\\{ y_1, y_2,...,y_M\\} 当我们忽略运动方程，即忽略u，之后忽略时间序列性，将输入看成一些的图片，于是问题就转化称为SFM问题，即根据一系列的点进行三维重建。 此时问题转换为求解 $P(x,y\\mid z,u)$，但是其分布很能求解。 之后，忽略运行方程，并将输入位姿和路标信息合并为$\\boldsymbol x$ ,为了估计上述的分布，我们使用了贝叶斯方法： P(\\boldsymbol{x}, \\boldsymbol{y} \\mid \\boldsymbol{z}, \\boldsymbol{u})=\\frac{P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y}) P(\\boldsymbol{x}, \\boldsymbol{y})}{P(\\boldsymbol{z}, \\boldsymbol{u})} \\propto \\underbrace{P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y})}_{\\text {似然 }} \\underbrace{P(\\boldsymbol{x}, \\boldsymbol{y})}_{\\text {先验 }} .简化之后可得： P(\\boldsymbol{x} \\mid \\boldsymbol{z})=\\frac{P(\\boldsymbol{z} \\mid \\boldsymbol{x}) P(\\boldsymbol{x})}{P(\\boldsymbol{z})} \\propto \\underbrace{P(\\boldsymbol{z} \\mid \\boldsymbol{x})}_{\\text {似然 }} \\underbrace{P(\\boldsymbol{x})}_{\\text {先验 }} .贝叶斯法则左侧称为后验概率，右侧的$P(z|x)$称为似然(（Likehood )，另一部分$P(x)$称为先验( Prior )。 直接求后验分布是困难的，但是求一个状态最优估计，使得在该状态下后验概率最大化，则是可行的，以下为最大后验估计(MAP)： (\\boldsymbol{x}, \\boldsymbol{y})^{*}{ }_{\\mathrm{MAP}}=\\arg \\max P(\\boldsymbol{x}, \\boldsymbol{y} \\mid \\boldsymbol{z}, \\boldsymbol{u})=\\arg \\max P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y}) P(\\boldsymbol{x}, \\boldsymbol{y}).但当我们不知道先验信息时，可以求解最大似然估计(MLE)： (\\boldsymbol{x}, \\boldsymbol{y})^{*}{ }_{\\mathrm{MLE}}=\\arg \\max P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y}).由于我们知道观测数据 $\\boldsymbol z, \\boldsymbol u$ ,最大似然可以理解成：在什么样的状态下，最可能产生现在观测到的数据。 最小二乘的引出在高斯分布的假设下，最大似然估计有比较简单的形式。回顾观测模型，对某一次估计有： \\boldsymbol z_{k,j}=h(\\boldsymbol x_k,\\boldsymbol y_j)+\\boldsymbol v_{k,j}其中假设噪声项符合高斯分布$\\boldsymbol v_k \\sim \\mathcal N(\\boldsymbol 0,\\boldsymbol Q_{k,j})$ ，于是观测数据的条件概率分布依然为一个高斯分布，表达式为： P(\\boldsymbol z_{k,j} \\mid x_k,y_j)=\\mathcal N(h(\\boldsymbol x_k,\\boldsymbol y_j),\\boldsymbol Q_{k,j})对于一般的高斯分布： P(\\boldsymbol{x})=\\frac{1}{\\sqrt{(2 \\pi)^{N} \\operatorname{det}(\\boldsymbol{\\Sigma})}} \\exp \\left(-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})\\right) 写成负对数形式可得： -\\ln (P(\\boldsymbol{x}))=\\frac{1}{2} \\ln \\left((2 \\pi)^{N} \\operatorname{det}(\\boldsymbol{\\Sigma})\\right)+\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) .其中，第一项为常数，只有第二项和我们的$x$有关，这样可以将原问题转化成负对数最小化，即对一个二次型进行最小化。 此时，原问题的最大似然为： \\begin{align} \\left(\\boldsymbol{x}_{k}, \\boldsymbol{y}_{j}\\right)^{*}&=\\arg \\max \\mathcal{N}\\left(h\\left(\\boldsymbol{y}_{j}, \\boldsymbol{x}_{k}\\right), \\boldsymbol{Q}_{k, j}\\right) \\\\ &=\\arg \\min \\left(\\left(\\boldsymbol{z}_{k, j}-h\\left(\\boldsymbol{x}_{k}, \\boldsymbol{y}_{j}\\right)\\right)^{\\mathrm{T}} \\boldsymbol{Q}_{k, j}^{-1}\\left(\\boldsymbol{z}_{k, j}-h\\left(\\boldsymbol{x}_{k}, \\boldsymbol{y}_{j}\\right)\\right)\\right) . \\end{align}考虑批量输入的数据，假设输入$x_k$ 和 观测$z_{k,j}$之间是相互独立的，同时同一批次的数据之间相互也是独立的，于是可得： P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y})=\\prod_{k} P\\left(\\boldsymbol{u}_{k} \\mid \\boldsymbol{x}_{k-1}, \\boldsymbol{x}_{k}\\right) \\prod_{k, j} P\\left(\\boldsymbol{z}_{k, j} \\mid \\boldsymbol{x}_{k}, \\boldsymbol{y}_{j}\\right)根据假设和上面的公式可得： P(\\boldsymbol{z}, \\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y}) = P(\\boldsymbol{z} \\mid \\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{u})P(\\boldsymbol{u} \\mid \\boldsymbol{x}, \\boldsymbol{y})=P(\\boldsymbol{u} \\mid \\boldsymbol{x}) P(\\boldsymbol{z} \\mid \\boldsymbol{x}, \\boldsymbol{y})于是定义误差： e_{\\boldsymbol{u}, k}=\\boldsymbol{x}_{k}-f\\left(\\boldsymbol{x}_{k-1}, \\boldsymbol{u}_{k}\\right) \\\\\\boldsymbol{e}_{\\boldsymbol{z}, j, k}=\\boldsymbol{z}_{k, j}-h\\left(\\boldsymbol{x}_{k}, \\boldsymbol{y}_{j}\\right)则最小化误差的二范数可以转化为： \\min J(\\boldsymbol{x}, \\boldsymbol{y})=\\sum_{k} \\boldsymbol{e}_{\\boldsymbol{u}, k}^{\\mathrm{T}} \\boldsymbol{R}_{k}^{-1} \\boldsymbol{e}_{\\boldsymbol{u}, k}+\\sum_{k} \\sum_{j} \\boldsymbol{e}_{\\boldsymbol{z}, k, j}^{\\mathrm{T}} \\boldsymbol{Q}_{k, j}^{-1} \\boldsymbol{e}_{\\boldsymbol{z}, k, j}.这样就得到了一个最小二乘问题（Least Square Problem ),它的解等价于状态的最大似然估计。直观上看，由于噪声的存在，当我们把估计的轨迹与地图代入SLAM的运动、观测方程中时，它们并不会完美地成立。这时怎么办呢?我们对状态的估计值进行微调，使得整体的误差下降一些。当然，这个下降也有限度，它一般会到达一个极小值。这就是一个典型的非线性优化的过程。 对于SLAM而言，其LSP问题有一定的特殊性： 误差函数有多个误差的加权二次型组成。且由于独立性的特点，其关系式会比较稀疏。 使用李代数表示增量们不会引入新的约束，因此该问题为一个无约束的非线性优化，但是如果用旋转矩阵，那会引入新的约束。。。还是别用了。 由于其信息矩阵(协方差的逆)相当于误差的权重，因此误差的分布会对权重产生比较大的影响。 批量估计的案例 非线性最小二乘考虑最简单的最小二乘问题： \\min\\limits_{\\boldsymbol x}F(x)=\\dfrac 1 2 ||f(x)||^2_2\\ ,x\\in \\mathbb R^n其中，$f(x)$为非线性函数。 当函数的新是很简单时，可以直接求导，令导数为0得出极值点或鞍点。 \\dfrac {df} {dx} = 0 \\Rightarrow x_0但是，一般情况下，我们的不是$\\dfrac {df} {dx}$ 不好求，就是$\\dfrac {df} {dx}=0$方程不好解，于是解析解是不可能了，我们考虑数值解，通过给定一个初值，不断迭代来逼近。 于是问题转换为寻找合适的增量 $\\Delta x_k$ 。 但是，数值方法求得的是局部问题的最小，而非全局的最小。 一阶和二阶梯度法这里我们直接对目标函数整体进行泰勒展开的，这是用来去区别高斯牛顿法的。 现在处于第k次迭代，假设我们在$x_k$处，要寻找 $\\Delta x_k$ ,于是进行泰勒展开可得： F\\left(\\boldsymbol{x}_{k}+\\Delta \\boldsymbol{x}_{k}\\right) \\approx F\\left(\\boldsymbol{x}_{k}\\right)+\\boldsymbol{J}\\left(\\boldsymbol{x}_{k}\\right)^{\\mathrm{T}} \\Delta \\boldsymbol{x}_{k}+\\frac{1}{2} \\Delta \\boldsymbol{x}_{k}^{\\mathrm{T}} \\boldsymbol{H}\\left(\\boldsymbol{x}_{k}\\right) \\Delta \\boldsymbol{x}_{k} .其中，$\\boldsymbol{J}(x)$ 为雅可比矩阵，$\\boldsymbol{H}(x)$ 为海塞矩阵。 如果仅仅保留一阶梯度，那其增量的方向就为反向梯度的方向，即为$\\Delta x^=-\\boldsymbol J^T(x)$ ，并且还要计算步长，一阶方法又称*最速下降法。 \\min\\limits_{\\boldsymbol \\Delta x}||f(x)||^2_2 +\\boldsymbol J(x)\\Delta x 如果保留了二阶梯度，此时的增量方程为： \\Delta \\boldsymbol{x}^{*}=\\arg \\min \\left(F(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x})^{\\mathrm{T}} \\Delta \\boldsymbol{x}+\\frac{1}{2} \\Delta \\boldsymbol{x}^{\\mathrm{T}} \\boldsymbol{H} \\Delta \\boldsymbol{x}\\right) .对右侧求导并将其等于可得： \\boldsymbol{J}+\\boldsymbol{H} \\Delta \\boldsymbol{x}=\\mathbf{0} \\Rightarrow \\boldsymbol{H} \\Delta \\boldsymbol{x}=-\\boldsymbol{J}这种方法又称牛顿法。 两种方法十分直观，并且易于操作，但是也存在一定的问题： 对于最速下降法，其下降的时候过于贪婪，下降的轨迹呈现锯齿形，这样反而增多了迭代的次数，zigzag问题。 对于牛顿法，虽然其迭代次数减少了，但是一方面Hessian 矩阵不是很好获得，另一方面就是求解上面的方程难度较大，对于大规模的矩阵很难求解，如果矩阵为非奇异，那就会直接无解。 针对如何回避计算Hessian 矩阵的问题，有以下两种改进方法，Gauss-Newton 以及 Levenberg-Marquadt 方法。 Gauss-Newton法相比之前的牛顿法直接对$F(x)$进行展开，高斯牛顿法是先将里面的非线性函数进行一阶近似线性化操作： f(\\boldsymbol{x}+\\Delta \\boldsymbol{x}) \\approx f(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}其中$J(x)$ 是一个$n \\times1$的列向量，根据前面的框架，优化的目标变成使得 $||f(x+\\Delta x)||^2=||f(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}||^2$最小。 于是平方误差变为： \\begin{aligned}\\frac{1}{2}\\|f(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}\\|^{2} &=\\frac{1}{2}(f(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x})^{T}(f(\\boldsymbol{x})+\\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}) \\\\&=\\frac{1}{2}\\left(\\|f(\\boldsymbol{x})\\|_{2}^{2}+2 f(\\boldsymbol{x})^{T} \\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}+\\Delta \\boldsymbol{x}^{T} \\boldsymbol{J}(\\boldsymbol{x})^{T} \\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}\\right) .\\end{aligned}令关于 $\\Delta x $ 导数为零： \\boldsymbol{J}(\\boldsymbol{x})^{T} f(\\boldsymbol{x})+2 \\boldsymbol{J}(\\boldsymbol{x})^{T} \\boldsymbol{J}(\\boldsymbol{x}) \\Delta \\boldsymbol{x}=\\mathbf{0} \\\\ \\underbrace {\\boldsymbol{J}(\\boldsymbol{x})^{T} \\boldsymbol{J}(\\boldsymbol{x})}_{\\boldsymbol{H(x)}} \\Delta \\boldsymbol{x}=\\underbrace {-\\boldsymbol{J}(\\boldsymbol{x})^{T} f(\\boldsymbol{x})}_{\\boldsymbol{g(x)}}\\\\ \\Rightarrow \\boldsymbol{H}\\Delta x=\\boldsymbol{g}上述方程称为增量方程，又叫高斯牛顿方程和正规方程。 这里把左侧记作H是有意义的。对比牛顿法可见，高斯牛顿法用$JJ^T$作为牛顿法中二阶Hessian矩阵的近似，从而省略了计算H的过程。求解增量方程是整个优化问题的核心所在。如果我们能够顺利解出该方程，那么高斯牛顿法的算法步骤可以写成： 主要的问题： Gauss-Newton简单实用，但是没办法保证$H^{-1}$一定存在，因为$JJ^T$其实也只能保证是半正定的，而非正定的，因此可能会由于$JJ^T$的奇异或者病态而导致算法不收敛。 其次是就算保证收敛，也可能由于其步长太长而导致无法保证迭代收敛。 尽管有以上的问题，他在先搜索领域还是具有一定的指导意义，在其基础上出现了一大批的改进算法。 Levenberg-Marquadt 方法 G-N属于线搜索方法：先找到方向，再确定长度 L-M属于信赖区域方法（Trust Region），认为近似只在区域内二阶近似是可靠的，出了这个区域就会出现问题。 确定这个信赖区域的方法，就是比较我们的近似函数和实际函数的差别，如果差别小，即近似的效果好，于是要扩大近似的范围，否则就减小近似的范围。 \\rho=\\dfrac {f(\\boldsymbol x+\\boldsymbol {\\Delta x})-f(\\boldsymbol x)} {\\boldsymbol J(x)^T \\Delta x} $\\rho$的分子是实际函数下降的值，分母是近似模型下降的值。 如果$\\rho$接近于1，则近似是好的。 如果$\\rho$太小，说明实际减小的值远少于近似减小的值，则认为近似比较差，需要缩小近似范围。 反之，如果$\\rho$比较大，则说明实际下降的比预计的更大，我们可以放大近似范围。 在列文伯格提出的优化方法中，把$D$取成单位阵$I$，相当于直接把$△x_k$。约束在一个球中。 随后，马夸尔特提出将$D$取成非负数对角阵，即为一个椭球，实际中通常用$J^TJ$的对角元素平方根，使得在梯度小的维度上约束范围更大一些。 Trust Region内的优化，利用Lagrange乘子转化为无约束： \\min _{\\Delta \\boldsymbol{x}_{k}} \\frac{1}{2}\\left\\|f\\left(\\boldsymbol{x}_{k}\\right)+\\boldsymbol{J}\\left(\\boldsymbol{x}_{k}\\right) \\Delta \\boldsymbol{x}_{k}\\right\\|^{2}+\\frac{\\lambda}{2}\\|\\boldsymbol{D} \\Delta \\boldsymbol{x}\\|^{2} . 仍参照G-N展开，令拉格朗日函数关于$\\Delta x$的函数为0，可得增量方程为： \\left(\\boldsymbol{H}+\\lambda \\boldsymbol{D}^{T} \\boldsymbol{D}\\right) \\Delta \\boldsymbol{x}=\\boldsymbol{g} 考虑到简化的形式，在Levenberg方法中，这里令$D=I$可得： (\\boldsymbol{H}+\\lambda \\boldsymbol{I}) \\Delta \\boldsymbol{x}=\\boldsymbol{g} . 对于L-M法来说： 一方面，当参数入比较小时，$H$占主要地位,这说明二次近似模型在该范围内是比较好的，列文伯格—-马夸尔特方法更接近于高斯牛顿法。 另一方面，当入比较大时，入$I$占据主要地位，列文伯格一马夸尔特方法更接近于一阶梯度下降法（即最速下降)，这说明附近的二次近似不够好。 L-M方法的求解方式，可在一定程度上避免线性方程组的系数矩阵的非奇异和病态问题,提供更稳定、更准确的增量$\\Delta x_k$。 L-M法可以很好的保证增量方程的正定性，即认为近似只在一定的范围之内成立，如果近似不好则会缩小范围。 从增量方程的角度来看，可以看成是一阶和二阶的混合，其中Lagrange乘子控制着两边的权重。 小结： 非线性优化是个很大的主题，研究者们为之奋斗多年。 主要方法：最速下降、牛顿、G-N、L-M、DogLeg等，在实际的SLAM中，我们以G-N法和L-M法为主，优先使用的是G-N方法。 与线性规划不同，非线性需要针对具体问题具体分析。 问题非凸时，对初值敏感，会陷入局部最优。 目前没有非凸问题的通用最优值的寻找办法； 问题凸时，二阶方法通常一两步就能收敛。","link":"/2022/04/05/SLAM/ch6-%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96-%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/"},{"title":"Ch6 非线性优化 实践部分","text":"hljs.initHighlightingOnLoad(); 本节主要进项一个曲线拟合的小实验，来进一步了解最小二乘问题是求解方法，以下部分是本个项目的CMakelists.txt.本文主要实验三种方法实现，首先是基于Eigen3G-N法，之后是基于Ceres和g2o的LM法和GN法的具体实现。 12345678910111213141516171819202122232425262728293031cmake_minimum_required(VERSION 2.8)project(ch6)set(CMAKE_BUILD_TYPE Release)set(CMAKE_CXX_FLAGS &quot;-std=c++14 -O3&quot;)list(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)# OpenCVfind_package(OpenCV REQUIRED)include_directories(${OpenCV_INCLUDE_DIRS})# Ceresfind_package(Ceres REQUIRED)include_directories(${CERES_INCLUDE_DIRS})# g2ofind_package(G2O REQUIRED)include_directories(${G2O_INCLUDE_DIRS})# Eigeninclude_directories(&quot;/usr/include/eigen3&quot;)add_executable(gaussNewton gaussNewton.cpp)target_link_libraries(gaussNewton ${OpenCV_LIBS})add_executable(ceresCurveFitting ceresCurveFitting.cpp)target_link_libraries(ceresCurveFitting ${OpenCV_LIBS} ${CERES_LIBRARIES})add_executable(g2oCurveFitting g2oCurveFitting.cpp)target_link_libraries(g2oCurveFitting ${OpenCV_LIBS} ${G2O_CORE_LIBRARY} ${G2O_STUFF_LIBRARY}) 手写GN法考虑满足以下方程的曲线： y=\\exp(ax^2+bx+c)+\\omega其中，$a,b,c$为曲线的参数，$\\omega \\sim \\mathcal N(0,\\sigma^2)$ 为高斯噪声，这里我们先通过随机数生成器，先生成一些列的数据点，然后将数据点代入，使得问题转换成为一个最小二乘问题： \\min\\limits_{a,b,c} \\frac 1 2 \\sum\\limits_{i=1}^{N}||y_i-\\exp(ax_i^2+bx_i+c)||^2这里的带估计参数为$a,b,c$，相当于是已知$\\{\\boldsymbol x, \\boldsymbol y\\}$ 来求$a,b,c$ 的最可能的取值。 结合最开始讲最小二乘定义的误差函数： \\min J(\\boldsymbol{x}, \\boldsymbol{y})=\\sum_{k} \\boldsymbol{e}_{\\boldsymbol{u}, k}^{\\mathrm{T}} \\boldsymbol{R}_{k}^{-1} \\boldsymbol{e}_{\\boldsymbol{u}, k}=\\sum_{k}\\boldsymbol{e}_{\\boldsymbol{i}}^{\\mathrm{T}} \\boldsymbol{\\sigma}_{k}^{-2} \\boldsymbol{e}_{\\boldsymbol{i}}.其中，$e_i=y_i-\\exp(ax_i^2+bx_i+c)$,我们分别对三个参数求导可得： \\frac {\\partial e_i} {\\partial a} = -x_i^2 \\exp(ax_i^2+bx_i+c) \\\\ \\frac {\\partial e_i} {\\partial b} = -x_i \\exp(ax_i^2+bx_i+c) \\\\ \\frac {\\partial e_i} {\\partial c} = - \\exp(ax_i^2+bx_i+c)于是由$\\boldsymbol J_i=[\\dfrac {\\partial e_i} {\\partial a},\\dfrac {\\partial e_i} {\\partial b},\\dfrac {\\partial e_i} {\\partial c}]^T$ ，于是高斯牛顿法的增量方程为： \\left(\\sum\\limits_{i=1}^{100}\\boldsymbol J_i(\\sigma^2)^{-1}\\boldsymbol J_i \\right) \\Delta x_k =\\sum\\limits_{i=1}^{100}\\boldsymbol J_i(\\sigma^2)^{-1}e_i123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &lt;iostream&gt;#include &lt;chrono&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;Eigen/Core&gt;#include &lt;Eigen/Dense&gt;using namespace std;using namespace Eigen;int main(int argc, char **argv) { double ar = 1.0, br = 2.0, cr = 1.0; // 真实参数值 double ae = 2.0, be = -1.0, ce = 5.0; // 估计参数值 int N = 100; // 数据点 double w_sigma = 1.0; // 噪声Sigma值 double inv_sigma = 1.0 / w_sigma; cv::RNG rng; // OpenCV随机数产生器 vector&lt;double&gt; x_data, y_data; // 数据 for (int i = 0; i &lt; N; i++) { double x = i / 100.0; x_data.push_back(x); y_data.push_back(exp(ar * x * x + br * x + cr) + rng.gaussian(w_sigma * w_sigma)); } // 开始Gauss-Newton迭代 int iterations = 100; // 迭代次数 double cost = 0, lastCost = 0; // 本次迭代的cost和上一次迭代的cost chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); for (int iter = 0; iter &lt; iterations; iter++) { Matrix3d H = Matrix3d::Zero(); // Hessian = J^T W^{-1} J in Gauss-Newton Vector3d b = Vector3d::Zero(); // bias //初始化 cost 否则之进行一轮就break了，cost是累加的 cost = 0; // 遍历数据集，计算误差 for (int i = 0; i &lt; N; i++) { double xi = x_data[i], yi = y_data[i]; // 第i个数据点 double error = yi - exp(ae * xi * xi + be * xi + ce); Vector3d J; // 雅可比矩阵 J[0] = -xi * xi * exp(ae * xi * xi + be * xi + ce); // de/da J[1] = -xi * exp(ae * xi * xi + be * xi + ce); // de/db J[2] = -exp(ae * xi * xi + be * xi + ce); // de/dc H += inv_sigma * inv_sigma * J * J.transpose(); b += -inv_sigma * inv_sigma * error * J; cost += error * error; } // 求解线性方程 Hx=b // 参考教程 http://eigen.tuxfamily.org/dox/classEigen_1_1LDLT.html // 使用这个方法可能是因为其求解速度快 // Cholesky 分解 Vector3d dx = H.ldlt().solve(b); if (isnan(dx[0])) { cout &lt;&lt; &quot;result is nan!&quot; &lt;&lt; endl; break; } if (iter &gt; 0 &amp;&amp; cost &gt;= lastCost) { cout &lt;&lt; &quot;cost: &quot; &lt;&lt; cost &lt;&lt; &quot;&gt;= last cost: &quot; &lt;&lt; lastCost &lt;&lt; &quot;, break.&quot; &lt;&lt; endl; break; } ae += dx[0]; be += dx[1]; ce += dx[2]; lastCost = cost; cout &lt;&lt; &quot;total cost: &quot; &lt;&lt; cost &lt;&lt; &quot;, \\t\\tupdate: &quot; &lt;&lt; dx.transpose() &lt;&lt; &quot;\\t\\testimated params: &quot; &lt;&lt; ae &lt;&lt; &quot;,&quot; &lt;&lt; be &lt;&lt; &quot;,&quot; &lt;&lt; ce &lt;&lt; endl; } chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;solve time cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl; cout &lt;&lt; &quot;estimated abc = &quot; &lt;&lt; ae &lt;&lt; &quot;, &quot; &lt;&lt; be &lt;&lt; &quot;, &quot; &lt;&lt; ce &lt;&lt; endl; return 0;} 基于Ceres的曲线拟合其主要的实现是模板编程，泛化性很好但是可读性很差。Ceres求解的一般形式是带边界的核函数最小二乘： \\min\\limits_{x} \\frac 1 2 \\sum_i \\rho_i\\left(||f_i(x_{i1},...,x_{in})||^2 \\right)\\\\ s.t. l_j \\le x_j \\le u_j.其中，$x_1,…x_n$ 为优化的参数块/优化变量，$f_i$ 为代价函数/残差块，$l_j,u_j$为上界和下界，无限制时可以取$l_i=-\\infty,u_i=\\infty$ 。目标函数是经过一堆平方项经过一个核函数$\\rho(.)$ 求和做成。 为了让Ceres帮我们求解这个问题，我们需要做以下几件事: 定义每个参数块。参数块通常为平凡的向量,但是在SLAM里也可以定义成四元数、李代数这种特殊的结构。如果是向量，那么我们]需要为每个参数块分配。个double数组来存储变量的值。 定义残差块的计算方式。残差块通常关联若千个参数块，对它们进行一-些自定义的计算，然后返回残差值。Ceres对它们求平方和之后，作为目标函数的值。 残差块往往也需要定义雅可比的计算方式。在Ceres中，你可以使用它提供的“自动求导”功能，也可以手动指定雅可比的计算过程。如果要使用自动求导，那么残差块需要按照特定的写法书写:残差的计算过程应该是一个带模板的括号运算符。这一点我们通过例子来说明。 把所有的参数块和残差块加入Ceres定义的Problem对象中，调用Solve函数求解即可。求解之前，我们可以传人一些配置信息，例如迭代次数、终止条件等，也可以使用默认的配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;ceres/ceres.h&gt;#include &lt;chrono&gt;using namespace std;// 代价函数的计算模型struct CURVE_FITTING_COST { CURVE_FITTING_COST(double x, double y) : _x(x), _y(y) {} // 残差的计算 template&lt;typename T&gt; bool operator()( const T *const abc, // 模型参数，有3维 T *residual) const { residual[0] = T(_y) - ceres::exp(abc[0] * T(_x) * T(_x) + abc[1] * T(_x) + abc[2]); // y-exp(ax^2+bx+c) return true; } const double _x, _y; // x,y数据};int main(int argc, char **argv) { double ar = 1.0, br = 2.0, cr = 1.0; // 真实参数值 double ae = 2.0, be = -1.0, ce = 5.0; // 估计参数值 int N = 100; // 数据点 double w_sigma = 1.0; // 噪声Sigma值 double inv_sigma = 1.0 / w_sigma; cv::RNG rng; // OpenCV随机数产生器 vector&lt;double&gt; x_data, y_data; // 数据 for (int i = 0; i &lt; N; i++) { double x = i / 100.0; x_data.push_back(x); y_data.push_back(exp(ar * x * x + br * x + cr) + rng.gaussian(w_sigma * w_sigma)); } double abc[3] = {ae, be, ce}; // 构建最小二乘问题 ceres::Problem problem; for (int i = 0; i &lt; N; i++) { // 首先定义自动求导函数 ceres::AutoDiffCostFunction&lt;CURVE_FITTING_COST, 1, 3&gt; *costfunction = new ceres::AutoDiffCostFunction&lt;CURVE_FITTING_COST, 1, 3&gt;(new CURVE_FITTING_COST(x_data[i], y_data[i])); problem.AddResidualBlock(// 向问题中添加误差项 costfunction, nullptr, // 核函数，因为这里不怎么使用，为空 abc // 待估计参数，这里的数据类型是 ); } // 配置求解器 ceres::Solver::Options options; // 这里有很多配置项可以填 options.linear_solver_type = ceres::DENSE_NORMAL_CHOLESKY; // 增量方程如何求解 options.minimizer_progress_to_stdout = true; // 输出到cout ceres::Solver::Summary summary; // 优化信息 chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); ceres::Solve(options, &amp;problem, &amp;summary); // 开始优化 chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;solve time cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl; // 输出结果 cout &lt;&lt; summary.BriefReport() &lt;&lt; endl; cout &lt;&lt; &quot;estimated a,b,c = &quot;; for (auto a:abc) cout &lt;&lt; a &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; return 0;} 定义残差块的类。方法是书写-一个类(或结构体)，并在类中定义带模板参数的()运算符，这样该类就成为了一个拟函数( Functor)。这种定义方式使得Ceres可以像调用函数-样,对该类的某个对象(比如a)调用a()方法。事实上，Ceres会把雅可比矩阵作为类型参数传人此函数，从而实现自动求导的功能。 程序中的double abc[3]即参数块，而对于残差块，我们对每一个数据构造CURVE_ FITTING_ COST对象，然后调用AddResidualBlock将误差项添加到目标函数中。由于优化需要梯度，我们有若干种选择: 使用Ceres的自动求导( AutoDiff)； 使用数值求导( Numeric Diff) ; 自行推导解析的导数形式，提供给Ceres。因为自动求导在编码上是最方便的，于是我们使用自动求导。 自动求导需要指定误差项和优化变量的维度。这里的误差是标量，维度为1；优化的是a,b,c三个量，维度为3。于是，在自动求导类AutoDiffCostFunction的模板参数中设定变量维度为1、3。 设定好问题后，调用Solve函数进行求解。你可以在options里配置(非常详细的)优化选项。例如，可以选择使用Line Search还是Trust Region、迭代次数、步长，等等。读者可以查看Options的定义，看看有哪些优化方法可选，当然默认的配置已经可用于很广泛的问题了。 基于G2O的曲线拟合非线性的最小二乘优化过程中，是由很多的误差项组成，但是我们尚不清楚这些误差项之间的一些关系，比如有些优化变量跨越了多个误差项，于是就有了图优化。 图优化的顶点表示优化变量，边代表误差项。于是就将我们的如构架成一个图，并且这个图和我们的最小二乘优化函数是一一对应的。 下图所示，三角形代表相机的位姿结点，圆形代表路标点，它们构建成了图优化的顶点。对于边来说，实线代表相机的运动模型，虚线代表观测方程。 对于曲线的拟合过程，整个问题由于只有一个误差项的表达式，整个模型的优化参数就只有一个向量$a,b,c$ ，于是误差项只有一条边，即一个一元边。 G2O的使用步骤大概为： 定义顶点和边的类型； 构建图； 选择优化算法； 调用g2o 进行优化，返回结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#include &lt;iostream&gt;#include &lt;g2o/core/g2o_core_api.h&gt;#include &lt;g2o/core/base_vertex.h&gt;#include &lt;g2o/core/base_unary_edge.h&gt;#include &lt;g2o/core/block_solver.h&gt;#include &lt;g2o/core/optimization_algorithm_levenberg.h&gt;#include &lt;g2o/core/optimization_algorithm_gauss_newton.h&gt;#include &lt;g2o/core/optimization_algorithm_dogleg.h&gt;#include &lt;g2o/solvers/dense/linear_solver_dense.h&gt;#include &lt;Eigen/Core&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;cmath&gt;#include &lt;chrono&gt;using namespace std;// 曲线模型的顶点，模板参数：优化变量维度和数据类型class CurveFittingVertex : public g2o::BaseVertex&lt;3, Eigen::Vector3d&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW // 重置 virtual void setToOriginImpl() override { _estimate &lt;&lt; 0, 0, 0; } // 更新 virtual void oplusImpl(const double *update) override { _estimate += Eigen::Vector3d(update); } // 存盘和读盘：留空 virtual bool read(istream &amp;in) {} virtual bool write(ostream &amp;out) const {}};// 误差模型 模板参数：观测值维度，类型，连接顶点类型class CurveFittingEdge : public g2o::BaseUnaryEdge&lt;1, double, CurveFittingVertex&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW CurveFittingEdge(double x) : BaseUnaryEdge(), _x(x) {} // 计算曲线模型误差 virtual void computeError() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); _error(0, 0) = _measurement - std::exp(abc(0, 0) * _x * _x + abc(1, 0) * _x + abc(2, 0)); } // 计算雅可比矩阵 virtual void linearizeOplus() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); double y = exp(abc[0] * _x * _x + abc[1] * _x + abc[2]); _jacobianOplusXi[0] = -_x * _x * y; _jacobianOplusXi[1] = -_x * y; _jacobianOplusXi[2] = -y; } virtual bool read(istream &amp;in) {} virtual bool write(ostream &amp;out) const {}public: double _x; // x 值， y 值为 _measurement};int main(int argc, char **argv) { double ar = 1.0, br = 2.0, cr = 1.0; // 真实参数值 double ae = 2.0, be = -1.0, ce = 5.0; // 估计参数值 int N = 100; // 数据点 double w_sigma = 1.0; // 噪声Sigma值 double inv_sigma = 1.0 / w_sigma; cv::RNG rng; // OpenCV随机数产生器 vector&lt;double&gt; x_data, y_data; // 数据 for (int i = 0; i &lt; N; i++) { double x = i / 100.0; x_data.push_back(x); y_data.push_back(exp(ar * x * x + br * x + cr) + rng.gaussian(w_sigma * w_sigma)); } // 构建图优化，先设定g2o typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;3, 1&gt;&gt; BlockSolverType; // 每个误差项优化变量维度为3，误差值维度为1 typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; // 线性求解器类型 // 梯度下降方法，可以从GN, LM, DogLeg 中选 auto solver = new g2o::OptimizationAlgorithmGaussNewton( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;())); g2o::SparseOptimizer optimizer; // 图模型 optimizer.setAlgorithm(solver); // 设置求解器 optimizer.setVerbose(true); // 打开调试输出 // 往图中增加顶点 CurveFittingVertex *v = new CurveFittingVertex(); v-&gt;setEstimate(Eigen::Vector3d(ae, be, ce)); v-&gt;setId(0); optimizer.addVertex(v); // 往图中增加边 for (int i = 0; i &lt; N; i++) { CurveFittingEdge *edge = new CurveFittingEdge(x_data[i]); edge-&gt;setId(i); edge-&gt;setVertex(0, v); // 设置连接的顶点 edge-&gt;setMeasurement(y_data[i]); // 观测数值 edge-&gt;setInformation(Eigen::Matrix&lt;double, 1, 1&gt;::Identity() * 1 / (w_sigma * w_sigma)); // 信息矩阵：协方差矩阵之逆 optimizer.addEdge(edge); } // 执行优化 cout &lt;&lt; &quot;start optimization&quot; &lt;&lt; endl; chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); optimizer.initializeOptimization(); optimizer.optimize(10); chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;solve time cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl; // 输出优化值 Eigen::Vector3d abc_estimate = v-&gt;estimate(); cout &lt;&lt; &quot;estimated model: &quot; &lt;&lt; abc_estimate.transpose() &lt;&lt; endl; return 0;} 在这个程序中，我们从g2o派生出了用于曲线拟合的图优化顶点和边: CurveFittingVertex 和CurveFittingEdge，这实质上扩展了g2o的使用方式。这两个类分别派生自BaseVertex和BaseU-naryEdge类。在派生类中，我们重写了重要的虚函数: 顶点的更新函数：oplusImpl。我们知道优化过程最重要的是增量$△x_k$的计算，而该函数处理的是$x_{k+1} =x_{k} +△x_k$的过程。 顶点的重置函数: setToOriginlmpl。 这是平凡的，我们把估计值置零即可。 边的误差计算函数：computeError。该函数需要取出边所连接的顶点的当前估计值，根据曲线模型，与它的观测值进行比较。这和最小二乘问题中的误差模型是一致的。 边的雅可比计算函数: linearizeOplus这个函数里我们计算了每条边相对于顶点的雅可比。 存盘和读盘函数: read、 write。由于我们并不想进行读/写操作，所以留空。定义了顶点和边之后,我们在main函数里声明了一个图模型，然后按照生成的噪声数据，往图模型中添加顶点和边，最后调用优化函数进行优化。","link":"/2022/04/06/SLAM/ch6-%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96-%E5%AE%9E%E8%B7%B5%E9%83%A8%E5%88%86/"},{"title":"自注意力机制Self Attention","text":"hljs.initHighlightingOnLoad(); 本文参考的是李宏毅的视频，主要讲解的是self-atttention机制的主要原理，因为其主要机制是transformer模型的重要的组成部分，本文从输入输出，以及关联度计算等方面进行详细的介绍。视频的具体链接：https://www.bilibili.com/video/BV1Wv411h7kN?p=39&amp;spm_id_from=pageDriver 模型的输入 问题的引入：针对输入的特征是一个长度可变的向量的问题，主要例子有： 文字处理，这里的输入是一系列的句子，且这些句子的长度是不一样的。比如可以将文字进行编码得到一个向量来表示词汇的信息，常见的方法有 one-hot编码和 word-embedding。 这里one-hot编码的维度是词袋里的所有的内容的个数，这样的缺点是编码向量的维度过于的长，其次是所有的词汇默认是相互独立的。 于是引入了Word-Embbeding的方法，这里嵌入了一些语义上的信息，可视化之后可见一些相似的词汇之间的距离是比较近的，聚集在一起的。 声音信号，其实就是一排向量，这里采用的是滑动的窗口法，每个窗口frame的长度是25ms的声音信号所携带的信息，每次滑动都移动10ms。 于是1s 的声音信号就蕴含着100个frames，即100个向量。 图，一个中的每个结点就对于一个向量，每个维度包含着人的各种属性信息。 分子，一个分子可以看作是一个图，使用one-hot编码向量来表示每个原子，这里是一个有机物的结构，将每个分子使用一个向量来表示。 模型的输出已知输入为不同的向量，那么输出对应长度的label(分类问题)、数值(回归)。 Each vector has a label.这里是每个向量都有一个Label其具体的例子有以下几个， 首先是词性的表达，就是输入是一个句子的，输出是一个每个单词对应的词性，前后有两个saw，但是其对应的词性是不同的。 之后是声音的辨识，就是将每一个声音向量的代表的信息进行输出。 The whole sequence has a label.这里是一整个序列都会对应一个label 第一个例子就是情感分析问题，输入时一个句子，即多个向量，输出时一个对应的情感的标签。 第二个例子就是语者辨认，就是输出说这句话的人。 第三个例子就是毒性的辨认，将化学结构的编码输入得出其有毒的概率或者是否有毒。 Model decides the number of labels itself.机器自主决定输出的结果的长度，这是典型的seq2seq模型。 以下将着重关注前两个问题。 Sequence Labeling 第一种解决问题的思路是使用一个Fully-Connected 网络来进行解释，但是对于两个输入相同的saw，使用这种方法得出的结果是相同的，那如何处理网络，使得网络可以学到上下文的信息？ 这个可以的，答案是将相邻的几个向量的结果都一同输入到神经网络中即可。 但是我们的句子的长度是不同的，有的长度长，有的长度短，如果取一个特别长的Window来包含的话会造成一定的浪费，而且可能会造成一定的过拟合。 之后就引出我们今天的主角self-attention，这个网络其实就是加入了一个Self-Attention层来考虑一整个句子的信息之后将输出的信息导入一个FC层。 但是Self-Attention的结构其实并不唯一，还可以将多个Self-Attention层和FC层进行交替叠加得出结果。 self-attention的机理接下来将具体的讲解self-attention的具体的产生机理，首先self-attention层的输入可能是原始的输入，也可能是某个隐藏层hidden layer。 首先，确定输入向量之间的关联性，如图所示是确定向量$a^1$和其他向量$a^2,a^3,a^4$的关联程度。那问题来了，用这个关联程度应该如何取量化？ 之后，计算关联程度，比较常见的做法Dot-product法和additive法。但是一般情况下，Dot-product法使用的比较多。 这里Dot-product首先将输入的词向量乘以一个变换矩阵，将得出的结果进行点成得出关联度的指标。 然后，有了关联度$\\alpha$的计算方法，我们之后带入到整个框架里计算。 这里我们要计算$a^1$和其他向量的关联性，于是将$a^1$乘以变化矩阵$W^q$得出query，其他的几个乘以$W^k$得出key，于是将$q^1$分别和$k^i\\ (i=2,3,4)$ 进行点乘可得每个的相似度。 但是单词一身的相似度也需要进行计算，因此$a^1$自己也要乘以$W^k$得出$k^1$然后将其和$q^1$进行点乘来计算自身的关联度。(自身的关联性计算其实很重要) 这边分类使用的是Softmax，当然其实Softmax其实不一定是最佳的，但是原论文使用的这个，也许Relu的效果也是不错的。 之后，根据计算的相似度来抽取其中蕴含的重要的咨询，将每个向量乘以$W^v$得出value值$v^i\\ (i=1,2,3,4)$ 。 这样计算得出的结果$b^1$会很趋向那个和$a^1$的相似度较大项对应的$v^i$ Value值，也就是提取出相似度最大项的信息。 最后，同理计算出其他的信息。这里的计算过程是并行的，对比LSTM的计算是顺序进行。 接下来从矩阵乘法的角度来重新理解上述的运算过程。 这里只有$W^q,W^k,W^v$ 的参数是需要学习才能得到参数。 Mult-head self-attention这里head数也是一个可控的超参数，对于语音辨识我们可以调高head数来得到更好的结果。 不同的head分别计算各自的结果，互不干扰。 最后，将不同head计算的结果乘以一个矩阵来进行拼接操作，合成一个$b^i$ 。 Positional Encoding 在一个句子中，是不会将谓语动词放到第一位的，这些信息就和位置编码有关系。于是要给自注意力机制增加位置编码。 位置信息其实就是一个$e^i$ ，直接加在$a^i$ 即可。 传统的位置信息就是给对应的位置加上一个1，其他的地方赋值为0即可。 不过这里是一行为一个position，要横着来看，第一个就是cos/sin编码。 Many applicationsSelf attention for Speech 对于语音信号而言，一小段话就会有很多的向量，刚才开始的时候也降了声音信号，其1s 就对于了100个向量，会造成计算的维度比较大，于是我们方法是使用Truncated seft-attention 的方法，每次计算只是关注一小段信号。 Self-attention for Image 这里每个向量就是一个像素点的RGB，一个有5*10个向量。 Self-attention v.s . CNN 这里CNN相比于真正的self-attention是一种在局部范围的简化，CNN其实只关注的是可信域之内的结果，是一种简化版的self-attention。 而self-attention考虑的可能是一种全局上面的CNN，是一种复杂化的卷积，可信域的范围是机器自动学习而不是人工划定的33，N N的范围。 对于通用性较强的model 需要跟更多的数据量才行，这里self attention使用较多的数据量才会有更好的结果，但是一般的CNN或者SVM这类模型就不太需要那么多的数据，而且也不容易overfitting. 对于RNN来说，对于距离较远的向量，有可能有信息的丢失，而且RNN没办法并行计算。 Self-attention for Graph 由于我们的图之间时具有一定的连接性，因此我们的方法是只是将一般的有相关性的结点进行计算关联度。","link":"/2022/04/09/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6Self-attention/"},{"title":"Transformer 基本知识","text":"hljs.initHighlightingOnLoad(); 总结来说，李宏毅这解课讲的优点科普，不如之前self-attention那节课讲得详细，因此简单了解以下即可，对于论文的一些问题建议直接看李沐来说的论文带读视频。 Sequence to sequence (Seq2seq)Input a sequence, output a sequence. The output length is determined by model. 这里根据输入和输出的长度来定义出不太的模型，之前的self-attention就是输入输出二的长度相同，但是输入的出度不确定。常见的形式有以下的几种： 首先，是语音辨识模型，输入的长度和输出完全不一样。 其次， 是翻译模型，输入和输出长度要机器自己来决定。 最后，是语音翻译模型，就是输入一种语言的声音，输出是另一种语言的文字，这样的话是能够解决很多没有文字的语言的保护和理解。 如果针对不同的使用情景使用不同的模型那么效果可能会好不少，相比所有的模型都是以相同的seq2seq的模型。 Seq2seq for Syntactic Parsing 比如对整个句子进行语法上的剖析，最后形成一个树状的结构其实就是一个seq2seq的模型。 Seq2seq for Multi label ClassificationMulti class Classification，相比之下不同的是，Multi class是一个传统的多分类的问题，但是Multi labels是一个样本可以属于多个类别。 由于每篇文章的对应的结果不同，可以属于一个，也可是多个，这个长度是不确定的。对应目标检测也可以使用seq2dqe模型。 Seq2seq for Object Detection Seq2seq 模型的基本原理 目前最火热的transformer模型其实就是一个典型的seq2seq模型。 下面我们将从Encoder和decoder两个方面来介绍之后其基本的原理。 Encoder其实就是input 一排向量，output另外的一排向量。 以下是encoder的内部的结构，是由多个block堆叠而成的结构，而每个block里面又是又seft-attention和FC层组成。 这里的transformer的结构是复杂化的，在原来的transformer里面其结构是更加复杂化的： 首先，其在输入部分就使用了residual 残差结构； 之后，使用Layer Norm 是将通过个向量的不同的dim进行计算的标准化。 Batch Norm 是将一个batch里面的向量，取同一个维度来进行标准化操作。 最后，在FC层也要使用residual，最后的输出也要进行Norm. 这里的Add &amp; Norm的意思是residual + Layer Norm层。 最后是对于模型的改进部分。 Decoder Autoregressive (AT) 这里的START 可能是one-hot编码； 输出是个向量，维度代表的是一个某个字输出的概率。 输入“机”，输出“器”。 接下来介绍的是Self-Attention的Decoder的具体结构，如下图所示。 相比之前的Encoder，Decoder比Encoder多一个Multi-Head Attention，其次是多一个Masked Multi-Head Attention的部分。下面将展示Masked Multi-Head Attention和一般的Multi-Head Attention的区别。 对于Masked self-attention来说，其输入只能和它之前的向量有关，使用它之前的向量进行计算，而不可以使用其之后的向量计算。 对于一般的self-attention来说，我们就按$a^2$时，将所有的$a^i$和计算相似度，但是对于mask self-attention时，我们的计算就变为，只计算$a^2$前面几项和$a^2$的相似度了。 但是我们的信号不可能这样一直无休止的进行下去，因此这里需要一个停止字符来讲上面的结果进行终止，有时候开始字符和停止字符是同一个字符。 以上是自回归Autoregressive的解码器，还有一种是非自回归的NAT non-Autoregressive (NAT) NAT是给一定数量的BEGIN 直接把要输出的内容全部的输出，但是问题是我们不知道要输入和输出的维度，主要的解决方法： 给足够的输入维度，对于输出而言，如果出现一个END，那么后面的内容就不要的，只保留前面的内容即可。 这个END的位置时有一个判别器来进行预测的。 这样就是可以直接达到期望的效果了。 NAT 的优点： NAT可以实现并行化，AT是结合了传统的RNN，因此不能并行化。 NAT可以控制输出的长度。 尽管NAT实现的热门，但是主要是NAT的效果不及那个AT，尽管计算速度更快。 Encoder-Decoder之间的交互 如图所示，在encoder中求取Key和Value，之后在decoder中解码query，然后进行相似度的计算并预测出下一个字的概率值。这部分就是Encoder和Decode的Cross-attention部分。 这里Cross-attention的出现时间Transformer更早的，在注意力交叉领域还有各种各样的形式，此处不在赘述。 Training 过程的介绍 这里，通过decoder预测得出一个分布，是用来预测下一个输出的字的，但是我们的Ground-truth是一系列的one-hot编码。通过最小的交叉商损失，使其最小化。注意最后一个字输入之后得出的输出是一个END。 当然这边很想一个分类的问题，这就是训练train原理。 在训练的时候，我们是将正确的答案作为输入来训练判别器。Teacher Forcing: using the ground truth as input. 这样做主要的问题是，在测试的时候，我们的decoder是看不到真正的值，于是就会造成mismatch，就是出入的一个环节出现了错误，会造成时候的结果都错误这样的问题。 解决的办法是给Decoder一些错误的内容，Scheduled Sampling 技术。","link":"/2022/04/10/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/Transformer-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"title":"Ch4 李群和李代数基础 应用和实践","text":"hljs.initHighlightingOnLoad(); 本文主要讲述ch4 李群和李代数基础的后两节，李代数的求导和扰动模型和代码实践的部分，介绍了SLAM中运用李群李代数的具体方面，之后介绍Sophus库的使用。 李代数求导和扰动模型BCH公式与近似形式实际对位姿进行估计和优化的时候，李群只有乘法，没有加法，使得导数不好定义，因此直观的想法是： 能都利用李代数上的加法来定义李群的导数； 之后通过指数映射和对数映射完成相互转换再回到李群。 总结来说就是解决：当在李代数中做加法时，是否等价于在李群上做乘法？ \\exp(\\phi_1^{\\wedge})\\exp(\\phi_2^{\\wedge})=?\\exp(\\phi_1^{\\wedge}+\\phi_2^{\\wedge}) 对于标量是显然成立的，但是对于向量和矩阵，由BCH公式可得其成立。 完整形式由 BCH（Baker-Campbell-Hausdorff） 公式给出： 公式的完整形式比较复杂，具体内容请见：(https://en.wikipedia.org/wiki/Baker-Campbell-Hausdorff_formula) 这里仅仅展示局部的展开式： \\ln (\\exp (\\boldsymbol{A}) \\exp (\\boldsymbol{B}))=\\boldsymbol{A}+\\boldsymbol{B}+\\frac{1}{2}[\\boldsymbol{A}, \\boldsymbol{B}]+\\frac{1}{12}[\\boldsymbol{A},[\\boldsymbol{A}, \\boldsymbol{B}]]-\\frac{1}{12}[\\boldsymbol{B},[\\boldsymbol{A}, \\boldsymbol{B}]]+\\cdots 特别地，考虑 $\\mathfrak {so}(3)$ 上的一个李代数 $\\ln(\\exp(\\phi_1^{\\wedge})\\exp(\\phi_2^{\\wedge}))^{\\vee}$ ，当考虑其中的一个量为小量时，其二次项以上的高阶项可以忽略可与忽略： \\ln \\left(\\exp \\left(\\phi_{1}^{\\wedge}\\right) \\exp \\left(\\phi_{2}^{\\wedge}\\right)\\right)^{\\vee} \\approx\\left\\{\\begin{array}{ll}\\boldsymbol{J}_{l}\\left(\\phi_{2}\\right)^{-1} \\phi_{1}+\\phi_{2} & \\text { if } \\phi_{1} \\text { is small } \\\\ \\boldsymbol{J}_{r}\\left(\\phi_{1}\\right)^{-1} \\phi_{2}+\\phi_{1} & \\text { if } \\phi_{2} \\text { is small. }\\end{array}\\right.这里我们以左乘为例，左乘BCH的近似雅可比矩阵为： \\boldsymbol{J}_{l}=\\boldsymbol{J}=\\frac{\\sin \\theta}{\\theta} \\boldsymbol{I}+\\left(1-\\frac{\\sin \\theta}{\\theta}\\right) \\boldsymbol{a} \\boldsymbol{a}^{T}+\\frac{1-\\cos \\theta}{\\theta} \\boldsymbol{a}^{\\wedge} .对其进行求逆可得： \\boldsymbol{J}_{l}^{-1}=\\frac{\\theta}{2} \\cot \\frac{\\theta}{2} \\boldsymbol{I}+\\left(1-\\frac{\\theta}{2} \\cot \\frac{\\theta}{2}\\right) \\boldsymbol{a} \\boldsymbol{a}^{T}-\\frac{\\theta}{2} \\boldsymbol{a}^{\\wedge}此处，右雅可比仅仅需要自变量取符号即可： \\boldsymbol{J}_{r}(\\boldsymbol{\\phi})=\\boldsymbol{J}_{l}(-\\boldsymbol{\\phi}) .这里我们假设左乘了一个微小的旋转，记作$\\boldsymbol {\\Delta R}$ ，其对应的李代数是$\\boldsymbol {\\Delta \\phi}$ 。于是再李群上面的$\\boldsymbol {\\Delta R}\\cdot\\boldsymbol { R}$ 对应的李代数就为： \\boldsymbol {\\Delta R}\\cdot\\boldsymbol { R}=\\exp \\left(\\Delta\\phi^{\\wedge}\\right)\\exp \\left(\\phi^{\\wedge}\\right)=\\exp \\left((\\phi+\\boldsymbol{J}_{l}^{-1}(\\boldsymbol{\\phi})\\Delta\\phi)^{\\wedge}\\right) 在李群上左乘小量，李代数上的加法相差左雅可比矩阵的逆。 反之，在李代数是加上一个小量，近似为李群上带左右雅可比的乘法： \\exp \\left((\\phi+\\Delta \\phi)^{\\wedge}\\right)=\\exp \\left(\\left(\\boldsymbol{J}_{l} \\Delta \\phi\\right)^{\\wedge}\\right) \\exp \\left(\\phi^{\\wedge}\\right)=\\exp \\left(\\phi^{\\wedge}\\right) \\exp \\left(\\left(\\boldsymbol{J}_{r} \\Delta \\boldsymbol{\\phi}\\right)^{\\wedge}\\right)同理可得，对应SE(3)，也会有类似的BCH近似： \\exp \\left(\\Delta \\boldsymbol{\\xi}^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\approx \\exp \\left(\\left(\\mathcal{J}_{l}^{-1} \\Delta \\boldsymbol{\\xi}+\\boldsymbol{\\xi}\\right)^{\\wedge}\\right) \\\\ \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\exp \\left(\\Delta \\xi^{\\wedge}\\right) \\approx \\exp \\left(\\left(\\mathcal{J}_{r}^{-1} \\Delta \\xi+\\boldsymbol{\\xi}\\right)^{\\wedge}\\right)这里的$\\mathcal J$的形式比较的复杂，是一个6 x 6 的矩阵。 SO(3)上的李代数求导问题的引入，在实际的一个SLAM问题，机器人此时的位姿为$\\boldsymbol {T}$ ，其观察到一个来自于世界坐标系下的一点$\\boldsymbol {p}$ ，观测的数据为 $\\boldsymbol z$ ，则有我们的坐标的变换关系可得： \\boldsymbol z = \\boldsymbol T \\boldsymbol p + \\boldsymbol\\omega.这里的$\\omega$ 代表随机噪声，于是定义实际和理论的误差为： \\boldsymbol e = \\boldsymbol z - \\boldsymbol T \\boldsymbol p一共有N个这样的路标和观测，于是就有N个上面的公式，为了求最佳的$\\boldsymbol {T}$，使得整体的误差最小化，我们需要对位姿矩阵 $\\boldsymbol {T}$ 进行求导： \\min_{\\boldsymbol T} J(\\boldsymbol T)=\\sum_{i=1}^N ||\\boldsymbol z_i - \\boldsymbol T \\boldsymbol p_i||_2^2求解此问题,需要计算目标函数$J$关于变换矩阵T的导数。 这里的重点是，我们经常会构建与位姿有关的函数，然后讨论该函数关于位姿的导数，以调整当前的估计值。然而，SO(3), SE(3)上并没有良好定义的加法，它们只是群。 如果我们把T当成一个普通矩阵来处理优化，就必须对它加以约束。而从李代数角度来说，由于李代数由向量组成，具有良好的加法运算，因此，使用李代数解决求导问题的思路分为两种： 用李代数表示姿态，然后根据李代数加法对李代数求导。 对李群左乘或右乘微小扰动，然后对该扰动求导，称为左扰动和右扰动模型。 第一种方式对应到李代数的求导模型，而第二种方式则对应到扰动模型。 导数模型首先，我们考虑导数模型，对应一个坐标点 $\\boldsymbol p$ ，进行旋转后可得其旋转后的坐标为$\\boldsymbol {Rp}$ 于是旋转后的向量对旋转矩阵求导可得比表达式为：$\\dfrac {\\partial \\boldsymbol {Rp}} {\\partial \\boldsymbol {R}}$ ，但是由于李群无法进行加法，不能求导，因此我们将其转化为李代数来进行计算：$\\dfrac {\\partial \\boldsymbol {\\exp(\\phi^{\\wedge})p}} {\\partial \\phi}$ . 之后， 计算可得： \\begin{aligned} \\frac{\\partial\\left(\\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}\\right)}{\\partial \\phi} &=\\lim _{\\delta \\boldsymbol{\\phi} \\rightarrow 0} \\frac{\\exp \\left((\\phi+\\delta \\boldsymbol{\\phi})^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}}{\\delta \\boldsymbol{\\phi}} \\\\ &=\\lim _{\\delta \\boldsymbol{\\phi} \\rightarrow 0} \\frac{\\exp \\left(\\left(\\boldsymbol{J}_{l} \\delta \\boldsymbol{\\phi}\\right)^{\\wedge}\\right) \\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}}{\\delta \\phi} \\\\ & \\approx \\lim _{\\delta \\phi \\rightarrow 0} \\frac{\\left(\\boldsymbol{I}+\\left(\\boldsymbol{J}_{l} \\delta \\boldsymbol{\\phi}\\right)^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\phi}^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\boldsymbol{\\phi}^{\\wedge}\\right) \\boldsymbol{p}}{\\delta \\phi} \\\\ &=\\lim _{\\delta \\boldsymbol{\\phi} \\rightarrow 0} \\frac{\\left(\\boldsymbol{J}_{l} \\delta \\boldsymbol{\\phi}\\right)^{\\wedge} \\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}}{\\delta \\phi} \\\\ &=\\lim _{\\delta \\phi \\rightarrow 0} \\frac{-\\left(\\exp \\left(\\boldsymbol{\\phi}^{\\wedge}\\right) \\boldsymbol{p}\\right)^{\\wedge} \\boldsymbol{J}_{l} \\delta \\boldsymbol{\\phi}}{\\delta \\boldsymbol{\\phi}}=-(\\boldsymbol{R} \\boldsymbol{p})^{\\wedge} \\boldsymbol{J}_{l} \\end{aligned}最后两行的反对称号可以看作是叉积，其主要的性质是交换位置要变号。 结果中含有一个左乘的雅可比，实际会计算量，于是我们想办法将其进行优化。 扰动模型和导数模型相比其主要的区别是，导数模型是加了一个小量，$\\dfrac{\\partial\\left(\\exp \\left(\\phi^{\\wedge}+\\Delta\\phi^{\\wedge}\\right) \\boldsymbol{p}\\right)}{\\partial \\phi}$ 而扰动模型是乘以了小量， 这里我们以左乘小量为例，带展示扰动模型的计算结果： \\begin{aligned} \\frac{\\partial(\\boldsymbol{R} p)}{\\partial \\varphi} &=\\lim _{\\varphi \\rightarrow 0} \\frac{\\exp \\left(\\varphi^{\\wedge}\\right) \\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}}{\\varphi} \\\\ & \\approx \\lim _{\\varphi \\rightarrow 0} \\frac{\\left(1+\\varphi^{\\wedge}\\right) \\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\phi^{\\wedge}\\right) \\boldsymbol{p}}{\\varphi} \\\\ &=\\lim _{\\varphi \\rightarrow 0} \\frac{\\varphi^{\\wedge} \\boldsymbol{R} \\boldsymbol{p}}{\\varphi}=\\lim _{\\varphi \\rightarrow 0} \\frac{-(\\boldsymbol{R} \\boldsymbol{p})^{\\wedge} \\varphi}{\\varphi}=-(\\boldsymbol{R} \\boldsymbol{p})^{\\wedge} \\end{aligned}扰动模型的形式更加简洁，实际的应用更加的广泛。 SE(3)上的李代数求导最后，类比之前SO(3)上的扰动模型，我们定义SE(3)上的扰动模型公式如下： \\begin{aligned} \\frac{\\partial(\\boldsymbol{T} \\boldsymbol{p})}{\\partial \\delta \\xi}&=\\lim _{\\delta \\boldsymbol{\\xi} \\rightarrow 0} \\frac{\\exp \\left(\\delta \\boldsymbol{\\xi}^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{p}}{\\delta \\boldsymbol{\\xi}}\\\\ & \\approx \\lim _{\\delta \\xi \\rightarrow 0} \\frac{\\left(\\boldsymbol{I}+\\delta \\boldsymbol{\\xi}^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{p}-\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) p}{\\delta \\boldsymbol{\\xi}} \\\\&=\\lim _{\\delta \\xi \\rightarrow 0} \\frac{\\delta \\xi^{\\wedge} \\exp \\left(\\xi^{\\wedge}\\right) p}{\\delta \\xi} \\\\& =\\lim _{\\delta \\xi \\rightarrow 0} \\frac{\\left[\\begin{array}{cc}\\delta \\phi^{\\wedge} & \\delta \\boldsymbol{\\rho} \\\\ \\mathbf{0}^{T} & 0\\end{array}\\right]\\left[\\begin{array}{c}\\boldsymbol{R} p+\\boldsymbol{t} \\\\ 1\\end{array}\\right]}{\\delta \\xi} \\\\&=\\lim _{\\delta \\xi \\rightarrow 0} \\frac{\\left[\\begin{array}{c}\\delta \\phi^{\\wedge}(\\boldsymbol{R} p+t)+\\delta \\rho \\\\ 0\\end{array}\\right]}{\\delta \\xi}=\\left[\\begin{array}{cc}I & -(\\boldsymbol{R} p+\\boldsymbol{t})^{\\wedge} \\\\ 0^{T} & 0^{T}\\end{array}\\right] \\triangleq(T \\boldsymbol{p})^{\\odot} \\end{aligned}下面是矩阵和向量求导的规则： \\frac{\\mathrm{d}\\left[\\begin{array}{l}\\boldsymbol{a} \\\\ \\boldsymbol{b}\\end{array}\\right]}{\\mathrm{d}\\left[\\begin{array}{l}\\boldsymbol{x} \\\\ \\boldsymbol{y}\\end{array}\\right]}=\\left(\\frac{\\mathrm{d}[\\boldsymbol{a}, \\boldsymbol{b}]^{\\mathrm{T}}}{\\mathrm{d}\\left[\\begin{array}{l}\\boldsymbol{x} \\\\ \\boldsymbol{y}\\end{array}\\right]}\\right)^{\\mathrm{T}}=\\left[\\begin{array}{ll}\\dfrac{\\mathrm{d} \\boldsymbol{a}}{\\mathrm{d} \\boldsymbol{x}} & \\dfrac{\\mathrm{d} \\boldsymbol{b}}{\\mathrm{d} \\boldsymbol{x}} \\\\ \\dfrac{\\mathrm{d} \\boldsymbol{a}}{\\mathrm{d} \\boldsymbol{y}} & \\dfrac{\\mathrm{d} b}{\\mathrm{~d} \\boldsymbol{y}}\\end{array}\\right]^{\\mathrm{T}}=\\left[\\begin{array}{cc}\\dfrac{\\mathrm{d} \\boldsymbol{a}}{\\mathrm{d} \\boldsymbol{x}} & \\dfrac{\\mathrm{d} \\boldsymbol{a}}{\\mathrm{d} \\boldsymbol{y}} \\\\ \\dfrac{\\mathrm{d} \\boldsymbol{b}}{\\mathrm{d} \\boldsymbol{x}} & \\dfrac{\\mathrm{d} b}{\\mathrm{~d} \\boldsymbol{y}}\\end{array}\\right]小结： 利用BCH线性近似，可以推导so(3)与se(3)上的导数和扰动模型； 通常情况下，扰动模型更为简洁实用。 实践部分Sophus库的使用首先是书写CMakeList.txt 123456789101112cmake_minimum_required(VERSION 3.0)project(useSophus)# 为使用 sophus，需要使用find_package命令找到它find_package(Sophus REQUIRED)# Eigeninclude_directories(&quot;/usr/include/eigen3&quot;)add_executable(useSophus useSophus.cpp)target_link_libraries(useSophus Sophus::Sophus)add_subdirectory(example) 之后是主要的程序useSophus.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;Eigen/Core&gt;#include &lt;Eigen/Geometry&gt;#include &quot;sophus/se3.hpp&quot;using namespace std;using namespace Eigen;/// 本程序演示sophus的基本用法int main(int argc, char **argv) { // =======================SO(3)============================ // 沿Z轴转90度的旋转矩阵 Matrix3d R = AngleAxisd(M_PI / 2, Vector3d(0, 0, 1)).toRotationMatrix(); // 或者四元数 Quaterniond q(R); Sophus::SO3d SO3_R(R); // Sophus::SO3d可以直接从旋转矩阵构造 Sophus::SO3d SO3_q(q); // 也可以通过四元数构造 // 二者是等价的 cout &lt;&lt; &quot;SO(3) from matrix:\\n&quot; &lt;&lt; SO3_R.matrix() &lt;&lt; endl; cout &lt;&lt; &quot;SO(3) from quaternion:\\n&quot; &lt;&lt; SO3_q.matrix() &lt;&lt; endl; cout &lt;&lt; &quot;they are equal&quot; &lt;&lt; endl; // 使用对数映射获得它的李代数 Vector3d so3 = SO3_R.log(); cout &lt;&lt; &quot;so3 = &quot; &lt;&lt; so3.transpose() &lt;&lt; endl; // hat 为向量到反对称矩阵 cout &lt;&lt; &quot;so3 hat=\\n&quot; &lt;&lt; Sophus::SO3d::hat(so3) &lt;&lt; endl; // 相对的，vee为反对称到向量 cout &lt;&lt; &quot;so3 hat vee= &quot; &lt;&lt; Sophus::SO3d::vee(Sophus::SO3d::hat(so3)).transpose() &lt;&lt; endl; // 增量扰动模型的更新 Vector3d update_so3(1e-4, 0, 0); //假设更新量为这么多 Sophus::SO3d SO3_updated = Sophus::SO3d::exp(update_so3) * SO3_R; cout &lt;&lt; &quot;SO3 updated = \\n&quot; &lt;&lt; SO3_updated.matrix() &lt;&lt; endl; cout &lt;&lt; &quot;*******************************&quot; &lt;&lt; endl; // =======================SE(3)============================ // 对SE(3)操作大同小异 Vector3d t(1, 0, 0); // 沿X轴平移1 Sophus::SE3d SE3_Rt(R, t); // 从R,t构造SE(3) Sophus::SE3d SE3_qt(q, t); // 从q,t构造SE(3) cout &lt;&lt; &quot;SE3 from R,t= \\n&quot; &lt;&lt; SE3_Rt.matrix() &lt;&lt; endl; cout &lt;&lt; &quot;SE3 from q,t= \\n&quot; &lt;&lt; SE3_qt.matrix() &lt;&lt; endl; // 李代数se(3) 是一个六维向量，方便起见先typedef一下 typedef Eigen::Matrix&lt;double, 6, 1&gt; Vector6d; Vector6d se3 = SE3_Rt.log(); cout &lt;&lt; &quot;se3 = &quot; &lt;&lt; se3.transpose() &lt;&lt; endl; // 观察输出，会发现在Sophus中，se(3)的平移在前，旋转在后. // 同样的，有hat和vee两个算符 cout &lt;&lt; &quot;se3 hat = \\n&quot; &lt;&lt; Sophus::SE3d::hat(se3) &lt;&lt; endl; cout &lt;&lt; &quot;se3 hat vee = &quot; &lt;&lt; Sophus::SE3d::vee(Sophus::SE3d::hat(se3)).transpose() &lt;&lt; endl; // 最后，演示一下更新 Vector6d update_se3; //更新量 update_se3.setZero(); update_se3(0, 0) = 1e-4; // 由此可知，这里是将平移排在旋转的前面 Sophus::SE3d SE3_updated = Sophus::SE3d::exp(update_se3) * SE3_Rt; cout &lt;&lt; &quot;SE3 updated = &quot; &lt;&lt; endl &lt;&lt; SE3_updated.matrix() &lt;&lt; endl; return 0;} 例子：评估轨迹的误差 \\mathrm{ATE}_{\\text {trans }}=\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}\\left\\|\\operatorname{trans}\\left(\\boldsymbol{T}_{\\mathrm{gt}, i}^{-1} \\boldsymbol{T}_{\\text {esti }, i}\\right)\\right\\|_{2}^{2}} ATE_{all} =\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}\\left\\|\\log \\left(\\boldsymbol{T}_{\\mathrm{gt}, i}^{-1} \\boldsymbol{T}_{\\text {esti }, i}\\right)^{\\vee}\\right\\|_{2}^{2}} \\mathrm{RPE}_{\\mathrm{all}}=\\sqrt{\\left.\\frac{1}{N-\\Delta t} \\sum_{i=1}^{N-\\Delta t} \\| \\log \\left(\\left(\\boldsymbol{T}_{\\mathrm{gt}, i}^{-1} \\boldsymbol{T}_{\\mathrm{gt}, i+\\Delta t}\\right)\\right)^{-1}\\left(\\boldsymbol{T}_{\\text {est }, i}^{-1} \\boldsymbol{T}_{\\text {est }, i+\\Delta t}\\right)\\right)^{\\vee} \\|_{2}^{2},} \\\\ \\mathrm{RPE}_{\\text {trans }}=\\sqrt{\\left.\\frac{1}{N-\\Delta t} \\sum_{i=1}^{N-\\Delta t} \\| \\operatorname{trans}\\left(\\left(\\boldsymbol{T}_{\\mathrm{gt}, i}^{-1} \\boldsymbol{T}_{\\mathrm{g}, i+\\Delta t}\\right)\\right)^{-1}\\left(\\boldsymbol{T}_{\\text {esti }, i}^{-1} \\boldsymbol{T}_{\\text {est }, i+\\Delta t}\\right)\\right) \\|_{2}^{2}} 12345678910option(USE_UBUNTU_20 &quot;Set to ON if you are using Ubuntu 20.04&quot; OFF)find_package(Pangolin REQUIRED)if(USE_UBUNTU_20) message(&quot;You are using Ubuntu 20.04, fmt::fmt will be linked&quot;) find_package(fmt REQUIRED) set(FMT_LIBRARIES fmt::fmt)endif()include_directories(${Pangolin_INCLUDE_DIRS})add_executable(trajectoryError trajectoryError.cpp)target_link_libraries(trajectoryError ${Pangolin_LIBRARIES} ${FMT_LIBRARIES}) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;unistd.h&gt;#include &lt;pangolin/pangolin.h&gt;#include &lt;sophus/se3.hpp&gt;using namespace Sophus;using namespace std;string groundtruth_file = &quot;./example/groundtruth.txt&quot;;string estimated_file = &quot;./example/estimated.txt&quot;;typedef vector&lt;Sophus::SE3d, Eigen::aligned_allocator&lt;Sophus::SE3d&gt;&gt; TrajectoryType;void DrawTrajectory(const TrajectoryType &amp;gt, const TrajectoryType &amp;esti);TrajectoryType ReadTrajectory(const string &amp;path);int main(int argc, char **argv) { TrajectoryType groundtruth = ReadTrajectory(groundtruth_file); TrajectoryType estimated = ReadTrajectory(estimated_file); assert(!groundtruth.empty() &amp;&amp; !estimated.empty()); assert(groundtruth.size() == estimated.size()); // compute rmse double rmse = 0; for (size_t i = 0; i &lt; estimated.size(); i++) { Sophus::SE3d p1 = estimated[i], p2 = groundtruth[i]; double error = (p2.inverse() * p1).log().norm(); rmse += error * error; } rmse = rmse / double(estimated.size()); rmse = sqrt(rmse); cout &lt;&lt; &quot;RMSE = &quot; &lt;&lt; rmse &lt;&lt; endl; DrawTrajectory(groundtruth, estimated); return 0;}TrajectoryType ReadTrajectory(const string &amp;path) { ifstream fin(path); TrajectoryType trajectory; if (!fin) { cerr &lt;&lt; &quot;trajectory &quot; &lt;&lt; path &lt;&lt; &quot; not found.&quot; &lt;&lt; endl; return trajectory; } while (!fin.eof()) { double time, tx, ty, tz, qx, qy, qz, qw; fin &gt;&gt; time &gt;&gt; tx &gt;&gt; ty &gt;&gt; tz &gt;&gt; qx &gt;&gt; qy &gt;&gt; qz &gt;&gt; qw; Sophus::SE3d p1(Eigen::Quaterniond(qw, qx, qy, qz), Eigen::Vector3d(tx, ty, tz)); trajectory.push_back(p1); } return trajectory;}void DrawTrajectory(const TrajectoryType &amp;gt, const TrajectoryType &amp;esti) { // create pangolin window and plot the trajectory pangolin::CreateWindowAndBind(&quot;Trajectory Viewer&quot;, 1024, 768); glEnable(GL_DEPTH_TEST); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); pangolin::OpenGlRenderState s_cam( pangolin::ProjectionMatrix(1024, 768, 500, 500, 512, 389, 0.1, 1000), pangolin::ModelViewLookAt(0, -0.1, -1.8, 0, 0, 0, 0.0, -1.0, 0.0) ); pangolin::View &amp;d_cam = pangolin::CreateDisplay() .SetBounds(0.0, 1.0, pangolin::Attach::Pix(175), 1.0, -1024.0f / 768.0f) .SetHandler(new pangolin::Handler3D(s_cam)); while (pangolin::ShouldQuit() == false) { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); d_cam.Activate(s_cam); glClearColor(1.0f, 1.0f, 1.0f, 1.0f); glLineWidth(2); for (size_t i = 0; i &lt; gt.size() - 1; i++) { glColor3f(0.0f, 0.0f, 1.0f); // blue for ground truth glBegin(GL_LINES); auto p1 = gt[i], p2 = gt[i + 1]; glVertex3d(p1.translation()[0], p1.translation()[1], p1.translation()[2]); glVertex3d(p2.translation()[0], p2.translation()[1], p2.translation()[2]); glEnd(); } for (size_t i = 0; i &lt; esti.size() - 1; i++) { glColor3f(1.0f, 0.0f, 0.0f); // red for estimated glBegin(GL_LINES); auto p1 = esti[i], p2 = esti[i + 1]; glVertex3d(p1.translation()[0], p1.translation()[1], p1.translation()[2]); glVertex3d(p2.translation()[0], p2.translation()[1], p2.translation()[2]); glEnd(); } pangolin::FinishFrame(); usleep(5000); // sleep 5 ms }}","link":"/2022/04/12/SLAM/ch4-%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80-%E5%BA%94%E7%94%A8%E5%92%8C%E5%AE%9E%E8%B7%B5/"},{"title":"Ch4 李群和李代数基础 概念引入","text":"hljs.initHighlightingOnLoad(); 本文主要讲述ch4 李群和李代数基础的前两节，李群和李代数基础和指数映射的部分，引入了李群李代数的概念及其之间的映射关系。 对于三维世界的刚体运动而言，其描述运动的方式有很多，包括旋转矩阵、旋转向量、欧拉角、四元数 。但是除了表示，还要就是对其进行估计和优化，但是旋转矩阵的自身带有约束，(其正交且行列式为1)，因此其作为变量时，会引入额外的约束，使得优化变得很困难。于是我们采用变换到李代数的方法，得到一个无约束的优化问题。 李群李代数基础三维旋转矩阵构成了特殊正交群（Special Orthogonal Group）: \\mathfrak {SO}(n)=\\{\\boldsymbol R \\in \\mathbb R^{n\\times n} | \\boldsymbol R\\boldsymbol R^T=\\boldsymbol I,\\det(\\boldsymbol R)=1\\}.三维变换矩阵构成了特殊欧氏群（Special Euclidean Group）： \\mathfrak{SE}(3) =\\left\\{\\boldsymbol{T}=\\left[\\begin{array}{ll}\\boldsymbol{R} & \\boldsymbol{t} \\\\ \\mathbf{0}^{T} & 1\\end{array}\\right] \\in \\mathbb{R}^{4 \\times 4} \\mid \\boldsymbol{R} \\in \\mathcal{SO}(3), \\boldsymbol{t} \\in \\mathbb{R}^{3}\\right\\}注意到旋转矩阵时对加法不封闭，但是其对乘法时封闭的： \\boldsymbol R_1 + \\boldsymbol R_2 \\notin SO(3),\\ \\boldsymbol T_1 + \\boldsymbol T_2 \\notin SE(3).\\\\ \\boldsymbol R_1 \\boldsymbol R_2 \\in SO(3),\\ \\boldsymbol T_1 \\boldsymbol T_2 \\in SE(3).\\\\对于这种只有一种(良好的)运算的集合我们称之为群。 群的概念群(Group): 是一种集合加上一种运算的代数结构。 于是将集合记作$A$ ，运算记作 $\\cdot$ ，则群记作 $G=(A, \\cdot)$ 。其满足的几个条件如下：简记为 “封结幺逆”。 可以验证的是旋转矩阵和变换矩阵对于矩阵乘法是构成群的，称它们为旋转矩阵群和变换矩阵群。 常见的变换群有： 群的结构是保证在群上的计算具有良好的性质。 群论是研究群的各种结构和性质的理论，具体的介绍见抽象代数或近世代数教材。 李群(Lie Group) 是满足以下特点的群： 具有连续和光滑的性质的群。 既是群也是流形。 直观上看，一个刚体能够连续地在空间运动，故$SO(3),SE(3)$都是李群。 但是，$SO(3),SE(3)$ 只有定义良好的乘法，没有加法，所以难以进行去极限、求导操作。 但是，如果研究一个集合+两个或多个运算，那就是需要研究环论和域论。 李代数的引出李代数：和李群一一对应的一种结构，位于向量空间。 通常记作小写的$\\mathfrak {so}(3),\\mathfrak {se}(3)$ 表示，这里的字体是哥特体，其主要的Latex代码为\\mathfrak 参考博客 但是，事实上李代数是李群单位元上的正切空间。 概念的引出过程： 对于任意的旋转矩阵：$\\boldsymbol R \\boldsymbol R^T=I$ ； 实际情况下，旋转矩阵是随时间的变化而改变的，于是有：$\\boldsymbol R(t) \\boldsymbol R(t)^T=I$ ； 两侧对时间求导可得：$\\dot {\\boldsymbol R(t)} \\boldsymbol R(t)^T + \\boldsymbol {R(t)} \\dot {\\boldsymbol {R(t)}^T}= \\boldsymbol 0$ ； 整理可得：$\\dot {\\boldsymbol R(t)} \\boldsymbol R(t)^T =-( \\boldsymbol {R(t)} \\dot {\\boldsymbol {R(t)}})^T$ 可以看出上述矩阵为一个反对称的矩阵，即这个反对称矩阵对应的三维向量为$\\phi(t) \\in \\mathbb R^3$ ，则有：$\\dot {\\boldsymbol R(t)} \\boldsymbol R(t)^T = \\phi(t)^\\wedge$ 参考博客 \\boldsymbol a^\\wedge=\\left[\\begin{array}{ccc}0 & -a_{3} & a_{2} \\\\ a_{3} & 0 & -a_{1} \\\\ -a_{2} & a_{1} & 0\\end{array}\\right] = \\boldsymbol A,\\ \\boldsymbol A^\\vee=a其中，这里的$a = [a_1,a_2,a_3]$ 是一个向量。 两侧右乘$\\boldsymbol R(t)$可得：$\\dot {\\boldsymbol R(t)} = \\phi(t)^\\wedge\\boldsymbol R(t)$ 其实就是一个微分方程 由此可得，求一次导数之后，左侧加一个$\\phi(t)^\\wedge $的矩阵即可. 将上述的公式$\\dot {\\boldsymbol R(t)} = \\phi(t)^\\wedge\\boldsymbol R(t)$作为一个微分方程来考虑，其初始的条件设为：在$t_0=0$时，旋转矩阵为${\\boldsymbol R(0)}=\\boldsymbol I.$ 在$t=0$处进行泰勒展开，并省去高阶项可得： {\\boldsymbol R(t)} \\approx \\boldsymbol R(t_0)+\\dot {\\boldsymbol R}(t_0)(t-t_0) = \\boldsymbol I + \\phi(t_0)^ \\wedge(t) 可见$\\phi$ 反映了旋转矩阵的导数性质，它就位于SO(3)空间的原点附近的正切空间上。 这里，假设在$t_0$附近，$\\phi(t_0)=\\phi_0$ 是保持不变的，于是微分方程可以化简为： \\dot {\\boldsymbol R(t)} = \\phi(t_0)^\\wedge\\boldsymbol R(t)=\\phi_0^\\wedge\\boldsymbol R(t)代入初值${\\boldsymbol R(0)}=\\boldsymbol I.$ 解得：${\\boldsymbol R(t)}=\\exp(\\phi_0^\\wedge t)$ 上述公式说明：对于任意的时间 $t$ 都可以找到一个 $R$ 和 $\\phi$ 的对于关系 该关系被称为指数映射； 这里的 $\\phi$ 称为SO(3)对应的李代数：$\\mathfrak {so}(3)$ . 那么下面将解决以下的几个问题： $\\mathfrak {so}(3)$ 即 $\\phi$ 什么具体的含义及性质； 给定李代数 $\\phi$ 如何通过指数映射来求解旋转矩阵，反之给定旋转矩阵，如何通过指数映射 计算出此处的李代数 $\\phi$ 。 李代数的定义每个李群都有与之对应的李代数。李代数描述了李群单位元附近的正切空间性质。 其中，二元运算$[,]$被称为李括号(Lie Bracket)。 直观来说，李括号表达了两个元素之间的差异，从自反性可得。 这里，比如在三维向量上面定义的叉积 $\\times$ 就是一种李括号，于是 $\\mathfrak g=(\\mathbb R^3, \\mathbb R, \\times)$ 就构成一个李代数。 李代数$\\mathfrak {so}(3)$SO(3)对应的李代数定义在$\\mathbb R^3$上的向量，这里记作$\\phi$ ，于是可得： \\Phi = \\phi^{\\wedge} = \\left[\\begin{array}{ccc}0 & -\\phi_{3} & \\phi_{2} \\\\ \\phi_{3} & 0 & -\\phi_{1} \\\\ -\\phi_{2} & \\phi_{1} & 0\\end{array}\\right] \\in \\mathbb R^{3 \\times 3}在此定义下的李括号为：(可以验证其满足四条性质) [\\phi_1,\\phi_2] = (\\Phi_1\\Phi_2-\\Phi_2\\Phi_1)^{\\vee}由于向量和反对称矩阵是一一对应的，因此可以不加区别的认为$\\mathfrak {so}(3)$ 是个向量或反对称矩阵： \\mathfrak {so}(3) = \\{ \\phi \\in\\mathbb R^3, \\Phi=\\phi^{\\wedge} \\in \\mathbb R^{3 \\times 3} \\}因此$\\mathfrak {so}(3)$ 可以看成是向量组成的一个集合，每个向量对应一个反对称矩阵，其可以用来表达一个旋转矩阵的导数。 其中SO(3)到$\\mathfrak {so}(3)$ 的映射为：${\\boldsymbol R(t)}=\\exp(\\phi_0^\\wedge t)$ 李代数$\\mathfrak{s e}(3)$同理对于$\\mathfrak{s e}(3)$ ,我们使用一个6维的向量来表示，这里记为$\\xi$ ， 其前三个维度是用来表示平移，记作$\\rho $，它就是是个普通的向量，但是不是SE(3)上的平移分量； 后三个维度是用来表示旋转，记作$\\phi$ 【这里其实就是$\\mathfrak {so}(3)$】。 \\mathfrak{s e}(3)=\\left\\{\\xi=\\left[\\begin{array}{c}\\rho \\\\ \\phi\\end{array}\\right] \\in \\mathbb{R}^{6}, \\rho \\in \\mathbb{R}^{3}, \\phi \\in \\mathfrak{s o}(3), \\xi^{\\wedge}=\\left[\\begin{array}{cc}\\phi^{\\wedge} & \\rho \\\\ 0^{T} & 0\\end{array}\\right] \\in \\mathbb{R}^{4 \\times 4}\\right\\}其中，$\\wedge$ 不再是反对称矩阵，但仍保留这种记法，其实也是符号的一种扩展： $\\wedge$ ：表示从向量到矩阵； $\\vee$ ：表示从矩阵到向量。 \\boldsymbol{\\xi}^{\\wedge}=\\left[\\begin{array}{cc}\\phi^{\\wedge} & \\rho \\\\ \\mathbf{0}^{T} & 0\\end{array}\\right] \\in \\mathbb{R}^{4 \\times 4}在此定义下的李括号为：(可以验证其满足四条性质) {\\left[\\boldsymbol{\\xi}_{1}, \\boldsymbol{\\xi}_{2}\\right]=\\left(\\boldsymbol{\\xi}_{1}^{\\wedge} \\boldsymbol{\\xi}_{2}^{\\wedge}-\\boldsymbol{\\xi}_{2}^{\\wedge} \\boldsymbol{\\xi}_{1}^{\\wedge}\\right)^{\\vee} }注意： 不同书籍对se(3)的平移/旋转分量的先后顺序定义不同。这里使用平移在前的方式，也有地方是旋转在前的。 把李代数理解成向量形式或矩阵形式都是可以的。向量形式更加自然一些。 指数映射和对数映射SO(3)上的指数映射指数映射反映了李群和李代数的对应关系，但是对于任意的矩阵来说，其指数映射可以写成一个Tarylor展开： \\exp(\\boldsymbol A) = \\sum_{n=0}^{\\infty} \\frac 1 {n!} \\boldsymbol A^n \\Rightarrow \\exp(\\phi^{\\wedge}) = \\sum_{n=0}^{\\infty} \\frac 1 {n!} (\\phi^{\\wedge})^n但是这里的$\\phi^{\\wedge}$ 是一个向量，定义其对于的模长和方向(角度)： 角度乘单位向量：$\\phi = \\theta a$； 关于单位方向向量$a$ ，有以下的性质： \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}=\\left[\\begin{array}{ccc}-a_{2}^{2}-a_{3}^{2} & a_{1} a_{2} & a_{1} a_{3} \\\\ a_{1} a_{2} & -a_{1}^{2}-a_{3}^{2} & a_{2} a_{3} \\\\ a_{1} a_{3} & a_{2} a_{3} & -a_{1}^{2}-a_{2}^{2}\\end{array}\\right]=\\boldsymbol{a a}^{\\mathrm{T}}-\\boldsymbol{I}\\\\ \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge} = \\boldsymbol{a}^{\\wedge} (\\boldsymbol{a a}^{\\mathrm{T}}-\\boldsymbol{I}) =- \\boldsymbol{a}^{\\wedge} 上述的式子提供了计算高阶项的方法，于是可得李代数的展开式为： \\begin{aligned} \\exp \\left(\\phi^{\\wedge}\\right) &=\\exp \\left(\\theta \\boldsymbol{a}^{\\wedge}\\right)=\\sum_{n=0}^{\\infty} \\frac{1}{n !}\\left(\\theta \\boldsymbol{a}^{\\wedge}\\right)^{n} \\\\ &=\\boldsymbol{I}+\\theta \\boldsymbol{a}^{\\wedge}+\\frac{1}{2 !} \\theta^{2} \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}+\\frac{1}{3 !} \\theta^{3} \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}+\\frac{1}{4 !} \\theta^{4}\\left(\\boldsymbol{a}^{\\wedge}\\right)^{4}+\\ldots \\\\ &=\\boldsymbol{a} \\boldsymbol{a}^{T}-\\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}+\\theta \\boldsymbol{a}^{\\wedge}+\\frac{1}{2 !} \\theta^{2} \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}-\\frac{1}{3 !} \\theta^{3} \\boldsymbol{a}^{\\wedge}-\\frac{1}{4 !} \\theta^{4}\\left(\\boldsymbol{a}^{\\wedge}\\right)^{2}+\\ldots \\\\ &=\\boldsymbol{a} \\boldsymbol{a}^{T}+\\left(\\theta-\\frac{1}{3 !} \\theta^{3}+\\frac{1}{5 !} \\theta^{5}-\\ldots\\right) \\boldsymbol{a}^{\\wedge}-\\left(1-\\frac{1}{2 !} \\theta^{2}+\\frac{1}{4 !} \\theta^{4}-\\ldots\\right) \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge} \\\\ &=\\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}+\\boldsymbol{I}+\\sin \\theta \\boldsymbol{a}^{\\wedge}-\\cos \\theta \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge} \\\\ &=(1-\\cos \\theta) \\boldsymbol{a}^{\\wedge} \\boldsymbol{a}^{\\wedge}+\\boldsymbol{I}+\\sin \\theta \\boldsymbol{a}^{\\wedge} \\\\ &=\\cos \\theta \\boldsymbol{I}+(1-\\cos \\theta) \\boldsymbol{a} \\boldsymbol{a}^{T}+\\sin \\theta \\boldsymbol{a}^{\\wedge} \\end{aligned}对比上述的化简结果可得罗德里格斯公式： \\exp \\left(\\theta \\boldsymbol{a}^{\\wedge}\\right)=\\cos \\theta \\boldsymbol{I}+(1-\\cos \\theta) \\boldsymbol{a} \\boldsymbol{a}^{T}+\\sin \\theta \\boldsymbol{a}^{\\wedge} 这就是说明了$\\mathfrak {so}(3)$ 的意义就是选旋转向量组成的空间，而指数映射就是罗德里格斯公式。 反之，定义对数映射也是可以将SO(3)中的元素映射到$\\mathfrak {so}(3)$中： \\phi=\\ln (\\boldsymbol{R})^{\\vee}=\\left(\\sum_{n=0}^{\\infty} \\frac{(-1)^{n}}{n+1}(\\boldsymbol{R}-\\boldsymbol{I})^{n+1}\\right)^{\\vee}但是实际上我们没必要在使用对数映射，因为上一章已经讲到过旋转矩阵来转成旋转向量的公式： \\theta=\\arccos \\left( \\dfrac {\\tr(\\boldsymbol R)-1} {2}\\right),\\ \\boldsymbol R \\boldsymbol n =\\boldsymbol n 至此，我们就得到了SO(3)和$\\mathfrak {so}(3)$ 之间的转换关系，但是值得注意的是，指数映射只是一个满射，不是单射，也就是SO(3)中的元素都可以找到对应的$\\mathfrak {so}(3)$ 的元素，但是可能存在多个$\\mathfrak {so}(3)$的元素对应同一个SO(3)的元素。 因为显然旋转矩阵旋转一周之后的结果是相同的，因此如果定义旋转角在$[-\\pi,\\pi]$之间，那么指数映射就是一个满射。 SE(3)上的指数映射类比之前的$\\mathfrak {so}(3)$ 可得，$\\mathfrak {se}(3)$的指数映射的形式为： \\begin{aligned} \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) &=\\left[\\begin{array}{cc}\\sum\\limits_{n=0}^{\\infty} \\dfrac{1}{n !}\\left(\\phi^{\\wedge}\\right)^{n} & \\sum\\limits_{n=0}^{\\infty} \\dfrac{1}{(n+1) !}\\left(\\phi^{\\wedge}\\right)^{n} \\boldsymbol{\\rho} \\\\ \\boldsymbol{0}^{\\mathrm{T}}\\end{array}\\right] \\\\ & \\triangleq\\left[\\begin{array}{cc}\\boldsymbol{R} & \\boldsymbol{J} \\boldsymbol{\\rho} \\\\ \\mathbf{0}^{\\mathrm{T}} & 1\\end{array}\\right]=\\boldsymbol{T} . \\end{aligned}代入上述的计算公式，计算可得： \\begin{aligned} \\sum_{n=0}^{\\infty} \\frac{1}{(n+1) !}\\left(\\phi^{\\wedge}\\right)^{n} &=\\boldsymbol{I}+\\frac{1}{2 !} \\theta \\boldsymbol{a}^{\\wedge}+\\frac{1}{3 !} \\theta^{2}\\left(\\boldsymbol{a}^{\\wedge}\\right)^{2}+\\frac{1}{4 !} \\theta^{3}\\left(\\boldsymbol{a}^{\\wedge}\\right)^{3}+\\frac{1}{5 !} \\theta^{4}\\left(\\boldsymbol{a}^{\\wedge}\\right)^{4} \\cdots \\\\ &=\\frac{1}{\\theta}\\left(\\frac{1}{2 !} \\theta^{2}-\\frac{1}{4 !} \\theta^{4}+\\cdots\\right)\\left(\\boldsymbol{a}^{\\wedge}\\right)+\\frac{1}{\\theta}\\left(\\frac{1}{3 !} \\theta^{3}-\\frac{1}{5} \\theta^{5}+\\cdots\\right)\\left(\\boldsymbol{a}^{\\wedge}\\right)^{2}+\\boldsymbol{I} \\\\ &=\\frac{1}{\\theta}(1-\\cos \\theta)\\left(\\boldsymbol{a}^{\\wedge}\\right)+\\frac{\\theta-\\sin \\theta}{\\theta}\\left(\\boldsymbol{a} \\boldsymbol{a}^{\\mathrm{T}}-\\boldsymbol{I}\\right)+\\boldsymbol{I} \\\\ &=\\frac{\\sin \\theta}{\\theta} \\boldsymbol{I}+\\left(1-\\frac{\\sin \\theta}{\\theta}\\right) \\boldsymbol{a} \\boldsymbol{a}^{\\mathrm{T}}+\\frac{1-\\cos \\theta}{\\theta} \\boldsymbol{a}^{\\wedge} \\stackrel{\\text { def }}{=} \\boldsymbol{J} \\end{aligned}于是我们将平移部分经过指数变换，其实相当于一个系数为$\\boldsymbol J$ 的线性变换： \\boldsymbol{J}=\\frac{\\sin \\theta}{\\theta} \\boldsymbol{I}+\\left(1-\\frac{\\sin \\theta}{\\theta}\\right) \\boldsymbol{a} \\boldsymbol{a}^{\\mathrm{T}}+\\frac{1-\\cos \\theta}{\\theta} \\boldsymbol{a}^{\\wedge}这里和$\\mathfrak {so}(3)$相同，但是一般使用是不用对数变换，有对应的公式可以解出，$\\phi$ 已知，就可以解出$\\boldsymbol J$ 进而解方程可以求出$\\rho$ . 上面两种变化的总结如下：","link":"/2022/04/12/SLAM/ch4-%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80-%E6%A6%82%E5%BF%B5%E5%BC%95%E5%85%A5/"},{"title":"Ch2 Learning to Answering Yes &#x2F; No","text":"hljs.initHighlightingOnLoad(); 本讲主要解决是二元的是非的问题，本章简单的介绍了一些PLA感知器的定义和求解问题，比较的基础。并且证明其在线性可分的条件下是可以收敛的，并讨论了一些线性不可分的情况。 Perceptron Hypothesis Set首先，复习之前学习问题的主要的框架——以是否发放信用卡的问题为例。 A Simple Hypothesis Set: the ‘Perceptron’ 将每个使用者转换为向量表示，每个维度代表一种属性； 将每个维度值进行加权求和，如果最后的值大于一个阈值，就借钱，否则就不给发贷款。 这里使用两个数字来代表二元的问题，使用+1代表good、使用-1代表bad; 这里使用$sign()$函数，由于刚好等于0的概率是很小的，这里就选择忽略，或者随机指向二者中的一个来进行决策。 $h$ 代表是一种函数映射，其参数主要包括的是$w_i$和 $threshold$ .这种模型别称为感知器(perceptron)。 但是上述的表示公式比较的复杂，于是我们就考虑将上述的公式进行简化如下。 Vector Form of Perceptron Hypothesis 这里为了可以更加直观的了解，我们于是考虑二维的情况。 此时的$h(x)$就对应一条分界线，对于3为的情况就是一个分界面。 这里感知器别称为线性分类器。linear (binary) classifiers Perceptron Learning Algorithm (PLA)Select g from $\\mathcal{H}$ $\\mathcal{H}$ = all possible perceptron, 现在要求的是 g 这里希望的是 g 可以无限的对 f 进行逼近，尽可能的保证在数据点上是相同的。 但是面临的主要的困难是：可选假设集合$\\mathcal{H}$ 的规模是无限大的。 于是我们考虑首先初始化一条线，然后通过优化的方法来进行优化。 will represent $g_0$ by its weight vector $ w_0$ Perceptron Learning Algorithm 首先，找到一个犯了错误的点$(x_n,y_n)$； 之后，观察可得： 第一种情况下w和x的夹角是大于90°的，内积的结果为-1，但是真实的情况是y=+1，于是我们就将$w\\leftarrow w+y*x$ 这样可以减小对于的夹角。 第二种情况，夹角过大，内积后的结果为-1了，但是实际要求的结果是y=-1，$w\\leftarrow w+y*x$ 这样一来就减小的夹角。 重复，一直到最后的错误点全部消失。 Practical Implementation of PLA 下面展示一组优化的过程，来直观的理解该算法的工作原理。 刚开始的时候，全部初始化为+1或者-1； 之后就是不断遍历当前情况下分类错误的点，更新一次之后，其分类错误的点的集合也会更新。 Some Remaining Issues of PLA主要的问题： 如果算法停止之后就会找到比较好的分类曲线，但问题是这个算法会不会收敛并终止计算。 g 和 f 在已有的数据$\\mathcal{D}$上是非常满足逼近的，但是如果在$\\mathcal{D}$ 之外是否还满足计算上的要求，就是未知的了。 Guarantee of PLALinear Separability 使用PLA算法首先就是要保证其一定要是线性可分的。 对于非线性的处理，之后的课程会给出详细的求解的方法。 下面主要就是来讨论，在给定线性可分的前提下，是否可以保证PLA算法是一定可以停止的。 PLA Fact: $w_t$ gets more Aligned with $w_f$ 下面主要证明的是，对于PLA而言，每一次更新的值$w_{t}$ 总是更加接近最优值的。 第一步是想说明对于每个分类正确的值而言，$y_nw_f^Tx_n$的值一定是大于0的，而且越接近边界值，其值就愈来愈小。 第二步就证明了每次更新之后，$w_fw_{t+1}$的值就越大。 但是第二步仅仅说明了，在不考虑$w$的长度的情况下，其夹角是逐渐减小的，下面证明其长度的变化可以忽略。 PLA Fact: $w_t$ Does Not Grow Too Fast 这里每次控制其权重更新的点其实主要是上一轮分类错误的点。 $y_{n(t)}=\\pm1\\ \\Rightarrow\\ y_{n(t)}^2=1$ 这里主要是证明了，其每次增加的量不是很大，可以忽略。 start from $w_0=0$, after T mistake corrections, \\frac{w_f^T}{||w_f||}\\frac{w_T}{||w_T||} \\ge \\sqrt{T} \\vdot constant这里代表的是内积的计算，其实相当于余弦夹角，上式的最大值为1. Non-Separable Data 在保证线性可分的情况下，可得其内积在很快的减小，并且其长度上升的很慢，于是可得其$w_t$在不断地接近最优值$w_f$. 其好处是运算速度快，可以处理高维的数据。 存在的问题： 我们无法实现知道线性可分以及对应的最优解$w_f$，知识仅仅知道其是存在的，但是具体值是未知的。 其次，在计算收敛次数的时候，$\\rho$ 的计算也是紧密的依赖于$w_f$ . 因此，在$w_f$ 未知的情况下，很难确定，如果一直不出结果，有可能就是不是线性可分的。 如果一开始就不是线性可分的，那应该如何计算？ Learning with Noisy Data对应有噪声的数据，很大概率不是线性可分的。 这里就需要给一定的容错率(Tolerance)，使用优化的方法来最小化犯错的大小来进行求解，线性不可分。 但是这个问题是一个NP-hard的问题。 Pocket Algorithm贪心的算法用来解决这个问题，一直把寻找最优的那个权重$w$. 对比一般的PLA，其主要的缺点是，每次要对最优的权重进行存储； 其次就是每次要进行比较操作比较浪费时间。 小结： 本章其实主要介绍的是PLA，做二元的分类运算操作，证明其在线性可分的情况下有比较的好的效果。","link":"/2022/06/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/Ch2-learning-to-Answering-Yes-No/"},{"title":"Ch1 the Learning Problem","text":"hljs.initHighlightingOnLoad(); 本讲主要简单的介绍什么是机器学习，以及机器学习的一些应用。这门课是复习机器学习的一门课程，相比吴恩达的课程要有一些的难度。 what is Machine LearningFrom Learning to Machine Learning 那么如何定义Skill，这里的Skill就是improve some performance measure，举例来说有prediction accuracy . Yet Another Application: Tree Recognition 简而言之，就是让机器自己去学习如何辨认树，比我们给出复杂的定义要来的快很多。 The Machine Learning RouteML: an alternative route to build complicated systems when human cannot program the system manually—navigating on Mars 火星上的环境过于复杂，很多是人之前没有见过的，因此会变得难以建模，于是使用机器学习的方法，让探测器自己学习 when human cannot ‘define the solution’ easily—speech/visual recognition 语音信号也是比较多变且复杂，因此使用机器学习来让其自主处理 when needing rapid decisions that humans cannot do—high-frequency trading 对于高频变化的系统，如股票的交易需要机器学习来快速反应 when needing to be user-oriented in a massive scale—consumer-targeted marketing 主要是教会电脑钓鱼，而不是直接给电脑鱼。 Key Essence of Machine Learning使用机器学习需要满足的三个关键： 具有确定的规则和评价标准，即目标函数。 具有一定的可编程性，但是要有一定的不确定性，否则可以通过计算机直接枚举来求解。 具有一定的输入信息。 这里的是机器学习的是3问题。 对于问题1，没有十分确定规则可供学习。 对于问题2，其是编程确定问题，可以直接遍历求解。 对于问题4，是比较缺乏数据来学习。 Applications of Machine LearningDaily Needs机器学习在衣食住行上的应用。 预测餐馆的卫生状况； 对于穿衣，推荐系统，基于销售数据来进行推荐； 土木建筑，预测耗能状况； 行，无人驾驶，交通标志的辨识。 预测考题的正答率，已经预测这种考题下的mean cores等。 key part of the world-champion system from National Taiwan Univ. in KDDCup 2010 在娱乐方面的应用，推荐系统。 根据客户的评分来推荐电影和评分者的喜好。 将评分者和特征向量和电影的特征向量进行内积或self-attention. Components of Machine Learning Formalize the Learning Problem 使用假设的函数g来逼近 目标函数 f(未知)。 其中g 不一定会等于 f 但是g只要不断地逼近 f 就好。 所谓机器学习的模型，其实就是算法和其使用的假设集合。 Practical Definition of Machine Learning Machine Learning and Other FieldsMachine Learning and Data Mining ML和DM有很大的相似度，因此如今几乎很难来进行区分了。 机器学习在乎的是预测，而数据挖掘在意的是发现有趣且重要的信息。 DM需要的数据量也很大，关注于在大的数据库内进行操作，发觉一些比较隐秘的东西，eg.对于使用DM来分析买A和买B的相关性。 Machine Learning and Artificial Intelligence 机器学习是实现人工智能的一种方法。 对于一般的机器人下棋，可以通过强化学习来让机器人自己下棋，并给予一定的反馈。 也可以让机器人学习其他棋手的下棋策略来实现学习。 Machine Learning and Statistics 统计是实现机器学习的一种方法； 统计其实就是利用统计的工具来预测和推断未知的数据。 总结","link":"/2022/06/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/Ch1-The-Learning-Problem/"},{"title":"Ch7 视觉里程计 第一部分 特征点法","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是关于第七章的第一部分，主要介绍的是基于特征点法求解目标的匹配的问题。最后是一个基于C++和OpenCV库是实践。 简介首先，视觉里程计的核心的问题是根据图像来估计相机的运动，但是直接从图像的色彩和灰度矩阵来考虑的话，计算量很大，因此通过选取图像中有代表性的点，并且在视角发生变化后尽量保持不变。通过这些点来讨论位姿的变化和点的定位问题。 经典的SLAM是以位姿——路标来描述SLAM的过程的。 路标是三维空间中固定不变的点，能够在特定位姿下观察到 数量比较充足，以实现良好的定位 具有较好的区分性，来实现数据的关联 在视觉SLAM中，可以利用图像特征点作为SLAM的路标 此时在视觉SLAM中，特征就是路标。 对于数据图像而言，灰度受到光照、形变、物质材质的影响比较严重，变化比较大同时不够稳定，因此一般是采用特征点法。 书中提到，就可辨识度方面来看，角点 &gt; 边缘 &gt; 像素块；但是在一般的情况下，单纯的角点无法满足我们的需求，远近变化、旋转变化会使得同一个角点变得无法辨识，于是需要设计更加稳定的局部特征图，SIFT、SURF、ORB等等。 特征点是图像中具有代表性的部分，于是其主要具有以下的性质： 可重复性：相同的特征可以在不同的图像中找到； 可区别性：不同的特征的表达不同 高效性：同一个图像里，特征点的数量要小于像素的数量 本地性：特征仅与一小片图像区域相关 特征点的信息主要包括两个部分， 关键点：即在图像里的位置信息、方向、大小、评分等信息 描述子：一个向量，类似于Word2Vec，记录的是特征点周围的信息，使用其来计算特征点的相似度，来判断是否为同一个相似点。 这里的特征点描述应该在光照、视角发生少量的变化时还能保持一致。 计算描述子的算法优很多，其中SIFT（保持了平移、旋转和缩放）、SURF、ORB，因此对于问题来讲，SIFT的效果好，但是运算的速度慢，没办法满足实时不变性的需要，但是ORB尽管简单但是速度快，使用的范围也比较多。 详细可以参考OpenCV 的feature2d模块。 ORB特征是比较常用和最新的方法，计算比较容易，在2010年首次提出。 ORB特征ORB特征的描述子和关键点主要是BRIEF(Binary Robust Independent Elementary Feature) 和 Oriented FAST. FAST角点提取：主要是找到图像的角点，相比于原来的FAST增加了主方向，以及为后续的BRIEF描述子提供了旋转不变性。 BRIEF描述子：对前一步提取出的特征点的周围图像区域进行描述，在ORB中使用了先前关键点的方向信息。 FAST关键点 主要的思想是检测局部的像素灰度变化明显的地方，如果周围点的像素会连续的N个都大于之前的中间点一个数量级的话，此时该将给点示为一个角点。该方法仅仅比较亮度即可，可以满足实时性的要求。 但是原始的FAST会出现好多角点扎堆的情况，于是我们的需要一些方法来进行筛选，常用的方法为非最大值抑制，选择扎推点中最大的那个。 对于FAST方法中的问题，如FAST不具有尺度不变性和方向性的特征，于是提出了金字塔法和灰度质心法。 金字塔是计算图视觉中常用的一种处理方法,示意图如图7-3所示。金字塔底层是原始图像。每往上一层，就对图像进行一个固定倍率的缩放，这样我们就有了不同分辨率的图像。较小的图像可以看成是远处看过来的场景。在特征匹配算法中，我们可以匹配不同层上的图像，从而实现尺度不变性。例如,如果相机在后退，那么我们应该能够在上一个图像金字塔的上层和下一个图像金字塔的下层中找到匹配。 在旋转方面，计算灰度质心，就是将图像块的灰度值作为权重质心，主要的步骤如下： 比如，左边的灰度值普遍比右边大时，主要时此灰度的质心偏向于左边，于是会出现原点指向质心的一条向量，于是就有了方向。 BRIEF描述子 BRIEF-128主要是由128位的向量组成，每一位上的数字为0或者1，这里会根据不同的模式来进行取点操作，取出128个点对(x,y) ，如果x&gt;y：则为1，否则就为0，于是就会有一个128位的向量。 上图是不同的(x,y)两个点的选取的pattern，但是需要注意的是，上述选点的模式一旦确定，就不要再变了。 前面讲到的旋转向量OC可知，如果前面发生旋转之后，那BRIEF的描述子pattern也就跟着旋转。 距离计算：对于这里使用的是对于二进制数比较方便的汉明距离来度量，就是如果连个向量位置上的数字相同，那距离值就是0，不同就为1，最后比较的二者之间的距离。 其实这个距离本质上是有多少个点描述特征是相同的，因为每个向量的含义就是对于的点对是否是左边像素大于右边，两个描述子再同一位上面的数字相同，就代表其哪一位上都是左边的特征点大于右边的特征点。 特征匹配 最简单的方法就是暴力匹配，就是将所有本时刻特征点$x_t^m$和下一时刻所有的特征点$x_{t+1}^n$进行匹配 。 即对每一个特征点$x_t^m$与所有$x_{t+1}^n$的测量描述子的距离，然后排序，取最近的一个作为匹配点。 描述子距离表示了两个特征之间的相似程度，不过在实际运用中还可以取不同的距离度量范数。对于浮点类型的描述子，使用欧氏距离进行度量即可。而对于二进制的描述子（比如BRIEF这样的)，我们往往使用汉明距离（Hamming distance)作为度量——两个二进制串之间的汉明距离,指的是其不同位数的个数。 由于暴力匹配的计算量很大，于是实际情况下使用较多的是快速近似最近邻(FLANN)，该算法比较成熟，再OpenCV上已经实现。 实践本实践是一个对于简单特征点的实践教程。 首先，就是配置CmakeList.txt 123456789101112131415161718192021222324252627282930313233343536373839404142cmake_minimum_required(VERSION 2.8)project(vo1)set(CMAKE_BUILD_TYPE &quot;Release&quot;)add_definitions(&quot;-DENABLE_SSE&quot;)set(CMAKE_CXX_FLAGS &quot;-std=c++11 -O2 ${SSE_FLAGS} -msse4&quot;)list(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)find_package(OpenCV 3 REQUIRED)find_package(G2O REQUIRED)find_package(Sophus REQUIRED)include_directories( ${OpenCV_INCLUDE_DIRS} ${G2O_INCLUDE_DIRS} ${Sophus_INCLUDE_DIRS} &quot;/usr/include/eigen3/&quot;)add_executable(orb_cv orb_cv.cpp)target_link_libraries(orb_cv ${OpenCV_LIBS})add_executable(orb_self orb_self.cpp)target_link_libraries(orb_self ${OpenCV_LIBS})# add_executable( pose_estimation_2d2d pose_estimation_2d2d.cpp extra.cpp ) # use this if in OpenCV2 add_executable(pose_estimation_2d2d pose_estimation_2d2d.cpp)target_link_libraries(pose_estimation_2d2d ${OpenCV_LIBS})# # add_executable( triangulation triangulation.cpp extra.cpp) # use this if in opencv2add_executable(triangulation triangulation.cpp)target_link_libraries(triangulation ${OpenCV_LIBS})add_executable(pose_estimation_3d2d pose_estimation_3d2d.cpp)target_link_libraries(pose_estimation_3d2d g2o_core g2o_stuff ${OpenCV_LIBS})add_executable(pose_estimation_3d3d pose_estimation_3d3d.cpp)target_link_libraries(pose_estimation_3d3d g2o_core g2o_stuff ${OpenCV_LIBS}) 下面是orb_cv.cpp的主要代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;opencv2/imgcodecs/legacy/constants_c.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;chrono&gt;using namespace std;int main(int argc , char **argv){ if (argc != 3) { cout &lt;&lt; &quot;usage: feature_extraction img1 img2&quot; &lt;&lt; endl; return 1; } // - 读取图像 cv::Mat img_1 = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR); cv::Mat img_2 = cv::imread(argv[2], CV_LOAD_IMAGE_COLOR); assert(img_1.data != nullptr &amp;&amp; img_2.data != nullptr); // - 初始化 // 分别建立关键点和描述子 std::vector&lt;cv::KeyPoint&gt; keypoints_1, keypoints_2; cv::Mat descriptors_1, descriptors_2; // 分别申请ORB的描述子和关键点 cv::Ptr&lt;cv::FeatureDetector&gt; detector = cv::ORB::create(); // 这里create()函数的默认的特征点是500个，可以修改为create(1000) cv::Ptr&lt;cv::DescriptorExtractor&gt; descriptor = cv::ORB::create(); // 设置一个匹配将关键点和描述子进行匹配 cv::Ptr&lt;cv::DescriptorMatcher&gt; matcher = cv::DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;) ; // 第一步：检测Oriented Fast 角点 detector-&gt;detect(img_1, keypoints_1); detector-&gt;detect(img_2, keypoints_2); // 第二步：根据角点信息计算描述子 descriptor-&gt;compute(img_1, keypoints_1, descriptors_1); descriptor-&gt;compute(img_2, keypoints_2, descriptors_2); cv::Mat outimg_1; // 可视化计算得到的特征点 cv::drawKeypoints(img_1, keypoints_1, outimg_1, cv::Scalar::all(-1), cv::DrawMatchesFlags::DEFAULT); cv::imshow(&quot;ORB的特征点&quot;, outimg_1); // 第三步：对两幅图像计算BRIEF描述子的汉明距离 vector&lt;cv::DMatch&gt; matches ; matcher-&gt;match(descriptors_1, descriptors_2, matches); // 第四步：匹配点对的筛选 double min_dist = 10000, max_dist = 0; // 遍历找到所有的点的最小距离和最大距离，即为最相似和最不相似的两组点之间的距离 for (int i = 0; i &lt; descriptors_1.rows; i++) { double dist = matches[i].distance; // DMatch 里保存的距离就是汉明距离 if (dist &lt; min_dist) min_dist = dist; if (dist &gt; max_dist) max_dist = dist; } printf(&quot;-- Max dist : %f \\n&quot;, max_dist); printf(&quot;-- Min dist : %f \\n&quot;, min_dist); // 当描述子之间的距离大于两倍的最小距离，就认为其匹配错误 // 但是如果最小的距离很小时，我们会设为经验值30 std::vector&lt;cv::DMatch&gt; good_matches; for (int i = 0; i &lt; descriptors_1.rows; i++) { if (matches[i].distance &lt;= max(2 *min_dist, 30.0)) { good_matches.push_back(matches[i]); // 筛选，保留比较好的匹配 } } // 第五步：绘制匹配前后的结果 cv::Mat img_match; cv::Mat img_goodmatch; // 绘制一般的匹配 cv::drawMatches(img_1, keypoints_1, img_2, keypoints_2, matches, img_match); // 绘制筛选后的匹配 cv::drawMatches(img_1, keypoints_1, img_2, keypoints_2, good_matches, img_goodmatch); imshow(&quot;all matches&quot;, img_match); imshow(&quot;good matches&quot;, img_goodmatch); cv::waitKey(0); return 0;} 对于纹理比较均匀的桌面上，其特征点比较少。 接下来是orb_self.cpp的主要代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154#include &lt;opencv2/opencv.hpp&gt;#include &lt;string&gt;#include &lt;nmmintrin.h&gt;#include &lt;chrono&gt;using namespace std;// global variablesstring first_file = &quot;./1.png&quot;;string second_file = &quot;./2.png&quot;;// 32 bit unsigned int, will have 8, 8x32=256typedef vector&lt;uint32_t&gt; DescType; // Descriptor type/** * compute descriptor of orb keypoints * @param img input image * @param keypoints detected fast keypoints * @param descriptors descriptors * * NOTE: if a keypoint goes outside the image boundary (8 pixels), descriptors will not be computed and will be left as * empty */void ComputeORB(const cv::Mat &amp;img, vector&lt;cv::KeyPoint&gt; &amp;keypoints, vector&lt;DescType&gt; &amp;descriptors);/** * brute-force match two sets of descriptors * @param desc1 the first descriptor * @param desc2 the second descriptor * @param matches matches of two images */void BfMatch(const vector&lt;DescType&gt; &amp;desc1, const vector&lt;DescType&gt; &amp;desc2, vector&lt;cv::DMatch&gt; &amp;matches);int main(int argc, char **argv) { // load image cv::Mat first_image = cv::imread(first_file, 0); cv::Mat second_image = cv::imread(second_file, 0); assert(first_image.data != nullptr &amp;&amp; second_image.data != nullptr); // detect FAST keypoints1 using threshold=40 chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); vector&lt;cv::KeyPoint&gt; keypoints1; cv::FAST(first_image, keypoints1, 40); vector&lt;DescType&gt; descriptor1; ComputeORB(first_image, keypoints1, descriptor1); // same for the second vector&lt;cv::KeyPoint&gt; keypoints2; vector&lt;DescType&gt; descriptor2; cv::FAST(second_image, keypoints2, 40); ComputeORB(second_image, keypoints2, descriptor2); chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;extract ORB cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl; // find matches vector&lt;cv::DMatch&gt; matches; t1 = chrono::steady_clock::now(); BfMatch(descriptor1, descriptor2, matches); t2 = chrono::steady_clock::now(); time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;match ORB cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl; cout &lt;&lt; &quot;matches: &quot; &lt;&lt; matches.size() &lt;&lt; endl; // plot the matches cv::Mat image_show; cv::drawMatches(first_image, keypoints1, second_image, keypoints2, matches, image_show); cv::imshow(&quot;matches&quot;, image_show); cv::imwrite(&quot;matches.png&quot;, image_show); cv::waitKey(0); cout &lt;&lt; &quot;done.&quot; &lt;&lt; endl; return 0;}// compute the descriptorvoid ComputeORB(const cv::Mat &amp;img, vector&lt;cv::KeyPoint&gt; &amp;keypoints, vector&lt;DescType&gt; &amp;descriptors) { const int half_patch_size = 8; const int half_boundary = 16; int bad_points = 0; for (auto &amp;kp: keypoints) { if (kp.pt.x &lt; half_boundary || kp.pt.y &lt; half_boundary || kp.pt.x &gt;= img.cols - half_boundary || kp.pt.y &gt;= img.rows - half_boundary) { // outside bad_points++; descriptors.push_back({}); continue; } float m01 = 0, m10 = 0; for (int dx = -half_patch_size; dx &lt; half_patch_size; ++dx) { for (int dy = -half_patch_size; dy &lt; half_patch_size; ++dy) { uchar pixel = img.at&lt;uchar&gt;(kp.pt.y + dy, kp.pt.x + dx); m10 += dx * pixel; m01 += dy * pixel; } } // angle should be arc tan(m01/m10); float m_sqrt = sqrt(m01 * m01 + m10 * m10) + 1e-18; // avoid divide by zero float sin_theta = m01 / m_sqrt; float cos_theta = m10 / m_sqrt; // compute the angle of this point DescType desc(8, 0); for (int i = 0; i &lt; 8; i++) { uint32_t d = 0; for (int k = 0; k &lt; 32; k++) { int idx_pq = i * 32 + k; cv::Point2f p(ORB_pattern[idx_pq * 4], ORB_pattern[idx_pq * 4 + 1]); cv::Point2f q(ORB_pattern[idx_pq * 4 + 2], ORB_pattern[idx_pq * 4 + 3]); // rotate with theta cv::Point2f pp = cv::Point2f(cos_theta * p.x - sin_theta * p.y, sin_theta * p.x + cos_theta * p.y) + kp.pt; cv::Point2f qq = cv::Point2f(cos_theta * q.x - sin_theta * q.y, sin_theta * q.x + cos_theta * q.y) + kp.pt; if (img.at&lt;uchar&gt;(pp.y, pp.x) &lt; img.at&lt;uchar&gt;(qq.y, qq.x)) { d |= 1 &lt;&lt; k; } } desc[i] = d; } descriptors.push_back(desc); } cout &lt;&lt; &quot;bad/total: &quot; &lt;&lt; bad_points &lt;&lt; &quot;/&quot; &lt;&lt; keypoints.size() &lt;&lt; endl;}// brute-force matchingvoid BfMatch(const vector&lt;DescType&gt; &amp;desc1, const vector&lt;DescType&gt; &amp;desc2, vector&lt;cv::DMatch&gt; &amp;matches) { const int d_max = 40; for (size_t i1 = 0; i1 &lt; desc1.size(); ++i1) { if (desc1[i1].empty()) continue; cv::DMatch m{i1, 0, 256}; for (size_t i2 = 0; i2 &lt; desc2.size(); ++i2) { if (desc2[i2].empty()) continue; int distance = 0; for (int k = 0; k &lt; 8; k++) { distance += _mm_popcnt_u32(desc1[i1][k] ^ desc2[i2][k]); } if (distance &lt; d_max &amp;&amp; distance &lt; m.distance) { m.distance = distance; m.trainIdx = i2; } } if (m.distance &lt; d_max) { matches.push_back(m); } }}","link":"/2022/05/31/SLAM/ch7-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E7%89%B9%E5%BE%81%E7%82%B9%E6%B3%95/"},{"title":"Ch7 视觉里程计 第二部分 对极几何和三角测量","text":"hljs.initHighlightingOnLoad(); 本文主要讲解的是视觉里程计VO的第二部分，对极几何和三角测量，其主要是建立在第一节的提取特征点的基础上，求得相机的位置变换情况，在通过三角估计来测量对于的深度值。 对极几何对极约束在我们得到特征的匹配之后，现在需要对得到的特征点进行匹配，来确定的相机的运动情况： 如果相机只有两个单目的相机时，为了确定2D-2D的关系，使用对极几何。 如果匹配的是RGBD，即一个相机是双目另一个位RGBD，或者通过某种方法可以来得到距离信息，即3D-3D的关系，使用ICP。 如果使用匹配的是帧和地图，即得到的是3D点已经在投影中位置，即得到3D-2D的信息，使用PnP。 几何关系： P在两个图像的投影为$p_1,p_2$, 此时相机的两个投影面为$I_1、I_2$ 两个相机之间的变换为$T_{12},R,t$ $p_1=T_{12}p_2$ 这里的$p_1,p_2$为坐标 $O_1P$ 在图像$I_2$上投影为$e_2p_2$，记为$l_2$，称为极线 $O_2P$在图像$I_1$上的投影为$e_1p_1$，记为$l_1$ ，称为极线 $O_1O_2$与$I_1\\ I_2$的交点为$e_1、e_2$，称为极点 只有$I_1$那么P可以出现在$O_1p_1$上面的任意一个地方，需要两个才可以确定最后的P的位置。 这个问题可以转化称为已经图像的信息，来求解转换矩阵$T_{12}$和P点的位置的。 对约束的代数形式 在第一帧的坐标系之下，设P为空间位置为$P=[x,y,z]^T$ 根据之前讲解的相机模型可得两个像素点的像素位置$p_1,p_2$为： s_1p_1=Kp, \\ s_2p_2=K(R_{21}P+t_{21})有时我们会使用齐次坐标来表达一个像素点，在使用齐次坐标时，一个向量将等于自身乘以任意一个非零的常数，这通常来表达一个投影的关系，于是$s_1p_1$和$p_1$可以认为是在齐次坐标系下是相等的$sp\\simeq p$ 于是上述的投影关系可以是： p_1 \\simeq KP ,\\ p_2\\simeq K(KP+t)于是现在可以取： x_1=K^{-1}p_1,x_2=K^{-1}p_2这里的$x_1,x_2$是两个像素点的归一化的平面上的坐标(z=1)，代入可得： x_2 \\simeq R_{21}x_1 + t_{21}两边同时左乘$t^{\\wedge}$，这里是反对称矩阵的意思，其实也就是叉乘，外积： t^{\\wedge}x_2 \\simeq t^{\\wedge}Rx_1然后，两侧同时乘以$x_2^T$可得： x_2^Tt^{\\wedge}x_2\\simeq x_2^Tt^{\\wedge}Rx_1观察等式$x_2^Tt^{\\wedge}$ 是一个与t和$x_2$ 都是垂直的向量。他们再和$x_2$求内积可得0，于是得到： x_2^{T}t^{\\wedge}Rx_1=0在代入$p_1,p_2$可得： p_2^TK^{-T}t^{\\wedge}RK^{-1}p_1=0上述两式都为对极约束，其几何意义是$O_1,P,O_2$三点共面。 于是以下定义： $E=t^{\\wedge}R$ ,称为本质矩阵(Essential Matrix) $F=K^{-T}EK^{-1}$,称为基础矩阵(Fundamental Matrix) 于是位姿估计问题就转化为下面两个问题。 根据配对点的像素位置$p_1,p_2$，来求出对应的$E,F$; 根据$E,F$ 来反解出 $R,t$。 本质矩阵本质矩阵是一个$3\\times3$的矩阵，但是并非任何$3\\times3$的矩阵都是本质矩阵，这里面有一定的约束在里面： 尽管E具有五个自由度，我们最少是可以使用5个点来进行求解，但是本质矩阵的内在性质是一个非线性的约束，其在估计的时候会带来麻烦，需要考虑尺度等价性。 因此仅仅考虑尺度等价性也需要8对点来估计E，这就是经典的八点法，这里八点法只是利用了E的线性性质，在线性的框架下求解比较容易可行。 八点法的推导考虑一对匹配点，他们的归一化坐标为$x_1=[u_1,v_1,1]^T,x_2=[u_2,v_2,1]^T$ 根据对极约束有： \\left(u_{1}, v_{1}, 1\\right)\\left(\\begin{array}{lll}e_{1} & e_{2} & e_{3} \\\\ e_{4} & e_{5} & e_{6} \\\\ e_{7} & e_{8} & e_{9}\\end{array}\\right)\\left(\\begin{array}{c}u_{2} \\\\ v_{2} \\\\ 1\\end{array}\\right)=0于是我们将矩阵E写成向量的形式： e=[e_1,e_2,e_3,e_4,e_5,e_6,e_7,e_8.e_9]^T那么，对极约束可以写成关于e的线性形式： \\left[u_{1} u_{2}, u_{1} v_{2}, u_{1}, v_{1} u_{2}, v_{1} v_{2}, u_{2}, v_{2}, 1\\right] \\cdot e=0同理，对于其他的点对来说也有相同的形式： 如果系数空间为满秩为8，于是对于的零空间维数为1，于是e也就构成了一条线的形式，即满足了尺度等价性。 求解R,t求解的过程使用到的是矩阵的奇异值分解，对本质矩阵E进行SVD分解可得： E=U\\Sigma V^T其中U,V为正交矩阵，$\\Sigma$ 为奇异值矩阵。根据E的内在性质可得$\\Sigma=diag(\\sigma,\\sigma,0)$ ,对于任意的E，都存在两个可能的t,R与之对应： \\boldsymbol{t}_{1}^{\\wedge}=\\boldsymbol{U} \\boldsymbol{R}_{Z}\\left(\\frac{\\pi}{2}\\right) \\boldsymbol{\\Sigma} \\boldsymbol{U}^{T}, \\quad \\boldsymbol{R}_{1}=\\boldsymbol{U} \\boldsymbol{R}_{Z}^{T}\\left(\\frac{\\pi}{2}\\right) \\boldsymbol{V}^{T}\\\\ \\boldsymbol{t}_{2}^{\\wedge}=\\boldsymbol{U} \\boldsymbol{R_{Z}}\\left(-\\frac{\\pi}{2}\\right) \\Sigma \\boldsymbol{U}^{T}, \\quad \\boldsymbol{R}_{2}=\\boldsymbol{U} \\boldsymbol{R}_{Z}^{T}\\left(-\\frac{\\pi}{2}\\right) \\boldsymbol{V}^{T}起主要有四个可能的解，其中也只能有一个对应的是深度为正值的情况，因此只要将接出来的情况代入，找到满足两个相机都为0的情况即可。 注意： 对于五点法来说，在工程上可能有几十对或者几百对的点对，因此从8对减到5对之后的效果并不明显。 如果求解得到特征值不满足E的内在性质，即特征值为$\\sigma,\\sigma,0$ 的形式，于是就有，这时我们会可以的将$\\Sigma$ 调节成上述的形式 当$\\Sigma=diag(\\sigma_1,\\sigma_2,\\sigma_3)$时，不妨$\\sigma_1&gt;\\sigma_2&gt;\\sigma_3$ 于是取： E=Udiag(\\dfrac{\\sigma_1+\\sigma_2}{2},\\dfrac{\\sigma_1+\\sigma_2}{2},0)V^T 这就相当于将矩阵投影到E的流形上面，或者直接取成1，1，0，因为E满足尺度的等价性。 八点法存在的问题 首先，八点法主要用于单目SLAM的初始化操作，但是这个初始化存在一定不好的性质如下。 尺度不确定性：根据E求出t,R,乘以任意的倍数之后都是成立的，因此通常将其归一化为1或者将特征点的平均深度为1； 其实主要就是就算归一化，那么真实值其实也是无法确定的，因为不知道真实值和规定值之间的放大倍数。 纯旋转的问题：t=0时，无法求解，$E=t^{\\wedge}R$ 此时的E为0，那旋转矩阵R就无法求解，因此单目相机初始化的不能只有旋转，必须要有一定程度上的平移。 多于八个点：此时的方程就是一个超定的方程，其求解是不现实的，需要进行使用最小二乘估计的方法来求解。 \\min\\limits_{e}||Ae||_2^2=\\min\\limits_e e^TA^TAe于是就求出E，但是如果存在错误匹配的话，这样解就相当不好，于是一般采用的是RANSAC的方法，(Random Sample Concensus) 。 单应矩阵 这个矩阵就是用来处理八点法特征点共面时的退化情况； 这里设其所在的平面为P，则有平面方程$n^TP+d=0$，稍加整理就会有$-\\dfrac{n^TP}{d}=1$ 回顾之前的讲解则有： 于是记中间的矩阵为H，于是得到两个特征之间的变换为： p_2\\simeq Hp_1这里的处理和F、E类似，就是根据匹配点将H求出来，进而再求解旋转和平移矩阵： \\left(\\begin{array}{c}u_{2} \\\\ v_{2} \\\\ 1\\end{array}\\right)\\simeq\\left(\\begin{array}{lll}h_{1} & h_{2} & h_{3} \\\\ h_{4} & h_{5} & h_{6} \\\\ h_{7} & h_{8} & h_{9}\\end{array}\\right)\\left(\\begin{array}{c}u_{1} \\\\ v_{1} \\\\ 1\\end{array}\\right)之后将第三行的元素去掉可得： u_{2}=\\frac{h_{1} u_{1}+h_{2} v_{1}+h_{3}}{h_{7} u_{1}+h_{8} v_{1}+h_{9}},v_{2}=\\frac{h_{4} u_{1}+h_{5} v_{1}+h_{6}}{h_{7} u_{1}+h_{8} v_{1}+h_{9}}\\\\ h_1u_1+h_2v_1+h_3-h_7u_1u_2-h_8v_1v_2=u_2\\\\ h_4u_1+h_5v_1+h_6-h_7u_1u_2-h_8v_1v_2=v_2一对点其实可以提供两种约束，于是就可以得到关于H的线性方程： \\left(\\begin{array}{cccccccc}u_{1}^{1} & v_{1}^{1} & 1 & 0 & 0 & 0 & -u_{1}^{1} u_{2}^{1} & -v_{1}^{1} u_{2}^{1} \\\\ 0 & 0 & 0 & u_{1}^{1} & v_{1}^{1} & 1 & -u_{1}^{1} v_{2}^{1} & -v_{1}^{1} v_{2}^{1} \\\\ u_{1}^{2} & v_{1}^{2} & 1 & 0 & 0 & 0 & -u_{1}^{2} u_{2}^{2} & -v_{1}^{2} u_{2}^{2} \\\\ 0 & 0 & 0 & u_{1}^{2} & v_{1}^{2} & 1 & -u_{1}^{2} v_{2}^{2} & -v_{1}^{2} v_{2}^{2} \\\\ u_{1}^{3} & v_{1}^{3} & 1 & 0 & 0 & 0 & -u_{1}^{3} u_{2}^{3} & -v_{1}^{3} u_{2}^{3} \\\\ 0 & 0 & 0 & u_{1}^{3} & v_{1}^{3} & 1 & -u_{1}^{3} v_{2}^{3} & -v_{1}^{3} v_{2}^{3} \\\\ u_{1}^{4} & v_{1}^{4} & 1 & 0 & 0 & 0 & -u_{1}^{4} u_{2}^{4} & -v_{1}^{4} u_{2}^{4} \\\\ 0 & 0 & 0 & u_{1}^{4} & v_{1}^{4} & 1 & -u_{1}^{4} v_{2}^{4} & -v_{1}^{4} v_{2}^{4}\\end{array}\\right)\\left(\\begin{array}{c}h_{1} \\\\ h_{2} \\\\ h_{3} \\\\ h_{4} \\\\ h_{5} \\\\ h_{6} \\\\ h_{7} \\\\ h_{8}\\end{array}\\right)=\\left(\\begin{array}{c}u_{2}^{1} \\\\ v_{2}^{1} \\\\ u_{2}^{2} \\\\ v_{2}^{2} \\\\ u_{2}^{3} \\\\ v_{2}^{3} \\\\ u_{2}^{4} \\\\ v_{2}^{4}\\end{array}\\right)最后就是类似于八点法来先求解H再恢复出对于的旋转矩阵和平移矩阵。具体的细节看论文。 小结： 2D-2D的情况下，仅仅知道图像坐标之间的对于关系 当特征点再平面上时(如俯视或仰视)，使用H来恢复出R,t 否则就是使用E(本质矩阵)，F(基础矩阵)来进行恢复 求得R,t之后： 利用三角化计算特征点的3D位置，即深度。 实践下面是pose_estimation_2d2d.cpp的主要代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;opencv2/calib3d/calib3d.hpp&gt;#include &lt;opencv2/imgcodecs/legacy/constants_c.h&gt;using namespace std;/**************************************************** * 本程序演示了如何使用2D-2D的特征匹配估计相机运动 * **************************************************/// 声明提取特征代点并匹配的函数;void find_feature_matches( const cv::Mat &amp;img_1, const cv::Mat &amp;img_2, // 如果想要修改里面的内容需要传指针或者引用 std::vector&lt;cv::KeyPoint&gt; &amp;keypoints_1, std::vector&lt;cv::KeyPoint&gt; &amp;keypoints_2, std::vector&lt;cv::DMatch&gt; &amp;matches);// 声明位姿估计函数void pose_estimation_2d2d( std::vector&lt;cv::KeyPoint&gt; keypoints_1, std::vector&lt;cv::KeyPoint&gt; keypoints_2, std::vector&lt;cv::DMatch&gt; matches, cv::Mat &amp;R, cv::Mat &amp;t);// 像素坐标转相机归一化cv::Point2d pixel2cam(const cv::Point2d &amp;p, const cv::Mat &amp;K);// 这个其实跟orb_cv.cpp一样，是它的一个封装void find_feature_matches( const cv::Mat &amp;img_1, const cv::Mat &amp;img_2, std::vector&lt;cv::KeyPoint&gt; &amp;keypoints_1, std::vector&lt;cv::KeyPoint&gt; &amp;keypoints_2, std::vector&lt;cv::DMatch&gt; &amp;matches){ // 初始化参数 // 创建描述子矩阵 cv::Mat descriptors_1, descriptors_2; // 分别申请ORB的描述子和关键点 cv::Ptr&lt;cv::FeatureDetector&gt; detector = cv::ORB::create(); cv::Ptr&lt;cv::DescriptorExtractor&gt; descriptor = cv::ORB::create(); // 设置一个匹配将关键点和描述子进行匹配 cv::Ptr&lt;cv::DescriptorMatcher&gt; matcher = cv::DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;) ; //-- 第一步:检测 Oriented FAST 角点位置 detector-&gt;detect(img_1, keypoints_1); detector-&gt;detect(img_2, keypoints_2); //-- 第二步:根据角点位置计算 BRIEF 描述子 descriptor-&gt;compute(img_1, keypoints_1, descriptors_1); descriptor-&gt;compute(img_2, keypoints_2, descriptors_2); //-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离 vector&lt;cv::DMatch&gt; match; //BFMatcher matcher ( NORM_HAMMING ); matcher-&gt;match(descriptors_1, descriptors_2, match); //-- 第四步:匹配点对筛选 double min_dist = 10000, max_dist = 0; //找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离 for (int i = 0; i &lt; descriptors_1.rows; i++) { double dist = match[i].distance; if (dist &lt; min_dist) min_dist = dist; if (dist &gt; max_dist) max_dist = dist; } printf(&quot;-- Max dist : %f \\n&quot;, max_dist); printf(&quot;-- Min dist : %f \\n&quot;, min_dist); //当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限. for (int i = 0; i &lt; descriptors_1.rows; i++) { if (match[i].distance &lt;= max(2 * min_dist, 30.0)) { matches.push_back(match[i]); } }}cv::Point2d pixel2cam(const cv::Point2d &amp;p, const cv::Mat &amp;K) { return cv::Point2d ( (p.x - K.at&lt;double&gt;(0, 2)) / K.at&lt;double&gt;(0, 0), (p.y - K.at&lt;double&gt;(1, 2)) / K.at&lt;double&gt;(1, 1) );}void pose_estimation_2d2d( std::vector&lt;cv::KeyPoint&gt; keypoints_1, std::vector&lt;cv::KeyPoint&gt; keypoints_2, std::vector&lt;cv::DMatch&gt; matches, cv::Mat &amp;R, cv::Mat &amp;t){ // 相机内参，TUM Freiburg2 cv::Mat K = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 325.1, 0, 521.0, 249.7, 0, 0, 1); // 将匹配点转化成为vector&lt;cv::Point2f&gt;的形式 vector&lt;cv::Point2f&gt; points1; vector&lt;cv::Point2f&gt; points2; for (int i = 0; i &lt; (int)matches.size(); i++) { points1.push_back(keypoints_1[matches[i].queryIdx].pt); points2.push_back(keypoints_2[matches[i].trainIdx].pt); } // 计算基础矩阵 cv::Mat fundamental_matrix; fundamental_matrix = cv::findFundamentalMat(points1, points2, cv::FM_8POINT); // https://blog.csdn.net/qq_38629044/article/details/96907844 // 使用八点法求解 cout &lt;&lt; &quot;fundamental_matrix is &quot; &lt;&lt; endl &lt;&lt; fundamental_matrix &lt;&lt; endl; // 计算本质矩阵 cv::Point2d principal_point(325.1, 249.7); // 相机光心，TUM dataset标定值 double focal_length = 521; // 相机焦距, TUM dataset标定值 cv::Mat essential_matrix; essential_matrix = cv::findEssentialMat(points1, points2, focal_length, principal_point); cout &lt;&lt; &quot;essential_matrix is &quot; &lt;&lt; endl &lt;&lt; essential_matrix &lt;&lt; endl; //-- 计算单应矩阵 //-- 但是本例中场景不是平面，单应矩阵意义不大 cv::Mat homography_matrix; homography_matrix = cv::findHomography(points1, points2, cv::RANSAC, 3); cout &lt;&lt; &quot;homography_matrix is &quot; &lt;&lt; endl &lt;&lt; homography_matrix &lt;&lt; endl; cv::recoverPose(essential_matrix, points1, points2, R, t, focal_length, principal_point); cout &lt;&lt; &quot;R is &quot; &lt;&lt; endl &lt;&lt; R &lt;&lt; endl; cout &lt;&lt; &quot;t is &quot; &lt;&lt; endl &lt;&lt; t &lt;&lt; endl;}int main(int argc, char **argv) { if (argc != 3) { cout &lt;&lt; &quot;usage: pose_estimation_2d2d img1 img2&quot; &lt;&lt; endl; return 1; } //-- 读取图像 cv::Mat img_1 = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR); cv::Mat img_2 = cv::imread(argv[2], CV_LOAD_IMAGE_COLOR); assert(img_1.data &amp;&amp; img_2.data &amp;&amp; &quot;Can not load images!&quot;); vector&lt;cv::KeyPoint&gt; keypoints_1, keypoints_2; vector&lt;cv::DMatch&gt; matches; find_feature_matches(img_1, img_2, keypoints_1, keypoints_2, matches); cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl; // 估计两个图像之间的运动 cv::Mat R,t; pose_estimation_2d2d(keypoints_1, keypoints_2, matches, R, t); // 验证E=t^R*scale cv::Mat t_x = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; 0, -t.at&lt;double&gt;(2, 0), t.at&lt;double&gt;(1, 0), t.at&lt;double&gt;(2, 0), 0, -t.at&lt;double&gt;(0, 0), -t.at&lt;double&gt;(1, 0), t.at&lt;double&gt;(0, 0), 0); // t_x为反对称矩阵 cout &lt;&lt; &quot;t^R=&quot; &lt;&lt; endl &lt;&lt; t_x * R &lt;&lt; endl; //-- 验证对极约束 cv::Mat K = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); for (cv::DMatch m: matches) { cv::Point2d pt1 = pixel2cam(keypoints_1[m.queryIdx].pt, K); cv::Mat y1 = (cv::Mat_&lt;double&gt;(3, 1) &lt;&lt; pt1.x, pt1.y, 1); cv::Point2d pt2 = pixel2cam(keypoints_2[m.trainIdx].pt, K); cv::Mat y2 = (cv::Mat_&lt;double&gt;(3, 1) &lt;&lt; pt2.x, pt2.y, 1); cv::Mat d = y2.t() * t_x * R * y1; cout &lt;&lt; &quot;epipolar constraint = &quot; &lt;&lt; d &lt;&lt; endl; } return 0;} 三角测量之前主要是根据讲解可得关于相机的位姿，下面将讲分析通过相机的空间位置来估计特征点的空间位置。在单目SLAM里，经常使用三角化法或三角测量来估计。 三角测量的求解方法三角测量主要是指通过不同位置对同一个路标点进行观察，从观察到的位置判断路标点的距离。 此时有对极几何的定义可得： s_1x_1=s_2\\boldsymbol{R} x_2+t求$s_2$时，我们将两侧同时乘以$x_1^{\\wedge}$可得： s_{1} x_{1}^{\\wedge} x_{1}=0=s_{2} x_{1}^{\\wedge} \\boldsymbol{R} x_{2}+{x}_{1}^{\\wedge} {t}于是问题转换成为，在已知$\\boldsymbol{R}, t$ 的情况下，如何求解$s_1,s_2$ ： \\left[-R x_{2}, x_{1}\\right]\\left[\\begin{array}{l}s_{1} \\\\ s_{2}\\end{array}\\right]=t 这个问题的解法很多，可以看成一个解方程组的问题，相当于求解一个超定的方程，使用最小二乘解来求解，$x=(A^TA)^{-1}A^Tb$ 但是由于估计值存在误差，因此我们求解得到$s_1,s_2$不一定是对应同一个地方，需要使用最小二乘求解。 三角测量存在的问题 三角测量是建立在平移的基础上的，没有平移的化就无法定义三角测量。 因此，但平移t的距离很小时，其相对的误差就比较的大，于是就造成对于目标点的估计误差很大。有可能出现其测量的深度为正无穷或者为负值的情况 当t的值较大的情况下，其相对的误差较小，相同的精度下其估计值会准确喝多。 出现上述状况的原因为：求解时其系数矩阵的伪逆是不可靠的。 通过$A^TA$ 的行列式的值可以判断，如果接近于0，那就是求解出的两条线近似平行。 例如，相机前进时，虽然有位移，但是位于图像的中心点，无法三角化。因为其本来就是在很远的地方，在两个位置上观察近似于没动。 直接的想法解决上述问题就是： 增大分分辨率，提高提缺点的精度。但是这种方法会极大的增大运算量和成本。 扩大位移t，这样会造成两次相机拍到的照片外观的变化较大，很难进行特征点的匹配问题，需要较小位移，但这样无疑增大了误差，这就是三角化的矛盾。 实践本节代码和上节有很多一样的地方，如pose_estimation_2d2d和find_feature_matches函数，此处就不在赘述。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647void triangulation( const vector&lt;KeyPoint&gt; &amp;keypoint_1, const vector&lt;KeyPoint&gt; &amp;keypoint_2, const std::vector&lt;DMatch&gt; &amp;matches, const Mat &amp;R, const Mat &amp;t, vector&lt;Point3d&gt; &amp;points) { Mat T1 = (Mat_&lt;float&gt;(3, 4) &lt;&lt; 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0); Mat T2 = (Mat_&lt;float&gt;(3, 4) &lt;&lt; R.at&lt;double&gt;(0, 0), R.at&lt;double&gt;(0, 1), R.at&lt;double&gt;(0, 2), t.at&lt;double&gt;(0, 0), R.at&lt;double&gt;(1, 0), R.at&lt;double&gt;(1, 1), R.at&lt;double&gt;(1, 2), t.at&lt;double&gt;(1, 0), R.at&lt;double&gt;(2, 0), R.at&lt;double&gt;(2, 1), R.at&lt;double&gt;(2, 2), t.at&lt;double&gt;(2, 0) ); Mat K = (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); vector&lt;Point2f&gt; pts_1, pts_2; for (DMatch m:matches) { // 将像素坐标转换至相机坐标 pts_1.push_back(pixel2cam(keypoint_1[m.queryIdx].pt, K)); pts_2.push_back(pixel2cam(keypoint_2[m.trainIdx].pt, K)); } Mat pts_4d; cv::triangulatePoints(T1, T2, pts_1, pts_2, pts_4d); // 转换成非齐次坐标 for (int i = 0; i &lt; pts_4d.cols; i++) { Mat x = pts_4d.col(i); x /= x.at&lt;float&gt;(3, 0); // 归一化 Point3d p( x.at&lt;float&gt;(0, 0), x.at&lt;float&gt;(1, 0), x.at&lt;float&gt;(2, 0) ); points.push_back(p); }}/// 作图用inline cv::Scalar get_color(float depth) { float up_th = 50, low_th = 10, th_range = up_th - low_th; if (depth &gt; up_th) depth = up_th; if (depth &lt; low_th) depth = low_th; return cv::Scalar(255 * depth / th_range, 0, 255 * (1 - depth / th_range));} 下面是程序的主函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344int main(int argc, char **argv) { if (argc != 3) { cout &lt;&lt; &quot;usage: triangulation img1 img2&quot; &lt;&lt; endl; return 1; } //-- 读取图像 Mat img_1 = imread(argv[1], CV_LOAD_IMAGE_COLOR); Mat img_2 = imread(argv[2], CV_LOAD_IMAGE_COLOR); vector&lt;KeyPoint&gt; keypoints_1, keypoints_2; vector&lt;DMatch&gt; matches; find_feature_matches(img_1, img_2, keypoints_1, keypoints_2, matches); cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl; //-- 估计两张图像间运动 Mat R, t; pose_estimation_2d2d(keypoints_1, keypoints_2, matches, R, t); //-- 三角化 vector&lt;Point3d&gt; points; triangulation(keypoints_1, keypoints_2, matches, R, t, points); //-- 验证三角化点与特征点的重投影关系 Mat K = (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); Mat img1_plot = img_1.clone(); Mat img2_plot = img_2.clone(); for (int i = 0; i &lt; matches.size(); i++) { // 第一个图 float depth1 = points[i].z; cout &lt;&lt; &quot;depth: &quot; &lt;&lt; depth1 &lt;&lt; endl; Point2d pt1_cam = pixel2cam(keypoints_1[matches[i].queryIdx].pt, K); cv::circle(img1_plot, keypoints_1[matches[i].queryIdx].pt, 2, get_color(depth1), 2); // 第二个图 Mat pt2_trans = R * (Mat_&lt;double&gt;(3, 1) &lt;&lt; points[i].x, points[i].y, points[i].z) + t; float depth2 = pt2_trans.at&lt;double&gt;(2, 0); cv::circle(img2_plot, keypoints_2[matches[i].trainIdx].pt, 2, get_color(depth2), 2); } cv::imshow(&quot;img 1&quot;, img1_plot); cv::imshow(&quot;img 2&quot;, img2_plot); cv::waitKey(); return 0;}","link":"/2022/06/04/SLAM/Ch7-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95%E4%B8%8E%E4%B8%89%E8%A7%92%E6%B5%8B%E9%87%8F/"},{"title":"Ch3 Types of Learning","text":"hljs.initHighlightingOnLoad(); 上节课主要讲解的是二元分类的问题，本节课主要讲解的是更多的学习的方式，其中根据输出空间来分可有分类、回归和结构化；根据y的标签来分，可以有监督、半监督和强化学习；根据输入的数据量来分，有批量学习、在线学习和主动学习；根据输入空间来分有具体数据、原数据和抽象数据。 Learning with Different Output Space YMore Binary Classification Problems 二元分类是机器学习中一个非常基本的问题，他是所有问题的基础。 Multiclass Classification: Coin Recognition Problem 相比于binary classification 的输出为0 / 1 ，都分类的输入为 一个类别数。经常是一个int类型的整数。 贩卖机对投入钱币进行分类，其主要是通过重量和大小来对投入的钱进行分类。 特殊的binary classification 可以看作类别数为2的都分类的问题。 Multiclass Classification 就是一种典型的模式识别问题。 Regression: Patient Recovery Prediction Problem 和前面的分类的问题不同，回归的问题Regression 的输出扩展到实数的范围上了。 其在统计学领域已经发展了好久，目前也已经比较成熟。回归问题在机器学习领域目前是相当的重要的一类问题。 Structured Learning: Sequence Tagging Problem 如果输入为一个单词，输出为单词的词性，那么这个问题就是一个简单的多分类的问题； 如果输入为一个句子，那么输出为需要辨识的句子中每个单词的在句子中的词性，那么本问题就是一个结构化学习的模型(structured Learning) 此时的输出的集合为每个句子的词性的排列，是一个输出类别数很大多分类的问题。 主要的结构化的问题有，NLP和胆蛋白质的结构预测等。 Learning with Different Data Label $y_n$Supervised: Coin Recognition Revisited 对于有监督学习而言，输入的一个$x_n$都对一应一个$y_n$ . Unsupervised: Coin Recognition without yn 右图为典型的聚类问题，相比有监督的学习而言，无监督的学习的主要的困难在于聚类数的选择，右图很可能就直接分成了三类。 因此无监督学习要比监督学习更加的困难。 典型的异常检测问题 密度分析问题：根据聚类的点分布的密度来分类； 异常点的检测：根据分布中的离群点来进行分类和异常检测。 unsupervised learning: diverse, with possibly very different performance goals Semi-supervised: Coin Recognition with Some $y_n$半监督学习：介于监督学习和无监督学习之间。 将已经标注的点作为聚类的中的中心，之和通过不断地迭代来进行分类操作； 但是存在的主要的问题：预先标记的最好要涵盖所有标签。 semi-supervised learning: leverage unlabeled data to avoid ‘expensive’ labeling 主要面向标记成本很贵的情况。 Reinforcement Learning 一种很不同但是很自然的学习的类型。a ‘very different’ but natural way of learning 通过反馈feedback和奖励reward，来对其标签的进行监督，是一种简洁的监督方法，而不是直接进行反馈。在多智能体的训练中使用较多。 这里奖励和惩罚不是绝对的，不同的action对于的奖励值可能都不一样。 强化学习主要应用在游戏棋牌，有时也会用在推荐系统上面，训练推荐器弹出广告的类型和时间。 reinforcement: learn with ‘partial/implicit information’ (often sequentially) 其主要特点为不是直接判断输出的优劣，而是通过其他的输出来完成的对当前输出动作的判断。 举个例子就是，可以使用剩余几步才到目的地来判断当前不同移动的奖励值。 core tool: supervised learning ,监督学习方法是核心。 Learning with Different Protocol $f (x_n, y_n)$Batch Learning: Coin Recognition Revisited 每次仅仅给一批数据，来进行监督学习。 batch supervised multiclass classification: learn from all known data Online: Spam Filter that ‘Improves’ 增量式的学习，或者叫做Online learning，主要是将垃圾邮件一封一封的给判别器来判断，这样就会使得我们的假设集里面的模型g 一种改变。 对于强化学习来说，其数据的输入也是增量式的，在线的。 对于PLA，这样的监督学习的方法其实也可以改成在线的学习。 online: hypothesis ‘improves’ through receiving data instances sequentially Active Learning: Learning by ‘Asking’ Batch ：填鸭式教育； Online：正常的学习方式； Active Learing：机器主动学习，根据后面的标签$y_n$来主动选择对应的$x_n$。通常用在label很难取得的情况。 active: improve hypothesis with fewer labels (hopefully) by asking questions strategically Learning with Different Input Space X之前的分类方法大部分是依据输出不同来划分的，下面来以输入为界限进行分类。 Concrete Featuresconcrete features: each dimension of $\\mathcal{X} \\in \\mathbb{R}^d$ represents ‘sophisticated physical meaning’ concrete features就是处理过的比较具体的数据点，其每一个数据的维度有有一定的物理上的含义。 Raw FeaturesRaw Features 于是相对应就是没有处理过的原始数据，其每一个维度并没有实在的物理意义。 Raw Features 就是对应的图片的像素值，256*256的矩阵。越raw就越抽象其学习起来的就越困难。 concrete features 这里取对称性symmerty, 和密度density来代表。 图片数据pixel，语音数据signal 对于信息的提取，如果是人工来做的，就叫做特征工程。 深度学习就是机器自动来学习。 Abstract Features Abstract Features：主要是给了最原始的ID编号，等非常抽象的数据。 需要更多的抽象和重构操作。 总结：","link":"/2022/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/ch3-Types-of-Learning/"},{"title":"G2O 曲线拟合","text":"hljs.initHighlightingOnLoad(); 本文详细的介绍了g2o库进行优化的一些模板，并提供一个曲线拟合的例子来加深对g2o的使用，为之后的PnP和ICP做准备，之后会结合第十章详细的介绍并进阶。 基本概念非线性的最小二乘优化过程中，是由很多的误差项组成，但是我们尚不清楚这些误差项之间的一些关系，比如有些优化变量跨越了多个误差项，于是就有了图优化。 图优化的顶点表示优化变量，边代表误差项。于是就将我们的如构架成一个图，并且这个图和我们的最小二乘优化函数是一一对应的。 下图所示，三角形代表相机的位姿结点，圆形代表路标点，它们构建成了图优化的顶点。对于边来说，实线代表相机的运动模型，虚线代表观测方程。 对于曲线的拟合过程，整个问题由于只有一个误差项的表达式，整个模型的优化参数就只有一个向量$a,b,c$ ，于是误差项只有一条边，即一个一元边。 G2O的使用步骤大概为： 定义顶点和边的类型； 构建图； 选择优化算法； 调用g2o 进行优化，返回结果。 这里运用G2O求解问题该优化问题： G2O顶点的工作内容(优化参数一般放在图的顶点上面)： 设置优化参数的初始值； 更新优化参数$x:=x+\\Delta x$； G2O边的工作内容(观测数据构成了边)： 获取相关的观测数据，以及和模型相关的已知数据； 以PnP为例，匹配的特征点就是观测数据，而相机内参就是和模型相关的数据。 构建误差函数； 构建雅可比矩阵； 源码精读节点的代码解析首先是关于基本模板类的构建g2o::BaseVertex&lt;3, Eigen::Vector3d&gt;这里是源码中的注释。 模板第一个参数D是需要优化矩阵维数的最小； 模板第二个参数是T要优化变量的类型，这里在代码里面的_estimate的类型和这个T是同一类型的。 123456789* Templatized BaseVertex * D : minimal dimension of the vertex, e.g., 3 for rotation in 3D. -1 means dynamically assigned at runtime. * T : internal type to represent the estimate, e.g., Quaternion for rotation in 3D */ template &lt;int D, typename T&gt; class BaseVertex : public OptimizableGraph::Vertex typedef T EstimateType;EstimateType _estimate; 下面，通过继承BaseVertex基类来定义边向量的表达。 EIGEN_MAKE_ALIGNED_OPERATOR_NEW 主要声明了Eigen的内存管理，其主要是赋值Eigen进行数据储存的。 setToOriginImpl()：设置初始化，这里_estimate 就是在模板里说如的那个Eigen::Vector3d的操作，因此_estimate &lt;&lt; 0, 0, 0;就是Eigen::Vector3d的输入形式。 void oplusImpl(const double *update)：这里的update其实就是数组的形式，下面首先将其转化为Eigen类型，并加到_estimate上面。 下面为完整的定义节点的代码： 1234567891011121314151617181920// 曲线模型的顶点，模板参数：优化变量维度和数据类型class CurveFittingVertex : public g2o::BaseVertex&lt;3, Eigen::Vector3d&gt;{public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW // 重置 virtual void setToOriginImpl() override { _estimate &lt;&lt; 0, 0, 0; } // 更新 virtual void oplusImpl(const double *update) override { _estimate += Eigen::Vector3d(update); } // 存盘和读盘：留空 virtual bool read(istream &amp;in) {} virtual bool write(ostream &amp;out) const {} }; 边的代码解析之后，来看边的建立，这里我们的优化变量只有一个及只有一个节点，于是我们建立的单元边的，继承了单元边BaseUnaryEdge的基类。 这里的Measurement实际上就是真实值的y值。 而对应的x的值，则要通过构造函数初始化。 1234567891011template &lt;int D, typename E, typename VertexXi&gt;class BaseUnaryEdge : public BaseEdge&lt;D,E&gt;{ public: static const int Dimension = BaseEdge&lt;D, E&gt;::Dimension; typedef typename BaseEdge&lt;D,E&gt;::Measurement Measurement; typedef VertexXi VertexXiType; typedef typename Eigen::Matrix&lt;number_t, D, VertexXiType::Dimension, D==1?Eigen::RowMajor:Eigen::ColMajor&gt;::AlignedMapType JacobianXiOplusType; typedef typename BaseEdge&lt;D,E&gt;::ErrorVector ErrorVector; typedef typename BaseEdge&lt;D,E&gt;::InformationType InformationType;} 下面来分析曲线拟合的代码，起主要是继承的单元边的代码。 首先，来分析的是构造函数，以及观测样本点(x,y)是如何输入到程序里面去的。 12const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]);const Eigen::Vector3d abc = v-&gt;estimate(); CurveFittingEdge(double x) : BaseUnaryEdge(), _x(x) {}通过构造函数初始化观测数据的x值； const Eigen::Vector3d abc = v-&gt;estimate(); 这里的v是刚才定义的节点参数。这样就可以将节点里面的参数输进边里面，构建了连接点和边的桥梁。 123typedef E Measurement;typedef typename internal::BaseEdgeTraits&lt;D&gt;::ErrorVector ErrorVector;typedef typename internal::BaseEdgeTraits&lt;D&gt;::InformationType InformationType 以上为相关变量的模板参数定义，这里E为定义的模板的变量，因此对应的Measurement也就是E类型的。 edge-&gt;setMeasurement(y_data[i])：主要的工作是输入观测量的y值的参数。这部分是类的外面定义的，后面会详细的解释。 注意，在类里有下滑线_xxx的变量都是其内部的变量，有的是继承基类的，有的就是自己的新定义的变量，其为保护类型的。 1CurveFittingEdge(double x) : BaseUnaryEdge(), _x(x) {} 之后，来定义损失，并计算Jacobi矩阵。 123456// 计算曲线模型误差virtual void computeError() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); _error(0, 0) = _measurement - std::exp(abc(0, 0) * _x * _x + abc(1, 0) * _x + abc(2, 0));} 下面代码 int Dimension代表的矩阵的维度； ErrorVector对于的类型为Eigen::Matrix，这里其为一个$D\\times1$ 的矩阵，这里有上面的代码可得，$D=1$，于是这里的_error就是一个$1\\times1$的矩阵。 12345678910111213class BaseEdge : public OptimizableGraph::Edge{ public: static constexpr int Dimension = internal::BaseEdgeTraits&lt;D&gt;::Dimension; typedef E Measurement; typedef typename internal::BaseEdgeTraits&lt;D&gt;::ErrorVector ErrorVector; typedef typename internal::BaseEdgeTraits&lt;D&gt;::InformationType InformationType;}struct BaseEdgeTraits { static constexpr int Dimension = D; typedef Eigen::Matrix&lt;number_t, D, 1, Eigen::ColMajor&gt; ErrorVector; typedef Eigen::Matrix&lt;number_t, D, D, Eigen::ColMajor&gt; InformationType; }; 然后计算Jacobi矩阵如下： 123456789// 计算雅可比矩阵virtual void linearizeOplus() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); double y = exp(abc[0] * _x * _x + abc[1] * _x + abc[2]); _jacobianOplusXi[0] = -_x * _x * y; _jacobianOplusXi[1] = -_x * y; _jacobianOplusXi[2] = -y;} _vertices[0]为CurveFittingVertex类型，其实就是关联的顶点的数值&amp;指针，因为就只有一个顶点，于是索引就为0. 1class CurveFittingEdge : public g2o::BaseUnaryEdge&lt;1, double, CurveFittingVertex&gt; { 下面就是求Jacobi矩阵，其主要的类型为JacobianXiOplusType： 123typedef typename Eigen::Matrix&lt;number_t, D, VertexXiType::Dimension, D==1?Eigen::RowMajor:Eigen::ColMajor&gt;::AlignedMapType JacobianXiOplusType;// 根据其是否是1来进行划分JacobianXiOplusType _jacobianOplusXi; 其维度为$D\\times \\text{Vertex_dim}$ 即为D*顶点的维度，再这边是$1\\times3$. 而且Jacobi矩阵的求导的对象是误差函数，不是原函数，因此会有负号。 下面为完整的拟合部分边的代码： 123456789101112131415161718192021222324252627282930class CurveFittingEdge : public g2o::BaseUnaryEdge&lt;1, double, CurveFittingVertex&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW CurveFittingEdge(double x) : BaseUnaryEdge(), _x(x) {} // 计算曲线模型误差 virtual void computeError() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); _error(0, 0) = _measurement - std::exp(abc(0, 0) * _x * _x + abc(1, 0) * _x + abc(2, 0)); } // 计算雅可比矩阵 virtual void linearizeOplus() override { const CurveFittingVertex *v = static_cast&lt;const CurveFittingVertex *&gt; (_vertices[0]); const Eigen::Vector3d abc = v-&gt;estimate(); double y = exp(abc[0] * _x * _x + abc[1] * _x + abc[2]); _jacobianOplusXi[0] = -_x * _x * y; _jacobianOplusXi[1] = -_x * y; _jacobianOplusXi[2] = -y; } virtual bool read(istream &amp;in) {} virtual bool write(ostream &amp;out) const {}public: double _x; // x 值， y 值为 _measurement}; 初始化估计数据12345678910111213double ar = 1.0, br = 2.0, cr = 1.0; // 真实参数值double ae = 2.0, be = -1.0, ce = 5.0; // 估计参数值int N = 100; // 数据点double w_sigma = 1.0; // 噪声Sigma值double inv_sigma = 1.0 / w_sigma;cv::RNG rng; // OpenCV随机数产生器vector&lt;double&gt; x_data, y_data; // 数据for (int i = 0; i &lt; N; i++) { double x = i / 100.0; x_data.push_back(x); y_data.push_back(exp(ar * x * x + br * x + cr) + rng.gaussian(w_sigma * w_sigma));} 这部分主要使用的是OpenCV的随机数产生器来生成需要的参数； 这里再原来标准参数的基础上加入了随机噪声 构建图优化的参数 定义求解器，先是定义优化变量的BlockSolverTraits。其中的第一的模板参数代表的是优化变量的个数，第二个是观测变量y的维度，也可以是误差的维度。 然后定义求解增量方程的求解器LinearSolverDense 12345// ==============构建图优化，设定G2O=================typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;3, 1&gt;&gt; BlockSolverType;// 每个误差项优化变量维度为3，误差值维度为1typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType;// 线性方程求解器 定义优化方法，这里的solver代表的是根据的方法，包括G-N、L-M等。 然后构建图模型 SparseOptimizer，将之前设计求解器的导入到图模型中，并且打开调试输出。 12345678// 梯度下降方法，可以从GN，LM，DogLeg 中选择auto solver = new g2o::OptimizationAlgorithmLevenberg( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;()));g2o::SparseOptimizer optimizer;optimizer.setAlgorithm(solver); // 设置求解器optimizer.setVerbose(true); // 打开调试输出 创建顶点，即需要优化的变量，之后设计初始值。 setEstimate 为设置优化变量初始值，这个函数估计是基类里面自带的，节点类直接继承的。 setId设置节点的ID值，之后将此节点加入到对于的图中optimizer.addVertex(v);。 因为这里就仅仅有一个节点，就加入一次即可。 12345// 往图中增加顶点CurveFittingVertex *v = new CurveFittingVertex();v-&gt;setEstimate(Eigen::Vector3d(ae, be, ce));v-&gt;setId(0);optimizer.addVertex(v); 创建边的对象new CurveFittingEdge(x_data[i])，构造函数是需要将x值传进去。 然后给每条边设计一个ID值，setId。 setVertex设置边指向的点，这里面的0不是ID，是索引。本例子是单元的边的情况，因此就一个边就连接一个点，如果是双节点的边，那就有两个setVertex(0,v1)和setVertex(1,v2)。 接下来setMeasurement是将观测值也输入进去。 setInformation计算误差时我们使用的时最小二乘法，需要协方差矩阵(信息矩阵)。 最后将边加入到图模型中，这里每个观测变量和观测值组成的样本都是一条边。 123456789// 往图中增加边for (int i = 0; i &lt; N; i++) { CurveFittingEdge *edge = new CurveFittingEdge(x_data[i]); edge-&gt;setId(i); edge-&gt;setVertex(0, v); // 设置连接的顶点 edge-&gt;setMeasurement(y_data[i]); // 观测数值 edge-&gt;setInformation(Eigen::Matrix&lt;double, 1, 1&gt;::Identity() * 1 / (w_sigma * w_sigma)); // 信息矩阵：协方差矩阵之逆 optimizer.addEdge(edge);} 执行优化123456789101112// 执行优化cout &lt;&lt; &quot;start optimization&quot; &lt;&lt; endl;chrono::steady_clock::time_point t1 = chrono::steady_clock::now();optimizer.initializeOptimization();optimizer.optimize(10);chrono::steady_clock::time_point t2 = chrono::steady_clock::now();chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);cout &lt;&lt; &quot;solve time cost = &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl;// 输出优化值Eigen::Vector3d abc_estimate = v-&gt;estimate();cout &lt;&lt; &quot;estimated model: &quot; &lt;&lt; abc_estimate.transpose() &lt;&lt; endl; optimizer.initializeOptimization();初始化图。 optimizer.optimize(10);设置优化步数。 Eigen::Vector3d abc_estimate = v-&gt;estimate();进行输出。","link":"/2022/06/07/SLAM/G2O-%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88/"},{"title":"Ch7 视觉里程计 第三部分 PnP","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是PnP的相关的算法及其实践，PnP的全称为Perspective-n-Point 是求解3D到2D点对运动的方法，求解的方法一种是通过解方程，另一种是将位姿作为优化变量来最小化重投影误差。实践部分主要分为使用的OpenCV自带的求解PnP的方法，手写高斯牛顿法已经使用G2O方法三个部分。 概述PnP的全称为Perspective-n-Point 是求解3D到2D点对运动的方法，其描述了已知3D空间点和其位置时，如何位姿估计的姿态，即相机的外参。 对于2D-2D的方法而言，主要是一般需要八个点求解，也存在初始化、纯旋转和尺度的问题。而对于特征点的3D位置已知，那么最少也需要3个点点对就可以对相机的姿态进行估计。 这里特征点的3D位置可以由三角化或RGBD相机的深度图来确定。因此对于双目或RGBD相机来说，可以直接使用PnP法来估计，对于单目相机而言，则需要使用三角法和对极几何先进行初始化操作。 3D-2D的方法不需要对极约束，可以使用很少的点就可以进行匹配，是一种重要的位姿估计方法。 在解法上，主要分成代数解法和优化解法： 代数法：DLT、P3P、EPnP / UPnP等； 优化法：Bundle Adjustment 一般的代数方法对于噪声的鲁棒性较差，求出来的解误差较大，因此多使用万金油式得到BA算法(Bundle Adjustment) 下面将分别介绍上述的几种求解方法。 直接线性变换DLT如果将3D点看成是另一个相机坐标系的中的点时，就可以将其转化为求解两个相加的运动问题。 考虑空间点P，其对应的其次坐标就为：$P=(X,Y,Z,1)^T$ . 在图像$I_1$中，其对应的特征点为$x_1=(u_1,v_1,1)^T$. 然后，定义增广矩阵$[R|t]$ 得到其投影关系为$sx_1=[R|t]p$，将上述投影方程展开可得： s\\left(\\begin{array}{l}u_{1} \\\\ v_{1} \\\\ 1\\end{array}\\right)=\\left(\\begin{array}{llll}t_{1} & t_{2} & t_{3} & t_{4} \\\\ t_{5} & t_{6} & t_{7} & t_{8} \\\\ t_{9} & t_{10} & t_{11} & t_{12}\\end{array}\\right)\\left(\\begin{array}{l}X \\\\ Y \\\\ Z \\\\ 1\\end{array}\\right) 下面联立方程，消去s可得： u_{1}=\\frac{t_{1} X+t_{2} Y+t_{3} Z+t_{4}}{t_{9} X+t_{10} Y+t_{11} Z+t_{12}}, \\quad v_{1}=\\frac{t_{5} X+t_{6} Y+t_{7} Z+t_{8}}{t_{9} X+t_{10} Y+t_{11} Z+t_{12}} . 之后，为了简化表示，定义了T的行向量可得： \\boldsymbol{t}_{1}=\\left(t_{1}, t_{2}, t_{3}, t_{4}\\right)^{\\mathrm{T}}, \\boldsymbol{t}_{2}=\\left(t_{5}, t_{6}, t_{7}, t_{8}\\right)^{\\mathrm{T}}, \\boldsymbol{t}_{3}=\\left(t_{9}, t_{10}, t_{11}, t_{12}\\right)^{\\mathrm{T}} 于是原方程可以转换成： \\boldsymbol{t}_{1}^{\\mathrm{T}} \\boldsymbol{P}-\\boldsymbol{t}_{3}^{\\mathrm{T}} \\boldsymbol{P} u_{1}=0\\\\ \\boldsymbol{t}_{2}^{\\mathrm{T}} \\boldsymbol{P}-\\boldsymbol{t}_{3}^{\\mathrm{T}} \\boldsymbol{P} v_{1}=0 这里我们要求解的变量为$t$，每个三维点可以提供两个约束方程，当我们一共求解N个点时，要求解的线性方程如下： \\left(\\begin{array}{ccc}\\boldsymbol{P}_{1}^{\\mathrm{T}} & 0 & -u_{1} \\boldsymbol{P}_{1}^{\\mathrm{T}} \\\\ 0 & \\boldsymbol{P}_{1}^{\\mathrm{T}} & -v_{1} \\boldsymbol{P}_{1}^{\\mathrm{T}} \\\\ \\vdots & \\vdots & \\vdots \\\\ \\boldsymbol{P}_{N}^{\\mathrm{T}} & 0 & -u_{N} \\boldsymbol{P}_{N}^{\\mathrm{T}} \\\\ 0 & \\boldsymbol{P}_{N}^{\\mathrm{T}} & -v_{N} \\boldsymbol{P}_{N}^{\\mathrm{T}}\\end{array}\\right)\\left(\\begin{array}{c}\\boldsymbol{t}_{1} \\\\ \\boldsymbol{t}_{2} \\\\ \\boldsymbol{t}_{3}\\end{array}\\right)=0 求解12个未知量，一共需要12/2=6个点，当给定的点多于6个时，我们使用最小二乘法来求解。 以上就是DIL方法的基本解法，但是这样做会有下面的不足： 首先，我们求解的矩阵T，仅仅将其看作是12个未知数，忽略了其作为旋转矩阵应有的性质，$\\mathrm{R} \\in \\mathfrak{SO}(3)$ 。对于平移向量来说还比较好解决，旋转矩阵使用QR分解来解决，选择下面的公式来来进行优化： R\\leftarrow (RR^T)^{-1/2}R 其次，这里的$x_1$代表的是归一化坐标，去掉了内参矩阵的K的影响，即使内参未知，其实也不影响求解，我们可以使用更多的特征点来估计$K,R,t$三个量。 P3P此方法中，我们仅仅根据3对3D-2D的匹配点就可以得相机的位姿以及相机的外参。此外，还需要一个点进行验证。 如图所示，3D点A,B,C；2D点为a,b,c。此时A,B,C为在世界坐标系中的坐标，不是在相机坐标系下的坐标，因为如果3D点在相机坐标系下的坐标要是已知的化，那么就成了一个ICP的问题。 这里我们不知到A,B,C三点的深度值，于是aA,bB,cC未知即OA,OB,OC是未知的，但是AB,AC,BC是已知的。于是u和w就是已知的，但是v还是未知的，而且x,y也是未知的。 之后，将未知数v消去，得到一个二元二次方程，然后使用吴氏消元法求解，也可以使用数值方法来求解。 最后求解可得OC，进而得到3D-3D的点对即将A,B,C的深度也一起求出。于是就有可以求出$R,t$. P3P的大概原理就是使用三角形相似的性质，得出a,b,c在相机坐标系下的3D坐标即深度，最后就将问题转换为3D-3D的位姿问题。 算法存在的缺点： 当给的信息点的个数大于3个时，我们只能用三个点的信息，没办法利用更多的信息。 当3D,2D点的受到噪声的影响之后，或者是误匹配，此时算法将失效。 最小化重投影误差法除了使用传统的线性方法外，还可以将其构建成为一个优化的算法，但是我们可以将其改进成为一个重投影最小误差的最小二乘地问题。 这里区别一般传统方法，先求相机位姿，再求空间点，这里是将其一并示为非线性最小二乘法地优化变量，这个方法统称为 Bundle Adjustment. 首先，我们考虑 n 个空间点P以及其投影p，这里假设其中的一个空间点的坐标是$P=[X_i,Y_i,Z_i]^T$ ，其投影值为$u_i=[u_i,v_i]^T$ 。根据第5讲的内容，有$s_i{u_i}=\\boldsymbol{KTP_i}=\\boldsymbol{K}\\exp(\\xi^{\\wedge}) \\boldsymbol{P_i} $ 。 之后，定义最小重投影的误差： \\boldsymbol{T}^*=\\arg\\min\\limits_{T}\\frac 1 2 \\sum\\limits_{i=1}^{n}||\\boldsymbol{u_i}-\\frac{1}{s_i}\\boldsymbol{KTP_i} ||^2_2 下面主要解决的是一个关于线性化和求雅可比的过程： 考虑到单个投影点的误差：$e_i=u_i-\\dfrac{1}{s_i}K\\exp(\\xi^{\\wedge})P_i$ ; 线性化：$e_i(x+\\Delta x)\\approx e_i(x)+J(x)\\Delta x$ ； 求解雅可比矩阵$\\boldsymbol{J}^T$ ： \\frac{\\partial \\boldsymbol{e}}{\\partial \\delta \\boldsymbol{\\xi}}=\\lim _{\\delta \\boldsymbol{\\xi} \\rightarrow 0} \\frac{e(\\delta \\boldsymbol{\\xi} \\oplus \\boldsymbol{\\xi})}{\\delta \\boldsymbol{\\xi}}=\\frac{\\partial \\boldsymbol{e}}{\\partial \\boldsymbol{P}^{\\prime}} \\frac{\\partial \\boldsymbol{P}^{\\prime}}{\\partial \\delta \\boldsymbol{\\xi}} 对于第一项，下面来处理对$P’$求导的问题： 这里的 $P’$ 是在相机坐标系下的3D点的坐标。 $P’$为在相机坐标系下的坐标： P'=[TP]_{(1:3)}=[X',Y',Z']^T 对 $P’$ 进行投影可得： s\\boldsymbol{u}=\\boldsymbol{KP'} 将上述的式子展开可得： \\left[\\begin{array}{l}s u \\\\ s v \\\\ s\\end{array}\\right]=\\left[\\begin{array}{ccc}f_{x} & 0 & c_{x} \\\\ 0 & f_{y} & c_{y} \\\\ 0 & 0 & 1\\end{array}\\right]\\left[\\begin{array}{l}X^{\\prime} \\\\ Y^{\\prime} \\\\ Z^{\\prime}\\end{array}\\right]\\\\ u=f_{x} \\frac{X^{\\prime}}{Z^{\\prime}}+c_{x}, \\quad v=f_{y} \\frac{Y^{\\prime}}{Z^{\\prime}}+c_{y} 代入可得偏导数的值为： \\dfrac{\\partial \\boldsymbol{e}}{\\partial \\boldsymbol{P}^{\\prime}}=-\\left[\\begin{array}{ccc}\\dfrac{\\partial u}{\\partial X^{\\prime}} & \\dfrac{\\partial u}{\\partial Y^{\\prime}} & \\dfrac{\\partial u}{\\partial Z^{\\prime}} \\\\ \\dfrac{\\partial v}{\\partial X^{\\prime}} & \\dfrac{\\partial v}{\\partial Y^{\\prime}} & \\dfrac{\\partial v}{\\partial Z^{\\prime}}\\end{array}\\right]=-\\left[\\begin{array}{ccc}\\dfrac{f_{x}}{Z^{\\prime}} & 0 & -\\dfrac{f_{x} X^{\\prime}}{Z^{\\prime 2}} \\\\ 0 & \\dfrac{f_{y}}{Z^{\\prime}} & -\\dfrac{f_{y} Y^{\\prime}}{Z^{\\prime 2}}\\end{array}\\right] 对于第二项，下面将其进行拆分可得： 这里因为我们仅仅保留了前三维的数据，于此求解的结果也就保留前三维即可，最后一维舍去。 两式相乘得到最后的求导的结果为： \\frac{\\partial \\boldsymbol{e}}{\\partial \\delta \\boldsymbol{\\xi}}=-\\left[\\begin{array}{cccccc}\\dfrac{f_{x}}{Z^{\\prime}} & 0 & -\\dfrac{f_{x} X^{\\prime}}{Z^{\\prime 2}} & -\\dfrac{f_{x} X^{\\prime} Y^{\\prime}}{Z^{\\prime 2}} & f_{x}+\\dfrac{f_{x} X^{\\prime 2}}{Z^{\\prime 2}} & -\\dfrac{f_{x} Y^{\\prime}}{Z^{\\prime}} \\\\ 0 & \\dfrac{f_{y}}{Z^{\\prime}} & -\\dfrac{f_{y} Y^{\\prime}}{Z^{\\prime 2}} & -f_{y}-\\dfrac{f_{y} Y^{\\prime 2}}{Z^{\\prime 2}} & \\dfrac{f_{y} X^{\\prime} Y^{\\prime}}{Z^{\\prime 2}} & \\dfrac{f_{y} X^{\\prime}}{Z^{\\prime}}\\end{array}\\right] 刚才的优化主要针对的是3D相机，就是通过优化相机的位姿来得到n个样本点下的最佳的重投影误差。 当然我们也可以对3D点进行求导： 首先是其求导也要使用链式法则： \\frac{\\partial \\boldsymbol{e}}{\\partial \\boldsymbol{P}}=\\frac{\\partial \\boldsymbol{e}}{\\partial \\boldsymbol{P}^{\\prime}} \\frac{\\partial \\boldsymbol{P}^{\\prime}}{\\partial \\boldsymbol{P}} 其中第一项刚才已经求解了，至于第二项则按照定义： P'=[TP]_{(1:3)}=RP+t求解之后就剩下一个旋转矩阵R了。 最后的结果为： \\frac{\\partial \\boldsymbol{e}}{\\partial \\boldsymbol{P}}=-\\left[\\begin{array}{ccc}\\dfrac{f_{x}}{Z^{\\prime}} & 0 & -\\dfrac{f_{x} X^{\\prime}}{Z^{\\prime 2}} \\\\ 0 & \\dfrac{f_{y}}{Z^{\\prime}} & -\\dfrac{f_{y} Y^{\\prime}}{Z^{\\prime 2}}\\end{array}\\right] \\boldsymbol{R} . 实践使用EPnP求解位姿使用EPnP对问题进行求解，这里我们使用OpenCV自带的EPnP的算法来对问题进行求解，由于PnP需要使用到3D点，因此这里我们使用已有的深度信息，而不在使用初始化来进行(初始化的误差太大了) 1ushort d = d1.ptr&lt;unsigned short&gt;(int(keypoints_1[m.queryIdx].pt.y))[int(keypoints_1[m.queryIdx].pt.x)]; 这里是使用一个行指针来进行读取操作，分别从行和列的方向来对像素进行读取操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647int main(int argc, char **argv) { if (argc != 5) { cout &lt;&lt; &quot;usage: pose_estimation_3d2d img1 img2 depth1 depth2&quot; &lt;&lt; endl; return 1; } //-- 读取图像 cv::Mat img_1 = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR); cv::Mat img_2 = cv::imread(argv[2], CV_LOAD_IMAGE_COLOR); assert(img_1.data &amp;&amp; img_2.data &amp;&amp; &quot;Can not load images!&quot;); vector&lt;cv::KeyPoint&gt; keypoints_1, keypoints_2; vector&lt;cv::DMatch&gt; matches; find_feature_matches(img_1, img_2, keypoints_1, keypoints_2, matches); cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl; // 建立3D点 cv::Mat d1 = cv::imread(argv[3], CV_LOAD_IMAGE_UNCHANGED); // 深度图为16位无符号数，单通道图像 cv::Mat K = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); vector&lt;cv::Point3f&gt; pts_3d; vector&lt;cv::Point2f&gt; pts_2d; for (cv::DMatch m:matches) { ushort d = d1.ptr&lt;unsigned short&gt;(int(keypoints_1[m.queryIdx].pt.y))[int(keypoints_1[m.queryIdx].pt.x)]; if (d == 0) // bad depth continue; float dd = d / 5000.0; cv::Point2d p1 = pixel2cam(keypoints_1[m.queryIdx].pt, K); pts_3d.push_back(cv::Point3f(p1.x * dd, p1.y * dd, dd)); pts_2d.push_back(keypoints_2[m.trainIdx].pt); } cout &lt;&lt; &quot;3d-2d pairs: &quot; &lt;&lt; pts_3d.size() &lt;&lt; endl; chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); cv::Mat r, t; solvePnP(pts_3d, pts_2d, K, cv::Mat(), r, t, false); // 调用OpenCV 的 PnP 求解，可选择EPNP，DLS等方法 cv::Mat R; cv::Rodrigues(r, R); // r为旋转向量形式，用Rodrigues公式转换为矩阵 chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;solve pnp in opencv cost time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;R=&quot; &lt;&lt; endl &lt;&lt; R &lt;&lt; endl; cout &lt;&lt; &quot;t=&quot; &lt;&lt; endl &lt;&lt; t &lt;&lt; endl; return 0;} 然后输入命令，即可执行结果，并得到输出： 123456789101112131415./pose_estimation_3d2d /home/czt/slamlearning/ch7/vo1/1.png /home/czt/slamlearning/ch7/vo1/2.png /home/czt/slamlearning/ch7/vo1/1_depth.png /home/czt/slamlearning/ch7/vo1/2_depth.png-- Max dist : 94.000000 -- Min dist : 4.000000 一共找到了79组匹配点3d-2d pairs: 75solve pnp in opencv cost time: 0.126052 seconds.R=[0.9979059095501517, -0.05091940089119591, 0.03988747043579327; 0.04981866254262534, 0.9983623157437967, 0.02812094175427922; -0.04125404886006491, -0.02607491352939112, 0.9988083912027803]t=[-0.1267821389545255; -0.00843949681832986; 0.06034935748864372] 以下式OpenCV自带得EPnP函数： 1CV_EXPORTS_W bool solvePnP( InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess = false, int flags = SOLVEPNP_ITERATIVE ); objectPoints： 3D点坐标，这里输入为一个组的形式，一般使用的是一个·vector容器来解决。 imagePoints：2D点坐标，同上。 cameraMatrix：相机的内参，这里输入的是一个cv::Mat flags：使用的方法的标签； 从求解的速度来看，OpenCV自带 &gt; Ceres &gt; g2o 但是g2o可以很好的解决的BA问题。不过G2O编译make的确实比较耗时。 使用GN手写姿态识别这里我们手写了之前Gauss-Newton方法进行姿态的求解计算，主要的函数如图所示，输出为收敛速度迭代损失。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485void bundleAdjustmentGaussNewton( const VecVector3d &amp;points_3d, const VecVector2d &amp;points_2d, const cv::Mat &amp;K, Sophus::SE3d &amp;pose){ typedef Eigen::Matrix&lt;double, 6, 1&gt; Vector6d; // 设置迭代次数 const int iterations = 10; // 定义损失 double cost = 0, last_cost = 0; double fx = K.at&lt;double&gt;(0, 0); double fy = K.at&lt;double&gt;(1, 1); double cx = K.at&lt;double&gt;(0, 2); double cy = K.at&lt;double&gt;(1, 2); for (int iter = 0; iter &lt; iterations; iter++){ Eigen::Matrix&lt;double, 6, 6&gt; H = Eigen::Matrix&lt;double, 6, 6&gt;::Zero(); Vector6d b = Vector6d::Zero(); // 初始化成0 cost = 0; // 开始计算损失 for(int i = 0; i &lt; points_3d.size(); i++){ // 先将其转化到相机坐标系下 Eigen::Vector3d pc = pose * points_3d[i]; // 进行归一化 double inv_z = 1.0 / pc[2]; double inv_z2 = inv_z * inv_z; // 计算得到相机坐标 Eigen::Vector2d proj(fx * pc[0] / pc[2] + cx, fy * pc[1] / pc[2] + cy); // 计算误差 Eigen::Vector2d e = points_2d[i] - proj; cost += e.squaredNorm();// 就是2范数 // 定义Jacobi Matrix 公式7.46 Eigen::Matrix&lt;double, 2, 6&gt; J; J &lt;&lt; -fx * inv_z, 0, fx * pc[0] * inv_z2, fx * pc[0] * pc[1] * inv_z2, -fx - fx * pc[0] * pc[0] * inv_z2, fx * pc[1] * inv_z, 0, -fy * inv_z, fy * pc[1] * inv_z, fy + fy * pc[1] * pc[1] * inv_z2, -fy * pc[0] * pc[1] * inv_z2, -fy * pc[0] * inv_z; H += J.transpose() * J; b += -J.transpose() * e; } // 求解增量方程 Vector6d dx; dx = H.ldlt().solve(b); // 无解则退出循化 if (isnan(dx[0])){ cout &lt;&lt; &quot;result is nan!&quot; &lt;&lt; endl; break; } // last_cost 是上一步的损失 if(iter &gt; 0 &amp;&amp; cost &gt;= last_cost){ // cost increase, update is not good cout &lt;&lt; &quot;cost: &quot; &lt;&lt; cost &lt;&lt; &quot;, last cost: &quot; &lt;&lt; last_cost &lt;&lt; endl; break; } // update your estimation pose = Sophus::SE3d::exp(dx) * pose; last_cost = cost; cout &lt;&lt; &quot;iteration &quot; &lt;&lt; iter &lt;&lt; &quot; cost=&quot; &lt;&lt; std::setprecision(12) &lt;&lt; cost &lt;&lt; endl; if (dx.norm() &lt; 1e-6) { // converge break; } } cout &lt;&lt; &quot;pose by g-n: \\n&quot; &lt;&lt; pose.matrix() &lt;&lt; endl;} 使用G2O进行BA优化 由于第一个相机位姿固定为零，所以我们没有把它写到优化变量里，但在更多的场合里，我们会考虑更多相机的估计。现在，我们根据一组3D点和第二个图像中的2D投影，估计第二个相机的位姿。所以我们把第一个相机画成虚线，表明不希望考虑它。 上述求解的过程中，已经将Jacobi矩阵求出，$f$ 求出，于是仅仅只有一个误差的更新量$\\Delta(\\xi)$ 为未知的，通过求解增量方程来求解，再更新变量。 具体代码部分如下： 首先，创建优化的顶点，这里顶点类是继承的是BaseVertex，这里的模板参数为6，因为李代数特殊欧氏群里面有六个参数，变量的类型就选择李代数的类型。 12345678910111213141516171819202122class VertexPose : public g2o::BaseVertex&lt;6, Sophus::SE3d&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW; virtual void setToOriginImpl() override { _estimate = Sophus::SE3d(); } /// left multiplication on SE3 virtual void oplusImpl(const double *update) override { Eigen::Matrix&lt;double, 6, 1&gt; update_eigen; update_eigen &lt;&lt; update[0], update[1], update[2], update[3], update[4], update[5]; _estimate = Sophus::SE3d::exp(update_eigen) * _estimate; // 这里增量的是左乘 // 其中的exp(update_eigen)是一个6 x 1的向量 // _estimate对应的是 4 x 4 的矩阵 } virtual bool read(istream &amp;in) override {} virtual bool write(ostream &amp;out) const override {}}; 其中的exp(update_eigen)是一个6 x 1的向量； _estimate对应的是 4 x 4 的矩阵； 这里的左乘实际上使用了重载。 之后，创建单元边来进行优化操作。 其主要继承自BaseUnaryEdge，模板参数第一个为2，起主要是因为我们有优化的变量的投影在2D点上面的，因此只有两维，即误差为2. 然后，要计算误差，那么我们需要一些参数，需要将其输入到类中，这里主要有两种办法， 一种是通过构造函数进行输入，对应的要再类里面创建对应的变量；’ 另一种是作为观测值，通过setestimate()来导入。 pos_pixel.head&lt;2&gt;()的意思是仅仅取前两维，因为最后一维是1. 1234567891011121314151617181920212223242526272829303132333435363738394041// 创建边的集合class EdgeProjection : public g2o::BaseUnaryEdge&lt;2, Eigen::Vector2d, VertexPose&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW; EdgeProjection(const Eigen::Vector3d &amp;pos, const Eigen::Matrix3d &amp;K) : _pos3d(pos), _K(K) {} virtual void computeError() override { const VertexPose *v = static_cast&lt;VertexPose *&gt; (_vertices[0]); // 仅有一个顶点 Sophus::SE3d T = v-&gt;estimate(); Eigen::Vector3d pos_pixel = _K * (T * _pos3d); pos_pixel /= pos_pixel[2]; // 将第三维进行归一化，即重投影操作 _error = _measurement - pos_pixel.head&lt;2&gt;(); // 计算误差 // 这里的意思是仅仅取前两维 } virtual void linearizeOplus() override { const VertexPose *v = static_cast&lt;VertexPose *&gt; (_vertices[0]); Sophus::SE3d T = v-&gt;estimate(); Eigen::Vector3d pos_cam = T * _pos3d; double fx = _K(0, 0); double fy = _K(1, 1); double cx = _K(0, 2); double cy = _K(1, 2); double X = pos_cam[0]; double Y = pos_cam[1]; double Z = pos_cam[2]; double Z2 = Z * Z; // 计算Jacobi矩阵 _jacobianOplusXi &lt;&lt; -fx / Z, 0, fx * X / Z2, fx * X * Y / Z2, -fx - fx * X * X / Z2, fx * Y / Z, 0, -fy / Z, fy * Y / (Z * Z), fy + fy * Y * Y / Z2, -fy * X * Y / Z2, -fy * X / Z; } private: Eigen::Vector3d _pos3d; Eigen::Matrix3d _K;} 接下来是一些关于变量定义的内容。 123// BA by g2otypedef vector&lt;Eigen::Vector2d, Eigen::aligned_allocator&lt;Eigen::Vector2d&gt;&gt; VecVector2d;typedef vector&lt;Eigen::Vector3d, Eigen::aligned_allocator&lt;Eigen::Vector3d&gt;&gt; VecVector3d; 上述的定义其实是关于内存管理的，其实作用是和typedef vector&lt;g2o::Vector2&gt; VecVector2d;差不多。但是实际用的时候，更欢迎的是使用自带的操作。 之后对于位姿表示，g2o自带的是g2o::Isometry3，但是本质上也是Eigen，因此尽量使用其自带的比较好。 12typedef Eigen::Transform&lt;number_t,2,Eigen::Isometry,Eigen::ColMajor&gt; Isometry2;typedef Eigen::Transform&lt;number_t,3,Eigen::Isometry,Eigen::ColMajor&gt; Isometry3; 最后是代码的执行部分，这部分和之前第六章差不多，参数处理上和前面的方法也差不多，这里直接展示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void bundleAdjustmentG2O( const VecVector3d &amp;points_3d, const VecVector2d &amp;points_2d, const cv::Mat &amp;K, Sophus::SE3d &amp;pose) { // 构建图优化，先设定g2o typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;6, 3&gt;&gt; BlockSolverType; // pose is 6, landmark is 3 typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; // 线性求解器类型 // 梯度下降方法，可以从GN, LM, DogLeg 中选 auto solver = new g2o::OptimizationAlgorithmGaussNewton( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;())); g2o::SparseOptimizer optimizer; // 图模型 optimizer.setAlgorithm(solver); // 设置求解器 optimizer.setVerbose(true); // 打开调试输出 // vertex VertexPose *vertex_pose = new VertexPose(); // camera vertex_pose vertex_pose-&gt;setId(0); vertex_pose-&gt;setEstimate(Sophus::SE3d()); optimizer.addVertex(vertex_pose); // K Eigen::Matrix3d K_eigen; K_eigen &lt;&lt; K.at&lt;double&gt;(0, 0), K.at&lt;double&gt;(0, 1), K.at&lt;double&gt;(0, 2), K.at&lt;double&gt;(1, 0), K.at&lt;double&gt;(1, 1), K.at&lt;double&gt;(1, 2), K.at&lt;double&gt;(2, 0), K.at&lt;double&gt;(2, 1), K.at&lt;double&gt;(2, 2); // edges int index = 1; for (size_t i = 0; i &lt; points_2d.size(); ++i) { auto p2d = points_2d[i]; auto p3d = points_3d[i]; EdgeProjection *edge = new EdgeProjection(p3d, K_eigen); edge-&gt;setId(index); edge-&gt;setVertex(0, vertex_pose); edge-&gt;setMeasurement(p2d); edge-&gt;setInformation(Eigen::Matrix2d::Identity()); // 这里的信息矩阵为单位矩阵 optimizer.addEdge(edge); index++; } chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); optimizer.setVerbose(true); optimizer.initializeOptimization(); optimizer.optimize(10); chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;optimization costs time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;pose estimated by g2o =\\n&quot; &lt;&lt; vertex_pose-&gt;estimate().matrix() &lt;&lt; endl; pose = vertex_pose-&gt;estimate();}","link":"/2022/06/11/SLAM/ch7-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-PnP/"},{"title":"Ch7 视觉里程计 第四部分 ICP","text":"hljs.initHighlightingOnLoad(); 本文主要讲解的是3d-3d的ICP方法，主要是讲第二张图片的3d点通过变换转换到第一个相机坐标上，通过SVD和非线性优化的方法来求解，最后使用基于SVD和G2O的方法来进行实现。 3D-3D问题的位姿估计，这里假设我们有一组配对好的3D点，一般是使用RGBD相机获取的，可以使用RGBD相机进行匹配。 \\boldsymbol{P}=\\left\\{\\boldsymbol{p}_{1}, \\cdots, \\boldsymbol{p}_{n}\\right\\}, \\quad \\boldsymbol{P}^{\\prime}=\\left\\{\\boldsymbol{p}_{1}^{\\prime}, \\cdots, \\boldsymbol{p}_{n}^{\\prime}\\right\\}此时使用欧式变化$R,t$，来表示其运动上的关系： \\forall i, \\boldsymbol{p}_{i}=\\boldsymbol{R} \\boldsymbol{p}_{i}^{\\prime}+\\boldsymbol{t}此时，上述的问题可以使用迭代最近点来求解(Iterative Closest Point)来进行求解，不同于激光SLAM，在视觉中我们一般使用两个已经配对好的点来进行相机的位姿估计，而激光问题是不带匹配的。 SVD这里我们以带匹配的为为主来进行介绍。 同样是定义误差项可得： \\boldsymbol{e}_{i}=\\boldsymbol{p}_{i}-\\left(\\boldsymbol{R} \\boldsymbol{p}_{i}^{\\prime}+\\boldsymbol{t}\\right)然后构建最小二乘问题，来寻找误差平方和极小的$R,t$： \\min _{\\boldsymbol{R}, \\boldsymbol{t}} \\frac{1}{2} \\sum_{i=1}^{n}\\left\\|\\left(\\boldsymbol{p}_{i}-\\left(\\boldsymbol{R} \\boldsymbol{p}_{i}^{\\prime}+\\boldsymbol{t}\\right)\\right)\\right\\|_{2}^{2}下面来推到其求解的方法： 首先，定义两组点的质心： \\boldsymbol{p}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\boldsymbol{p}_{i}\\right), \\quad \\boldsymbol{p}^{\\prime}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\boldsymbol{p}_{i}^{\\prime}\\right) 之后，注意不带角标的为质心，于是改写误差函数 注意交叉项$\\left(\\boldsymbol{p}_{i}-\\boldsymbol{p}-\\boldsymbol{R}\\left(\\boldsymbol{p}_{i}^{\\prime}-\\boldsymbol{p}^{\\prime}\\right)\\right)$ 在求和之后为0，于是可以消去。 此时目标函数可以简化为： \\min _{\\boldsymbol{R}, t} J=\\frac{1}{2} \\sum_{i=1}^{n}\\left\\|\\boldsymbol{p}_{i}-\\boldsymbol{p}-\\boldsymbol{R}\\left(\\boldsymbol{p}_{i}{ }^{\\prime}-\\boldsymbol{p}^{\\prime}\\right)\\right\\|^{2}+\\left\\|\\boldsymbol{p}-\\boldsymbol{R} \\boldsymbol{p}^{\\prime}-\\boldsymbol{t}\\right\\|^{2}第一项仅和$R$有关，而第二项和$R,t$ 都有关，于是我们可以先优化$R$来控制第一项最小，之后再控制$t$来控制后一项最小。 首先，最小化旋转矩阵$R$： 先进行去质心化$\\boldsymbol{q}_{i}=\\boldsymbol{p}_{i}-\\boldsymbol{p}, \\quad \\boldsymbol{q}_{i}^{\\prime}=\\boldsymbol{p}_{i}^{\\prime}-\\boldsymbol{p}^{\\prime}$ 于是误差函数可以改写为： \\frac{1}{2} \\sum_{i=1}^{n}\\left\\|\\boldsymbol{q}_{i}-\\boldsymbol{R} \\boldsymbol{q}_{i}^{\\prime}\\right\\|^{2}=\\frac{1}{2} \\sum_{i=1}^{n}\\left(\\boldsymbol{q}_{i}^{\\mathrm{T}} \\boldsymbol{q}_{i}+\\boldsymbol{q}_{i}^{\\prime \\mathrm{T}} \\boldsymbol{R}^{\\mathrm{T}} \\boldsymbol{R} \\boldsymbol{q}_{i}^{\\prime}-2 \\boldsymbol{q}_{i}^{\\mathrm{T}} \\boldsymbol{R} \\boldsymbol{q}_{i}^{\\prime}\\right) 之后我们注意到第一项和$R$无关，第二项$R^TR=I$ 可知其和R也无关，于是优化时我们仅仅关注最后一项，其优化的目标函数变为： \\sum_{i=1}^{n}-\\boldsymbol{q}_{i}^{\\mathrm{T}} \\boldsymbol{R} \\boldsymbol{q}_{i}^{\\prime}=\\sum_{i=1}^{n}-\\operatorname{tr}\\left(\\boldsymbol{R} \\boldsymbol{q}_{i}^{\\prime} \\boldsymbol{q}_{i}^{\\mathrm{T}}\\right)=-\\operatorname{tr}\\left(\\boldsymbol{R} \\sum_{i=1}^{n} \\boldsymbol{q}_{i}^{\\prime} \\boldsymbol{q}_{i}^{\\mathrm{T}}\\right) 最后使用SV分解可得： \\boldsymbol{W}=\\sum_{i=1}^{n} q_{i} \\boldsymbol{q}_{i}^{\\mathrm{T}} . \\quad \\boldsymbol{W}=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\mathrm{T}} . \\quad \\boldsymbol{R}=\\boldsymbol{U} \\boldsymbol{V}^{\\mathrm{T}} 然后，将旋转矩阵固定，优化第二项可得平移向量$t$： \\boldsymbol{t^*}=\\boldsymbol{p}-\\boldsymbol{Rp'} 非线性优化方法BA算法是个万金油式的方法，其也可以使用到本问题中，其表达和PnP上面是一样的，于是我们可得当使用李群来表达位姿时，其目标函数为： \\min _{\\boldsymbol{\\xi}}=\\frac{1}{2} \\sum_{i=1}^{n}\\left\\|\\left(\\boldsymbol{p}_{i}-\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{p}_{i}^{\\prime}\\right)\\right\\|_{2}^{2}下面求解单个误差项关于位姿的导数，前面已经进行了推导，其李代数的扰动模型的表达式为： \\frac{\\partial \\boldsymbol{e}}{\\partial \\delta \\boldsymbol{\\xi}}=-\\left(\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{p}_{i}^{\\prime}\\right)^{\\odot}小结ICP也可以从非线性优化角度求解，但： 已知匹配时，ICP问题存在唯一解或无穷多解的情况。在唯一解的情况下，只要能找到极小值解，那么这个极小值就是全局最优值。就是一个凸优化的问题。 所以正常情况下，SVD结果和优化一样，且优化很快收敛。 注意： 在激光情况下，匹配点未知(这是比较关心的问题)，将指定最近点为匹配点。此时问题非凸，极小值不一定为最小值。 利用非线性优化可以将ICP与PnP结合在一起求解。对于深度已知问题我们可以使用一般的3D-3D来求解，而对于深度的未知的问题，可以使用一般的PnP最小重投影误差来估计。 实践首先要注意一个读取图片的细节，在读取图片时，需要根据不太的图片设计不太的读取方式，如果设置错误会造成较大的误差。 1234567891011121314151617181920cv::Mat img_1 = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR);cv::Mat img_2 = cv::imread(argv[2], CV_LOAD_IMAGE_COLOR);cv::Mat depth1 = cv::imread(argv[3], CV_LOAD_IMAGE_UNCHANGED); // 深度图为16位无符号数，单通道图像cv::Mat depth2 = cv::imread(argv[4], CV_LOAD_IMAGE_UNCHANGED); // 深度图为16位无符号数，单通道图像/* 8bit, color or not */ CV_LOAD_IMAGE_UNCHANGED =-1,/* 8bit, gray */ CV_LOAD_IMAGE_GRAYSCALE =0,/* ?, color */ CV_LOAD_IMAGE_COLOR =1,/* any depth, ? */ CV_LOAD_IMAGE_ANYDEPTH =2,/* ?, any color */ CV_LOAD_IMAGE_ANYCOLOR =4,/* ?, no rotate */ CV_LOAD_IMAGE_IGNORE_ORIENTATION =128 SVD方法首先是实现SVD的函数pose_estimation_3d3d,其输入主要是两组3D点的引用已经旋转矩阵和平移向量。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657void pose_estimation_3d3d( const vector&lt;cv::Point3f&gt; &amp;pts1, const vector&lt;cv::Point3f&gt; &amp;pts2, cv::Mat &amp;R, cv::Mat &amp;t){ // 定义质心 cv::Point3f p1, p2; int N = pts1.size(); for(int i = 0; i &lt; N; i++){ p1 += pts1[i]; p2 += pts2[i]; } p1 = cv::Point3d(cv::Vec3f(p1) / N); p2 = cv::Point3d(cv::Vec3f(p2) / N); // 定义去质心族坐标 vector&lt;cv::Point3d&gt; q1(N), q2(N); for(int i = 0; i &lt; N; i++){ q1[i] = pts1[i] - p1; q2[i] = pts2[i] - p2; } // 计算q1 * q2^T Eigen::Matrix3d W = Eigen::Matrix3d::Zero(); for (int i = 0; i &lt; N; i++){ W += Eigen::Vector3d(q1[i].x, q1[i].y, q1[i].z) * Eigen::Vector3d(q2[i].x, q2[i].y, q2[i].z).transpose(); } cout &lt;&lt; &quot;W=&quot; &lt;&lt; endl; // SVD on W 对W使用SVD分解 // ComputeFullU是稀疏矩阵U Eigen::JacobiSVD&lt;Eigen::Matrix3d&gt; svd(W, Eigen::ComputeFullU | Eigen::ComputeFullV); Eigen::Matrix3d U = svd.matrixU(); Eigen::Matrix3d V = svd.matrixV(); cout &lt;&lt; &quot;U=&quot; &lt;&lt; U &lt;&lt; endl; cout &lt;&lt; &quot;V=&quot; &lt;&lt; V &lt;&lt; endl; Eigen::Matrix3d R_ = U * (V.transpose()); if (R_.determinant() &lt; 0) { R_ = -R_; // 保证姿态矩阵的输出之正 } // 求解t Eigen::Vector3d t_ = Eigen::Vector3d(p1.x, p1.y, p1.z) - R_ * Eigen::Vector3d(p2.x, p2.y, p2.z); // 将Eigen矩阵转化为CV::Mat() R = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; R_(0, 0), R_(0, 1), R_(0, 2), R_(1, 0), R_(1, 1), R_(1, 2), R_(2, 0), R_(2, 1), R_(2, 2) ); t = (cv::Mat_&lt;double&gt;(3, 1) &lt;&lt; t_(0, 0), t_(1, 0), t_(2, 0));} G2O方法值得注意的是，对于G2O来所，在编译的时候需要将其加入到动态链接库中。 1234add_executable(pose_estimation_3d3d pose_estimation_3d3d.cpp)target_link_libraries(pose_estimation_3d3d ${OpenCV_LIBS})target_link_libraries(pose_estimation_3d3d Sophus::Sophus)target_link_libraries(pose_estimation_3d3d ${G2O_CORE_LIBRARY} ${G2O_STUFF_LIBRARY}) 这一部分是和PnP和类似，就是一个将原来的暑输入从3D、2D变成是3D、3D，其他部分基本相似。 首先创建点和边。 这里的基本原理是将参考点乘以待优化的矩阵得到当前点的估计值，然后和当前点作差，计算3D点的三坐标的差。因此其边的维度就为3. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/// vertex and edges used in g2o baclass VertexPose : public g2o::BaseVertex&lt;6, Sophus::SE3d&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW; virtual void setToOriginImpl() override { _estimate = Sophus::SE3d(); } /// left multiplication on SE3 virtual void oplusImpl(const double *update) override { Eigen::Matrix&lt;double, 6, 1&gt; update_eigen; update_eigen &lt;&lt; update[0], update[1], update[2], update[3], update[4], update[5]; _estimate = Sophus::SE3d::exp(update_eigen) * _estimate; } virtual bool read(istream &amp;in) override {} virtual bool write(ostream &amp;out) const override {}};/// g2o edgeclass EdgeProjectXYZRGBDPoseOnly : public g2o::BaseUnaryEdge&lt;3, Eigen::Vector3d, VertexPose&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW; EdgeProjectXYZRGBDPoseOnly(const Eigen::Vector3d &amp;point) : _point(point) {} virtual void computeError() override { const VertexPose *pose = static_cast&lt;const VertexPose *&gt; ( _vertices[0] ); _error = _measurement - pose-&gt;estimate() * _point; } virtual void linearizeOplus() override { VertexPose *pose = static_cast&lt;VertexPose *&gt;(_vertices[0]); Sophus::SE3d T = pose-&gt;estimate(); Eigen::Vector3d xyz_trans = T * _point; _jacobianOplusXi.block&lt;3, 3&gt;(0, 0) = -Eigen::Matrix3d::Identity(); _jacobianOplusXi.block&lt;3, 3&gt;(0, 3) = Sophus::SO3d::hat(xyz_trans); } bool read(istream &amp;in) {} bool write(ostream &amp;out) const {}protected: Eigen::Vector3d _point;}; 这里在求解导数时要注意，其求导的对象是$-Tp$，因此其求导的结果要在上式的基础上加符号。 之后创建优化和执行的函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051void bundleAdjustment( const vector&lt;cv::Point3f&gt; &amp;pts1, const vector&lt;cv::Point3f&gt; &amp;pts2, cv::Mat &amp;R, cv::Mat &amp;t) { // 构建图优化，先设定g2o typedef g2o::BlockSolverX BlockSolverType; typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; // 线性求解器类型 // 梯度下降方法，可以从GN, LM, DogLeg 中选 auto solver = new g2o::OptimizationAlgorithmLevenberg( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;())); g2o::SparseOptimizer optimizer; // 图模型 optimizer.setAlgorithm(solver); // 设置求解器 optimizer.setVerbose(true); // 打开调试输出 // vertex VertexPose *pose = new VertexPose(); // camera pose pose-&gt;setId(0); pose-&gt;setEstimate(Sophus::SE3d()); optimizer.addVertex(pose); // edges for (size_t i = 0; i &lt; pts1.size(); i++) { EdgeProjectXYZRGBDPoseOnly *edge = new EdgeProjectXYZRGBDPoseOnly( Eigen::Vector3d(pts2[i].x, pts2[i].y, pts2[i].z)); edge-&gt;setVertex(0, pose); edge-&gt;setMeasurement(Eigen::Vector3d( pts1[i].x, pts1[i].y, pts1[i].z)); edge-&gt;setInformation(Eigen::Matrix3d::Identity()); optimizer.addEdge(edge); } chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); optimizer.initializeOptimization(); optimizer.optimize(10); chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); chrono::duration&lt;double&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;optimization costs time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl; cout &lt;&lt; endl &lt;&lt; &quot;after optimization:&quot; &lt;&lt; endl; cout &lt;&lt; &quot;T=\\n&quot; &lt;&lt; pose-&gt;estimate().matrix() &lt;&lt; endl; // convert to cv::Mat Eigen::Matrix3d R_ = pose-&gt;estimate().rotationMatrix(); Eigen::Vector3d t_ = pose-&gt;estimate().translation(); R = (cv::Mat_&lt;double&gt;(3, 3) &lt;&lt; R_(0, 0), R_(0, 1), R_(0, 2), R_(1, 0), R_(1, 1), R_(1, 2), R_(2, 0), R_(2, 1), R_(2, 2) ); t = (cv::Mat_&lt;double&gt;(3, 1) &lt;&lt; t_(0, 0), t_(1, 0), t_(2, 0));}","link":"/2022/06/11/SLAM/ch7-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86-ICP/"},{"title":"Ch8 视觉里程计 第一部分 光流法","text":"hljs.initHighlightingOnLoad(); 本文主要讲解的是光流法，他是直接法的基础，相交特征点法其主要的改进是取消的描述子的计算和特征匹配，大大的节省了实践上的开销。其主要基于的假设是灰度不变理论，在较为连续图片上不错的结果，为了解决光流非凸的问题，本文引入了图像金字塔，解决的是优化求解遇到的非凸问题，最后使用OpenCV自带的求解器和手写的高斯牛顿法的求解器来编程实现。 光流法和直接法的引入回顾整个特征点提取算法： 在图像中提取特征点并计算特征描述，耗时10ms+。 在不同图像中寻找特征匹配，耗时$O(n^2)$ 。 利用匹配点信息计算相机位姿，不是很耗费时间，耗时&lt;1ms。 尽管传统的特征匹配算法是当下的主流，但是其也具有很大的局限性： 关键点的提取和描述子的计算是相当耗时的，大部分的时间其实都浪费在算法的提取上了。 使用特征点时，由于其忽略了除去特征点以外的其他的信息，如果为了加快运算的速度而减少了特征点的提取时，两幅图上提取的特征点可能不一致。信息的丢失较为严重。 相机遇到一些特征缺失的地方时，比如白墙和比较光滑的曲面，此时可以得到的特征点的数量会明显减小。 对于上述的一些问题，主要有以下的几个解决的方法： 保留特征点，仅仅计算关键点，不计算描述子。使用光流来对特征点进行跟踪，回避特征匹配的带来的时间上的耗费。 仅计算关键点，不计算描述子。同时使用直接法计算特征点的下一个时刻位置。这样就可以跳过描述子的计算省去光流的时间，这样可以不要进行配对。 对于直接法来讲，其可以不计算具体地点和点的配对关系，但是通过最小光度误差来求出。 根据使用像素的数量，直接法分为稀疏、稠密和半稠密三种与特征点法只能重构稀疏特征点（稀疏地图）相比，直接法还具有恢复稠密或半稠密结构的能力。 这里的直接法是建立在光流法的基础上的，有着相同的假设条件。因此首先介绍光流法来为之后的直接法做铺垫。 基本概念光流：追踪源图像某个点在其他图像中的运动。 一般分为稀疏光流和稠密光流： 稀疏以Lucas-Kanade(LK)光流为代表，稀疏光流主要计算的是部分像素点的运动，特别地如计算关键点之间的运动关系。 稠密以Horn–Schunck(HS)光流为代表，稠密光流主要计算的是全局像素点(运动出图像的点除外)的运动。 其本质上是估计像素在不同时刻图像中的运动，本讲主要介绍的为LK光流。 LK光流在LK光流中，我们认为相机图像是岁时间的变化而变幻的，于是我们定义某一时刻，在(x,y)像素上的灰度值为$I(x,y,t)$ ，其值域为图像的灰度。 之后引入LK光流的关键假设，灰度不变性假设，其主要的内容就是同一空间点上的灰度值在各个图像中是保持不变的。 于是可得，在$t$时刻$(x,y)$处的像素，我们设$t+dt$ 时刻它运动到$(x+dx,y+dy)$ 处，由于灰度不变，我们有： \\boldsymbol{I}(x+dx,y+dy,t+dt)=\\boldsymbol{I}(x,y,t)这个假设是一个很强的假设，实际中很可能不成立，但是事实上，相机的高光/阴影/材质/曝光等不同，这时灰度不变性假设是明显不成立的。但是目前我们默认它成立。 于是对左边进行Taylor展开可得： \\boldsymbol{I}(x+\\mathrm{d} x, y+\\mathrm{d} y, t+\\mathrm{d} t) \\approx \\boldsymbol{I}(x, y, t)+\\frac{\\partial \\boldsymbol{I}}{\\partial x} \\mathrm{~d} x+\\frac{\\partial \\boldsymbol{I}}{\\partial y} \\mathrm{~d} y+\\frac{\\partial \\boldsymbol{I}}{\\partial t} \\mathrm{~d} t因为灰度不变假设，将上述相等的两项约掉： \\frac{\\partial \\boldsymbol{I}}{\\partial x} \\mathrm{~d} x+\\frac{\\partial \\boldsymbol{I}}{\\partial y} \\mathrm{~d} y+\\frac{\\partial \\boldsymbol{I}}{\\partial t} \\mathrm{~d} t=0之后，两边同时除以$dt$ 可得： \\frac{\\partial \\boldsymbol{I}}{\\partial x} \\frac{\\mathrm{d} x}{\\mathrm{~d} t}+\\frac{\\partial \\boldsymbol{I}}{\\partial y} \\frac{\\mathrm{d} y}{\\mathrm{~d} t}=-\\frac{\\partial \\boldsymbol{I}}{\\partial t}这里的光流的梯度，我们使用中心差分来做，于是得到关于$dx/dt,dy/dt$的二元一次方程，这个方程式欠定的，需要进行额外的约束。 \\left[\\begin{array}{ll}\\boldsymbol{I}_{x} & \\boldsymbol{I}_{y}\\end{array}\\right]\\left[\\begin{array}{l}u \\\\ v\\end{array}\\right]=-\\boldsymbol{I}_{t}于是我们引入了LK光流特有的假设，来引入一定的外部约束，在某一窗口内的像素具有相同的运动。于是还可以将这个出口内的所有的点代入方程可得： \\left[\\begin{array}{ll}\\boldsymbol{I}_{x} & \\boldsymbol{I}_{y}\\end{array}\\right]_{k}\\left[\\begin{array}{c}u \\\\ v\\end{array}\\right]=-\\boldsymbol{I}_{t k}, \\quad k=1, \\ldots, w^{2}其中的A和b矩阵为： \\boldsymbol{A}=\\left[\\begin{array}{c}{\\left[\\boldsymbol{I}_{x}, \\boldsymbol{I}_{y}\\right]_{1}} \\\\ \\vdots \\\\ {\\left[\\boldsymbol{I}_{x}, \\boldsymbol{I}_{y}\\right]_{k}}\\end{array}\\right], \\boldsymbol{b}=\\left[\\begin{array}{c}\\boldsymbol{I}_{t 1} \\\\ \\vdots \\\\ \\boldsymbol{I}_{t k}\\end{array}\\right]求解上述的超定的方程，我们可以使用最小二乘法来进行求解： \\left[\\begin{array}{l}u \\\\ v\\end{array}\\right]^{*}=-\\left(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}\\right)^{-1} \\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{b}这个问题可以转化为一个最小二乘法的问题，求解一个非线性的最小二乘约束，使用G-N法或L-M法来求解，可以使用G2O库。 根据求解得到的结果，可知图像是向着某个方向不断地移动，这个方向优化损失值是最小的，于是就得到了一个大概的移动轨迹。 但是由于相机的运动比较快，移动的位移也比较大，因此对应的点不一定都可以追上。因此引入图像金字塔来解决问题。 为了使得其特征点匹配在图像发生前进后退时还能很好的工作，因此可以将特征点不同的层之间进行匹配。 在光流里，一般地为了保证精度，只有在位移很小时才行，假如一般在5px像素内才能更好的保证其精度，有时目标点移动的过快会造成两个图像上特征点相差的像素过大，路线不准确。我们可以在缩小的图片上进行第一次的匹配，之后逐步同时放大到下一层进行精确一点的匹配，进而得到其准确的路径。一开始可能不一定找到精确解，这个问题有可能时非凸的问题。 总结： 光流法可以看成最小化像素误差的非线性优化； 其每次主要使用了Taylor一阶近似，这样使得在离优化点较远时效果不佳，往往需要迭代多次； 运动较大时要使用金字塔，不断迭代可以获得更精确的解； 光流法可以用于跟踪图像中的稀疏关键点的运动轨迹； 得到配对点后，后续计算与特征法VO中相同，使用最小二乘来求解姿态或者时是解方程来求解； 按方法可分为正向/反向+平移/组合的方式，具体在习题中介绍。 优点： 绕过了特征描述和特征匹配，直接通过tracking的方式来得到关键点的对应关系。 使用特征点法是，其特征点的数目减少之后可能就很难再次找到，因为这些点有的会移出到图像外，有的会被遮住，有的会变形导致算法无法识别。但是光流的话可以再较少的特征点下得到不错的结果。 光流解决平移的效果很好，但是如果出现旋转、滚转时要使用较为复杂的方法来解决，加入旋转不变性的假设。 对于我们复杂曲面，其纹理信息较弱，也很难用光流法识别。因为其系数矩阵的系数对于的时光流的梯度值，很难解出很好的解。SLAM经常拿白墙来距离，其结果和一般的曲面一样只有减弱的明暗关系，会造成匹配失误，一般情况下用直接法解决。 实践首先准备好相应的CMakeList.txt文件： 123456789101112131415161718192021cmake_minimum_required(VERSION 3.0.0)project(vo2 VERSION 0.1.0)set(CMAKE_BUILD_TYPE &quot;Release&quot;)add_definitions(&quot;-DENABLE_SSE&quot;)set(CMAKE_CXX_FLAGS &quot;-std=c++11 ${SSE_FLAGS} -g -O3 -march=native&quot;)find_package(OpenCV 4 REQUIRED)find_package(Sophus REQUIRED)find_package(Pangolin REQUIRED)include_directories( ${OpenCV_INCLUDE_DIRS} ${G2O_INCLUDE_DIRS} ${Sophus_INCLUDE_DIRS} &quot;/usr/include/eigen3/&quot; ${Pangolin_INCLUDE_DIRS})add_executable(optical_flow optical_flow.cpp)target_link_libraries(optical_flow ${OpenCV_LIBS}) 使用LK光流首先使用OpenCV里面自带的光流算法来进行识别，提取第一张的角点，之后通过光流来追踪其在第二张图片中的位置。 主要的代码如下，在main.cpp里，主要是首先读取图片。 123// IMREAD_GRAYSCALE = 0cv::Mat img_1 = cv::imread(file_1, 0);cv::Mat img_2 = cv::imread(file_2, 0); 对于特征点的提取，这里使用为GFTTDetector提取器，我们可以通过GFTTDetector::create()来创建一个GFTT特征点检测器，其参数如下： 参数 maxCorners：检测到的最大角点数量； 参数qualityLevel：输出角点的质量等级，取值范围是 [ 0 , 1 ]；如果某个候选点的角点响应值小于（qualityLeve * 最大角点响应值），则该点会被抛弃，相当于判定某候选点为角点的阈值； 参数minDistance：两个角点间的最小距离，如果某两个角点间的距离小于minDistance，则会被认为是同一个角点； 参数blockSize：计算角点响应值的邻域大小，默认值为3；如果输入图像的分辨率比较大，可以选择比较大的blockSize； 参数useHarrisDector：布尔类型，如果为true则使用Harris角点检测；默认为false，使用shi-tomas角点检测算法； 参数k：只在使用Harris角点检测时才生效，也就是计算角点响应值时的系数k。 12345// 首先，读取第一个图片里面的特征点vector&lt;cv::KeyPoint&gt; kp1;cv::Ptr&lt;cv::GFTTDetector&gt; detector = cv::GFTTDetector::create(500, 0.01, 20);// 参数的主要含义是 最大的角点数，输出点的质量，最小距离detector -&gt; detect(img_1, kp1); 之后就使用OpenCV使用自带的光流函数进行读取。 calcOpticalFlowPyrLK函数主要存在于opencv.hpp里面。 12345678CV_EXPORTS_W void calcOpticalFlowPyrLK( InputArray prevImg, InputArray nextImg, InputArray prevPts, InputOutputArray nextPts,OutputArray status, OutputArray err,Size winSize = Size(21,21), int maxLevel = 3,TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01), int flags = 0, double minEigThreshold = 1e-4 ); int maxLevel = 3 视觉金字塔的层数； Size winSize = Size(21,21) 代表的为一次所取patch块的大小，即有21*21=441个样本点。 前三个参数prevImg nextImg prevPts为输入的第一个图片，第二张图片，以及特征点的位置。 第4、5、6个参数为nextPts status err 分别是计算得出第二个点的特征点、输出状态和误差。 int flags = 0 可以设置成使用初值来进行优化。 1234567@param flags operation flags: - **OPTFLOW_USE_INITIAL_FLOW** uses initial estimations, stored in nextPts; if the flag is not set, then prevPts is copied to nextPts and is considered the initial estimate. - **OPTFLOW_LK_GET_MIN_EIGENVALS** use minimum eigen values as an error measure (see minEigThreshold description); if the flag is not set, then L1 distance between patches around the original and a moved point, divided by number of pixels in a window, is used as a error measure. 12345678910111213// 使用自带的光流函数进行读取// use opencv's flow for validationvector&lt;cv::Point2f&gt; pt1, pt2;for(auto &amp;kp: kp1) pt1.push_back(kp.pt);vector&lt;uchar&gt; status;vector&lt;float&gt; error;t1 = chrono::steady_clock::now();// 此函数在opencv.hpp里面cv::calcOpticalFlowPyrLK(img_1, img_2, pt1, pt2, status, error);// 这里的参数，其三个为输入，后面三个为输出t2 = chrono::steady_clock::now();time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);cout &lt;&lt; &quot;optical flow by opencv: &quot; &lt;&lt; time_used.count() &lt;&lt; endl; 最后进行可视化操作，显示出其特征点的位置用绿的的圆圈表示，和捕捉到的移动情况使用红色的细线表示。 cvtColor是用来将图片的类型进行转换的函数，这里imgproc/types_c.h -&gt; CV_GRAY2BGR中的CV_GRAY2BGR为将灰度图转换为BGR图。 cv::Scalar(0, 250, 0) 用来设置颜色，这里的含义时BGR，蓝绿红。 123456789101112131415161718cv::Mat img2_cv;// cvtcolor()函数是一个颜色空间转换函数，// 可以实现RGB颜色向HSV，HSI等颜色空间转换。也可以转换为灰度图。cv::cvtColor(img_2, img2_cv, CV_GRAY2BGR);// imgproc/types_c.h -&gt; CV_GRAY2BGRfor(int i = 0; i &lt; pt2.size(); i++){ if (status[i]) { // 标记特征点 cv::circle(img2_cv, pt2[i], 2, cv::Scalar(0, 250, 0), 2); // 使用直线来显示出移动的情况 cv::line(img2_cv, pt1[i], pt2[i], cv::Scalar(0, 250, 0)); } }cv::imshow(&quot;tracked by opencv&quot;, img2_cv);cv::waitKey(0); 使用G-N方法实现光流光流可以看成时一个优化的问题，通过最小化像素的误差来估计最优的偏移值。这里使用手写的高斯牛顿法来进行实现。 error: static assertion failed: YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES 维度的定义有误； 首先定义实现GN算法的类： 123456789101112131415161718192021222324252627class OpticalFlowTracker{public: // 构造函数 OpticalFlowTracker( const cv::Mat &amp;img1_, const cv::Mat &amp;img2_, const vector&lt;cv::KeyPoint&gt; &amp;kp1_, vector&lt;cv::KeyPoint&gt; &amp;kp2_, vector&lt;bool&gt; &amp;success_, bool inverse_ = true, bool has_initial_ = false ): img1(img1_), img2(img2_), kp1(kp1_), kp2(kp2_), success(success_), inverse(inverse_), has_initial(has_initial_){} void calculateOpticalFlow(const cv::Range &amp;range); // cv::Range 随机数类型 // 函数的实现在类的定义之外来实现private: const cv::Mat &amp;img1; const cv::Mat &amp;img2; const vector&lt;cv::KeyPoint&gt; &amp;kp1; vector&lt;cv::KeyPoint&gt; &amp;kp2; vector&lt;bool&gt; &amp;success; bool inverse = true; bool has_initial = false;}; bool inverse 变量为是否为可逆光流，即反向光流； bool has_initial = false 变量为是否进行初始化； 前两个为输入的图片，后边的两个参数为两个特征点，其中第二张图片的特征点为待求的特征点，vector&lt;cv::KeyPoint&gt; &amp;kp2; 下面介绍成员函数的实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110void OpticalFlowTracker::calculateOpticalFlow(const cv::Range &amp;range){ // 相关的参数 int half_patch_size = 4; // 采样块的半径 int iterations = 10; // 迭代次数 for (size_t i = range.start; i &lt; range.end; i++){ // 这里对于特征点是随机选择的，不是按顺序来的 auto kp = kp1[i]; double dx = 0, dy = 0; // dx,dy 需要进行估计 if(has_initial){ dx = kp2[i].pt.x - kp.pt.x; dy = kp2[i].pt.y - kp.pt.y; // 初始化操作 } double cost = 0, lastCost = 0; bool succ = true; // indicate if this point succeeded // 代表优化知否成功 // Gauss-Newton法 进行迭代 Eigen::Matrix2d H = Eigen::Matrix2d::Zero(); // hessian Eigen::Vector2d b = Eigen::Vector2d::Zero();// bias Eigen::Vector2d J; for (int iter = 0; iter &lt; iterations; iter++) { if (inverse == false) { // 二者都进行重置 H = Eigen::Matrix2d::Zero(); b = Eigen::Vector2d::Zero(); } else { // only reset b 仅仅将b进行重置 b = Eigen::Vector2d::Zero(); } cost = 0; // 计算误差和雅克比Jacobi矩阵 for(int x = -half_patch_size; x &lt; half_patch_size; x++) for (int y = -half_patch_size; y &lt; half_patch_size; y++) { // 求解误差函数 double error = GetPixelValue(img1, kp.pt.x + x, kp.pt.y + y) - GetPixelValue(img2, kp.pt.x + x + dx, kp.pt.y + y + dy); // 求解Jacobi矩阵 // inverse的意思是反向光流 if (inverse == false) { J = -1.0 * Eigen::Vector2d( 0.5 * (GetPixelValue(img2, kp.pt.x + dx + x + 1, kp.pt.y + dy + y) - GetPixelValue(img2, kp.pt.x + dx + x - 1, kp.pt.y + dy + y)), 0.5 * (GetPixelValue(img2, kp.pt.x + dx + x, kp.pt.y + dy + y + 1) - GetPixelValue(img2, kp.pt.x + dx + x, kp.pt.y + dy + y - 1)) ); } else if (iter == 0) { // 以下是反向光流模块，因为其计算的是第一个图像的信息，于是可得其Jacobi矩阵一直不变 // in inverse mode, J keeps same for all iterations // NOTE this J does not change when dx, dy is updated, so we can store it and only compute error J = -1.0 * Eigen::Vector2d( 0.5 * (GetPixelValue(img1, kp.pt.x + x + 1, kp.pt.y + y) - GetPixelValue(img1, kp.pt.x + x - 1, kp.pt.y + y)), 0.5 * (GetPixelValue(img1, kp.pt.x + x, kp.pt.y + y + 1) - GetPixelValue(img1, kp.pt.x + x, kp.pt.y + y - 1)) ); } // compute H, b and set cost; // 将所有采样点的值相加 b += -error * J; cost += error * error; if(inverse == false || iter == 0){ // also update H += J * J.transpose(); } } // 计算更新值 // compute update Eigen::Vector2d update = H.ldlt().solve(b); // 异常情况 if (std::isnan(update[0])) { // sometimes occurred when we have a black or white patch and H is irreversible cout &lt;&lt; &quot;update is nan&quot; &lt;&lt; endl; succ = false; break; } if (iter &gt; 0 &amp;&amp; cost &gt; lastCost) { break; } // update dx, dy dx += update[0]; dy += update[1]; lastCost = cost; succ = true; if (update.norm() &lt; 1e-2) { // converge break; } } // 成功计算光流，并且得出匹配点 success[i] = succ; // set kp2 kp2[i].pt = kp.pt + cv::Point2f(dx, dy); }} 成员函数的大概思路已经很明显了，下面将一些细节的地方进行解释。 首先，这里的特征点时通过随机生成器来随机选取的cv::Range，直到遍历所有的情况。 这里个dx dy 设置初始值，在多层光流的实现中，下面一层的光流时基于上面一层的计算得到的第二个图片的特征点进行下一步优化的，这样可以防止出现局部最小化。 12345if(has_initial){ dx = kp2[i].pt.x - kp.pt.x; dy = kp2[i].pt.y - kp.pt.y; // 初始化操作} for(int x = -half_patch_size; x &lt; half_patch_size; x++) 这里时遍历临近的 half_patch_size * half_patch_size * 4 = 64个采样点。 这里Jacobi矩阵的求解过程如下： \\begin{align} \\frac{\\partial \\boldsymbol{J}}{\\partial \\Delta x}&=\\frac{\\partial \\boldsymbol{J}}{\\partial \\boldsymbol{I_2}} \\frac{\\partial \\boldsymbol{I_2}}{\\partial \\Delta x} =-1*\\frac{\\partial \\boldsymbol{I_2}}{\\partial \\Delta x}\\\\&=-1*\\left(\\frac{\\boldsymbol{I_2}(x+\\Delta x +1,y + \\Delta y) - \\boldsymbol{I_2}(x + \\Delta x -1,y+\\Delta y)}{1-(-1)}\\right) \\end{align}采用为中心差商代替的导数的方法。 对于正向光流计算的关于$\\boldsymbol{I_2}$ 的梯度，反向光流就是的则是$\\boldsymbol{I_1}$ ，因为$\\boldsymbol{I_1}$ 随着优化是不变的，因此不需要遍历所有的采用点，计算一组即可，比较节约时间和计算量。 下面是在上述GN方法中使用到的求解图片像素值的函数，其主要是实现求解离散像素节点值的插值。 思考：为什么使用内联函数？ 1234567891011121314151617inline double GetPixelValue(const cv::Mat &amp;img, float x, float y) { // boundary check if (x &lt; 0) x = 0; if (y &lt; 0) y = 0; if (x &gt;= img.cols - 1) x = img.cols - 2; if (y &gt;= img.rows - 1) y = img.rows - 2; float xx = x - floor(x); float yy = y - floor(y); int x_a1 = std::min(img.cols - 1, int(x) + 1); int y_a1 = std::min(img.rows - 1, int(y) + 1); return (1 - xx) * (1 - yy) * img.at&lt;uchar&gt;(y, x) + xx * (1 - yy) * img.at&lt;uchar&gt;(y, x_a1) + (1 - xx) * yy * img.at&lt;uchar&gt;(y_a1, x) + xx * yy * img.at&lt;uchar&gt;(y_a1, x_a1);} 最后，实现一个层光流的函数。 首先，将关键点的维度和size()统一； 之后，实例化一个OpticalFlowTracker； 最后，通过parallel_for_调用成员函数，计算得到一个第二张图片的关键点。 思考：parallel_for_的作用。 123456789101112131415161718192021222324// 单层光流void OpticalFlowSingleLevel( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const vector&lt;cv::KeyPoint&gt; &amp;kp1, vector&lt;cv::KeyPoint&gt; &amp;kp2, vector&lt;bool&gt; &amp;success, bool inverse = false, bool has_initial_guess = false);void OpticalFlowSingleLevel( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const vector&lt;cv::KeyPoint&gt; &amp;kp1, vector&lt;cv::KeyPoint&gt; &amp;kp2, vector&lt;bool&gt; &amp;success, bool inverse, bool has_initial) { kp2.resize(kp1.size()); success.resize(kp1.size()); OpticalFlowTracker tracker(img1, img2, kp1, kp2, success, inverse, has_initial); parallel_for_(cv::Range(0, kp1.size()), std::bind(&amp;OpticalFlowTracker::calculateOpticalFlow, &amp;tracker, placeholders::_1));} 以下是单层光流追踪的结果，可以看到优化出现了收敛到局部最优解的状况。 最后，基于上面的单层光流，我们可以实现一个基于图像金字塔的多层光流函数，其主要的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 多层光流void OpticalFlowMultiLevel( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const vector&lt;cv::KeyPoint&gt; &amp;kp1, vector&lt;cv::KeyPoint&gt; &amp;kp2, vector&lt;bool&gt; &amp;success, bool inverse = false);void OpticalFlowMultiLevel( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const vector&lt;cv::KeyPoint&gt; &amp;kp1, vector&lt;cv::KeyPoint&gt; &amp;kp2, vector&lt;bool&gt; &amp;success, bool inverse){ // 参数 // 金字塔的层数 int pyramids = 4; // 缩小比例 double pyramids_scale = 0.5; double scales[] = {1.0, 0.5, 0.25, 0.125}; // create 创建金字塔 vector&lt;cv::Mat&gt; pyr1, pyr2; // 向图像金字塔里面加图片 for(int i = 0; i &lt; pyramids; i++){ if(i == 0){ pyr1.push_back(img1); pyr2.push_back(img2); }else{ cv::Mat img1_pyr, img2_pyr; // 使用递归，在前一个的基础上缩小到原来的一半 cv::resize(pyr1[i - 1], img1_pyr, cv::Size(pyr1[i - 1].cols * pyramids_scale, pyr1[i - 1].rows * pyramids_scale)); cv::resize(pyr2[i - 1], img2_pyr, cv::Size(pyr2[i - 1].cols * pyramids_scale, pyr2[i - 1].rows * pyramids_scale)); pyr1.push_back(img1_pyr); pyr2.push_back(img2_pyr); } } // coarse-to-fine LK tracking in pyramids // 将keypoints 保存到金字塔中 vector&lt;cv::KeyPoint&gt; kp1_pyramids, kp2_pyramids; for(auto &amp;kp: kp1){ auto kp_top = kp; // 得到最高层金字塔的特征点 kp_top.pt *= scales[pyramids - 1]; kp1_pyramids.push_back(kp_top); kp2_pyramids.push_back(kp_top); } // 从金字塔的顶端开始向底端遍历 for(int level = pyramids - 1; level &gt;= 0; level--) { success.clear(); OpticalFlowSingleLevel(pyr1[level], pyr2[level], kp1_pyramids, kp2_pyramids, success, inverse, true); // kp2_pyramids 计算并更新了金字塔level层上面的特征点 if(level &gt; 0){ // 计算上一层的特征点 // kp1_pyramids,kp2_pyramids是一个存储特征变量的临时的vector for(auto &amp;kp: kp1_pyramids) kp.pt /= pyramids_scale; for(auto &amp;kp: kp2_pyramids) kp.pt /= pyramids_scale; // 将上一层的特征点作为初始值来更新下一层的特征点 } } for(auto &amp;kp: kp2_pyramids){ kp2.push_back(kp); } // 保存计算出来的第二张图片的特征点} 首先，初始化特征金字塔的参数，并创建图像金字塔，将图片不断压缩放入其中，vector&lt;cv::Mat&gt; pyr1, pyr2. 之后，初始化最顶层的特征点的金字塔。 最后，从顶层像底部对每一层使用一次单层光流跟踪，得出的第二张图片的特征点，将其作为下一层下一层的第二张图片特征点的初始值。 这样可以很好的防止出现仅仅使用单层光流造成的优化过程非凸，收敛到局部最优的情况。 对于其在main()函数里的调用和之前类似，此处直接上代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;chrono&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/imgproc/types_c.h&gt;//&quot;CV_GRAY2BGR&quot; 包含在imgproc/types_c.h#include &lt;Eigen/Core&gt;#include &lt;Eigen/Dense&gt;using namespace std;// 要读取两章图片的路径string file_1 = &quot;../LK1.png&quot;; // first imagestring file_2 = &quot;../LK2.png&quot;; // second imageint main(int argc, char **argv){ // IMREAD_GRAYSCALE = 0 cv::Mat img_1 = cv::imread(file_1, 0); cv::Mat img_2 = cv::imread(file_2, 0); // 首先，读取第一个图片里面的特征点 vector&lt;cv::KeyPoint&gt; kp1; cv::Ptr&lt;cv::GFTTDetector&gt; detector = cv::GFTTDetector::create(500, 0.01, 20); // 参数的主要含义是 最大的角点数，输出点的质量，最小距离 detector -&gt; detect(img_1, kp1); // ====================================================================== // now lets track these key points in the second image // first use single level LK in the validation picture // 单层光流法 vector&lt;cv::KeyPoint&gt; kp2_single; vector&lt;bool&gt; success_single; OpticalFlowSingleLevel(img_1, img_2, kp1, kp2_single, success_single); // ====================================================================== // then test multi-level LK vector&lt;cv::KeyPoint&gt; kp2_multi; vector&lt;bool&gt; success_multi; chrono::steady_clock::time_point t1 = chrono::steady_clock::now(); OpticalFlowMultiLevel(img_1, img_2, kp1, kp2_multi, success_multi, true); chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); auto time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;optical flow by gauss-newton: &quot; &lt;&lt; time_used.count() &lt;&lt; endl; // ====================================================================== // 使用自带的光流函数进行读取 // use opencv's flow for validation vector&lt;cv::Point2f&gt; pt1, pt2; for(auto &amp;kp: kp1) pt1.push_back(kp.pt); vector&lt;uchar&gt; status; vector&lt;float&gt; error; t1 = chrono::steady_clock::now(); // 此函数在opencv.hpp里面 cv::calcOpticalFlowPyrLK(img_1, img_2, pt1, pt2, status, error); // 这里的参数，其三个为输入，后面三个为输出 t2 = chrono::steady_clock::now(); time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;optical flow by opencv: &quot; &lt;&lt; time_used.count() &lt;&lt; endl; // plot the differences of those functions // 可视化 cv::Mat img2_single; cv::cvtColor(img_2, img2_single, CV_GRAY2BGR); for (int i = 0; i &lt; kp2_single.size(); i++) { if (success_single[i]) { cv::circle(img2_single, kp2_single[i].pt, 2, cv::Scalar(0, 250, 0), 2); cv::line(img2_single, kp1[i].pt, kp2_single[i].pt, cv::Scalar(0, 250, 0)); } } cv::Mat img2_multi; cv::cvtColor(img_2, img2_multi, CV_GRAY2BGR); for (int i = 0; i &lt; kp2_multi.size(); i++) { if (success_multi[i]) { cv::circle(img2_multi, kp2_multi[i].pt, 2, cv::Scalar(0, 250, 0), 2); cv::line(img2_multi, kp1[i].pt, kp2_multi[i].pt, cv::Scalar(0, 250, 0)); } } cv::Mat img2_cv; // cvtcolor()函数是一个颜色空间转换函数， // 可以实现RGB颜色向HSV，HSI等颜色空间转换。也可以转换为灰度图。 cv::cvtColor(img_2, img2_cv, CV_GRAY2BGR); // imgproc/types_c.h -&gt; CV_GRAY2BGR for(int i = 0; i &lt; pt2.size(); i++) { if (status[i]) { // 标记特征点 cv::circle(img2_cv, pt2[i], 2, cv::Scalar(0, 250, 0), 2); // 使用直线来显示出移动的情况 cv::line(img2_cv, pt1[i], pt2[i], cv::Scalar(0, 250, 0)); } } cv::imshow(&quot;tracked single level&quot;, img2_single); cv::imshow(&quot;tracked multi level&quot;, img2_multi); cv::imshow(&quot;tracked by opencv&quot;, img2_cv); cv::waitKey(0); return 0;}","link":"/2022/06/11/SLAM/ch8-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E5%85%89%E6%B5%81%E6%B3%95/"},{"title":"Ch8 视觉里程计 第二部分 直接法","text":"hljs.initHighlightingOnLoad(); 本文主要介绍了直接法，相比光流法其鲁棒性更好，即使随机取点，其效果依然不错。相比光流法求解的时在像素上移动的距离，直接法则是通过优化光度误差直接求解对应的第二张相对第一张的姿态变换情况。最后我们使用GN方法进行编程实现。 在光流法仅仅时估计了相机之间的平移，但是其主要有以下的问题： 没有用到相机本身的几何结构； 没有考虑到相机的旋转和图像的缩放； 对于边界上的点，光流不好追踪； 直接法则考虑了这些信息，其将DA数据搜寻，pose计算姿态，直接法将两个步骤合成为一步。他是根据图像整体的信息来估计运动的， 直接法的推导考虑空间点$P=[X,Y,Z]$和两个相机上的成的像，记为像素坐标$p_1,p_2$ 其表达形式如下图所示。 这里以第一帧为参照系，第二个到第一个的旋转和平移为 $\\boldsymbol{R,t}$ 对于的李群为 $\\boldsymbol{T}$ 。假设两个相机的内参相同，记为 $\\boldsymbol{K}$ .于是我们得到投影上的关系为： \\boldsymbol{p_1}=\\left[\\begin{array}{l}u \\\\ v \\\\ 1\\end{array}\\right]_{1}=\\frac{1}{Z_{1}} \\boldsymbol{K} \\boldsymbol{P} \\boldsymbol{p_2}=\\left[\\begin{array}{l}u \\\\ v \\\\ 1\\end{array}\\right]_{2}=\\frac{1}{Z_{2}} \\boldsymbol{K}(\\boldsymbol{R} \\boldsymbol{P}+\\boldsymbol{t})=\\frac{1}{Z_{2}} \\boldsymbol{K}\\left(\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{P}\\right)_{1: 3}其中，$Z_1,Z_2$ 分别是P对应的深度。 对于光流法的灰度不变假设以同样的适用，其就是优化位姿使得$\\boldsymbol{I_1}(p_1) \\approx \\boldsymbol{I_2}(p_2)$ 尽可能的相等即可。 这里类似于最小重投影误差，我们定义了两个像素点亮度的重投影误差。 e=\\boldsymbol{I_1}(p_1) - \\boldsymbol{I_2}(p_2)这里的e是由变量，其实就是灰度值的误差，同样是优化误差的二范数，这里不加相应的权重，于是有： \\min\\limits_{T}J(T)=\\left|| e\\right||^2基于灰度不变性假设：在空间不同的视角下成像的灰度是不变的。这里取N个空间点，于是就有： \\min _{\\boldsymbol{T}} J(\\boldsymbol{T})=\\sum_{i=1}^{N} e_{i}^{\\mathrm{T}} e_{i}, \\quad e_{i}=\\boldsymbol{I}_{1}\\left(\\boldsymbol{p}_{1, i}\\right)-\\boldsymbol{I}_{2}\\left(\\boldsymbol{p}_{2, i}\\right)这里的优化变量是相机的位姿，而光流上的优化变量是对应的特征点的运动，因此需要求解目标相对于姿态T的导数： 于是就有： \\begin{align} e(\\boldsymbol{\\xi} \\oplus \\delta \\boldsymbol{\\xi})&=\\boldsymbol{I}_{1}\\left(\\frac{1}{Z_{1}} \\boldsymbol{K} \\boldsymbol{P}\\right)-\\boldsymbol{I}_{2}\\left(\\frac{1}{Z_{2}} \\boldsymbol{K} \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{P}+\\boldsymbol{u}\\right)\\\\ &\\approx \\boldsymbol{I}_{1}\\left(\\frac{1}{Z_{1}} \\boldsymbol{K} \\boldsymbol{P}\\right)-\\boldsymbol{I}_{2}\\left(\\frac{1}{Z_{2}} \\boldsymbol{K} \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{P}\\right)-\\frac{\\partial \\boldsymbol{I}_{2}}{\\partial \\boldsymbol{u}} \\frac{\\partial \\boldsymbol{u}}{\\partial \\boldsymbol{q}} \\frac{\\partial \\boldsymbol{q}}{\\partial \\delta \\boldsymbol{\\xi}} \\delta \\boldsymbol{\\xi}\\\\ &=e(\\boldsymbol{\\xi})-\\frac{\\partial \\boldsymbol{I}_{2}}{\\partial \\boldsymbol{u}} \\frac{\\partial \\boldsymbol{u}}{\\partial \\boldsymbol{q}} \\frac{\\partial \\boldsymbol{q}}{\\partial \\delta \\boldsymbol{\\xi}} \\delta \\boldsymbol{\\xi} \\end{align}这里的求导的部分主要分为三个部分： 图像梯度，$\\partial \\boldsymbol{I}_{2} / \\partial \\boldsymbol{u}$ 在 u 处的梯度； 像素对投影点的梯度，$\\partial \\boldsymbol{u} / \\partial \\boldsymbol{q}$ 为投影关于相机坐标系下三维点的导数。这里的q 其实就是将三维点在第二个相机坐标系下的坐标，u 为对应的像素坐标。 \\dfrac{\\partial \\boldsymbol{u}}{\\partial \\boldsymbol{q}}=\\left[\\begin{array}{ccc}\\dfrac{\\partial u}{\\partial X} & \\dfrac{\\partial u}{\\partial Y} & \\dfrac{\\partial u}{\\partial Z} \\\\ \\dfrac{\\partial v}{\\partial X} & \\dfrac{\\partial v}{\\partial Y} & \\dfrac{\\partial v}{\\partial Z}\\end{array}\\right]=\\left[\\begin{array}{ccc}\\dfrac{f_{x}}{Z} & 0 & -\\dfrac{f_{x} X}{Z^{2}} \\\\ 0 & \\dfrac{f_{y}}{Z} & -\\dfrac{f_{y} Y}{Z^{2}}\\end{array}\\right] 投影点对位姿的导数：$\\dfrac{\\partial \\boldsymbol{q}}{\\partial \\delta \\boldsymbol{\\xi}}=\\left[\\boldsymbol{I},-\\boldsymbol{q}^{\\wedge}\\right]$ 综上可得： \\frac{\\partial \\boldsymbol{u}}{\\partial \\delta \\boldsymbol{\\xi}}=\\left[\\begin{array}{cccccc}\\dfrac{f_{x}}{Z} & 0 & -\\dfrac{f_{x} X}{Z^{2}} & -\\dfrac{f_{x} X Y}{Z^{2}} & f_{x}+\\dfrac{f_{x} X^{2}}{Z^{2}} & -\\dfrac{f_{x} Y}{Z} \\\\ 0 & \\dfrac{f_{y}}{Z} & -\\dfrac{f_{y} Y}{Z^{2}} & -f_{y}-\\dfrac{f_{y} Y^{2}}{Z^{2}} & \\dfrac{f_{y} X Y}{Z^{2}} & \\dfrac{f_{y} X}{Z}\\end{array}\\right]上述的矩阵为一个$2 \\times6$ 的矩阵，于是可得李代数的Jacobi矩阵为： \\boldsymbol{J}=-\\frac{\\partial \\boldsymbol{I}_{2}}{\\partial \\boldsymbol{u}} \\frac{\\partial \\boldsymbol{u}}{\\partial \\delta \\boldsymbol{\\xi}}对于N个点的问题，我们可以用这种方法计算优化问题的雅可比矩阵，然后使用高斯牛顿法或列文伯格一马夸尔特方法计算增量，迭代求解。至此，我们推导了直接法估计相机位姿的整个流程,下面通过程序来演示直接法是如何使用的。 相关的讨论对于空间点P是的获取方法 RGBD相机，将任意像素点反投影到三维空间即可； 双目相机，根据视差来计算深度； 单目相机，比较困难，存在深度的不确定性，可以使用三角化方法，也可以使用下一章的方法。 直接法和一般PnP方法的区别 PnP是对于已经匹配好的点进行重投影误差的最小化的，求出对于的姿态矩阵$R,t$。 直接法是开始时位置两个点是否匹配，但是也可以时周围其他的点，是通过多个点一起来得出最优的$R,t$ 从而得到匹配的关系的。 e(\\boldsymbol{\\xi})-\\frac{\\partial \\boldsymbol{I}_{2}}{\\partial \\boldsymbol{u}} \\frac{\\partial \\boldsymbol{u}}{\\partial \\boldsymbol{q}} \\frac{\\partial \\boldsymbol{q}}{\\partial \\delta \\boldsymbol{\\xi}} \\delta \\boldsymbol{\\xi}通过上式可以看出直接法的雅可比项有一个图像梯度因子，因此就有在图像梯度不明显的地方，对相机运动的估计贡献值比较小。 白墙和天空的影响权重比较小，对于位姿估计的影响小，但是可以投影。 直接发的分类根据图像信息以及P的来源，可以对其进行分类可得： 稀疏直接法：仅仅处理稀疏的角点和关键点，和LK光流法类似，假设周围像素是不变的，这种方法不应计算描述子，速度快，但也只能计算稀疏的重构。 半稠密直接法：对于图像梯度为0的点，其对雅可比矩阵计算的贡献较小，因此我们可以舍去，仅仅计算有梯度点的情况。 稠密直接法：计算所有的像素，但是比较消耗计算的资源。但是可以得到完整的地图。 对于上述方法的选择，要根据场景和实际的计算资源来定。 直观解释和优缺点直观解释 像素灰度引导着优化的方向。 对于特征点法来说，当图像整体变亮时，对于特征点关键点的选取不影响太大； 对于直接法来说，如果$I_1$ 比 $I_2$ 明显的亮，就会导致光度误差要很大，会造成匹配出错。 要使得优化成立，必须要保证初始估计到最优化估计中间的梯度一直下降。因为如果遇到非凸的情况时，我们的会遇到局部最优的情况，导致其陷入到一个局部的最小值中。 一方面可以使用优化算法上的辅助，如使用智能优化算法来跳出局部最优； 或者想办法将目前的问题转化成为凸的问题。 另一方面可以使用图像金字塔，在最模糊的一层中得到一个初始的姿态$R,t$，之后来如到第二层优化的时候，使用第一层的结果作为初始值，不断地迭代，这样可以环节局部最优的问题。 优缺点 优势： 省略了特征提取的时间 (特征提取的点也不一定非要为角点，也可以随机的选)，于是特征描述和匹配关系的时间也可以省去。 只是需要像素梯度而不必是角点，对白墙等地方有较好的效果，对于曲面点云其深度是渐变的过程，特征点很难进行识别，光流法也具有一定的不确定性，但是直接法就可以很好的识别，更加鲁棒。 可稠密或半稠密。但是一般得到特征点会因为关键点的减少而出现无法匹配的情况。 劣势 灰度不变的假设过强。灰度不变的假设在容易受到相机曝光、模糊以及自然光照变化的影响。相机存在暗角，中央部分是通过透镜来成像的，而非中央部分即边缘部分的光照是比较暗的，因此从边缘转向中央时会有光照的变化。 非凸性。由于图像具有很强的非凸性，因此其可能在优化的过程陷入到局部最优中去。 单个像素没有区分性。其优化时是选取的一系列的点来进行的，少数服从多数，来调整姿态的，因此要具有一定的数量上的规模才有效，一般建议500个点以上。 实践首先准备好本程序需要使用的CMakeList.txt文件。 123456789101112131415161718192021cmake_minimum_required(VERSION 3.0.0)project(vo2 VERSION 0.1.0)set(CMAKE_BUILD_TYPE &quot;Release&quot;)add_definitions(&quot;-DENABLE_SSE&quot;)set(CMAKE_CXX_FLAGS &quot;-std=c++11 ${SSE_FLAGS} -g -O3 -march=native&quot;)find_package(OpenCV 4 REQUIRED)find_package(Sophus REQUIRED)find_package(Pangolin REQUIRED)include_directories( ${OpenCV_INCLUDE_DIRS} ${G2O_INCLUDE_DIRS} ${Sophus_INCLUDE_DIRS} &quot;/usr/include/eigen3/&quot; ${Pangolin_INCLUDE_DIRS})add_executable(direct_method direct_method.cpp)target_link_libraries(direct_method ${OpenCV_LIBS} ${Pangolin_LIBRARIES} Sophus::Sophus) 单层直接法这边不针对稠密直接法的编程，不涉及GPU编程。为了简单易于理解，我们使用RGBD图像，给出深度数据，省略了深度会恢复的部分。 和光流类似，这里采取了并行计算每个像素点的误差和Jacobi矩阵，为此我们定义了一个求解Jacobi的类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class JacobianAccumulator{public: // 构造函数 JacobianAccumulator( const cv::Mat &amp;img1_, const cv::Mat &amp;img2_, const VecVector2d &amp;px_ref_, const vector&lt;double&gt; depth_ref_, Sophus::SE3d &amp;T21_ ):img1(img1_), img2(img2_), px_ref(px_ref_), depth_ref(depth_ref_), T21(T21_) { projection = VecVector2d(px_ref.size(), Eigen::Vector2d(0, 0)); } // 成员函数 /// accumulate jacobians in a range void accumulate_jacobian(const cv::Range &amp;range); /// get hessian matrix Matrix6d hessian() const { return H; } /// get bias Vector6d bias() const { return b; } /// get total cost double cost_func() const { return cost; } /// get projected points VecVector2d projected_points() const { return projection; } /// reset h, b, cost to zero void reset() { H = Matrix6d::Zero(); b = Vector6d::Zero(); cost = 0; }// 成员变量private: const cv::Mat &amp;img1; const cv::Mat &amp;img2; const VecVector2d &amp;px_ref; const vector&lt;double&gt; depth_ref; Sophus::SE3d &amp;T21; VecVector2d projection; // projected points std::mutex hessian_mutex; Matrix6d H = Matrix6d::Zero(); Vector6d b = Vector6d::Zero(); double cost = 0;}; 其主要的成员变量主要包含： 前后两帧的图像，img1,img2； 第一个图片的像素信息px_ref，和深度信息depth_ref,这里第一张图片为主要的参考基准。 第二张图片相对第一张相机的姿态T21,以及特征点在第一张图片上的投影projection 以及求解增量方程所需的hessian 矩阵和bias向量。 其主要的成员函数包括： 一个参数重置矩阵reset(). 由于成员变量为私有的private因此需要只用成员函数来获取私有变量的值。hessian() bias() 获取hessian矩阵和bias，cost_func() 获取损失值， projected_points()获取在第一张图片在第二张图片上的投影点。 并行计算Jacobi矩阵的accumulate_jacobian(). 下面来介绍accumulate_jacobian的具体实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/ 函数的实现void JacobianAccumulator::accumulate_jacobian(const cv::Range &amp;range){ // 参数 const int half_patch_size = 1; int cnt_good = 0; // 记录可以用来计算光流的点的个数 // 初始化Hessian Matrix and bias Matrix6d hessian = Matrix6d::Zero(); Vector6d bias = Vector6d::Zero(); double cost_tmp = 0; // 临时记录损失 for(size_t i = range.start; i &lt; range.end; i++) { // 计算在第二个图片上的深度 // 由像素坐标还原成为3d坐标 // 按照当前估计的位姿变换到第二帧相机下,得到第二个相机坐标系下的空间点坐标 Eigen::Vector3d point_ref = depth_ref[i] * Eigen::Vector3d((px_ref[i][0] - cx) / fx, (px_ref[i][1] - cy) / fy, 1); // 将第一个图片上的三维点转移到第二个相片上面 Eigen::Vector3d point_cur = T21 * point_ref; // 深度信息无效则跳过 if (point_cur[2] &lt; 0) // depth invalid continue; // 在第二个图片上进行投影 // 由投影方程倒推到点在第二个相机坐标系下的像素平面坐标 float u = fx * point_cur[0] / point_cur[2] + cx; float v = fy * point_cur[1] / point_cur[2] + cy; if(u &lt; half_patch_size || u &gt; img2.cols - half_patch_size || v &lt; half_patch_size || v &gt; img2.rows - half_patch_size){ // 舍弃采样 patch块 跑到图像外的情况 continue; } projection[i] = Eigen::Vector2d(u, v); // 将投影保存 double X = point_cur[0], Y = point_cur[1], Z = point_cur[2]; double Z2 = Z * Z, Z_inv = 1.0 / Z, Z2_inv = Z_inv * Z_inv; cnt_good++; // 可以用来计算光流的是点的数量 // 计算雅克比矩阵 for(int x = -half_patch_size; x &lt;= half_patch_size; x++){ for(int y = -half_patch_size; y &lt;= half_patch_size; y++){ double error = GetPixelValue(img1, px_ref[i][0] + x, px_ref[i][1] + y) - GetPixelValue(img2, u + x, v + y); // 第一个图片的元素为px_ref里面存储的 // 第二个图片的元素为 u, v // 初始化Jacobi矩阵 Matrix26d J_pixel_xi; // 像素对3D坐标(姿态)的求导 直接法相比光流法多出来的 Eigen::Vector2d J_img_pixel; // 光流对像素的坐标求导 这部分在光流里里面也是有的 J_pixel_xi(0, 0) = fx * Z_inv; J_pixel_xi(0, 1) = 0; J_pixel_xi(0, 2) = -fx * X * Z2_inv; J_pixel_xi(0, 3) = -fx * X * Y * Z2_inv; J_pixel_xi(0, 4) = fx + fx * X * X * Z2_inv; J_pixel_xi(0, 5) = -fx * Y * Z_inv; J_pixel_xi(1, 0) = 0; J_pixel_xi(1, 1) = fy * Z_inv; J_pixel_xi(1, 2) = -fy * Y * Z2_inv; J_pixel_xi(1, 3) = -fy - fy * Y * Y * Z2_inv; J_pixel_xi(1, 4) = fy * X * Y * Z2_inv; J_pixel_xi(1, 5) = fy * X * Z_inv; J_img_pixel = Eigen::Vector2d( 0.5 * (GetPixelValue(img2, u + 1 + x, v + y) - GetPixelValue(img2, u - 1 + x, v + y)), 0.5 * (GetPixelValue(img2, u + x, v + 1 + y) - GetPixelValue(img2, u + x, v - 1 + y)) ); // 中心差分 // 计算总的Jacobi Vector6d J = -1.0 * (J_img_pixel.transpose() * J_pixel_xi).transpose(); hessian += J * J.transpose(); bias += -error * J.transpose(); cost_tmp += error * error; } } } if(cnt_good){ // 设置该点处的求得的Hessian matrix and bias unique_lock&lt;mutex&gt; lck(hessian_mutex); // 因为使用并行计算，为了防止抢占变量，需要先获得锁 H += hessian; b += bias; cost += cost_tmp / cnt_good; }} 前面的注释已经很清晰了，结合光流法的一些注释，可以很好的理解。 最后的地方，这里是并行的计算每个点对应的光流，每次会调用unique_lock&lt;mutex&gt; lck(hessian_mutex)获得锁为了防止抢占变量，保持计算每个点的hessian时不会受到之前点的影响。 思考：如何理解并行计算的过程，和N个点如何优化出最好的相机姿态 接下来为实现单层光流的函数，其主要代码如下， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 单层直接法的实现void DirectPoseEstimationSingleLayer( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const VecVector2d &amp;px_ref, const vector&lt;double&gt; depth_ref, Sophus::SE3d &amp;T21){ // 这里主要进行GN优化的主体部分 const int iteration = 10; double cost = 0, lastCost = 0; auto t1 = chrono::steady_clock::now(); // 雅克比Jacobi矩阵计算 JacobianAccumulator jaco_accu(img1, img2, px_ref, depth_ref, T21); for(int iter = 0; iter &lt; iteration; iter++){ jaco_accu.reset(); // 初始化，先将其中的 H b 清零 // 并行化计算，与光流法这一步的工作十分类似 // 计算出更新用的雅可比矩阵 cv::parallel_for_(cv::Range(0, px_ref.size()), std::bind(&amp;JacobianAccumulator::accumulate_jacobian, &amp;jaco_accu, std::placeholders::_1)); Matrix6d H = jaco_accu.hessian(); Vector6d b = jaco_accu.bias(); // 求解增量方程，得到增量值来更新姿态参数 Vector6d update = H.ldlt().solve(b);; // 更新姿态矩阵 T21 = Sophus::SE3d::exp(update) * T21; cost = jaco_accu.cost_func(); if (std::isnan(update[0])) { // sometimes occurred when we have a black or white patch and H is irreversible cout &lt;&lt; &quot;update is nan&quot; &lt;&lt; endl; break; } if (iter &gt; 0 &amp;&amp; cost &gt; lastCost) { cout &lt;&lt; &quot;cost increased: &quot; &lt;&lt; cost &lt;&lt; &quot;, &quot; &lt;&lt; lastCost &lt;&lt; endl; break; } if (update.norm() &lt; 1e-3) { // converge break; } lastCost = cost; cout &lt;&lt; &quot;iteration: &quot; &lt;&lt; iter &lt;&lt; &quot;, cost: &quot; &lt;&lt; cost &lt;&lt; endl; } // 计算时间 cout &lt;&lt; &quot;T21 = \\n&quot; &lt;&lt; T21.matrix() &lt;&lt; endl; auto t2 = chrono::steady_clock::now(); auto time_used = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1); cout &lt;&lt; &quot;direct method for single layer: &quot; &lt;&lt; time_used.count() &lt;&lt; endl; // plot the projected pixels here cv::Mat img2_show; cv::cvtColor(img2, img2_show, CV_GRAY2BGR); VecVector2d projection = jaco_accu.projected_points(); // 计算在第二个图像上的投影点 for (size_t i = 0; i &lt; px_ref.size(); ++i) { // 绘制光流 auto p_ref = px_ref[i]; auto p_cur = projection[i]; if (p_cur[0] &gt; 0 &amp;&amp; p_cur[1] &gt; 0) { cv::circle(img2_show, cv::Point2f(p_cur[0], p_cur[1]), 2, cv::Scalar(0, 250, 0), 2); cv::line(img2_show, cv::Point2f(p_ref[0], p_ref[1]), cv::Point2f(p_cur[0], p_cur[1]), cv::Scalar(0, 250, 0)); } } cv::imshow(&quot;current&quot;, img2_show); cv::waitKey();} 其基本的思路为首先初始化；然后并行计算求解增量方程，得到对应的更新量；之后将更新量代入得到更新后的姿态；最后可视化，得到运动过程中的光流。 其主程序和之前的光流比较类似，我们用一些示例图片测试直接法的结果。我们会用到几张Kittil自动驾驶数据集的图像。首先，我们读取第一个图像left.png，在对应的视差图disparity.png中，计算每个像素对应的深度，然后对000001.png-~000005.png这五张图像，利用直接法计算相机的位姿。为了展示直接法对特征点的不敏感性，我们随机地在第一张图像中选取一些点,不使用任何角点或特征点提取算法，来看看它的结果。 12345678910111213141516171819202122232425262728293031323334353637383940414243int main(int argv, char **argc){ // 读取图片 cv::Mat left_img = cv::imread(left_file, 0); cv::Mat disparity_img = cv::imread(disparity_file, 0); // let's randomly pick pixels in the first image and generate some 3d points in the first image's frame // 在第一个图片上随机选择3D点 cv::RNG rng; // 随机取得2000个点 int nPoints = 2000; int boarder = 20; VecVector2d pixels_ref; vector&lt;double&gt; depth_ref; // generate pixels in ref and load depth data // 生成像素点和导入深度数据 for (int i = 0; i &lt; nPoints; i++) { // 控制随机数避开靠边界的点 int x = rng.uniform(boarder, left_img.cols - boarder); // don't pick pixels close to boarder int y = rng.uniform(boarder, left_img.rows - boarder); // don't pick pixels close to boarder int disparity = disparity_img.at&lt;uchar&gt;(y, x); // 这里的 disparity 为视差 本例子为一个双目视觉 // baseline 代表基线 double depth = fx * baseline / disparity; // you know this is disparity to depth depth_ref.push_back(depth); pixels_ref.push_back(Eigen::Vector2d(x, y)); } // estimates 01~05.png's pose using this information Sophus::SE3d T_cur_ref; for (int i = 1; i &lt; 6; i++) { // 1~10 cv::Mat img = cv::imread((fmt_others % i).str(), 0); // try single layer by uncomment this line // 实现单层 // DirectPoseEstimationSingleLayer(left_img, img, pixels_ref, depth_ref, T_cur_ref); // 实现多层 DirectPoseEstimationMultiLayer(left_img, img, pixels_ref, depth_ref, T_cur_ref); } return 0;} 这里我们没有选择特征点法而是使用随机取点的方法，由此可见，相比光流法直接法更加鲁棒，且速度更快。 多层光流法下面时多层光流法的实现函数，其主体部分和之前的光流法类似，之前的特征点变成了深度值和随机像素值。通过在不同尺度下使用直接法不断迭代，利用上一层求解得到的值来作为下一层姿态的初始值，不断迭代得到比较好的解，防止出现局部最优。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 多层直接法的实现void DirectPoseEstimationMultiLayer( const cv::Mat &amp;img1, const cv::Mat &amp;img2, const VecVector2d &amp;px_ref, const vector&lt;double&gt; depth_ref, Sophus::SE3d &amp;T21){ // 参数 // 金字塔的层数 int pyramids = 4; // 缩小比例 double pyramids_scale = 0.5; double scales[] = {1.0, 0.5, 0.25, 0.125}; // create 创建金字塔 vector&lt;cv::Mat&gt; pyr1, pyr2; // 向图像金字塔里面加图片 for(int i = 0; i &lt; pyramids; i++){ if(i == 0){ pyr1.push_back(img1); pyr2.push_back(img2); }else{ cv::Mat img1_pyr, img2_pyr; // 使用递归，在前一个的基础上缩小到原来的一半 cv::resize(pyr1[i - 1], img1_pyr, cv::Size(pyr1[i - 1].cols * pyramids_scale, pyr1[i - 1].rows * pyramids_scale)); cv::resize(pyr2[i - 1], img2_pyr, cv::Size(pyr2[i - 1].cols * pyramids_scale, pyr2[i - 1].rows * pyramids_scale)); pyr1.push_back(img1_pyr); pyr2.push_back(img2_pyr); } } // 随着特征金字塔不断向上，相机的内参也在不断地改变 // 这里将最底层的内参存其来 double fxG = fx, fyG = fy, cxG = cx, cyG = cy; // backup the old values // 从底层向上开始计算 for(int level = pyramids - 1; level &gt;= 0; level--) { // 计算每层的特征点 VecVector2d px_ref_pyr; for(auto &amp;px: px_ref){ px_ref_pyr.push_back(scales[level] * px); } // 计算不同层的相机内参 double fx = fxG * scales[level]; double fy = fyG * scales[level]; double cx = cxG * scales[level]; double cy = cyG * scales[level]; // 对每层分别使用直接法 DirectPoseEstimationSingleLayer(pyr1[level], pyr2[level], px_ref_pyr, depth_ref, T21); }} 可见其已经先前行驶了2.82706m，即使我们随机选点，直接法也能够正确追踪大部分的像素，同时估计相机的运动。这中间没有任何的特征提取、匹配或光流的过程。从运行时间上看，在2000个点时，直接法每迭代一层需要1~2毫秒，所以四层金字塔约耗时8毫秒。相比之下，2000个点的光流耗时大约在十几毫秒，还不包括后续的位姿估计。所以，直接法相比于传统的特征点和光流通常更快一些。","link":"/2022/06/12/SLAM/ch8-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-%E7%9B%B4%E6%8E%A5%E6%B3%95/"},{"title":"多GPU并行训练简易教程","text":"hljs.initHighlightingOnLoad(); 使用单机多卡目前有两个常用的API，下面我们将分别来介绍这两种API。 DataParallel这个API的基本原理是通过调用单个进程来实现的数据上并行，目前使用的比较的少，不是当的主流，但是为了看懂前人的代码，需要进行学一下。 这个API的特点就是比较简单，方便修改。 模型修改首先检测GPU的数量，主要的代码如下： 123456789if __name__ ==&quot;__main__&quot;: if torch.cuda.is_available(): logging.warning(&quot;Cuda is available&quot;) if torch.cuda.device_count() &gt; 1: logging.warning(f&quot;Find {torch.cuda.device_count()} GPUs!&quot;) else: logging.warning(&quot;Too few GPU!&quot;) else: logging.warning(&quot;Cuda is not available! Exit!&quot;) 主要使用的API为torch.cuda.device_count()：检测可用的GPU的数量； torch.cuda.is_available()：检测GPU是否可用。 之后，将模型放入到DataParallel中： 12model = generator_model()model = torch.nn.DataParallel(module=model, device_ids=[0, 1, 2, 3]) 模型保存和加载然后，对于模型的保存，也要进行一定的修改： 之前使用的是model.state_dict(). 123torch.save({ 'model_state_dict': model.module.state_dict()}) 但是，一般载入之前的模型，一般是在导入到DataParallel之前进行的，因此我们可以不需要修改，仅仅是将一些简单导入模型的未知进行修改即可，通过map_location=来确定导入的设备。 123checkpoint = torch.load(f=xxxx, map_location=torch.device(&quot;cuda:0&quot;))# 这里可以是cpu,cuda,cuda:indexmodel.load_state_dict(checkpoint['model_state_dict']) 最后，修改的是batch_size参数，使用几张卡，就在原来的基础上成乘以记就行。 DistributedDataParallel(推荐)该API是当下比较火的API，最新推出的，可以实现多进程执行多卡训练，效率比较高，修改了之前一些DataParallel的一些弊端。 但是这个API需要修改的内容很多，而且还要定义一些关于进程和多卡通信方式的内容。 代码修改首先，是定义多进程组的内容： 1torch.distributed.init_process_group(&quot;nccl&quot;, world_size=n_gpus, rank=args.local_rank) &quot;nccl&quot;代表的是多卡的通信方式； world_size=n_gpus 代表当前节点上有几张GPU卡； rank=args.local_rank 指定当前的进程在第个GPU上。 之后，指定当前进程使用的是第几张卡： 1torch.cuda.set_device(args.local_rank) args.local_rank其实是在外部定义的配置信息。 这个语句的信息相当于CUDA_VISIBLE_DEVICES环境变量。 以上的两步均为准备工作，下面我们开始进行将模型封装导入到多线程的类中，这里的包裹模型的方法和DataParallel。 1model = torch.nn.parallel.DistributedDataParallel(model.cuda(args.local_rank), device_ids=[args.local_rank]) model.cuda(args.local_rank)将模型拷贝到当前的GPU卡上； device_ids=[args.local_rank] 指定训练所用的GPU设备，这里一个进程使用一个GPU就好。 之后，将数据随机分配到对应的GPU上。 12train_sampler = DistributedSampler(train_set)# 主要是将数据随机取样，再分到各个GPU内 trainset代表训练集； 这个函数的主要的作用是将数据随机的分到不同的GPU上； 其所在的未知为from torch.utils.data import DistributedSampler 和Dataloader 在一起，作用也比较的类似。 DistributedSampler的主要的源码如下所示： 12345678class DistributedSampler(Sampler[T_co]): r&quot;&quot;&quot;Sampler that restricts data loading to a subset of the dataset. It is especially useful in conjunction with :class:`torch.nn.parallel.DistributedDataParallel`. In such a case, each process can pass a :class:`~torch.utils.data.DistributedSampler` instance as a :class:`~torch.utils.data.DataLoader` sampler, and load a subset of the original dataset that is exclusive to it. 其主要是配合DistributedDataParallel一起来使用的，其主要的作用是将数据均匀的分配到几个GPU中，几个GPU的数据一汇总就是原来的数据集。 1234self.num_samples = math.ceil(len(self.dataset) / self.num_replicas)self.total_size = self.num_samples * self.num_replicasself.shuffle = shuffleself.seed = seed 下面是对应__iter__ 的部分代码，其主要是返回的每个epoch中一个batch对应的索引下标的值。这里有两个控制索引随机性的参数: self.seed 随机种子，默认为0； self.epoch 当前的epoch值，默认为0，求默认是不变的。 123456def __iter__(self) -&gt; Iterator[T_co]: if self.shuffle: # deterministically shuffle based on epoch and seed g = torch.Generator() g.manual_seed(self.seed + self.epoch) indices = torch.randperm(len(self.dataset), generator=g).tolist() 如果这两个参数是不变的，那么每个epoch里面产生的batch划分是一样的，在训练的过程中就会出现比较有规律的周期性的震荡，因此我们要对上述两个参数中至少调节其中的一个， 可以将·epoch参数赋予当前运行的epoch的值，即调用set_epoch(); 或者调整随机种子，self.seed. 1234indices = torch.randperm(len(self.dataset), generator=g).tolist()# subsampleindices = indices[self.rank:self.total_size:self.num_replicas]assert len(indices) == self.num_samples indices 产生的是索引的序列值，来分配到不同的GPU上。 然后，定义好的sampler导入的对应的Dataloader中。 1train_loader = DataLoader(..., sampler=train_sampler) 注意：这里Dataloader如果接受了自定义的sample之后，就不用再定义shuffle参数了。 最后，将数据导入到对应节点的GPU中。 1data = data.cuda(args.local_rank) 执行命令在运行命令时，需要对参数进行一定的设置操作： 1python -m torch.distributed.launch --nproc_per_node=ngpus train.py 模型保存和加载一般将torch.save() 在local_rank=0的位置进行保存，同样注意调用model.module.state_dict(). 模型的加载还是使用的是torch.load()但是要注意map_location. 其他注意事项 train.py中要有接受local_rank的参数选项，launch会传入这个参数。 每个进程的batch_size应该是一个GPU所需要的batch_size大小，这种方法是增加进程数的，每个GPU占一个进程。 在每个周期开始处，调用train_sampler.set_epoch(epoch)可以使得数据充分打乱。 有了sampler，就不要在DataLoader中设置shuffle=True了。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940# 设置argparse的参数parser = argparse.ArgumentParser()parser.add_argument(&quot;--local_rank&quot;, help=&quot;local device id on current node&quot;, type=int)args = parser.parse_args()# 一共几个可用的 GPUn_gpus = 4# local_rank表示当前的进程 idtorch.distributed.init_process_group(&quot;nccl&quot;, world_size=n_gpus, rank=args.local_rank)# 相当于修改了CUDA_VISIBLE_DEVICES的环境变量torch.cuda.set_device(args.local_rank)# 将模型导入DDT的API中model = torch.nn.parallel.DistributedDataParallel(model.cuda(args.local_rank), device_ids=[args.local_rank])# 创建数据集train_dataset = YepianDatasets( root_dir=config.TRAIN_DIR, vib_dir='vib', condition_dir='condition', fre_dir='fre', label_dir='label',)train_sampler = DistributedSampler(train_dataset)# 主要是将数据随机取样，再分到各个GPU内train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=64)# 对于验证集而言，就不需要使用上述的train_sample了for epoch in range(500): # 保证数据随机获得，防止出现周期的性的震荡 train_sampler.set_epoch(epoch) # 模型的保存 local_rank = args.local_rank if local_rank == 0: # 再local_rank == 0才进行模型的保存 torch.save({ 'model_state_dict': model.module.state_dict() }) 之后在命令行输入相关的命令 1python -m torch.distributed.launch --nproc_per_node=4 train.py","link":"/2022/06/13/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/%E5%A4%9AGPU%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83%E7%AE%80%E6%98%93%E6%95%99%E7%A8%8B/"},{"title":"Ch9 后端 第一部分 EKF","text":"hljs.initHighlightingOnLoad(); 之前的视觉里程计只有连续两张图片的短暂的记忆，而我们希望的是在整个运动轨迹上保持最优，需要使用新进的信息来更新系统的状态。 本讲主要介绍的常用后端中的第一种EKF扩展卡尔曼滤波的方法。 状态估计问题的概率解释对于后端问题，其实可以理解成： 从带有噪声的数据来估计内在的状态的问题； 第一章建立的状态方程和运动方程可知，其主要就是使用$u,z$ 来估计$x_k,y_j$ 的值； \\boldsymbol x_{k+1}=f(\\boldsymbol x_k,\\boldsymbol u_k)+\\boldsymbol \\omega_k \\\\ \\boldsymbol z_{k,j}=h(\\boldsymbol x_k,\\boldsymbol y_j)+\\boldsymbol v_{k,j} 这里数据噪声通常被认为是高斯噪声。 通过MLE，MAP等方法转换成为一个非线性优化的问题。 在后端优化的过程中，我们会考虑一段较长的时间内的状态估计问题，其中不仅要使用过去的时间来更新自己的状态，同时也需要未来的信息来进行更新于是可以分为渐进式和批量式的方法。 渐进式/增量式 保持当前状态的估计，在加入新的信息是，更新已有的估计(滤波)。 线性系统+高斯噪声=Kalmen filter; 非线性系统+高斯噪声+线性近似=EKF； 相机模型就是一个非线性的模型。 非线性系统+非高斯噪声+非参数化=粒子滤波器； 视觉里程计的特张点过多，因此滤波器很难承受视觉SLAM的计算量，在激光里用的可能比较多。 Sliding window filter &amp; multiple state Kalman (MSCKF) 滑动窗口法是批量法和滤波方法相结合的一种方法。其主要的想法是在一段滑动窗口内求解最值。 批量式 其主要式给定一定规模的数据，这部分数据不仅有过去的也有未来的，批量法是计算该组数据下的状态估计问题。 左侧仅仅只有运动方程，其运动是发散的，不确定度很大。因为其输入的数据是纯在噪声的，会不断的积累，导致下一时刻的估计相比前一时刻误差越积越大。 其实就相当于蒙着眼走路： 一开始我们知道自己在哪； 能粗略估计每步的距离，但不确定 不确定性随时间累积 导致自身的位置不确定性越来越大 右侧是存在路标点的情况下，其不确定性会迅速的减小， 此时就相当于在某个时刻睁开一下眼睛： 能够观测到周围； 尽管也有不确定性，但比估计步长小很多； 能够将不确定性保持在一定范围内。 我们SLAM主要解决的是未知环境信息下的状态估计问题，即我们对路标点在环境当中的未知也是一无所知的，这个问题是有一定难度的。 在第六讲中，介绍的主要是极大似然估计问题，就是批量式的状态估计问题可以转换为最大似然估计问题，并使用最小二乘法来估计求解。 在本章主要想解决的是如何解决渐进式的问题。 首先，需要明确的是运动和观测都受到噪声的影响，其次就是有可能没有运动方程，纯视觉的SLAM。下面我们使用贝叶斯滤波器的方法来推到卡尔曼滤波器。 \\left\\{\\begin{array}{l}\\boldsymbol{x}_{k}=f\\left(\\boldsymbol{x}_{k-1}, \\boldsymbol{u}_{k}\\right)+\\boldsymbol{w}_{k} \\\\ \\boldsymbol{z}_{k, j}=h\\left(\\boldsymbol{y}_{j}, \\boldsymbol{x}_{k}\\right)+\\boldsymbol{v}_{k, j}\\end{array} \\quad k=1, \\ldots, N, j=1, \\ldots, M\\right. 需要强调的是，姿态 $x$ 和路标 $y$ 其实可以看成服从某种状态分布的随机变量，不是一个单独的数。其不确定度主要是指的方差的大小。其估计值指的是随机变量的均值。 为了简化上述的表达式，我们将 k 时刻所有待估计的量组成 k 时刻的状态，其中暴扣当前时刻的姿态和m个路标点。 \\boldsymbol{x}_{k} \\triangleq\\left\\{\\boldsymbol{x}_{k}, \\boldsymbol{y}_{1}, \\ldots, \\boldsymbol{y}_{m}\\right\\}同时，我们将观测统一写成$z_k$ 此时状态方程和运动方程的表达形式可以更加的简洁。表达式如下： \\left\\{\\begin{array}{l}x_{k}=f\\left(x_{k-1}, \\boldsymbol{u}_{k}\\right)+\\boldsymbol{w}_{k} \\\\ \\boldsymbol{z}_{k}=h\\left(\\boldsymbol{x}_{k}\\right)+\\boldsymbol{v}_{k}\\end{array} \\quad k=1, \\ldots, N\\right.现在考虑k时刻的情况，希望使用过去从0到k中的数据来估计现在的状态分布情况，即$P\\left(\\boldsymbol{x}_{k} \\mid \\boldsymbol{x}_{0}, \\boldsymbol{u}_{1: k}, \\boldsymbol{z}_{1: k}\\right)$. 其中$0:k$ 表示从0到k 时刻的所有数据。注意$z_k$ 表示所有在 k 时刻的观测数据，可能不止一个，只是这种记法比较方便。$x_k$ 其实和$x_{k-1},x_{k-2}$ 这些变量都相关但是此式并没有将其显示的表现出来。 使用Bayes公式可得： P\\left(\\boldsymbol{x}_{k} \\mid \\boldsymbol{x}_{0}, \\boldsymbol{u}_{1: k}, \\boldsymbol{z}_{1: k}\\right) \\propto P\\left(\\boldsymbol{z}_k|\\boldsymbol{x}_k \\right)P\\left(\\boldsymbol{x}_{k} \\mid \\boldsymbol{x}_{0}, \\boldsymbol{u}_{1: k}, \\boldsymbol{z}_{1: k-1}\\right)其中，第一项被称为似然，后一项被称为先验，其中的似然可以通过观测来给出，而对于先验部分，$x_k$ 会受到 $x_{k-1}$ 的影响，于是使用条件展开可得： P\\left(x_{k} \\mid x_{0}, u_{1: k}, z_{1: k-1}\\right)=\\int P\\left(x_{k} \\mid x_{k-1}, x_{0}, u_{1: k}, z_{1: k-1}\\right) P\\left(x_{k-1} \\mid x_{0}, u_{1: k}, z_{1: k-1}\\right) \\mathrm{d} x_{k-1}上面式子中的第二项可以通过上一轮迭代得出，是k-1时刻的状态估计。 对于第一项，k时刻受先前状态的影响，有两种主要的解决方法： 一种可以假设k时刻状态仅仅和k-1时刻有关，使用一阶马尔可夫性，基于此假设可以推出扩展卡尔曼滤波EKF。 另一种可以假设k时刻和先前所有时刻均有关，此时采用非线性优化的方法求解。 接下来我们将分别介绍上述两个框架的原理。 线性系统与KF我们首先来看滤波器模型。当我们假设了马尔可夫的情况时，其表达式可以简化： P\\left(\\boldsymbol x_{k} \\mid \\boldsymbol x_{k-1}, \\boldsymbol x_{0}, \\boldsymbol u_{1: k}, \\boldsymbol z_{1: k-1}\\right)=P\\left(\\boldsymbol x_{k} \\mid \\boldsymbol x_{k-1}, \\boldsymbol x_{0}, \\boldsymbol u_{1: k}\\ \\right)针对第二项,由于$u_k$和k-1时刻的状态无关，于是可得： P\\left(x_{k-1} \\mid x_{0}, u_{1: k}, z_{1: k-1}\\right)=P\\left(x_{k-1} \\mid x_{0}, u_{1: k-1}, z_{1: k-1}\\right) .于是这就成了一个递推的问题，一直k-1时刻状态变量的均值和协方差，给出一个输入来更新并求出第k时刻的状态变量和协方差。 下面来从最简单的线性高斯系统出发，来推到出卡尔曼滤波器。 首先，介绍线性高斯系统的数学表达，其中包含观测方程和运动方程如下： \\left\\{\\begin{array}{l}\\boldsymbol{x}_{k}=\\boldsymbol{A}_{k} \\boldsymbol{x}_{k-1}+\\boldsymbol{u}_{k}+\\boldsymbol{w}_{k} \\\\ \\boldsymbol{z}_{k}=\\boldsymbol{C}_{k} \\boldsymbol{x}_{k}+\\boldsymbol{v}_{k}\\end{array} \\quad k=1, \\ldots, N\\right.其中，假设所有的噪声都满足高斯分布： \\boldsymbol{w}_{k} \\sim N(\\mathbf{0}, \\boldsymbol{R}) . \\quad \\boldsymbol{v}_{k} \\sim N(\\mathbf{0}, \\boldsymbol{Q})于是问题转化成已知 k-1时刻后验的状态估计 $\\hat{x}_{k-1}$ 和协方差 $\\hat{P}_{k}$ ，以及k 时刻的输入$u_k$ 和观测 $z_k$ ，来确定$x_k$ 的后验。 这里，我们记上帽为后验$\\hat {x_k}$，下帽为先验$\\check {x_k}$ 于是可得$x_k$ 的先验，此步并成为预测。 P\\left(x_{k} \\mid x_{0}, u_{1: k}, z_{1: k-1}\\right)=N\\left(A_{k} \\hat{x}_{k-1}+u_{k}, A_{k} \\hat{P}_{k} A_{k}^{\\mathrm{T}}+R\\right) .即有，其先验的表达式为： \\check{\\boldsymbol{x}}_{k}=\\boldsymbol{A}_{k} \\hat{\\boldsymbol{x}}_{k-1}+\\boldsymbol{u}_{k}, \\quad \\check{\\boldsymbol{P}}_{k}=\\boldsymbol{A}_{k} \\hat{\\boldsymbol{P}}_{k-1} \\boldsymbol{A}_{k}^{\\mathrm{T}}+\\boldsymbol{R}由于本系统为加了噪声的系统，因此先验的不确定性会增大。需要引入似然/观测来进行减小。 之后代入观测方程可得：$\\boldsymbol{P}(z_k|x_k)=\\boldsymbol{N}(C_kx_k,\\boldsymbol Q)$ 根据前面的Bayes展开可得后验=似然$\\times$先验： \\boldsymbol P\\left(x_{k} \\mid x_{0}, u_{1: k}, z_{1: k}\\right) \\propto \\boldsymbol P\\left(z_{k} \\mid x_{k}\\right) \\ \\boldsymbol P\\left(x_{k} \\mid x_{0}, u_{1: k}, z_{1: k-1}\\right)由于高斯过程的乘积还是高斯过程，于是就有： N\\left(\\hat{x}_{k}, \\hat{P}_{k}\\right)=N\\left(C_{k} x_{k}, Q\\right) \\cdot N\\left(\\check{x}_{k}, \\check{P}_{k}\\right)既然都是高斯分布，我们比较指数部分的二次项和一次项部分即可。 \\left(x_{k}-\\hat{x}_{k}\\right)^{\\mathrm{T}} \\widehat{P}_{k}^{-1}\\left(x_{k}-\\hat{x}_{k}\\right)=\\left(z_{k}-C_{k} x_{k}\\right)^{\\mathrm{T}} Q^{-1}\\left(z_{k}-C_{k} x_{k}\\right)+\\left(x_{k}-\\bar{x}_{k}\\right)^{\\mathrm{T}} \\bar{P}_{k}^{-1}\\left(x_{k}-\\bar{x}_{k}\\right)对比二次项的系数可得： \\hat{P}_{k}^{-1}=C_{k}^{\\mathrm{T}} Q^{-1} C_{k}+\\check{P}_{k}^{-1}接下来对比一次项的系数可得： -2 \\hat{x}_{k}^{\\mathrm{T}} \\hat{P}_{k}^{-1} x_{k}=-2 z_{k}^{\\mathrm{T}} Q^{-1} C_{k} x_{k}-2 \\check{x}_{k}^{\\mathrm{T}} \\check{P}_{k}^{-1} x_{k}\\\\ \\Rightarrow \\hat{P}_{k}^{-1} \\hat{x}_{k}=C_{k}^{\\mathrm{T}} Q^{-1} z_{k}+\\check{P}_{k}^{-1} \\bar{x}_{k}将两边同时乘以$\\hat{P}_{k}$ 并定义：$K=\\hat{P}_{k}C^T_kQ^{-1}$ \\begin{align} \\hat{x}_{k}&=\\hat{P}_{k} C_{k}^{\\mathrm{T}} Q^{-1} z_{k}+\\check{P}_{k} \\check{P}_{k}^{-1} \\check{x}_{k}\\\\ &=K z_{k}+\\left(I-K C_{k}\\right) \\check{x}_{k}=\\bar{x}_{k}+K\\left(z_{k}-C_{k} \\check{x}_{k}\\right) \\end{align}上式称为卡尔曼滤波的更新式，第二项称为修正量，K称为卡尔曼滤波的增益。 注意上面式子的K的表达式和我们一般的刚才的$K=\\hat{P}_{k}C^T_kQ^{-1}$ 其实等价的，其一般称为SMB恒等式。 方便理解但是具体的细节还要参考其他的资料。 以上为经典的卡尔曼滤波器的公式，其给出了线性高斯系统的最优无偏估计，但是其主要是基于了以下的经典的假设： 线性假设：即运动方程和观测方程基本都是线性的变换； 高斯分布假设：主要是所有的状态变量、观测变量以及系统的噪声都满足高斯分布，因为其比较好估计 [仅仅只有一阶矩(均值)和二阶矩(协方差矩阵)两个变量]，而且高斯分布的参数较少，适用的范围比较广。 马尔可夫假设。 非线性系统和扩展卡尔曼滤波在视觉SLAM的应用场景下，大多是非线性的情况，因此将Kalman Filter进行非线性扩展EKF。 当 观测方程和运动方程都为非线性函数时： \\left\\{\\begin{array}{l}x_{k}=f\\left(x_{k-1}, \\boldsymbol{u}_{k}\\right)+\\boldsymbol{w}_{k} \\\\ \\boldsymbol{z}_{k}=h\\left(\\boldsymbol{x}_{k}\\right)+\\boldsymbol{v}_{k}\\end{array} \\quad k=1, \\ldots, N\\right.我们的做法时将其在某个点处进行一阶展开， x_{k} \\approx f\\left(\\hat{\\boldsymbol{x}}_{k-1}, \\boldsymbol u_{k}\\right)+\\left.\\frac{\\partial f}{\\partial \\boldsymbol x_{k-1}}\\right|_{\\hat{\\boldsymbol{x}}_{k-1}}\\left(\\boldsymbol x_{k-1}-\\hat{\\boldsymbol{x}}_{k-1}\\right)+\\boldsymbol w_{k} .\\\\ \\boldsymbol{z}_{k} \\approx h\\left(\\check{\\boldsymbol{x}}_{k}\\right)+\\left.\\frac{\\partial h}{\\partial \\boldsymbol{x}_{k}}\\right|_{\\check{\\boldsymbol{x}}_{k}}\\left(\\boldsymbol{x}_{k}-\\hat{\\boldsymbol{x}}_{k}\\right)+\\boldsymbol{n}_{k}.这里我们记$\\boldsymbol F=\\left. \\dfrac{\\partial f}{\\partial \\boldsymbol x_{k-1}}\\right|_{\\hat{\\boldsymbol{x}}_{k-1}}$，$\\boldsymbol H=\\left. \\dfrac{\\partial f}{\\partial \\boldsymbol x_{k-1}}\\right|_{\\check{\\boldsymbol{x}}_{k-1}}$ . 那么在预测步骤中，根据运动方程有： P\\left(\\boldsymbol{x}_{k} \\mid \\boldsymbol{x}_{0}, \\boldsymbol{u}_{1: k}, \\boldsymbol{z}_{0: k-1}\\right)=N\\left(f\\left(\\hat{\\boldsymbol{x}}_{k-1}, \\boldsymbol{u}_{k}\\right), \\boldsymbol{F} \\hat{\\boldsymbol{P}}_{k-1} \\boldsymbol{F}^{\\mathrm{T}}+\\boldsymbol{R}_{k}\\right)这里将先验和协方差记为： \\check{\\boldsymbol{x}}_{k}=f\\left(\\hat{\\boldsymbol{x}}_{k-1}, \\boldsymbol{u}_{k}\\right), \\quad \\check{\\boldsymbol{P}}_{k}=\\boldsymbol{F} \\hat{\\boldsymbol{P}}_{k-1} \\boldsymbol{F}^{\\mathrm{T}}+\\boldsymbol{R}_{k}之后再观测中我们有： P\\left(\\boldsymbol{z}_{k} \\mid \\boldsymbol{x}_{k}\\right)=N\\left(h\\left(\\check{\\boldsymbol{x}}_{k}\\right)+\\boldsymbol{H}\\left(\\boldsymbol{x}_{k}-\\check{\\boldsymbol{x}}_{k}\\right), \\boldsymbol{Q}_{k}\\right)最后，根据最开始的Bayes展开式可得$\\hat{x_k}$ 的后验形式为： \\hat{\\boldsymbol{x}}_{k}=\\check{\\boldsymbol{x}}_{k}+\\boldsymbol{K}_{k}\\left(\\boldsymbol{z}_{k}-h\\left(\\check{\\boldsymbol{x}}_{k}\\right)\\right), \\hat{\\boldsymbol{P}}_{k}=\\left(\\boldsymbol{I}-\\boldsymbol{K}_{k} \\boldsymbol{H}\\right) \\check{\\boldsymbol{P}}_{k}其中卡尔曼增益为： \\boldsymbol{K}_{k}=\\check{\\boldsymbol{P}}_{k} \\boldsymbol{H}^{\\mathrm{T}}\\left(\\boldsymbol{H} \\check{\\boldsymbol{P}}_{k} \\boldsymbol{H}^{\\mathrm{T}}+\\boldsymbol{Q}_{k}\\right)^{-1}关于EKF的讨论主要的优点： 推导简单清楚，适用于各种传感器的形式； 易于做多传感器融合，在比较的简答的场合比较适用。 主要的缺点： 首先，一阶的马尔可夫性比较简单，假设过于强，会损失很多信息。很难进行回环检测，回环检测中主要两者看到了近似的事物就代表其存在一定的关系(共视图)。 其次，其没有误差检测机制，就是我们的不可以有outliner，如果我们在视觉里程计这边出现了一些误匹配等错误很可能导致其出现发散。 然后，具有很大的线性化误差，其不像优化算法，非线性优化时进行了多次的迭代才完成上述的操作的，而EKF就进行一次线性化的处理，无法完成相关的操作。 最后，其存储的成本过大，因为其主要保存的为均值和协方差矩阵，当路标点过多时，其协方差矩阵的维度过大。","link":"/2022/06/21/SLAM/ch9-%E5%90%8E%E7%AB%AF-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-EKF/"},{"title":"R-CNN和Fast R-CNN","text":"hljs.initHighlightingOnLoad(); 本文为目标检测的开篇，今后开始学习和了解目标检测问题，本文主要介绍目标检测的开篇之作R-CNN和Fast R-CNN但是，由于比较的老，因此这里的没有代码的复现，仅仅关注其基本的原理。最后我们介绍了关于FPN网络的内容。 目标检测的前言目标检测，又称为Object Detection 主要分为两个大的类别，One-Stage 包含SSD、YOLO；Two-Stage 包含Faster-RCNN。 对于Two-Stage来说，其主要原理是： 通过专门模块去生成候选框(RPN)，寻找前景以及调整边界框(基于achors) 基于之前生成的候选框，进行进一步的分类和调整边界框(基于proposals) 相比之下，One-Stage来说，起主要原理： 基于anchors直接进行分类以及调整边界框。 二者的比较： Faster R-CNN是一个非常基础的网络，其具有很强的学习意义。 在介绍Faster R-CNN之前，我们首先介绍其基础的几个工作，R-CNN和Fast R-CNN的。 R-CNN(Region with CNN feature) 首先，原论文中陈述的主要的计算流程为： 在一张图像中生成1K-2K个候选的区域(使用Selective Search方法)。 对每个候选的区域，使用深度网络进行提取特征。 特征送入每个类的SVM分类器，判别是否属于该类。 使用回归器精细修正候选框的位置。 主要步骤1.候选区域的生成： 利用Selective Search算法通过图像分割的方法得到一些原始区域，然后使用一些合并策略将这些区域合并，得到一个层次化的区域结构，而这些结构就包含着可能需要的物体。 2.对每个候选区域，使用深度网络提取特征 将2000候选区域缩放到227x227pixel，接着将候选区域输入事先训练好的AlexNet CNN网络获取4096维的特征得到2000×4096维矩阵。这里的网络使用PASCAL VOC dataset 预先训练好的数据集。 这里相当于batch_size为2000，并且将最后的几个全连接层给去掉了，于是就得到一个4096为的特征向量。 3.特征送入每一类的SVM分类器，判定类别将2000×4096维特征与20个SVM和一个backround组成的权值矩阵4096×20相乘,获得2000×20维矩阵表示每个建议框是某个目标类别的得分。分别对上述2000×20维矩阵中每一列即每一类进行非极大值抑制剔除重叠建议框，得到该列即该类中得分最高的一些建议框。 这里每个向量都进入相应的SVM分类器，这里每个分类器的输入为二元的，Yes or No. 为了方便理解，我们将得到的2000x4096 和 4096x20相乘，得到一个2000x20向量，其中每个行向量代表的是每个框被分到这20个类和1个背景的概率或0/1值。 针对每一列的值，其本质是一类的，于是采用非极大值抑制的方法，操作时选出预测概率值最高两项，将两项计算IoU，即一种包容关系，如果这个值大于一定的阈值就仅仅保留概率最大的那个即可。 通过非极大值抑制的方法，可以提出很多的无用的重复的框。 使用回归器精细修正候选框位置对NMS处理后剩余的建议框进一步筛选。接着分别用20个回归器对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box。 这里使用回归使其Bounding box尽可能的逼近Ground truth对应的Bounding box 。其中这里对应的参数有四个变量，框的中心点(x,y)以及框的高度和宽度(h,w). R-CNN存在的问题 测试速度慢：测试一张图片约53s(CPU)。用Selective Search算法提取候选框用时约2秒，一张图像内候选框之间存在大量重叠，提取特征操作冗余。 训练速度慢：过程及其繁琐。即CNN、SVM、regression是相互不独立的，需要分开进行训练。 训练所需空间大：对于SVM和bbox回归训练，需要从每个图像中的每个目标候选框提取特征，并写入磁盘。对于非常深的网络，如VGG16，从VOCO7训练集上的5k图像上提取的特征需要数百GB的存储空间。 Fast R-CNN主要步骤 一张图像生成1K~2K个候选区域(使用Selective Search方法)； 将图像输入网络得到相应的特征图，将SS算法生成的候选框投影到特征图上获得相应的特征矩阵； 将每个特征矩阵通过ROI pooling层缩放到7x7大小的特征图，接着将特征图展平通过一系列全连接层得到预测结果。 ROI是Region of Interest的缩写。 Fast R-CNN和R-CNN的不同点： 对于第二步：一般的R-CNN是通过SS算法选出所需的特征图，然后分别输入到特征提取的网络中得到特征向量。而我们这个Fast R-CNN是将整个图像一起输入到特征提取的网络中得到对应的特征图，之前SS得到的框也对应的向特征图上面进行投影。 对于第三步：之前的操作为单独训练分类器和边界框的回归器，现在是通过一个ROI pooling层将其缩到7x7之后直接FC。 第一步 Fast R-CNN可以避免R-CNN那样是重复识别操作，参考的SPP-Net。 这里定义正样本为对应的框中确实存在所需的内容，负样本代表框中仅仅存在一定的背景。为什么一定要存在相应的负样本，因为如果没有负样本就会造成样本不平衡，于是就很可能错把背景也当成目标了。 这里正负样本的划分方法其实就是将划分的区域和Ground truth进行对比，计算IoU值，大于0.5的设置为正样本，在0.1-0.5之间就为负样本。 第二步将上一步筛选得到的特征图输入进来通过ROI Pooling layer得到7x7的patch. 上述的图片主要是方便我们进行举例子来实现，这里仅仅画了一个channel，其他的channel同理。 第三步得到7x7的特征图之后，我们将其导入到边全连接层，这里全连接连个FC层，之后分流，一部分进入分类器，另一部分进行边界框回归器。 分类器：输出N+1个类别的概率(N为检测目标的种类，1为背景)一共N+1个节点。下面的向量是经过Softmax之后的结果，代表了每个框被分到下面的几个类别的概率，其总和为1. 边界框回归器：输出对应N+1个类别的候选边界框的回归参数$(d_x,d_y,d_w,d_h)$ ，一共(N+1)x4个节点。这里每个类别都对应4个参数。 这里是候选框的参数是确定的，$P_w,P_h,P_x,P_y$ 回归模型的训练参数是$d_w(P),d_h(P),d_x(P),d_y(P)$ . 为什么宽度和高度的拟合用的是指数函数，因为高度和宽度不可以为负数。 损失函数 这个损失函数是一个多任务的损失函数 Multi-task loss。 注意这里的回归参数的部分是$t^u$ ，是计算对应类别回归的系数。 首先，来看分类损失： L_{cls}(p,u)=-\\log p_u这里的$p_u$代表是该特征的类别为u的概率。 其中，这是类别的编码已经转换为one-hot编码$[0,0,…1,0,…0]$; 而我们预测得到的是softmax的概率值$[0.1,0.3,0.4,…,0.1]$ 之后，来看边界框的回归损失： 主要的公式为： L=\\lambda[u \\ge1]L_{loc}(t^u,v) 第一项代表的是一个加权系数，用来平衡两个损失函数； 第二项中的u是标签里给出的类别数，仅仅会对其真实的类别进行边界框的回归损失。 这里相比最初的R-CNN已经是精简了两个模块了，起主要的贡献是推理的速度大大的提高，相比原来的R-CNN提高了213倍。 但是由于其Selective Search在进行选取的时候，每张图片还是会浪费2s的时间，后面的三个也就是0.x s就可以完成。于是Faster R-CNN会在其上面进行改进。 Feature Pyramid Networks 下面来看几个典型的图像金字塔结构： a是最典型的图像金字塔结构，其在传统的图像处理里经常使用，首先将图片缩放到不同的尺度上面，之后针对每个尺度都来预测，但是这样做需要每个尺度都要重复一次效率比较低。 b是最典型的特征映射，通过卷积操作得到对应的特征图，用特征图进行预测，得到最后的预测值，但是缺点是对于比较小的目标很难是识别到。Faster R-CNN的预测流程。 c是金字塔型的结构，在卷积的各个尺度的图上分别进行预测，在SSD算法中会有使用。 d是特征图金字塔结构，其不是直接在对不同尺度的特征图进行预测操作，其主要是将不同尺度上的特征图进行融合，之后再进行预测。 1x1卷积的作用主要是来调整维度的，使得其可以正常地融合。 上采样操作的主要方法上利用邻接插值进行的。 首先，使用的$P_2 \\sim P_6$来预测候选框，之后将将预测框映射到$P_2 \\sim P_5$。 然后，使用$P_2\\sim P_5$进行Faster R-CNN操作。 这里，对于小目标的检测，我们一般会使用比较底层的特征图来进行检测。 例如，我们在$P_2$上检测$32^2$尺度的achor的信息，在$P_3$ 上面检测$64^2$尺度的信息，依次类推往下进行。 上面的操作主要是进行特征图的生成操作，对于Faster R-CNN来说，其下一步是使用RPN网络生成的候选框，然后将候选框和特征图进行分类和回归处理。 因此，FPN网络主要也是修改的特征图的生成算法，使其可以得到多尺度的信息。然后，我们就得到了多个特征图的信息，相当于有多个特征图。 实验证明共享权重的效果其实和分开训练差不多，这里为了减小参数就共享RPN和Fast CNN部分的权重。 最后，如何将生成的共享框放到对应的特征图上，这里使用了一个经验公式： k= \\lfloor k_0 + \\log_2(\\sqrt {wh}/224)\\rfloor 其中 $k_0=4$，$k$为对应的特征图的序号$P_k$，$w,h$为对应的长和宽。 具体地细节可以参考原论文。","link":"/2022/06/24/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/R-CNN%E5%92%8CFast-R-CNN/"},{"title":"语义分割前言和转置卷积与膨胀卷积","text":"hljs.initHighlightingOnLoad(); 从本文开始就启动语义分割的学习, 首先对语义分割进行大概的介绍, 其主要的分类等, 接下来就是语义分割常采用常用的转置卷积和膨胀卷积的相关的理论介绍。 语义分割前沿常见的任务分类 语义分割 (semantic segmentation) : FCN，仅仅是对每个像素进行分类，将所有飞机都用同一个颜色来分类。 实例分割 (Instance segmentation) : Mask R-CNN，对同个类别的不同的物体进行分割。 全景分割 (Panoramic segmentation) : Panoptic，不仅仅对目标分割，对背景也进行分割。将背景的蓝天、马路、白云也进行分割。 语义分割任务常见的数据集PASCAL VOC 这里分割以后的图片其实是一个单通道的图片，其像素对应的颜色是(0,0,0)的黑色，像素1对应的是(127,0,0)的深红色，像素255对应的是(224,224,129)。 这里分割的部分使用的是像素值为1的图片，其他地方使用的是像素值为0作为背景，之后的边界使用的像素值为255线条，对于左下角来说，由于其只有半个机翼，于是将其全部涂成边界的颜色。 MS COCO其主要是针对每个目标都记录了多边形坐标 (polygons) 在实际使用时需要自己读取每张图片的分割的多边形的信息，并自己在图中绘制出来。这个数据集也比较方便进行实例分割。 语义分割得到结果的具体形式 如果保存成一个单通道的灰度值会使得其颜色的差别比较小，于是这里加上调色板，同时不同的类别对应不同的颜色值。 语义分割评价指标常见的指标主要包括： Pixel Accuracy (Global Acc) ：$\\dfrac{\\sum_in_{ii}}{\\sum_it_i}$; mean Accuracy ：$\\dfrac{1}{n_{cls}}\\cdot \\sum_i \\dfrac{n_{ii}}{t_i}$ mean IoU：$\\dfrac{1}{n_{cls}}\\cdot \\sum_i \\dfrac{n_{ii}}{t_i+\\sum_jn_{ji}-n_{ii}}$ 其中，$n_{ij}$：类别 $i$ 被预测成类别 $j$ 的像素个数； $n_{cls}$ ：目标类别个数（包含背景）； $t_i=\\sum_i n_{ij}$ ：目标类别 $i$ 的总像素个数 (真实标签)； 这里的绿色的部分就是Ground truth 而蓝色是预测的部分 predict ，这里的IOU和目标检测是一样的，计算预测和实际相互交叉的面积占总的面积的比值。 Pytorch 官方的计算方法是建立了一个混淆矩阵，然后再来预测上述的指标。 IoU=真实标签 / (行总数+列总数-真实标签) cls_acc=真实标签 / 列总数 分割任务的标注工具 这个工具需要一个一个点用手来标注。 这个工具可以自动识别来进行分割，其具有一定预训练的手法，实现自动化的标注。 相关的知识补充转置卷积 其主要的作用是进行上采样操作，但是转置卷积不是转置的逆运算，仅仅是形状上变成原来的两倍，其具体的数值跟原来是不一样的。 转置卷积的步骤 在输入特征图元素间填充s-1行、s-1列的0元素； 在输入特征图四周填充k-p-1行、k-p-1列的0元素； 将卷积核参数上下、左右翻转； 做正常卷积运算(填充0，步距1)。 下面，我们以一个具体的实例来进行讲解如下。 下面为在Pytorch的实现过程，这里主要使用的是前面的几个参数， 这里 output_channel一般直接使用默认值0，不去直接使用。 其次dilation一般空洞卷积，或叫做膨胀卷积，具体内容后面会详细介绍。 卷积的计算步骤理论的计算步骤在基础的课程上已经讲的很清楚了，但是实际的计算时是不用之前理论的过程的，因为其计算比较低效，在一般情况下使用的是叫卷积核等效矩阵来进行计算。 在计算时，仅仅将输入的 feature map 分别和对应的等效矩阵相乘即可。 将输入的feature map 进行展平操作得到一个行向量： 将等效矩阵也对应的进行展平操作得到一系列的列向量： 这里相乘得到的结果其实就是卷积输出结果的展平： 上述将卷积转换成为一般的矩阵求拟的问题，其主要的原因是时方便并行化的处理操作。 通过上述的处理，可以将卷积转换成为一个矩阵的运算，但是这个过程是否可你呢？很显然这个过程时不可逆的，因为这里的矩阵$\\boldsymbol C^{16\\times 4}$不是方阵，无法进行求拟操作，因此转置卷积不能称为反卷积。 那退一步来说，如何得到一个输入为$1\\times4$ 输出为$1\\times16$ 的卷积呢？ 其实就是将我们等效矩阵转置处理即可，这里仅仅是保证形状上是相似的，但是其数值上不相等。 由于在进行等效矩阵转化时，我们的主要将每一个等效矩阵进行展平处理，将$\\boldsymbol C^{T}(4\\times16)$ 反变换得到16个$4\\times4$的等效矩阵。 这里我们使用等效卷积核和$O^{2\\times2}$进行卷积的结果和绿色卷积核与右下角的卷积运算的结果时相同的。 这里绿色的卷积核可以看成是核原来的卷积核进行上下左右反转操作 总结之前的操作如下： 膨胀卷积基本知识 膨胀卷积其实就是卷积核是存在间隙的，中间的间隙叫做膨胀因子，其主要的作用其实就是增大感受野。一般情况下是对其padding进行设置，使得其输入和输出保持不变。 对于语义分割来说，我们需要上采样和下采样，下采样一般是分类网络，在分类过程中一般加入最大池化max pooling层来进行操作的，但是其会极大的减小高宽、并且丢失一些细节信息和小目标的信息，这个无法通过上采样来恢复。 那么直接去掉max pooling，但是这样做会使得感受野减小，因为前面感受野发生变化也会影响后续网络的分类和识别。 因此使用膨胀卷积，一方面保持原来的H,W，同时可以增大感受野，因此在语义分割中比较常用。 gridding effect现象 下图就是gridding effect现象，起主要是因为这里膨胀的系数相同，导致连续的几层上面都没有利用到间隔行列上面的细节信息。 如下图所示，上面的数字代表的是这个块被用到的次数，实际进行膨胀卷积时要尽可能的避免上述信息。 参数的数量上是一样的，如果使用的是一般的卷积的话，感受野只有7x7. 如何设计膨胀系数 这里定义了最大非0元素的距离为$M_{i}$ M_{i}=\\max[M_{i+1}-2r_i,M_{i+1}-2(M_{i+1}-r_i),r_i] 其中的$M_n=r_n$，我们设计的目标是让$M_2 \\le K$。在实际求解的时候就是将通过递推，从$M_n=r_n$ 不断来推理得到$M_2$即可。 下面给出$r=[1,2,5]$和$r=[1,2,9]$的效果。 这里由递推公式可得，$M_1\\ge r_1$，如果$r_1&gt;1$时，那样的话就一定存在间隙，因此这里的$r_i$一般都要设计成1. 可以将参数设计成锯齿结构，同时公约数是不可以大于1的。 当$r=[2,4,8]$ 的时候，其预测的结果为： 以上是分割的效果对比，使用HDC设计准则的细节信息保存的很好。","link":"/2022/06/26/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%89%8D%E8%A8%80/"},{"title":"Ch9 后端 第二部分 BA方法和图优化","text":"hljs.initHighlightingOnLoad(); 本文主要承接ch6的观测问题，解决的另一种方法，现阶段使用的比EKF要高。主要包括投影模型和BA代价函数建模和求解，稀疏化和边缘化以及鲁棒核函数。代码部分之后单独列出。 所谓的 Bundle AdjustmentR(BA)，是指从视觉图像中提炼出最优的3D模型和相机参数（内参数和外参数）。 考虑从任意特征点发射出来的几束光线(bundles of light rays )，它们会在几个相机的成像平面上变成像素或是检测到的特征点。 如果我们调整（adjustment)各相机姿态和各特征点的空间位置，使得这些光线最终收束到相机的光心，就称为BA。 接下来，先来复习一下之前学习关于相机投影模型和非线性优化的知识。 投影模型和BA代价函数首先来复习投影的整个过程，从一个世界坐标系中的点p出发，把相机的内外参数和畸变都考虑进来，最后投影成像素。 把世界坐标转换成相机的坐标，这里将使用到相机的外参数($R,t$)： \\boldsymbol{P}^{\\prime}=\\boldsymbol{R} \\boldsymbol{p}+\\boldsymbol{t}=\\left[X^{\\prime}, Y^{\\prime}, Z^{\\prime}\\right]^{\\mathrm{T}} 将$\\boldsymbol P’$ 投影到归一化平面，得到归一化的坐标： \\boldsymbol{P}_{\\mathrm{c}}=\\left[u_{\\mathrm{c}}, v_{\\mathrm{c}}, 1\\right]^{\\mathrm{T}}=\\left[X^{\\prime} / Z^{\\prime}, Y^{\\prime} / Z^{\\prime}, 1\\right]^{\\mathrm{T}} 考虑归一化时坐标的畸变情况，得到去畸变前的原始像素数据坐标。这里暂时只考虑径向的畸变： \\left\\{\\begin{array}{l}u_{\\mathrm{c}}^{\\prime}=u_{\\mathrm{c}}\\left(1+k_{1} r_{\\mathrm{c}}^{2}+k_{2} r_{\\mathrm{c}}^{4}\\right) \\\\ v_{\\mathrm{c}}^{\\prime}=v_{\\mathrm{c}}\\left(1+k_{1} r_{\\mathrm{c}}^{2}+k_{2} r_{\\mathrm{c}}^{4}\\right)\\end{array}\\right. 根据内参模型，计算像素的坐标： \\left\\{\\begin{array}{l}u_{s}=f_{x} u_{\\mathrm{c}}^{\\prime}+c_{x} \\\\ v_{s}=f_{y} v_{\\mathrm{c}}^{\\prime}+c_{y}\\end{array}\\right. 将上述的表示使用一个流程图就可以形象的表示出来： 上述的过程其实就是一个观测方程 $\\boldsymbol{z}=h(\\boldsymbol{x}, \\boldsymbol{y})$。 现在我们将上述观测方程进行参数化过程，具体的有 这里的$x$ 代表的就是此时相机的位姿，即外参$R,t$ 它对应的李群为$T$ ，对于的李代数为$\\xi$ . 路标点$y$ 即这里的三维点 $p$ ，而观测数据则是像素坐标 z \\stackrel{\\text { def }}{=}\\left[u_{s}, v_{s}\\right]^{\\mathrm{T}} 。 于是，从最小二乘的角度来考虑，那么可以列写关于此观测方程的误差： \\boldsymbol{e}=\\boldsymbol{z}-h(\\boldsymbol{T}, \\boldsymbol{p})之后将其他时刻的观测量也考虑进来，给误差加入下标。设$z_{ij}$ 为在姿态$T_i$ 处观察路标$p_j$ 产生的数据，整体的代价函数为： J=\\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left\\|\\boldsymbol{e}_{i j}\\right\\|^{2}=\\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left\\|\\boldsymbol{z}_{i j}-h\\left(\\boldsymbol{T}_{i}, \\boldsymbol{p}_{j}\\right)\\right\\|^{2} 事实上BA属于批量式的优化方法； 给定很多个相机位姿与观测数据，计算最优的状态估计； 定义每个运动/观测方程的误差，并从初始估计开始寻找梯度下降。 BA的求解根据上述的公式，很明显该问题是一个非线性的优化问题，求解的主要方法也是给定初值，不断地寻找下降的方向$\\Delta x$，来确定目标函数的最优解，之后不断地求解增量方程。尽管误差项都是针对单个位姿和路标点的，在整体的BA目标函数上，自变量写成所有变量的向量的形式： \\boldsymbol{x}=\\left[\\boldsymbol{T}_{1}, \\ldots, \\boldsymbol{T}_{m}, \\boldsymbol{p}_{1}, \\ldots, \\boldsymbol{p}_{n}\\right]^{\\mathrm{T}}其对于的增量方程中的自变量应该写成向量的形式，在这个意义下，当我们的给自自变量一个增量时，其目标函数变为： \\frac{1}{2}\\|f(\\boldsymbol{x}+\\Delta \\boldsymbol{x})\\|^{2} \\approx \\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left\\|\\boldsymbol{e}_{i j}+\\boldsymbol{F}_{i j} \\Delta \\boldsymbol{\\xi}_{i}+\\boldsymbol{E}_{i j} \\Delta \\boldsymbol{p}_{j}\\right\\|^{2}其中，$F_{ij}$ 表示整个代价函数在当前状态下对相机位姿的偏导数，而$E_{ij}$ 为目标函数对位置点的偏导。于是将相机位姿变量和空间点单独写到一起可得： \\boldsymbol{x}_{\\mathrm{c}}=\\left[\\boldsymbol{\\xi}_{1}, \\boldsymbol{\\xi}_{2}, \\ldots, \\boldsymbol{\\xi}_{m}\\right]^{\\mathrm{T}} \\in \\mathbb{R}^{6 m}\\\\ \\boldsymbol{x}_{p}=\\left[\\boldsymbol{p}_{1}, \\boldsymbol{p}_{2}, \\ldots, \\boldsymbol{p}_{n}\\right]^{\\mathrm{T}} \\in \\mathbb{R}^{3 n}于是将上述表达式简化表示为： \\frac{1}{2}\\|f(\\boldsymbol{x}+\\Delta \\boldsymbol{x})\\|^{2}=\\frac{1}{2}\\left\\|\\boldsymbol{e}+\\boldsymbol{F} \\Delta \\boldsymbol{x}_{c}+\\boldsymbol{E} \\Delta \\boldsymbol{x}_{p}\\right\\|^{2} .需要注意的是，该式从一个由很多小型二次项之和，变成矩阵的形式。这里的雅可比矩阵的E和F必须是目标函数对整体变量的导数，它将一个很大的矩阵，里面进行分块。最后组合起来形成增量方程： \\boldsymbol{H} \\Delta \\boldsymbol{x}=\\boldsymbol{g}根据第六章可得，这里的$H=J^TJ/J^TJ+\\lambda I$ 的形式，其中我们将整个变量进行分类可得，$J=[F\\ \\ E].$ 这里以G-N法为例，对H矩阵进行分块： \\boldsymbol{H}=\\boldsymbol{J}^{\\mathrm{T}} \\boldsymbol{J}=\\left[\\begin{array}{ll}\\boldsymbol{F}^{\\mathrm{T}} \\boldsymbol{F} & \\boldsymbol{F}^{\\mathrm{T}} \\boldsymbol{E} \\\\ \\boldsymbol{E}^{\\mathrm{T}} \\boldsymbol{F} & \\boldsymbol{E}^{\\mathrm{T}} \\boldsymbol{E}\\end{array}\\right]不难发现，因为考虑了所有的优化变量，所以这个线性方程的维度将非常大，包含了所有的相机位姿和路标点。尤其是在视觉SLAM中，一幅图像会提出数百个特征点，大大增加了这个线性方程的规模。 如果直接对H求逆来计算增量方程，由于矩阵求逆是复杂度为O(n3)的操作，那么消耗的计算资源会非常多。 这里的H矩阵是有一定的特殊结构的： 每个观测只关系两个变量，其中一个是相机，一个是路标； 纯视觉BA中，不存在相机与相机/路标与路标之间的关联； 整个误差函数由许多个这样小的项组成。 利用变量的稀疏性，可以极大的加速运算效率。 稀疏化和边缘化考虑代价函数里的一项$e_{ij}$可得，此项仅仅和第i个相机和第j个路标有关，因此计算得到的雅可比矩阵，仅仅在第i项和第j项的位置有值其余位置都为零。 \\boldsymbol{J}_{i j}(\\boldsymbol{x})=\\left(\\mathbf{0}_{2 \\times 6}, \\ldots \\mathbf{0}_{2 \\times 6}, \\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\boldsymbol{T}_{i}}, \\boldsymbol{0}_{2 \\times 6}, \\ldots \\mathbf{0}_{2 \\times 3}, \\ldots \\boldsymbol{0}_{2 \\times 3}, \\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\boldsymbol{p}_{j}}, \\mathbf{0}_{2 \\times 3}, \\ldots \\boldsymbol{0}_{2 \\times 3}\\right)在计算这个增量方程系数H时，计算的公式如下： \\boldsymbol{H}=\\sum_{i, j} \\boldsymbol{J}_{i j}^{\\mathrm{T}} \\boldsymbol{J}_{i j}$\\boldsymbol{J}_{i j}^{\\mathrm{T}} \\boldsymbol{J}_{i j}$ 仅仅在$(i,i),(i,j),(j,j),(j,i)$处是不为0的，其余的地方都为0的稀疏矩阵。 注意，$i$ 是所有相机位姿的取值，$j$ 是所有路标点中的取值。于是我们分块可得如下的矩阵： \\boldsymbol{H}=\\left[\\begin{array}{ll}\\boldsymbol{H}_{11} & \\boldsymbol{H}_{12} \\\\ \\boldsymbol{H}_{21} & \\boldsymbol{H}_{22}\\end{array}\\right] 但是，以上的讨论是针对纯视觉的SLAM的，因为纯视觉的SLAM是没有运动方程，仅仅只有观测方程，但是如果换做是激光SLAM时，有运动方程，于是$H_{11},H_{22}$也不稀疏了。 比如，如果$x_{k}=Ax_k+b$ 时，此时就有$H_{11}$为三对角矩阵。 这里，为了方便理解我们使用了一个具体的案例： 在此场景下的BA目标函数可以写成： J=\\frac{1}{2}\\left(\\left\\|e_{11}\\right\\|^{2}+\\left\\|e_{12}\\right\\|^{2}+\\left\\|e_{13}\\right\\|^{2}+\\left\\|e_{14}\\right\\|^{2}+\\left\\|e_{23}\\right\\|^{2}+\\left\\|e_{24}\\right\\|^{2}+\\left\\|e_{25}\\right\\|^{2}+\\left\\|e_{26}\\right\\|^{2}\\right)这里的$e_{ij}$使用之前的定义，这里以$e_{11}$为例，其仅仅描述的为$C_1$和$P_1$的关系，于是$J_{11}$的表达式为： \\boldsymbol{J}_{11}=\\frac{\\partial \\boldsymbol{e}_{11}}{\\partial \\boldsymbol{x}}=\\left(\\frac{\\partial \\boldsymbol{e}_{11}}{\\partial \\boldsymbol{\\xi}_{1}}, \\mathbf{0}_{2 \\times 6}, \\frac{\\partial \\boldsymbol{e}_{11}}{\\partial \\boldsymbol{p}_{1}}, \\mathbf{0}_{2 \\times 3}, \\mathbf{0}_{2 \\times 3}, \\mathbf{0}_{2 \\times 3}, \\mathbf{0}_{2 \\times 3}, \\mathbf{0}_{2 \\times 3}\\right)这里的$x=(\\xi_1,\\xi_2,p_1,p_2,p_3,p_4,p_5,p_6)^T$ ，仅对$\\xi_1$的偏导有值，其他都为0. 由下图所示，将 $J_{ij}$ 按照一定的顺序排列可得$J$ 矩阵，进而得到了$H$ 矩阵图下图所示。 通过观察$H$矩阵可得，除去对角线元素，对于上述图结构的邻接矩阵和$H$矩阵的除对角线位置外其余部分有着完全一致的结构。其非零部分的矩阵块可以理解为两个元素之间存在联系，或称为约束。 于是可得，图结构和增量方程的稀疏性存在明显的联系。 考虑更为一般的情况，其路标点的个数是远大于相机的姿态的，因此$H$矩阵的形状比较类似于箭头的形状。 接下来，我们将利用$H$的特殊结构来进行增量方程 $Hx=g$ 的求解。 加速的手段为Schur消元，又称为边缘化(Marglinalization)。 如图所示将矩阵进行分块可得上述4个块$\\boldsymbol {B,E,E^T,C}$ 。于是我们可以将增量方程 $Hx=g$ 转化成为： \\left[\\begin{array}{ll}\\boldsymbol{B} & \\boldsymbol{E} \\\\ \\boldsymbol{E}^{\\mathrm{T}} & \\boldsymbol{C}\\end{array}\\right]\\left[\\begin{array}{l}\\Delta \\boldsymbol{x}_{\\mathrm{c}} \\\\ \\Delta \\boldsymbol{x}_{p}\\end{array}\\right]=\\left[\\begin{array}{l}\\boldsymbol{v} \\\\ \\boldsymbol{w}\\end{array}\\right] B，C：都是对角块，但是B的维度小，C的维度大。 E和E转置：与图模型对应，可稠密。 因为对角块的求拟比较简单，于是就将C进行类似高斯消元处理，消去右上角的矩阵块可得： \\left[\\begin{array}{cc}\\boldsymbol{I} & -\\boldsymbol{E} \\boldsymbol{C}^{-1} \\\\ \\mathbf{0} & \\boldsymbol{I}\\end{array}\\right]\\left[\\begin{array}{cc}\\boldsymbol{B} & \\boldsymbol{E} \\\\ \\boldsymbol{E}^{\\mathrm{T}} & \\boldsymbol{C}\\end{array}\\right]\\left[\\begin{array}{l}\\Delta \\boldsymbol{x}_{\\mathrm{c}} \\\\ \\Delta \\boldsymbol{x}_{p}\\end{array}\\right]=\\left[\\begin{array}{cc}\\boldsymbol{I} & -\\boldsymbol{E} \\boldsymbol{C}^{-1} \\\\ \\boldsymbol{0} & \\boldsymbol{I}\\end{array}\\right]\\left[\\begin{array}{l}\\boldsymbol{v} \\\\ \\boldsymbol{w}\\end{array}\\right]进一步简化可得： \\left[\\begin{array}{cc}\\boldsymbol{B}-\\boldsymbol{E} \\boldsymbol{C}^{-1} \\boldsymbol{E}^{\\mathrm{T}} & \\mathbf{0} \\\\ \\boldsymbol{E}^{\\mathrm{T}} & \\boldsymbol{C}\\end{array}\\right]\\left[\\begin{array}{c}\\Delta \\boldsymbol{x}_{\\mathrm{c}} \\\\ \\Delta \\boldsymbol{x}_{p}\\end{array}\\right]=\\left[\\begin{array}{c}\\boldsymbol{v}-\\boldsymbol{E} \\boldsymbol{C}^{-1} \\boldsymbol{w} \\\\ \\boldsymbol{w}\\end{array}\\right]消元之后，第一行和 $\\Delta x_p$ 是无关的，因此我们使用单独取出后可得姿态部分的增量方程为： \\left[\\boldsymbol{B}-\\boldsymbol{E} \\boldsymbol{C}^{-1} \\boldsymbol{E}^{\\mathrm{T}}\\right] \\Delta \\boldsymbol{x}_{\\mathrm{c}}=\\boldsymbol{v}-\\boldsymbol{E} \\boldsymbol{C}^{-1} \\boldsymbol{w}该方程的求解可以分成两部分： 求解上半部分，规模比较小，于是得到 $\\Delta x_c$ ； 然后将其结果带入到下半部分，得出$\\Delta \\boldsymbol{x}_{p}=\\boldsymbol{C}^{-1}\\left(\\boldsymbol{w}-\\boldsymbol{E}^{\\mathrm{T}} \\Delta \\boldsymbol{x}_{\\mathrm{c}}\\right)$ 这里主要是利用了对角阵$C$ 的逆比较容易求解的特点，而且整个的计算量主要几种在求解第一个增量方程的部分，其中我们记$S=\\boldsymbol{B}-\\boldsymbol{E} \\boldsymbol{C}^{-1} \\boldsymbol{E}^{\\mathrm{T}}$ ，如图所示S矩阵不一定具有很强的稀疏性了。 上述做法称为Marginalization或Schur消元： 从消元角度来讲，亦可使用Cholesky等其他消元方式解此稀疏方程； 从Marginalization角度来讲，是我们把所有的路标信息边缘化到了相机的信息中。 这部分消元的部分又叫Schur补。 对边缘化的理解： 根据以下联合分布个条件分布、边缘分布的关系有： P\\left(\\boldsymbol{x}_{\\mathrm{c}}, \\boldsymbol{x}_{p}\\right)=P\\left(\\boldsymbol{x}_{\\mathrm{c}} \\mid \\boldsymbol{x}_{p}\\right) P\\left(\\boldsymbol{x}_{p}\\right)使用概率的思路理解就是，首先是固定$\\Delta x_p$ 来求解$\\Delta x_c$ 可以看作是已知的联合和边缘，求解条件概率$P\\left(\\boldsymbol{x}_{\\mathrm{c}} \\mid \\boldsymbol{x}_{p}\\right)$ 【这里我的理解为求解的$\\Delta x_c$的过程对于的是求得概率$P\\left(\\boldsymbol{x}_{\\mathrm{c}} \\mid \\boldsymbol{x}_{p}\\right)$ 】，之后反过来在求解$P\\left(\\boldsymbol{x}_{p}\\right)$【对于的求解$ \\Delta x_p$的过程】 。 对于EKF来讲，其前面的所有的进行也是被边缘化到最近的一个状态上面，即我们根据已知来计算 $P(\\boldsymbol x_k|\\boldsymbol x_{k-1},\\boldsymbol x_{k-2},…,\\boldsymbol z_{k-1},…)$ 。 这个过程也叫作高斯推论。 通常情况下的Marg操作会给H矩阵带来填充（fill-in），使其不再具有稀疏结构； 所以，要么刻意选择特定的marg策略，要么仅使用稠密的H求解线性方程，但这样效率会降低。 这里比较难以理解，之后看到相关的教程在仔细思考。 之前分析了H稀疏性的物理意义，现在我来分析以下这个S矩阵的物理意义。 这里S矩阵的维度和相机的维度相同，每个行列都对应一个相机。于是有对于S矩阵的非零项代表是两个相机变量之间存在共同观测的路标点，有时称为共视。 鲁棒核函数主要考察的是优化的目标函数，当面对误匹配的项时，此项本来就是错的，造成了很大的误差，在进行梯度优化时，其会将本来正确的项也改错了。 出现上述问题的主要原因为：当误差很大时，其二范数的增长很快。于是主要的解决办法就是将误差的二范数换成一个增长没那么快的函数，同时也要保证自己的可导性和光滑性，使得整体的优化效果更加稳健，这样的核函数叫做Robust Kernel。 Robust Kernel鲁棒核函数的种类有很多，其中最常用的当属Huber核函数。 H(e)=\\left\\{\\begin{array}{ll}\\frac{1}{2} e^{2} & \\text { 当 }|e| \\leqslant \\delta, \\\\ \\delta\\left(|e|-\\frac{1}{2} \\delta\\right) & \\text { 其他 }\\end{array}\\right.当误差的增长达到一定的阈值后，其增长曲线由原来的二次变成了一次，相当于限制了最大的梯度值，同时也保证了原来的光滑性，方便求导。 还有很多核函数，如Cauchy核函数，Yukey核函数等等。 这里时间部分的代码比较多，之后会单独出一讲来介绍使用Ceres和G2O来解决BA问题。","link":"/2022/06/26/SLAM/ch9-%E5%90%8E%E7%AB%AF-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-BA%E6%96%B9%E6%B3%95/"},{"title":"Ch10 后端 第三部分 位置图和滑动窗口","text":"hljs.initHighlightingOnLoad(); 上一讲主要介绍BA图优化算法，但是可以精确地优化出每个相机的位姿和特征点的位置。不过在更大的场景中其计算的效率会大大的降低。导致计算量越来越大，以至于无法实现实时化的要求，本文主要介绍两种常用的方法，滑动窗口法和位姿图法。 滑动窗口实际环境下的BA结构带有相机位姿和空间点的图优化称为BA问题，它们能够有效地大规模的定位和建图。在SFM里是十分的重要的，但是对于SLAM里，我们往往是需要控制BA的规模，否则无法保证实时性。因此在SFM里和有效的方法，在SLAM里不见得有效。 控制规模的方法有很多，比如在连续的视频里提取出一部分作为关键帧，仅仅构造关键帧和路标点之间的BA，于是非关键帧只用于定位，对建图则没有影响。随着时间的推移，关键帧逐渐的增加，地图的规模扩张，BA算法的计算效率会大大的降低。因此，解决的主要的问题变成了如何更好的控制规模。 最简单的思路，仅保留离当前时刻最近的N个关键点，去掉更早时刻的关键点，该方法就是滑动窗口法的雏形。 这里不一定非要去时间上靠近，也可考虑在在时间上靠近，并且空间上可以展开的关键帧，防止相机停止运动后出现退化的现象。 进一步考虑，如ORB-SLAM2上面的，定义了共视图的结构，仅考虑和当前的视图有20个以上共视路标的关键帧，其余固定不变，这样在共视关系构造准确时，可以更长时间保证最优。 共视图：和当前相机存在共同观测的关键帧组成的图。 下面详细介绍关于滑动窗口法的主要实现。 滑动窗口法现在考虑一个滑动窗口，假设窗口内有N个关键帧，于是位姿可以表示为：$\\boldsymbol x_1,\\boldsymbol x_2,\\cdots,\\boldsymbol x_N$ ,这里假设其在向量空间，使用李代数来表达。 这里我们主要关注的是关键帧的位置和不确定度，其对应的是高斯分布的均值和协方差矩阵。 同时这几个关键帧和滑动窗口的路标点$\\boldsymbol y_1,\\boldsymbol y_2,\\cdots,\\boldsymbol y_M$ 一起构成了一个局部地图。这里可以使用上一章的BA方法来处理。主要包括构建图优化模型、构建Hessian矩阵、边缘化路标点来加速： \\left[\\boldsymbol{x}_{1}, \\ldots, \\boldsymbol{x}_{N}\\right]^{\\mathrm{T}} \\sim N\\left(\\left[\\boldsymbol{\\mu}_{1}, \\ldots, \\boldsymbol{\\mu}_{N}\\right]^{\\mathrm{T}}, \\boldsymbol{\\Sigma}\\right)其中，$\\mu_k$代表第k个关键帧位姿的均值，$\\Sigma$为所有关键帧的协方差矩阵。 这里的均值部分为BA优化之后的结果，而协方差为整个BA的H矩阵进行边缘化的结果，即S矩阵。 在滑动窗口中，当窗口结构发生改变，这些状态变量应该如何变化？这件事情可以分成两部分讨论： 我们需要在窗口中新增一个关键帧，以及它观测到的路标点。 我们需要把窗口中一个旧的关键帧删除，也可能删除它观测到的路标点。 新增一个关键帧和路标点考虑在上个时刻，滑动窗口已经建立了N个关键帧，我们也已知道它们服从某个高斯分布,其均值和方差如前所述。此时，新来了一个关键帧$\\boldsymbol x_N$，那么整个问题中的变量变为 N＋1 个关键帧和更多路标点的集合。这实际上仍是平凡的，我们只需按照正常的BA流程处理即可。对所有点进行边缘化时，即得到这N＋1个关键帧的高斯分布参数。 删除一个就的关键帧在考虑删除旧的关键帧时，就会出现一个理论问题，就是要删除的关键帧并不是孤立的，其会和其他关键帧一起观察到相同的路标点。即其边缘化势必会造成矩阵不在稀疏。 在这个例子中，我们假设看到了路标点$\\boldsymbol y_1$至$\\boldsymbol y_4$，于是，在处理之前，BA问题的Hessian矩阵应该像图10-2中的左图一样,在$\\boldsymbol x_1$行的$\\boldsymbol y_1$到$\\boldsymbol y_4$列存在着非零块表示$\\boldsymbol x_1$看到了它们。 考虑边缘化$\\boldsymbol x_1$，那么Schur消元过程相当于通过矩阵行和列操作消去非对角线处几个非零矩阵块，显然这将导致右下角的路标点矩阵块不再是非对角矩阵，这个过程称为边缘化中的填入(Fill-in) 。 之前ch9是考虑到关键帧的数量会比路标点小很多，于是将路标点边缘化了先求解出我们的位姿，此时的填入发生在左上角的位子矩阵上。 但是，删除关键帧时，我们优化的时窗口，于是将关键帧进行边缘化，这样对右下角的路标点部分造成破坏。之前稀疏加速的方法无法继续使用，因此在早期的EKF后端时无法处理大规模的滑动窗口的。 不过，如果我们对边缘化的过程进行一些改造，也可以保持滑动窗口BA的稀疏性。 例如，在边缘化某个旧的关键帧时，同时边缘化它观测到的路标点。这样，路标点的信息就会转换成剩下那些关键帧之间的共视信息，从而保持右下角部分的对角块结构。 例如，在OKVIS 中，我们会判断要边缘化的那个关键帧，它看到的路标点是否在最新的关键帧中仍能看到。 如果不能，就直接边缘化这个路标点； 如果能，就丢弃被边缘化关键帧对这个路标点的观测，从而保持BA的稀疏性。 SWF中边缘化的直观解释边缘化在概率上的意义就是指条件概率。 当我们边缘化某个关键帧，即“保持这个关键帧当前的估计值，求其他状态变量以这个关键帧为条件的条件概率”。 当某个关键帧被边缘化，它观测到的路标点就会产生一个“这些路标应该在哪里”的先验信息，从而影响其余部分的估计值。如果再边缘化这些路标点，那么它们的观测者将得到一个“观测它们的关键帧应该在哪里”的先验信息。 从数学的角度上来看，其边缘化某些帧的过程，其实可以看成是从联合分布到条件分布。 p\\left(\\boldsymbol{x}_{1}, \\ldots \\boldsymbol{x}_{4}, \\boldsymbol{y}_{1}, \\ldots \\boldsymbol{y}_{6}\\right)=p\\left(\\boldsymbol{x}_{2}, \\ldots, \\boldsymbol{x}_{4}, \\boldsymbol{y}_{1}, \\ldots \\boldsymbol{y}_{6} \\mid \\boldsymbol{x}_{1}\\right) \\underbrace{p\\left(\\boldsymbol{x}_{1}\\right)}_{\\text {舍去 }} .然后舍去被边缘化部分的信息。在变量被边缘化之后，我们在工程中就不应再使用它。所以滑动窗口法比较适合VO系统，而不适合大规模建图的系统。 位姿图位姿图的主要意义根据之前的讨论可得，特征点在优化的问题上占据了绝大多数的问题，经过若干次观测时候，收敛的点变化很小，而发散的点已经被剔除了，于是对收敛的点已知进行优化似乎有点费力不讨好的感觉。 因此我们倾向于将特征点进行固定，仅仅来优化位姿，将特张点看作是位姿之间的约束。 这样的思路可以应用在多传感器融合的问题上，比如轮速传感器和GPS的数据就可以将其也像特征点那样，仅仅将其作为约束考虑。 这里，对于BA来说，其特征点的数量远远大于位姿节点。一个关键帧往往关联了上百个关键点，就算利用稀疏性，其求解的规模也过于大，单靠CPU也很难计算，于是SLAM的应用场景就被大大的限制住了。主要的解决方法有两种： 一种是使用滑动窗口，舍去一些历史数据； 另一种是位姿图，舍去对路标的优化。 位姿图的优化现在进行位姿图优化，首先要明确的是位姿图的节点和边是什么。 节点：表示相机的位姿，以 $\\boldsymbol T_1,\\boldsymbol T_2,\\cdots,\\boldsymbol T_n$ 来表示。 边：两个位姿节点之间相对的位姿节点估计。 这里我们假设来估计 $\\boldsymbol T_i$ 和 $\\boldsymbol T_j$ 之前的运动为$\\boldsymbol \\Delta T_{ij}$ ,其可以有若干种表达的方式，主要的方式有以下两种： \\Delta \\boldsymbol{\\xi}_{i j}= \\boldsymbol{\\xi}_{i}^{-1} \\circ \\boldsymbol{\\xi}_{j}=\\ln \\left(\\exp \\left(\\left(-\\boldsymbol{\\xi}_{i}\\right)^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\xi}_{j}^{\\wedge}\\right)\\right)^{\\vee} \\\\ \\boldsymbol{\\Delta} \\boldsymbol{T}_{i j}=\\boldsymbol{T}_{i}^{-1} \\boldsymbol{T}_{j} \\\\按照图优化的思路上述的等式一般是不会很好的满足上述的恒等的关系的，我们优化的目标是想要让其尽可能地相等。 这里我们使用最小二乘误差，然后讨论误差关于优化变量的导数，于是构建$e_{ij}$ 的表达式如下： \\begin{aligned} \\boldsymbol{e}_{i j}&= \\ln \\left(\\Delta \\boldsymbol{T}_{i j}^{-1} \\boldsymbol{T}_{i}^{-1} \\boldsymbol{T}_{j}\\right)^{\\vee} \\\\ &=\\ln \\left(\\exp \\left(\\left(-\\boldsymbol{\\xi}_{i j}\\right)^{\\wedge}\\right) \\exp \\left(\\left(-\\boldsymbol{\\xi}_{i}\\right)^{\\wedge}\\right) \\exp \\left(\\boldsymbol{\\xi}_{j}^{\\wedge}\\right)\\right)^{\\vee} . \\end{aligned}注意在位姿图中，优化的变量有两个$\\boldsymbol \\xi_i$ 和 $\\boldsymbol \\xi_j$ ，是个二元函数求导，首先是一起给$\\boldsymbol \\xi_i$ 和 $\\boldsymbol \\xi_j$ 一个左扰动，可得： \\hat{\\boldsymbol{e}}_{i j}=\\ln \\left(\\boldsymbol{T}_{i j}^{-1} \\boldsymbol{T}_{i}^{-1} \\exp \\left(\\left(-\\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}\\right)^{\\wedge}\\right) \\exp \\left(\\delta \\boldsymbol{\\xi}_{j}^{\\wedge}\\right) \\boldsymbol{T}_{j}\\right)^{\\vee}这里扰动项被移动到式子的中间，为了利用上BCH近似，需要将其以到式子的左端或者右端，回顾第四讲的伴随性质可得： \\exp \\left((\\operatorname{Ad}(\\boldsymbol{T}) \\boldsymbol{\\xi})^{\\wedge}\\right)=\\boldsymbol{T} \\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{T}^{-1}\\\\\\exp \\left(\\boldsymbol{\\xi}^{\\wedge}\\right) \\boldsymbol{T}=\\boldsymbol{T} \\exp \\left(\\left(\\operatorname{Ad}\\left(\\boldsymbol{T}^{-1}\\right) \\boldsymbol{\\xi}\\right)^{\\wedge}\\right)这里，通过引入扰动项，我们可以很好的将扰动项向着左右侧进行交换，于是 将其带入到误差表达式可得： \\begin{aligned} \\hat{e}_{i j} &=\\ln \\left(\\boldsymbol{T}_{i j}^{-1} \\boldsymbol{T}_{i}^{-1} \\exp \\left(\\left(-\\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}\\right)^{\\wedge}\\right) \\exp \\left(\\delta \\boldsymbol{\\xi}_{j}^{\\wedge}\\right) \\boldsymbol{T}_{j}\\right)^{\\vee} \\\\ &=\\ln \\left(\\boldsymbol{T}_{i j}^{-1} \\boldsymbol{T}_{i}^{-1} \\boldsymbol{T}_{j} \\exp \\left(\\left(-\\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}\\right)^{\\wedge}\\right) \\exp \\left(\\left(\\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{j}\\right)^{\\wedge}\\right)^{\\vee}\\right.\\\\ & \\approx \\ln \\left(\\boldsymbol{T}_{i j}^{-1} \\boldsymbol{T}_{i}^{-1} \\boldsymbol{T}_{j}\\left[\\boldsymbol{I}-\\left(\\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}\\right)^{\\wedge}+\\left(\\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{j}\\right)^{\\wedge}\\right]\\right)^{\\vee} \\\\ & \\approx e_{i j}+\\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\delta \\xi_{i}} \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}+\\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\delta \\boldsymbol{\\xi}_{j}} \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{j} \\end{aligned}按照李代数上的求导法则，我们求出了误差关于两个位姿的Jacobi矩阵： \\begin{aligned} \\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{i}} &=-\\mathcal{J}_{r}^{-1}\\left(\\boldsymbol{e}_{i j}\\right) \\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\\\ \\frac{\\partial \\boldsymbol{e}_{i j}}{\\partial \\boldsymbol{\\delta} \\boldsymbol{\\xi}_{j}} &=\\mathcal{J}_{r}^{-1}\\left(\\boldsymbol{e}_{i j}\\right) \\operatorname{Ad}\\left(\\boldsymbol{T}_{j}^{-1}\\right) \\end{aligned}对于$\\mathscr {se}(3)$ 左右雅可比的$\\boldsymbol {\\mathcal J}_r$的形式会过于复杂，其通常我们仅仅取一定的近似即可，注意上述近似成立的要求是在$e_{ij}$不是很大的时候。 \\boldsymbol {\\mathcal{J}}_{r}^{-1}\\left(e_{i j}\\right) \\approx \\boldsymbol I+\\frac{1}{2}\\left[\\begin{array}{cc}\\phi_{e}^{\\wedge} & \\rho_{e}^{\\wedge} \\\\ 0 & \\phi_{e}^{\\wedge}\\end{array}\\right]上述问题本质上就是一个最小二乘问题，其优化的变量为各个顶点的位姿，边来自于位姿观测的约束，这里记 $\\mathcal E$ 为所有边的集合 ： \\min \\frac{1}{2} \\sum_{i, j \\in \\mathcal{E}} \\boldsymbol{e}_{i j}^{\\mathrm{T}} \\boldsymbol{\\Sigma}_{i j}^{-1} \\boldsymbol{e}_{i j}实践部分本节主要介绍的是使用G2O来解决位姿图的优化问题，首先来配置CMakeList.txt文件如下： 12345678910111213141516171819202122232425262728293031cmake_minimum_required(VERSION 2.8)project(pose_graph)set(CMAKE_BUILD_TYPE &quot;Release&quot;)set(CMAKE_CXX_FLAGS &quot;-std=c++11 -O2&quot;)list(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake_modules)# Eigeninclude_directories(&quot;/usr/include/eigen3&quot;)# sophus find_package(Sophus REQUIRED)include_directories(${Sophus_INCLUDE_DIRS})# g2o find_package(G2O REQUIRED)include_directories(${G2O_INCLUDE_DIRS})add_executable(pose_graph_g2o_SE3 pose_graph_g2o_SE3.cpp)target_link_libraries(pose_graph_g2o_SE3 g2o_core g2o_stuff g2o_types_slam3d ${CHOLMOD_LIBRARIES} )add_executable(pose_graph_g2o_lie pose_graph_g2o_lie_algebra.cpp)target_link_libraries(pose_graph_g2o_lie g2o_core g2o_stuff ${CHOLMOD_LIBRARIES} ${Sophus_LIBRARIES} Sophus::Sophus ) Sophus::Sophus 原来的文件因为缺少这一个而编译报错，加上这一句就可以正常运行了。 之后，本文解决的主要的问题是通过优化来解出一个螺线上升的球的轨迹，我们在螺旋上升的球上面加入了一些噪声可以得出以下的轨迹。 通过下面的程序优化之后就可以得到去除噪声的程序如下所示。 g2o原生的位姿优化这里优化的方法由两种，一种是使用g2o自带的方法来实现，其主要程序为pose_graph_g2o_SE3.cpp 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;g2o/types/slam3d/types_slam3d.h&gt;#include &lt;g2o/core/block_solver.h&gt;#include &lt;g2o/core/optimization_algorithm_levenberg.h&gt;#include &lt;g2o/solvers/eigen/linear_solver_eigen.h&gt;using namespace std;/************************************************ * 本程序演示如何用g2o solver进行位姿图优化 * sphere.g2o是人工生成的一个Pose graph，我们来优化它。 * 尽管可以直接通过load函数读取整个图，但我们还是自己来实现读取代码，以期获得更深刻的理解 * 这里使用g2o/types/slam3d/中的SE3表示位姿，它实质上是四元数而非李代数. * **********************************************/int main(int argc, char **argv) { if (argc != 2) { cout &lt;&lt; &quot;Usage: pose_graph_g2o_SE3 sphere.g2o&quot; &lt;&lt; endl; return 1; } ifstream fin(argv[1]); if (!fin) { cout &lt;&lt; &quot;file &quot; &lt;&lt; argv[1] &lt;&lt; &quot; does not exist.&quot; &lt;&lt; endl; return 1; } // 设定g2o typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;6, 6&gt;&gt; BlockSolverType; typedef g2o::LinearSolverEigen&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; auto solver = new g2o::OptimizationAlgorithmLevenberg( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;())); g2o::SparseOptimizer optimizer; // 图模型 optimizer.setAlgorithm(solver); // 设置求解器 optimizer.setVerbose(true); // 打开调试输出 int vertexCnt = 0, edgeCnt = 0; // 顶点和边的数量 while (!fin.eof()) { string name; fin &gt;&gt; name; if (name == &quot;VERTEX_SE3:QUAT&quot;) { // SE3 顶点 g2o::VertexSE3 *v = new g2o::VertexSE3(); int index = 0; fin &gt;&gt; index; v-&gt;setId(index); v-&gt;read(fin); optimizer.addVertex(v); vertexCnt++; if (index == 0) v-&gt;setFixed(true); } else if (name == &quot;EDGE_SE3:QUAT&quot;) { // SE3-SE3 边 g2o::EdgeSE3 *e = new g2o::EdgeSE3(); int idx1, idx2; // 关联的两个顶点 fin &gt;&gt; idx1 &gt;&gt; idx2; e-&gt;setId(edgeCnt++); e-&gt;setVertex(0, optimizer.vertices()[idx1]); e-&gt;setVertex(1, optimizer.vertices()[idx2]); e-&gt;read(fin); optimizer.addEdge(e); } if (!fin.good()) break; } cout &lt;&lt; &quot;read total &quot; &lt;&lt; vertexCnt &lt;&lt; &quot; vertices, &quot; &lt;&lt; edgeCnt &lt;&lt; &quot; edges.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;optimizing ...&quot; &lt;&lt; endl; optimizer.initializeOptimization(); optimizer.optimize(30); cout &lt;&lt; &quot;saving optimization results ...&quot; &lt;&lt; endl; optimizer.save(&quot;result.g2o&quot;); return 0;} 李代数上的位姿优化另一种方法是使用李代数来自己写需要优化的边和点，自己写雅可比矩阵等，其主要的程序为pose_graph_g2o_lie_algebra.cpp，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;Eigen/Core&gt;#include &lt;g2o/core/base_vertex.h&gt;#include &lt;g2o/core/base_binary_edge.h&gt;#include &lt;g2o/core/block_solver.h&gt;#include &lt;g2o/core/optimization_algorithm_levenberg.h&gt;#include &lt;g2o/solvers/eigen/linear_solver_eigen.h&gt;#include &lt;sophus/se3.hpp&gt;using namespace std;using namespace Eigen;using Sophus::SE3d;using Sophus::SO3d;/************************************************ * 本程序演示如何用g2o solver进行位姿图优化 * sphere.g2o是人工生成的一个Pose graph，我们来优化它。 * 尽管可以直接通过load函数读取整个图，但我们还是自己来实现读取代码，以期获得更深刻的理解 * 本节使用李代数表达位姿图，节点和边的方式为自定义 * **********************************************/typedef Matrix&lt;double, 6, 6&gt; Matrix6d;// 给定误差求J_R^{-1}的近似Matrix6d JRInv(const SE3d &amp;e) { Matrix6d J; J.block(0, 0, 3, 3) = SO3d::hat(e.so3().log()); J.block(0, 3, 3, 3) = SO3d::hat(e.translation()); J.block(3, 0, 3, 3) = Matrix3d::Zero(3, 3); J.block(3, 3, 3, 3) = SO3d::hat(e.so3().log()); // J = J * 0.5 + Matrix6d::Identity(); J = Matrix6d::Identity(); // try Identity if you want return J;}// 李代数顶点typedef Matrix&lt;double, 6, 1&gt; Vector6d;class VertexSE3LieAlgebra : public g2o::BaseVertex&lt;6, SE3d&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW virtual bool read(istream &amp;is) override { double data[7]; for (int i = 0; i &lt; 7; i++) is &gt;&gt; data[i]; setEstimate(SE3d( Quaterniond(data[6], data[3], data[4], data[5]), Vector3d(data[0], data[1], data[2]) )); } virtual bool write(ostream &amp;os) const override { os &lt;&lt; id() &lt;&lt; &quot; &quot;; Quaterniond q = _estimate.unit_quaternion(); os &lt;&lt; _estimate.translation().transpose() &lt;&lt; &quot; &quot;; os &lt;&lt; q.coeffs()[0] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[1] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[2] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[3] &lt;&lt; endl; return true; } virtual void setToOriginImpl() override { _estimate = SE3d(); } // 左乘更新 virtual void oplusImpl(const double *update) override { Vector6d upd; upd &lt;&lt; update[0], update[1], update[2], update[3], update[4], update[5]; _estimate = SE3d::exp(upd) * _estimate; }};// 两个李代数节点之边class EdgeSE3LieAlgebra : public g2o::BaseBinaryEdge&lt;6, SE3d, VertexSE3LieAlgebra, VertexSE3LieAlgebra&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW virtual bool read(istream &amp;is) override { double data[7]; for (int i = 0; i &lt; 7; i++) is &gt;&gt; data[i]; Quaterniond q(data[6], data[3], data[4], data[5]); q.normalize(); setMeasurement(SE3d(q, Vector3d(data[0], data[1], data[2]))); for (int i = 0; i &lt; information().rows() &amp;&amp; is.good(); i++) for (int j = i; j &lt; information().cols() &amp;&amp; is.good(); j++) { is &gt;&gt; information()(i, j); if (i != j) information()(j, i) = information()(i, j); } return true; } virtual bool write(ostream &amp;os) const override { VertexSE3LieAlgebra *v1 = static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[0]); VertexSE3LieAlgebra *v2 = static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[1]); os &lt;&lt; v1-&gt;id() &lt;&lt; &quot; &quot; &lt;&lt; v2-&gt;id() &lt;&lt; &quot; &quot;; SE3d m = _measurement; Eigen::Quaterniond q = m.unit_quaternion(); os &lt;&lt; m.translation().transpose() &lt;&lt; &quot; &quot;; os &lt;&lt; q.coeffs()[0] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[1] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[2] &lt;&lt; &quot; &quot; &lt;&lt; q.coeffs()[3] &lt;&lt; &quot; &quot;; // information matrix for (int i = 0; i &lt; information().rows(); i++) for (int j = i; j &lt; information().cols(); j++) { os &lt;&lt; information()(i, j) &lt;&lt; &quot; &quot;; } os &lt;&lt; endl; return true; } // 误差计算与书中推导一致 virtual void computeError() override { SE3d v1 = (static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[0]))-&gt;estimate(); SE3d v2 = (static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[1]))-&gt;estimate(); _error = (_measurement.inverse() * v1.inverse() * v2).log(); } // 雅可比计算 virtual void linearizeOplus() override { SE3d v1 = (static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[0]))-&gt;estimate(); SE3d v2 = (static_cast&lt;VertexSE3LieAlgebra *&gt; (_vertices[1]))-&gt;estimate(); Matrix6d J = JRInv(SE3d::exp(_error)); // 尝试把J近似为I？ _jacobianOplusXi = -J * v2.inverse().Adj(); _jacobianOplusXj = J * v2.inverse().Adj(); }};int main(int argc, char **argv) { if (argc != 2) { cout &lt;&lt; &quot;Usage: pose_graph_g2o_SE3_lie sphere.g2o&quot; &lt;&lt; endl; return 1; } ifstream fin(argv[1]); if (!fin) { cout &lt;&lt; &quot;file &quot; &lt;&lt; argv[1] &lt;&lt; &quot; does not exist.&quot; &lt;&lt; endl; return 1; } // 设定g2o typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;6, 6&gt;&gt; BlockSolverType; typedef g2o::LinearSolverEigen&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; auto solver = new g2o::OptimizationAlgorithmLevenberg( g2o::make_unique&lt;BlockSolverType&gt;(g2o::make_unique&lt;LinearSolverType&gt;())); g2o::SparseOptimizer optimizer; // 图模型 optimizer.setAlgorithm(solver); // 设置求解器 optimizer.setVerbose(true); // 打开调试输出 int vertexCnt = 0, edgeCnt = 0; // 顶点和边的数量 vector&lt;VertexSE3LieAlgebra *&gt; vectices; vector&lt;EdgeSE3LieAlgebra *&gt; edges; while (!fin.eof()) { string name; fin &gt;&gt; name; if (name == &quot;VERTEX_SE3:QUAT&quot;) { // 顶点 VertexSE3LieAlgebra *v = new VertexSE3LieAlgebra(); int index = 0; fin &gt;&gt; index; v-&gt;setId(index); v-&gt;read(fin); optimizer.addVertex(v); vertexCnt++; vectices.push_back(v); if (index == 0) v-&gt;setFixed(true); } else if (name == &quot;EDGE_SE3:QUAT&quot;) { // SE3-SE3 边 EdgeSE3LieAlgebra *e = new EdgeSE3LieAlgebra(); int idx1, idx2; // 关联的两个顶点 fin &gt;&gt; idx1 &gt;&gt; idx2; e-&gt;setId(edgeCnt++); e-&gt;setVertex(0, optimizer.vertices()[idx1]); e-&gt;setVertex(1, optimizer.vertices()[idx2]); e-&gt;read(fin); optimizer.addEdge(e); edges.push_back(e); } if (!fin.good()) break; } cout &lt;&lt; &quot;read total &quot; &lt;&lt; vertexCnt &lt;&lt; &quot; vertices, &quot; &lt;&lt; edgeCnt &lt;&lt; &quot; edges.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;optimizing ...&quot; &lt;&lt; endl; optimizer.initializeOptimization(); optimizer.optimize(30); cout &lt;&lt; &quot;saving optimization results ...&quot; &lt;&lt; endl; // 因为用了自定义顶点且没有向g2o注册，这里保存自己来实现 // 伪装成 SE3 顶点和边，让 g2o_viewer 可以认出 ofstream fout(&quot;result_lie.g2o&quot;); for (VertexSE3LieAlgebra *v:vectices) { fout &lt;&lt; &quot;VERTEX_SE3:QUAT &quot;; v-&gt;write(fout); } for (EdgeSE3LieAlgebra *e:edges) { fout &lt;&lt; &quot;EDGE_SE3:QUAT &quot;; e-&gt;write(fout); } fout.close(); return 0;} 数据其中的sphere.g2o文件里面记录的是上述螺旋球轨迹的代码，其中对于节点即位姿的表示使用的是节点ID、四元数和平移向量$q_x,q_y,q_z,q_w,t_x,t_y,t_z$ ，而对于边来说，其只要的表示为两个节点的ID、四元数、平移向量和信息矩阵(协方差矩阵)，具体的显示如下所示： 1234567VERTEX_SE3:QUAT 2496 0.693766 85.4427 -76.1338 0.762427 -0.0510961 -0.61895 -0.181645 VERTEX_SE3:QUAT 2497 0.796386 85.3713 -76.1324 0.769185 -0.00858573 -0.622899 -0.142402 VERTEX_SE3:QUAT 2498 0.911804 85.3343 -76.0976 0.776067 0.0278687 -0.621979 -0.10043 VERTEX_SE3:QUAT 2499 1.0318 85.323 -76.0615 0.779315 0.0718127 -0.620437 -0.0506864 EDGE_SE3:QUAT 0 1 -0.0187953 0.0328449 -0.125146 0.0634648 -0.000250128 0.00237634 0.997981 10000 0 0 0 0 0 10000 0 0 0 0 10000 0 0 0 40000 0 0 40000 0 40000 EDGE_SE3:QUAT 1 2 -0.00836587 0.0518559 -0.141405 0.0636098 -0.000538 0.00162238 0.997973 10000 0 0 0 0 0 10000 0 0 0 0 10000 0 0 0 40000 0 0 40000 0 40000 EDGE_SE3:QUAT 2 3 0.0116518 0.0646362 -0.123843 0.0628369 0.0060981 -0.00213561 0.998003 10000 0 0 0 0 0 10000 0 0 0 0 10000 0 0 0 40000 0 0 40000 0 40000","link":"/2022/06/26/SLAM/ch10-%E5%90%8E%E7%AB%AF-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-%E4%BD%8D%E7%BD%AE%E5%9B%BE%E5%92%8C%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"title":"Ch11 回环检测","text":"hljs.initHighlightingOnLoad(); 本文简单的入门了一下回环检测，主要的内容包括词袋模型、字典、相似度的计算、以及计算相似度的实验和构建词典的的实验。当先只要使用的构建字典的方法是基于聚类的方法。 概述回环检测的意义 VO和后端都存在误差； SLAM的建图和定位是耦合的，因此误差会不断地进行累计，上一步姿态估计的误差会积累到下一步。 特别地，对于单目相机而言，其误差主要包括三个部分，$R,t,S$(即scale). 在单目相机会有一个初始化的过程，这个初始化其实就是将平移向量 $\\boldsymbol t$ 进行归一化操作。 这里由于存在累计的误差，因此在过程中 $\\boldsymbol t$ 可能会不断地变大和缩小，这里我们就假设过程中其scale可能会不断地缩小，于是得出其估计的深度就在不断地变化。 尤其在出现转弯之后就会出现因为平移向量估计的累计误差而造成的scale减小的情况。 回环检测本质上就是将原来的位姿的基础上加了一个约束，之前相机之间的位姿估计是通过BA来进行的，回环检测相当于一个时间更加久远的约束。 总结： 一方面，回环检测主要是估计轨迹和地图在长时间的正确性问题。 另一方面，回环检测建立了历史数据和当前的关联，我们可以利用回环检测进行重定位。 回环检测的主要方法主要的步骤是： 检测到回环的发生； 计算回环候选帧和当前帧的运动； 这里是通过将候选帧的3D和当前帧的2D进行一个PnP来估计出相对的位姿变换的约束。主要的方法由两种： 将这个约束放入到pose graph中； 将其作为约束放入到一个全局的BA中。 验证回环检测是否成立； 闭环。 但是，问题是如何验证是否发生了回环： 最容易让人想到的方法就是直接从所有的图片中任意选择两个进行比对即可，但是这样做的计算复杂度比较的高为$O(n^2)$，但是这样会极大的增加计算量。 因此我们可以使用中随机取样的方法，来控制运算的规模，但是随着样本数量的增加，其运算的规模不断地扩大，于是取样会非常的盲目，取到的相似点的概率会比较小。 基于里程计的方法：先大概看一下里程计上面的估计的轨迹，如果比较相近那么就是进行回环检测。但是在如果运动的范围比较大，那么可能会由于累计误差而导致其相差的很远，不知到需不需要进行误差检测。 基于外观的方法： 直接看图像，计算相似度。 外观方法是主流方法； 核心在于衡量图像间的相似性，来一个新的图像，和历史图像进行相似性比较。 一个朴素的方法就是计算两个图片之间的灰度值之差，$S(A,B)=||A-B||$ 但是这种方法对光照和姿态不是很鲁棒，容易因为前后关照的变化或者相机位置的变换而产生巨大的误差。 因此这里引入了感知偏差(Perceptual Aliasing)和感知变异(Perceptual Variability) 准确率和召回率 这里将上述的四种情况将进行缩写成为 TP、FP、FN、TN。 这里将假阳性FP称为感知偏差，将假阴性FN称为感知变异。 于是得出两个重要的统计量准确率和召回率： Precision=\\dfrac {TP}{TP+FP},\\ Recall=\\dfrac{TP}{TP+FN} 通常情况下，上述的两个统计指标是相互矛盾的。 当我们将阈值提高时，算法会变得比较的严格，于是就会出现Precision很高的情况。由于检出率减小，原来一些回环的点可能会减小，于是就会有Recall变小的情况。 当阈值降低时，算法变得比较的宽松，于是被检测出的回环点的数量会增加，导致Recall增加，但是检测出来的点里面混入了很多的不是回环的假阳性的情况，导致准确率下降。 这里将准确率和召回率画到一个图像上面可得ROC曲线，当用召回率为横轴，用准确率为纵轴时，我们会关心整条曲线偏向右上方的程度、100%准确率下的召回率或者50%召回率时的准确率，作为评价算法的指标。不过请注意，除了一些“天壤之别”的算法，我们通常不能一概而论地说算法A就是优于算法B的。我们可能会说A在准确率较高时还有很好的召回率，而B在70%召回率的情况下还能保证较好的准确率，诸如此类。 但是在SLAM问题中，对一般的准确性比较的看重，因为一张不准确的图片很可能破环BA优化的目标，造成建图失效。 词袋模型词袋,也就是 Bag-of-Words (BoW)，目的是用“图像上有哪几种特征”来描述一幅图像。 例如，我们说某张照片中有一个人、一辆车；而另一张中有两个人、一只狗根据这样的描述,就可以度量这两幅图像的相似性。再具体一些，我们要做以下三步： 确定人、车、狗”等概念——对应于BoW中的“单词”( Word )，许多单词放在一起,组成了“字典”（Dictionary )。 确定一幅图像中出现了哪些在字典中定义的概念——我们用单词出现的情况(或直方图)描述整幅图像。这就把一幅图像转换成了一个向量的描述。 比较上一步中的描述的相似程度。 以上面举的例子来说，首先我们通过某种方式得到了一本“字典”。字典上记录了许多单词，每个单词都有一定意义，例如人、车、狗都是化求在字典中的平判，找个从$\\omega_1、\\omega_2、\\omega_3$。然后，对于任意图像A,根据它们含有的单词，可记为： A=1\\cdot \\omega_1+1\\cdot \\omega_2+0\\cdot \\omega_3字典是固定的的，此时将可以图片转换称为一个向量。这个向量主要是记录了word的有无，而忽略了特征的真实位置。这样做就比之前使用灰度计算更加鲁棒，可以防止相机姿态变换造成的相似度下降的情况。 于是相似度的计算公式可以作： s(a,b)=1-\\frac 1 {\\text{W}}||a-b||_1其中$a,b$为两个图片对应的向量。 字典这里字典的生成类似于一个聚类(Clustering)的问题，在无监督学习中比较的常见，其中K-means聚类是一个比较的简单有效的算法。 这里字典建立的步骤，首先在提取图像上N个特征点，在利用K-means聚类来来得出需要的k类。 K-means算法的主要优点是其比较简单有效，但是缺点是需要指定聚类的数量、同时由于随机选取点使得每次聚类的结果都是不同的，并且算法的效率不是很高。 将k个类提取出来以后，我们需要对字典进行排序操作，为了减小遍历的时间需要设计一种方便查找的数据结构，这里使用的是K-d tree ，如下图所示。 k-d tree：k分枝树，d层，即总共$k^d$个Word，需要最多d次比较，其对应的复杂度为$O(kd)$，这里$n=k^d$此时是对数级别的复杂度。 相似度的计算下面给定字典，获取图片里对应的Word之后，就可以进行相似度的计算了。但是，这里每个Word的作用并非是一样的，需要就是对其进行一定的加权处理。那么这里引入Term Frequency-Inverse Document Frequency，简写为TF-IDF，来进行权重的计算： TF的思想：某单词在图像中的中经常出现，其区分度就越大。TF部分则需要对图像的特征进行计算。 IDF的思想：某单词在字典中出现的概率越低，其在分类图片的区分度就越大。IDF部分可在字典训练过程中计算。 考虑权重以后，对于某幅图像A，它的特征点可对应到许多个单词，组成它的BoW： A=\\{(\\omega_1,\\eta_1),(\\omega_2,\\eta_2),\\cdots,(\\omega_N,\\eta_N)\\}由于相似的特征可能落到同一个类中，因此实际的$v_A$中会存在大量的零。无论如何，通过词袋我们用单个向量vA描述了一幅图像A。这个向量$v_A$是一个稀疏的向量，它的非零部分指示了图像A中含有哪些单词,而这些部分的值为TF-IDF 的值。 实验和讨论相似性的评价，这里评价相似性是会直接根据相似性的计算公式来计算，但是其值的绝对的大小并不能很好的解决实际的问题，一般使用的是相对值。 考虑到这种情况，我们会取一个先验相似度$s(v_t,v_{t-\\Delta t})$，它表示某时刻关键帧图像与上一时刻的关键帧的相似性。然后，其他的分值都参照这个值进行归一化： s(v_t,v_{t_j})'=s(v_t,v_{t_j})/s(v_t,v_{t-\\Delta t})站在这个角度上，如果当前帧与之前某关键帧的相似度超过当前帧与上一个关键帧相似度的3倍，就认为可能存在回环。这个步骤避免了引入绝对的相似性阈值，使得算法能够适应更多的环境。 就是前面几帧很高，之后的几帧慢慢的下降就是代表可能出现的回环，或者之前比较小，之后慢慢的上升，但是出现突变不代表其出现了回环检测。 由于词袋模型自身的问题，会导致出现感知偏差，将一些产生一些真阴性的结果，此时需要一定的验证的手段，这里主要的方法有两个： 一个方法是设立回环的缓存机制，认为单次检测到的回环并不足以构成良好的约束，而在一段时间中一直检测到的回环，才是正确的回环。这可以看成时间上的一致性检测。 另一个方法是空间上的一致性检测，即对回环检测到的两个帧进行特征匹配，估计相机的运动。然后，把运动放到之前的位姿图中，检查与之前的估计是否有很大的出入。 实践首先导入对应的CMakeList.txt文件如下： 1234567891011121314151617181920212223cmake_minimum_required( VERSION 2.8 )project( loop_closure )set( CMAKE_BUILD_TYPE &quot;Release&quot; )set( CMAKE_CXX_FLAGS &quot;-std=c++11 -O3&quot; )# opencv find_package( OpenCV REQUIRED )include_directories( ${OpenCV_INCLUDE_DIRS} )# dbow3 # dbow3 is a simple lib so I assume you installed it in default directory set( DBoW3_INCLUDE_DIRS &quot;/usr/local/include&quot; )set( DBoW3_LIBS &quot;/usr/local/lib/libDBoW3.so&quot; )add_executable( feature_training feature_training.cpp )target_link_libraries( feature_training ${OpenCV_LIBS} ${DBoW3_LIBS} )add_executable( loop_closure loop_closure.cpp )target_link_libraries( loop_closure ${OpenCV_LIBS} ${DBoW3_LIBS} )add_executable( gen_vocab gen_vocab_large.cpp )target_link_libraries( gen_vocab ${OpenCV_LIBS} ${DBoW3_LIBS} ) 注意这里主要的问题为将原来的set( DBoW3_LIBS &quot;/usr/local/lib/libDBoW3.a&quot; )改成set( DBoW3_LIBS &quot;/usr/local/lib/libDBoW3.so&quot; ) 下面首先进行读取图片中的特征点和描述子来构造极字典，这里主要读取图片的ORB特征。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &quot;DBoW3/DBoW3.h&quot;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace cv;using namespace std;/*************************************************** * 本节演示了如何根据data/目录下的十张图训练字典 * ************************************************/int main( int argc, char** argv ) { // read the image cout&lt;&lt;&quot;reading images... &quot;&lt;&lt;endl; vector&lt;Mat&gt; images; for ( int i=0; i&lt;10; i++ ) { // string path = &quot;./data&quot;+to_string(i+1)+&quot;.png&quot;; string path = &quot;../data/1.png&quot;; images.push_back( imread(path) ); } // detect ORB features cout&lt;&lt;&quot;detecting ORB features ... &quot;&lt;&lt;endl; Ptr&lt; Feature2D &gt; detector = ORB::create(); vector&lt;Mat&gt; descriptors; for ( Mat&amp; image:images ) { vector&lt;KeyPoint&gt; keypoints; Mat descriptor; detector-&gt;detectAndCompute( image, Mat(), keypoints, descriptor ); descriptors.push_back( descriptor ); } // create vocabulary cout&lt;&lt;&quot;creating vocabulary ... &quot;&lt;&lt;endl; DBoW3::Vocabulary vocab; vocab.create( descriptors ); cout&lt;&lt;&quot;vocabulary info: &quot;&lt;&lt;vocab&lt;&lt;endl; vocab.save( &quot;vocabulary.yml.gz&quot; ); cout&lt;&lt;&quot;done&quot;&lt;&lt;endl; return 0;} 注意路径的读取的位置，是否正确。 对于只有十张图片训练出来的字典来说，但是可能不够用，因此我们需要更大规模的字典，以下是训练的主要的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &quot;DBoW3/DBoW3.h&quot;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace cv;using namespace std;int main( int argc, char** argv ){ string dataset_dir = argv[1]; ifstream fin ( dataset_dir+&quot;/associate.txt&quot; ); if ( !fin ) { cout&lt;&lt;&quot;please generate the associate file called associate.txt!&quot;&lt;&lt;endl; return 1; } vector&lt;string&gt; rgb_files, depth_files; vector&lt;double&gt; rgb_times, depth_times; while ( !fin.eof() ) { string rgb_time, rgb_file, depth_time, depth_file; fin&gt;&gt;rgb_time&gt;&gt;rgb_file&gt;&gt;depth_time&gt;&gt;depth_file; rgb_times.push_back ( atof ( rgb_time.c_str() ) ); depth_times.push_back ( atof ( depth_time.c_str() ) ); rgb_files.push_back ( dataset_dir+&quot;/&quot;+rgb_file ); depth_files.push_back ( dataset_dir+&quot;/&quot;+depth_file ); if ( fin.good() == false ) break; } fin.close(); cout&lt;&lt;&quot;generating features ... &quot;&lt;&lt;endl; vector&lt;Mat&gt; descriptors; Ptr&lt; Feature2D &gt; detector = ORB::create(); int index = 1; for ( string rgb_file:rgb_files ) { Mat image = imread(rgb_file); vector&lt;KeyPoint&gt; keypoints; Mat descriptor; detector-&gt;detectAndCompute( image, Mat(), keypoints, descriptor ); descriptors.push_back( descriptor ); cout&lt;&lt;&quot;extracting features from image &quot; &lt;&lt; index++ &lt;&lt;endl; } cout&lt;&lt;&quot;extract total &quot;&lt;&lt;descriptors.size()*500&lt;&lt;&quot; features.&quot;&lt;&lt;endl; // create vocabulary cout&lt;&lt;&quot;creating vocabulary, please wait ... &quot;&lt;&lt;endl; DBoW3::Vocabulary vocab; vocab.create( descriptors ); cout&lt;&lt;&quot;vocabulary info: &quot;&lt;&lt;vocab&lt;&lt;endl; vocab.save( &quot;vocab_larger.yml.gz&quot; ); cout&lt;&lt;&quot;done&quot;&lt;&lt;endl; return 0;} 之后是通过之前构建的字典来计算相似度，首先我们之前10张图片创建的字典vocabulary.yml.gz，之后再读取2900张图片创建的字典vocab_larger.yml.gz但是读取这个字典可能要花费大量的时间。其主要的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &quot;DBoW3/DBoW3.h&quot;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace cv;using namespace std;/*************************************************** * 本节演示了如何根据前面训练的字典计算相似性评分 * ************************************************/int main(int argc, char **argv) { // read the images and database cout &lt;&lt; &quot;reading database&quot; &lt;&lt; endl; // DBoW3::Vocabulary vocab(&quot;./vocabulary.yml.gz&quot;); DBoW3::Vocabulary vocab(&quot;../vocab_larger.yml.gz&quot;); // use large vocab if you want: if (vocab.empty()) { cerr &lt;&lt; &quot;Vocabulary does not exist.&quot; &lt;&lt; endl; return 1; } cout &lt;&lt; &quot;reading images... &quot; &lt;&lt; endl; vector&lt;Mat&gt; images; for (int i = 0; i &lt; 10; i++) { string path = &quot;../data/&quot; + to_string(i + 1) + &quot;.png&quot;; images.push_back(imread(path)); } // NOTE: in this case we are comparing images with a vocabulary generated by themselves, this may lead to overfit. // detect ORB features cout &lt;&lt; &quot;detecting ORB features ... &quot; &lt;&lt; endl; Ptr&lt;Feature2D&gt; detector = ORB::create(); vector&lt;Mat&gt; descriptors; for (Mat &amp;image:images) { vector&lt;KeyPoint&gt; keypoints; Mat descriptor; detector-&gt;detectAndCompute(image, Mat(), keypoints, descriptor); descriptors.push_back(descriptor); } // we can compare the images directly or we can compare one image to a database // images : cout &lt;&lt; &quot;comparing images with images &quot; &lt;&lt; endl; for (int i = 0; i &lt; images.size(); i++) { DBoW3::BowVector v1; vocab.transform(descriptors[i], v1); for (int j = i; j &lt; images.size(); j++) { DBoW3::BowVector v2; vocab.transform(descriptors[j], v2); double score = vocab.score(v1, v2); cout &lt;&lt; &quot;image &quot; &lt;&lt; i &lt;&lt; &quot; vs image &quot; &lt;&lt; j &lt;&lt; &quot; : &quot; &lt;&lt; score &lt;&lt; endl; } cout &lt;&lt; endl; } // or with database cout &lt;&lt; &quot;comparing images with database &quot; &lt;&lt; endl; DBoW3::Database db(vocab, false, 0); for (int i = 0; i &lt; descriptors.size(); i++) db.add(descriptors[i]); cout &lt;&lt; &quot;database info: &quot; &lt;&lt; db &lt;&lt; endl; for (int i = 0; i &lt; descriptors.size(); i++) { DBoW3::QueryResults ret; db.query(descriptors[i], ret, 4); // max result=4 cout &lt;&lt; &quot;searching for image &quot; &lt;&lt; i &lt;&lt; &quot; returns &quot; &lt;&lt; ret &lt;&lt; endl &lt;&lt; endl; } cout &lt;&lt; &quot;done.&quot; &lt;&lt; endl;}","link":"/2022/06/29/SLAM/ch11-%E5%9B%9E%E7%8E%AF%E6%A3%80%E6%B5%8B/"},{"title":"Ch12 建图 第一部分 立体视觉建图","text":"hljs.initHighlightingOnLoad(); 本文首先介绍了一下建图的主要任务，本章建图和之前不同，之前使用的滤波器或是BA方法主要是基于关键帧的稀疏地图，本章建的主要是稠密地图。本文于是就基于移动的单目相机进行立体视觉的建图，其中使用的主要特征提取方法是极线搜索和块匹配计算相似度NCC的值，之后进行高斯分布深度滤波来估计当前帧的深度。 概述在之前视觉里程计和BA优化部分，我们主要关注的是关键点即路标点和相机的位置，此时建立的一个简答的稀疏的地图，其主要是满足一些简单的定位的操作，但是对于一些复杂的应用来说，比如导航和避障的问题就是比较的稀疏地图是无法满足要求的。下面列举不同的应用对于的需求： 定位。定位是地图的一项基本功能。在前面的视觉里程计部分，我们讨论了如何利用局部地图实现定位。在回环检测部分，我们也看到，只要有全局的描述子信息，我们也能通过回环检测确定机器人的位置。我们还希望能够把地图保存下来，让机器人在下次开机后依然能在地图中定位，这样只需对地图进行一次建模，而不是每次启动机器人都重新做一次完整的SLAM。 导航。导航是指机器人能够在地图中进行路径规划，在任意两个地图点间寻找路径，然后控制自己运动到目标点的过程。在该过程中，我们至少需要知道地图中哪些地方不可通过，而哪些地方是可以通过的。这就超出了稀疏特征点地图的能力范围，必须有另外的地图形式。稍后我们会说,这至少得是一种稠密的地图。 避障。避障也是机器人经常碰到的一个问题。它与导航类似，但更注重局部的、动态的障碍物的处理。同样，仅有特征点，我们无法判断某个特征点是否为障碍物，所以需要稠密地图。 重建。有时，我们希望利用SLAM获得周围环境的重建效果。这种地图主要用于向人展示，所以希望它看上去比较舒服、美观。或者，我们也可以把该地图用于通信，使其他人能够远程观看我们重建得到的三维物体或场景——例如三维的视频通话或者网上购物等。这种地图亦是稠密的，并且还对它的外观有一些要求。我们可能不满足于稠密点云重建,更希望能够构建带纹理的平面，就像电子游戏中的三维场景那样。 交互。交互主要指人与地图之间的互动。例如，在增强现实中，我们会在房间里放置虚拟的物体，并与这些虚拟物体之间有一些互动——例如我们会点击墙面上放着的虚拟网页浏览器来观看视频,或者向墙面投掷物体,希望它们有（虚拟的)物理碰撞。另外，机器人应用中也会有与人、与地图之间的交互。例如，机器人可能会收到命令“取桌子上的报纸”,那么,除了有环境地图,机器人还需要知道哪-块地图是“桌子”，什么叫作“之上”，什么叫作“报纸”。这就需要机器人对地图有更高层面的认知——也称为语义地图。 这里随着应用的不断增加，其对于地图的需求也在不断地变化，从最简单的稀疏地图，到建立稠密地图来满足对应的导航、避障，再到在稠密地图的基础上增加问题信息来满足三维重建的要求，最后为了满足三维交互的要求，给地图加入了一定的语义信息。 本章将主要围绕着稠密地图和加入纹理的方面进行介绍讨论。 单目稠密重建立体视觉视觉SLAM的稠密重建问题是本讲的第一个重要话题。相机，被认为是只有角度的传感器( Bearing only)。单幅图像中的像素，只能提供物体与相机成像平面的角度及物体采集到的亮度，而无法提供物体的距离(Range )。而在稠密重建中，我们需要知道每一个像素点（或大部分像素点）的距离,对此大致上有如下解决方案: 使用单目相机，估计相机运动，并且三角化计算像素的距离。 使用双目相机，利用左右目的视差计算像素的距离（多目原理相同)。 使用RGB-D相机直接获得像素距离。 其中，前面的两种方法被称为是立体视觉，其中移动单目相机的又被称为移动视角的立体视觉。相比RGBD相机，前面的计算量比较大，而且对应的精度也比较低，但是RGBD相机在室外大的场景下的使用的效果也不是很好，在室外还是通过立体视觉的方法。 这里，类比之前稀疏建图的方式，回顾之前特征点部分的过程： 对图像提取特征，并根据描述子计算特征之间的匹配。换言之，通过特征，我们对某一个空间点进行了跟踪,知道了它在各个图像之间的位置。 由于无法仅用一幅图像确定特征点的位置，所以必须通过不同视角下的观测估计它的深度，原理即前面讲过的三角测量。 而对于稠密的建图来说，其是将每个像素都作为特征点来计算的描述子，因此其匹配采用的是极线搜索和快匹配技术。而且确定深度是也是采用多次使用三角测量直至其估计收敛。这就是深度滤波技术。 极线搜索和块匹配首先，我们来明确一下极线和块匹配的含义： 如图所示，左边的相机观测到了某个像素p。由于这是一个单目相机，无从知道它的深度，所以假设这个深度可能在某个区域之内，不妨说是某最小值到无穷远之间$(d_{min},+\\infty)$。因此，该像素对应的空间点就分布在某条线段（本例中是射线)上。从另一个视角(右侧相机看)这条线段的投影也形成图像平面上的一条线，我们知道这称为极线。 但是如何确定极线上面的那个$p_2$才是和$p_1$匹配的那个，才是的情况是没有描述子，我们只能分别计算极线上的点和$p_1$的相似度。 一种直观的想法是：既然单个像素的亮度没有区分性，是否可以比较像素块呢?我们在周围取一个大小为 $\\omega \\times \\omega$ 的小块,然后在极线上也取很多同样大小的小块进行比较，就可以在定程度上提高区分性。这就是所谓的块匹配。在这个过程中，只有假设在不同图像间整个小块的灰度值不变，这种比较才有意义。所以算法的假设，从像素的灰度不变性变成了图像块的灰度不变性——在一定程度上变得更强了。 现在将取$p_1$周围的小块，并且在极线上也对应的去了很多小块，这里记$p_1$旁边的小块为$\\boldsymbol A \\in \\mathbb R^{\\omega \\times \\omega}$ ，这里将极线上面的小块$\\boldsymbol B_i,i=1,..,n$ 。下面是不同的计算方法： SAD (Sum of Absolute Difference) 即为绝对值之差： S(\\boldsymbol{A}, \\boldsymbol{B})_{\\mathrm{SAD}}=\\sum_{i, j}|\\boldsymbol{A}(i, j)-\\boldsymbol{B}(i, j)| SSD。平方和损失的意思： S(\\boldsymbol{A}, \\boldsymbol{B})_{\\mathrm{SSD}}=\\sum_{i, j}(\\boldsymbol{A}(i, j)-\\boldsymbol{B}(i, j))^2 NCC。(Normalized Cross Correlation) 归一化互相关，这种方式比前两种要复杂，它计算的是两个小块的互相关性： S(\\boldsymbol{A}, \\boldsymbol{B})_{\\mathrm{NCC}}=\\frac{\\sum_{i, j} \\boldsymbol{A}(i, j) \\boldsymbol{B}(i, j)}{\\sqrt{\\sum_{i, j} \\boldsymbol{A}(i, j)^{2} \\sum_{i, j} \\boldsymbol{B}(i, j)^{2}}} 和我们遇到过的许多情形一样，这些计算方式往往存在一个精度–效率之间的矛盾。精度好的方法往往需要复杂的计算，而简单的快速算法又往往效果不佳。这需要我们在实际工程中进行取舍。另外，除了这些简单版本，我们可以先把每个小块的均值去掉，称为去均值的SSD、去均值的 NCC，等等。去掉均值之后，允许像“小块B比A整体上亮一些，但仍然很相似”这样的情况”，因此比之前的更可靠。 这里的相似度分布函数是一个非凸的函数，存在很多的峰值，然而仅仅一个点是真实的情况。于是我们倾向于使用概率分布来描述深度的分布值，问题也就转化成为对不同的图片进行极线搜索，估计深度分布将会发生怎样的变化，即所谓的深度滤波器。 高斯分布的深度滤波器这里对像素进行深度估计其实可以看作是一个状态估计的问题，其中可以使用一般的非线性优化方法，或者是使用滤波的方法，考虑到其他部分比较耗费计算，因此这里选择使用滤波方法。 设某个像素值的深度值d满足：$P(d)=N(\\mu,\\sigma^2)$。 每次进来一个新的数据，我们就会观测到其深度，同样其观测也为高斯分布：$P(d_{obs})=N(\\mu_{obs},\\sigma_{obs}^2)$。 这里适应观测到的深度值来更新d的分布值： \\mu_{\\mathrm{fuse}}=\\frac{\\sigma_{\\mathrm{obs}}^{2} \\mu+\\sigma^{2} \\mu_{\\mathrm{obs}}}{\\sigma^{2}+\\sigma_{\\mathrm{obs}}^{2}}, \\quad \\sigma_{\\text {fuse }}^{2}=\\frac{\\sigma^{2} \\sigma_{\\mathrm{obs}}^{2}}{\\sigma^{2}+\\sigma_{\\mathrm{obs}}^{2}}由于我们仅仅只有一个观测方程，而没有运动方程，所以这里仅仅使用数据融合部分，不需要进行预测和更新。 下面，介绍的是如何观测$\\mu_{obs},\\sigma_{obs^2}$ . 这是一个典型的几何问题，我们列写出这些向量之间的几何关系： \\begin{aligned} \\boldsymbol{a} &=\\boldsymbol{p}-\\boldsymbol{t} \\\\ \\alpha &=\\arccos \\langle\\boldsymbol{p}, \\boldsymbol{t}\\rangle \\\\ \\beta &=\\arccos \\langle\\boldsymbol{a},-\\boldsymbol{t}\\rangle . \\end{aligned}这里对$p_2$扰动一个像素，使得$\\beta$ 产生一个变化量，成为$\\beta ‘$。根据几何关系有： \\begin{aligned} \\beta^{\\prime} &=\\arccos \\left\\langle\\boldsymbol{O}_{2} \\boldsymbol{p}_{2}^{\\prime},-\\boldsymbol{t}\\right\\rangle \\\\ \\gamma &=\\pi-\\alpha-\\beta^{\\prime} \\end{aligned}于是由正弦定理可得： \\left\\|\\boldsymbol{p}^{\\prime}\\right\\|=\\|\\boldsymbol{t}\\| \\frac{\\sin \\beta^{\\prime}}{\\sin \\gamma}我们确定了由单个像素的不确定引起的深度不确定性，如果假设其仅仅由一个像素的误差，于是有 \\sigma_{\\mathrm{obs}}=\\|\\boldsymbol{p}\\|-\\left\\|\\boldsymbol{p}^{\\prime}\\right\\|当然，如果极线搜索的不确定性大于一个像素，则我们可按照此推导放大这个不确定性。接下来的深度数据融合已经在前面介绍过了。在实际工程中，当不确定性小于一定阈值时，就可以认为深度数据已经收敛了。综上所述，我们给出了估计稠密深度的一个完整的过程： 具体的代码比较的多，不再复现，以下是实验的具体结果。 实验中存在的问题像素梯度的问题当我们进行快匹配时，如果对应的图像比较的平滑，其梯度和纹理比较的弱时，就会造成匹配的过程容易出现误匹配。 这里牵涉一个问题，该问题在直接法中已经见过一次。在进行块匹配（和NCC的计算）时，我们必须假设小块不变，然后将该小块与其他小块进行对比。这时，有明显梯度的小块将具有良好的区分度，不易引起误匹配。对于梯度不明显的像素，由于在块匹配时没有区分性，将难以有效地估计其深度。反之，像素梯度比较明显的地方，我们得到的深度信息也相对准确，例如桌面上的杂志、电话等具有明显纹理的物体。因此，演示程序反映了立体视觉中一个非常常见的问题：对物体纹理的依赖性。该问题在双目视觉中也极其常见，体现了立体视觉的重建质量十分依赖于环境纹理。我们的演示程序刻意使用了纹理较好的环境，例如，像棋盘格一般的地板,带有木纹的桌面，等等，因此能得到一个看似不错的结果。然而在实际中，像墙面、光滑物体表面等亮度均匀的地方将经常出现，影响我们对它的深度估计。从某种角度来说，该问题是无法在现有的算法流程上加以改进并解决的——如果我们依然只关心某个像素周围的邻域(小块）的话。 总是就是在弱纹理的情况下，块匹配时无法进行的。 在实际中，梯度与极线的情况很可能介于二者之间：既不是完全垂直也不是完全平行。这时，我们说，当像素梯度与极线夹角较大时，极线匹配的不确定性大;而当夹角较小时，匹配的不确定性变小。 逆深度这里主要时有对坐标点参数化的问题来进行引入。 首先，对于一个坐标点一般其使用世界坐标系下的$(x,y,z)$来进行描述，一般认为三个点都是随机(高斯)分布的。 然而，在本节的案例中其主要是通过的相机上的坐标$(u,v)$和对应像素处的深度值来表示的。通常认为坐标参数是个常值，而深度值$d$是一个一维的高斯分布。 虽然表示的是同一个量，但是结果确实不一样的，因此这里的坐标值$(x,y,z)$一定具有一定的相关性，即其协方差矩阵的非对角元素是不为0的。对应$(u,v),d$来说，其像素坐标和深度也是近似独立的情况，甚至也可以假设两个像素坐标也是独立的。 逆深度(Inverse depth)是近年来SLAM研究中出现的一种广泛使用的参数化技巧。在演示程序中，我们假设深度值满足高斯分布。然而这样做合不合理呢？深度真的近似于一个高斯分布吗?仔细想想，深度的正态分布确实存在一些问题: 我们实际想表达的是：这个场景深度大概是5~10米，可能有一些更远的点，但近处肯定不会小于相机焦距（或认为深度不会小于0)。这个分布并不是像高斯分布那样，形成一个对称的形状。它的尾部可能稍长，而负数区域则为零。 在一些室外应用中，可能存在距离非常远，乃至无穷远处的点。我们的初始值中难以涵盖这些点，并且用高斯分布描述它们会有一些数值计算上的困难。 于是，逆深度应运而生。人们在仿真中发现，假设深度的倒数，也就是逆深度,为高斯分布是比较有效的。随后，在实际应用中，逆深度也具有更好的数值稳定性，从而逐渐成为一种通用的技巧，存在于现有SLAM方案中的标准做法中。 图像间的坐标变换问题在进行块匹配之前，进行一次图像变换时非常常见的预处理方式，因此我们一般假设小块在相机运动时是保持不变的，但是这仅仅在平移时成立，在一般的相机发生旋转变换时就不成立了。 为防止运动对匹配的干扰，这里将在块匹配之前进行运动变换，消除运动带来的影响。把参考帧与当前帧之间的运动考虑进来，根据相机模型，参考帧上的一个像素$P_c$与真实的三维点世界坐标$P_w$有以下关系: d_{\\mathrm{R}} \\boldsymbol{P}_{\\mathrm{R}}=\\boldsymbol{K}\\left(\\boldsymbol{R}_{\\mathrm{RW}} \\boldsymbol{P}_{\\mathrm{W}}+\\boldsymbol{t}_{\\mathrm{RW}}\\right) .类似地，对于当前帧,亦有$P_w$在它上边的投影，记作$P_c$： d_{\\mathrm{C}} \\boldsymbol{P}_{\\mathrm{C}}=\\boldsymbol{K}\\left(\\boldsymbol{R}_{\\mathrm{CW}} \\boldsymbol{P}_{\\mathrm{W}}+\\boldsymbol{t}_{\\mathrm{CW}}\\right) .代入并消去$P_w$，即得两幅图像之间的像素关系： d_{\\mathrm{C}} \\boldsymbol{P}_{\\mathrm{C}}=d_{\\mathrm{R}} \\boldsymbol{K} \\boldsymbol{R}_{\\mathrm{CW}} \\boldsymbol{R}_{\\mathrm{RW}}^{\\mathrm{T}} \\boldsymbol{K}^{-1} \\boldsymbol{P}_{\\mathrm{R}}+\\boldsymbol{K} \\boldsymbol{t}_{\\mathrm{CW}}-\\boldsymbol{K} \\boldsymbol{R}_{\\mathrm{CW}} \\boldsymbol{R}_{\\mathrm{RW}}^{\\mathrm{T}} \\boldsymbol{K} \\boldsymbol{t}_{\\mathrm{RW}}当知道d,PR时，可以计算出P的投影位置。此时，再给P两个分量各一个增量$du,dv$ ,就可以求得$P$的增量$du_c,dv_c$。通过这种方式，算出在局部范围内参考帧和当前帧图像坐标变换的一个线性关系构成仿射变换： \\left[\\begin{array}{l}\\mathrm{d} u_{\\mathrm{c}} \\\\ \\mathrm{d} v_{\\mathrm{c}}\\end{array}\\right]=\\left[\\begin{array}{ll}\\dfrac{\\mathrm{d} u_{\\mathrm{c}}}{\\mathrm{d} u} & \\dfrac{\\mathrm{d} u_{\\mathrm{c}}}{\\mathrm{d} v} \\\\ \\dfrac{\\mathrm{d} v_{\\mathrm{c}}}{\\mathrm{d} u} & \\dfrac{\\mathrm{d} v_{\\mathrm{c}}}{\\mathrm{d} v}\\end{array}\\right]\\left[\\begin{array}{l}\\mathrm{d} u \\\\ \\mathrm{~d} v\\end{array}\\right]根据仿射变换矩阵，我们可以将当前帧(或参考帧)的像素进行变换，再进行块匹配，以期获得对旋转更好的效果。 其他的改进 首先，就是可以通过并行化来实现本程序，因为每个像素块的计算其实时互相独立的过程。 其次，结合我在深度学习预测深度的问题来看，其深度预测会出现相邻两个节点之间变换过于剧烈的问题，于是可以增加空间的正则项，使得其空间上更加平滑。 然后，我们没有显式地处理外点(Outlier)的情况。事实上，由于遮挡、光照、运动模糊等各种因素的影响，不可能对每个像素都保持成功匹配。而演示程序的做法中，只要NCC大于一定值,就认为出现了成功的匹配，没有考虑到错误匹配的情况。 最后，处理错误匹配亦有若干种方式，比如均匀-高斯混合分布下的深度滤波器等。 但是，尽管可以通过改进进行一定程度上的提高，但是有些问题存在理论上的困难，例如对于环境纹理的依赖，又如像素梯度和级线的关联的问题，这些很难提高通过调整代码实现来解决。对于立体视觉而言，这里的过于依赖环境纹理和光照是不可靠的。","link":"/2022/07/01/SLAM/ch12-%E5%BB%BA%E5%9B%BE-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89%E5%BB%BA%E5%9B%BE/"},{"title":"Ch12 建图 第二部分 RGB-D稠密建图","text":"hljs.initHighlightingOnLoad(); 本文主要介绍的是关于RGB-D进行稠密建图，根据不同的需求得到了不同的地图，包括一般的点云地图，点云网格地图，以及压缩之后的点云八叉树地图等，并进行相关代码的实现。 RGB-D稠密建图概述这里使用RGB-D相机有几点优势： 在RGB-D相机中可以完全通过传感器中硬件的测量得到，无须消耗大量的计算资源来估计。 并且，RGB-D的结构光或飞时原理，保证了深度数据对纹理的无关性。即使面对纯色的物体，只要它能够反射光，我们就能测量到它的深度。 利用RGB-D进行稠密建图是相对容易的。不过，根据地图形式不网，也存在有若干种的主流建图方式。最直观、最简单的方法就是根据估算的相机位姿，将RGB-D数据转化为点云，然后进行拼接，最后得到一个由离散的点组成的点云地图(Point Cloud Map )。 在此基础上，如果我们对外观有进一步的要求，希望估计物体的表面，则可以使用三角网格(Mesh)、面片(Surfel)进行建图。 另外，如果希望知道地图的障碍物信息开在地图上导航，也可进过体素(Voxel)建立占据网格地图(Occupancy Map )。 点云地图这里我们建立点云地图，其主要对点云读取的代码其实和第一版的ch5相似，但是这里在其基础上增加了一些滤波的操作。 首先执行pointcloud_mapping.cpp生成map.pcd文件，之后使用pcl_viewer map.pcd来进行打开操作。 在生成每帧点云时，去掉深度值无效的点。这主要是考虑到Kinect的有效量程，超过量程之后的深度值会有较大误差或返回一个零。 12345678// depth filter and statistical removal PointCloud::Ptr tmp(new PointCloud);pcl::StatisticalOutlierRemoval&lt;PointT&gt; statistical_filter;statistical_filter.setMeanK(50);statistical_filter.setStddevMulThresh(1.0);statistical_filter.setInputCloud(current);statistical_filter.filter(*tmp);(*pointCloud) += *tmp 利用统计滤波器方法去除孤立点。该滤波器统计每个点与距离它最近的N个点的距离值的分布，去除距离均值过大的点。这样，就保留了那些“粘在一起”的点，去掉了孤立的噪声点。 利用体素网络滤波器进行降采样。由于多个视角存在视野重叠，在重叠区域会存在大量的位置十分相近的点。这会占用许多内存空间。体素滤波保证了在某个一定大小的立方体（或称体素）内仅有一个点，相当于对三维空间进行了降采样，从而节省了很多存储空间。 12345678// voxel filter pcl::VoxelGrid&lt;PointT&gt; voxel_filter;double resolution = 0.03;voxel_filter.setLeafSize(resolution, resolution, resolution); // resolutionPointCloud::Ptr tmp(new PointCloud);voxel_filter.setInputCloud(pointCloud);voxel_filter.filter(*tmp);tmp-&gt;swap(*pointCloud); 体素滤波之后的效果图，在一个0.03x0.03x0.03的小立方体里面仅仅保留一个体素点： 点云重建网络点云的优点是可以是我们很快的进行可视化，对RGB-D图像可以高效的生成不用额外的处理，但是点云地图比较的初级，一些问题可能无法满足要求。 1．定位需求：决于前端视觉里程计的处理方式。如果是基于特征点的视觉里程计,由于点云中没有存储特征点信息，则无法用于基于特征点的定位方法。如果前端是点云的 ICP，那么可以考虑将局部点云对全局点云进行ICP以估计位姿。然而,这要求全局点云具有较好的精度。我们处理点云的方式并没有对点云本身进行优化,所以是不够的。2．导航与避障的需求：无法直接用于导航和避障。纯粹的点云无法表示“是否有障碍物”的信息，我们也无法在点云中做“任意空间点是否被占据”这样的查询，而这是导航和避障的基本需要。不过，可以在点云基础上进行加工，得到更适合导航与避障的地图形式。 3．可视化和交互：具有基本的可视化与交互能力。我们能够看到场景的外观,也能在场景里漫游。从可视化角度来说,由于点云只含有离散的点，没有物体表面信息（例如法线)，所以不太符合人们的可视化习惯。例如，从正面和背面看点云地图的物体是一样的，而且还能透过物体看到它背后的东西：这些都不太符合我们日常的经验。 因此可以从点云地图出发来开发更高级的功能。比如针对导航的功能，我们可以我们从点云出发构建占据网络(Occupancy Grid) 地图。再比如SFM中，常常用到泊松重建的方法，就可以构建物体的网络地图，得到表面的信息。除此以外，Surfel也是一种表达物体表面的方式，以面元作为地图的基本单元。 注意：这里网格化的是体素过滤之后的点云文件map.pcd。如果直接使用体素之前的文件就会出现卡顿时间长等问题。 主要的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;pcl/point_cloud.h&gt;#include &lt;pcl/point_types.h&gt;#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/visualization/pcl_visualizer.h&gt;#include &lt;pcl/kdtree/kdtree_flann.h&gt;#include &lt;pcl/surface/surfel_smoothing.h&gt;#include &lt;pcl/surface/mls.h&gt;#include &lt;pcl/surface/gp3.h&gt;#include &lt;pcl/surface/impl/mls.hpp&gt;// typedefstypedef pcl::PointXYZRGB PointT;typedef pcl::PointCloud&lt;PointT&gt; PointCloud;typedef pcl::PointCloud&lt;PointT&gt;::Ptr PointCloudPtr;typedef pcl::PointXYZRGBNormal SurfelT;typedef pcl::PointCloud&lt;SurfelT&gt; SurfelCloud;typedef pcl::PointCloud&lt;SurfelT&gt;::Ptr SurfelCloudPtr;SurfelCloudPtr reconstructSurface( const PointCloudPtr &amp;input, float radius, int polynomial_order) { pcl::MovingLeastSquares&lt;PointT, SurfelT&gt; mls; pcl::search::KdTree&lt;PointT&gt;::Ptr tree(new pcl::search::KdTree&lt;PointT&gt;); mls.setSearchMethod(tree); mls.setSearchRadius(radius); mls.setComputeNormals(true); mls.setSqrGaussParam(radius * radius); mls.setPolynomialFit(polynomial_order &gt; 1); mls.setPolynomialOrder(polynomial_order); mls.setInputCloud(input); SurfelCloudPtr output(new SurfelCloud); mls.process(*output); return (output);}pcl::PolygonMeshPtr triangulateMesh(const SurfelCloudPtr &amp;surfels) { // Create search tree* pcl::search::KdTree&lt;SurfelT&gt;::Ptr tree(new pcl::search::KdTree&lt;SurfelT&gt;); tree-&gt;setInputCloud(surfels); // Initialize objects pcl::GreedyProjectionTriangulation&lt;SurfelT&gt; gp3; pcl::PolygonMeshPtr triangles(new pcl::PolygonMesh); // Set the maximum distance between connected points (maximum edge length) gp3.setSearchRadius(0.05); // Set typical values for the parameters gp3.setMu(2.5); gp3.setMaximumNearestNeighbors(100); gp3.setMaximumSurfaceAngle(M_PI / 4); // 45 degrees gp3.setMinimumAngle(M_PI / 18); // 10 degrees gp3.setMaximumAngle(2 * M_PI / 3); // 120 degrees gp3.setNormalConsistency(true); // Get result gp3.setInputCloud(surfels); gp3.setSearchMethod(tree); gp3.reconstruct(*triangles); return triangles;}int main(int argc, char **argv) { // Load the points PointCloudPtr cloud(new PointCloud); if (argc == 0 || pcl::io::loadPCDFile(argv[1], *cloud)) { cout &lt;&lt; &quot;failed to load point cloud!&quot;; return 1; } cout &lt;&lt; &quot;point cloud loaded, points: &quot; &lt;&lt; cloud-&gt;points.size() &lt;&lt; endl; // Compute surface elements cout &lt;&lt; &quot;computing normals ... &quot; &lt;&lt; endl; double mls_radius = 0.05, polynomial_order = 2; auto surfels = reconstructSurface(cloud, mls_radius, polynomial_order); // Compute a greedy surface triangulation cout &lt;&lt; &quot;computing mesh ... &quot; &lt;&lt; endl; pcl::PolygonMeshPtr mesh = triangulateMesh(surfels); cout &lt;&lt; &quot;display mesh ... &quot; &lt;&lt; endl; pcl::visualization::PCLVisualizer vis; vis.addPolylineFromPolygonMesh(*mesh, &quot;mesh frame&quot;); vis.addPolygonMesh(*mesh, &quot;mesh&quot;); vis.resetCamera(); vis.spin();} 八叉树地图下面我们介绍一种在导航里面比较常见的、本身具有较好性能的地图的形式，八叉树地图。在点云地图中，我们虽然有了三维结构，进行了体素过滤提高分辨率，但是点云有几个明显的缺点： 点云地图通常规模很大，所以pcd 文件也会很大。一幅640像素×480像素的图像，会产生30万个空间点,需要大量的存储空间。即使经过一些滤波后，pcd文件也是很大的。而且讨厌之处在于,它的“大”并不是必需的。点云地图提供了很多不必要的细节。我们并不特别关心地毯上的褶皱、阴暗处的影子这类东西，把它们放在地图里是在浪费空间。由于这些空间的占用，除非我们降低分辨率，否则在有限的内存中无法建模较大的环境，然而降低分辨率会导致地图质量下降。 点云地图无法处理运动物体。因为我们的做法里只有“添加点”，而没有“当点消失时把它移除”的做法。而在实际环境中，运动物体的普遍存在，使得点云地图变得不够实用。 这里的主要的想法是将之前的一个提速块不断地进行八等份，直到达到想要的精度为止。当我们从由下一层向上一层走时，其地图的体积就会扩大到原来的八倍。其对于的体积和深度时呈现指数增长的，使用更大的深度时，其建模体积会增加的很快。 可能会有疑问，八叉树这样不是和一般的体素过滤器一样吗？这里要说明的是八叉树存储的是二值0/1，代表当前小正方体节点上有无元素的填充，不是三坐标的数值。如果精度要求不高时，仅仅需要进行展开到上面的节点处即可，不需要进行向下展开了。 前面说八叉树的节点存储了它是否被占据的信息。从点云层面来讲，自然可以用0表示空白，1表示被占据。这种0-1的表示可以用一个比特来存储，节约空间。但是，由于噪声的影响，可能会看到某个点一会儿为0，一会儿为1；或者多数时刻为0，少数时刻为1；或者除了“是”“否”两种情况，还有一个未知的状态。 选择用概率形式表达某节点是否被占据的事情。例如，用一个浮点数$x\\in[0,1]$来表达。这个$x$一开始取0.5。如果不断观测到它被占据，那么让这个值不断增加；反之，如果不断观测到它是空白，那就让它不断减小即可。但是如果让$x$不断地减小，它可能会跑到$[0,1]$之外，于是引入概率对数值(Log-odds)来表示。这里设$y \\in \\mathbb R$ 为概率对数值，$x=0\\sim1$的概率值，于是建立他们之间的logit变换： y=\\operatorname{logit}(x)=\\log \\left(\\frac{x}{1-x}\\right)其对应的反变换为： x=\\operatorname{logit}^{-1}(y)=\\frac{\\exp (y)}{\\exp (y)+1}可以看出来，当$y$从$-\\infty$ 到$+\\infty$ 时，$x$相应的也从0变到1。而当$y=0$时，$x=0.5$ ，因此这里不妨使用$y$来表示节点是否被占据，当检测不到占据时就将$y$增加一个值，否则就让$y$减小一个值。需要查询概率时就逆logit变换，转换为概率即可。使用数学表述就是，设某个节点为$n$，观测数据为$z$。那么从开始到 $t$ 时刻某节点的概率对数值就为$L(n|z_{1:t})$，于是$t+1$时刻由有： L\\left(n \\mid z_{1: t+1}\\right)=L\\left(n \\mid z_{1: t-1}\\right)+L\\left(n \\mid z_{t}\\right)转化为概率形式就是： P\\left(n \\mid z_{1: T}\\right)=\\left[1+\\frac{1-P\\left(n \\mid z_{T}\\right)}{P\\left(n \\mid z_{T}\\right)} \\frac{1-P\\left(n \\mid z_{1: T-1}\\right)}{P\\left(n \\mid z_{1: T-1}\\right)} \\frac{P(n)}{1-P(n)}\\right]^{-1}有了对数概率，就可以根据RGB-D数据更新整个八叉树地图了。假设在RGB-D图像中观测到某个像素带有深度d，就说明：在深度值对应的空间点上观察到了一个占据数据，并且，从相机光心出发到这个点的线段上应该是没有物体的（否则会被遮挡)。利用这个信息，可以很好地对八叉树地图进行更新,并且能处理运动的结构。 这部分对应的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;iostream&gt;#include &lt;fstream&gt;using namespace std;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;octomap/octomap.h&gt; // for octomap #include &lt;Eigen/Geometry&gt;#include &lt;boost/format.hpp&gt; // for formating stringsint main(int argc, char **argv) { vector&lt;cv::Mat&gt; colorImgs, depthImgs; // 彩色图和深度图 vector&lt;Eigen::Isometry3d&gt; poses; // 相机位姿 ifstream fin(&quot;../data/pose.txt&quot;); if (!fin) { cerr &lt;&lt; &quot;cannot find pose file&quot; &lt;&lt; endl; return 1; } for (int i = 0; i &lt; 5; i++) { boost::format fmt(&quot;../data/%s/%d.%s&quot;); //图像文件格式 colorImgs.push_back(cv::imread((fmt % &quot;color&quot; % (i + 1) % &quot;png&quot;).str())); depthImgs.push_back(cv::imread((fmt % &quot;depth&quot; % (i + 1) % &quot;png&quot;).str(), -1)); // 使用-1读取原始图像 double data[7] = {0}; for (int i = 0; i &lt; 7; i++) { fin &gt;&gt; data[i]; } Eigen::Quaterniond q(data[6], data[3], data[4], data[5]); Eigen::Isometry3d T(q); T.pretranslate(Eigen::Vector3d(data[0], data[1], data[2])); poses.push_back(T); } // 计算点云并拼接 // 相机内参 double cx = 319.5; double cy = 239.5; double fx = 481.2; double fy = -480.0; double depthScale = 5000.0; cout &lt;&lt; &quot;正在将图像转换为 Octomap ...&quot; &lt;&lt; endl; // octomap tree octomap::OcTree tree(0.01); // 参数为分辨率 for (int i = 0; i &lt; 5; i++) { cout &lt;&lt; &quot;转换图像中: &quot; &lt;&lt; i + 1 &lt;&lt; endl; cv::Mat color = colorImgs[i]; cv::Mat depth = depthImgs[i]; Eigen::Isometry3d T = poses[i]; octomap::Pointcloud cloud; // the point cloud in octomap for (int v = 0; v &lt; color.rows; v++) for (int u = 0; u &lt; color.cols; u++) { unsigned int d = depth.ptr&lt;unsigned short&gt;(v)[u]; // 深度值 if (d == 0) continue; // 为0表示没有测量到 Eigen::Vector3d point; point[2] = double(d) / depthScale; point[0] = (u - cx) * point[2] / fx; point[1] = (v - cy) * point[2] / fy; Eigen::Vector3d pointWorld = T * point; // 将世界坐标系的点放入点云 cloud.push_back(pointWorld[0], pointWorld[1], pointWorld[2]); } // 将点云存入八叉树地图，给定原点，这样可以计算投射线 tree.insertPointCloud(cloud, octomap::point3d(T(0, 3), T(1, 3), T(2, 3))); } // 更新中间节点的占据信息并写入磁盘 tree.updateInnerOccupancy(); cout &lt;&lt; &quot;saving octomap ... &quot; &lt;&lt; endl; tree.writeBinary(&quot;octomap.bt&quot;); return 0;} 我们使用octomap:OcTree构建整张地图。实际上，八叉树地图提供了许多种八叉树:有带地图的，有带占据信息的，也可以自己定义每个节点需要携带哪些变量。 八叉树地图内部提供了一个点云结构。它比 PCL的点云稍微简单一些，只携带点的空间位置信息。我们根据RGB-D图像和相机位姿信息，先将点的坐标转至世界坐标，然后放入八叉树地图的点云，最后交给八叉树地图。之后，八叉树地图会根据之前介绍的投影信息，更新内部的占据概率，最后保存成压缩后的八叉树地图。我们把生成的地图存成octomap.bt件。 总结最后一部分为实时三维重建的内容，这里由于数里的介绍比较简略，因此这里不再赘述。 这次的视觉SLAM十四讲的第一轮已经完结，后续针对一些模块会出一些细化的教程，以及会深入学习两个框架ORB-SLAM和VINS-SLAM的这两个经典的框架。","link":"/2022/07/01/SLAM/ch12-%E5%BB%BA%E5%9B%BE-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-RGB-D%E7%A8%A0%E5%AF%86%E5%BB%BA%E5%9B%BE/"},{"title":"Faster R-CNN理论知识和PASCAL VOC2012数据集","text":"hljs.initHighlightingOnLoad(); 本文主要讲解的是Faster R-CNN基本理论和PASCAL VOC2012数据集的使用，关于Faster R-CNN理论的代码部分将会在后面的教程中进行详细的讲解。 Faster R-CNN基本理论 主要步骤Faster R-CNN算法流程可分为3个步骤： 将图像输入网络得到相应的特征图； 使用RPN结构生成候选框，将RPN生成的候选框投影到特征图上获得相应的特征矩阵； 将每个特征矩阵通过ROI pooling层缩放到7x7大小的特征图，接着将特征图展平通过一系列全连接层得到预测结果。 总结来说，就是一个RPN+Fast R-CNN的后三层。 RPN网络 这里输入的是特征图(feature map)而不是原来的图片，使用一个滑动串口在feature map上面进行滑动。 这里的k指的是achor box的数量，achor box为事先定义好的具有一定矩形框，其生成的主要过程是： 首先生成中心点，将原图的边长/特征图的边长得到x,y方向的放大比例，记为$x_{scale},y_{scale}$ ，记在特征图上的坐标为$x_0,y_0$。在原图中的坐标记为$x=x_{scale}x_0$, $y=y_{scale}y_0$。 之后以$(x,y)$为中心生成几个achor。 将滑动窗口输入到对应的输入到对应的网络中去，这里有两个可以参考的网络： 一个是ZF网络，其输出为256维的编码； 另一个是VGG16网络，其输出是512维的编码。 之后将编码分别提高各自的全连接层。 cls layer输出的为2k的score，其含义是这个achor box所包含的特征图是图片或是背景的概率。 reg layer输出的为4k的coordinate 的概率，4个参数分别为achor box对应框的位置(x,y)和宽度高度(h,w)。 cls得到的仅仅是预测每个achor 对应的是背景的概率和是目标的概率。 reg也是仅仅对应每个achor对应的回归参数，其中包含着对位置和宽高参数。 因为目标对应的长短和高宽比例各自不同，多以这里会根据经验得到对应的先验框。 在每个尺度上生成对应尺度的3个，每个尺度下有三种对应的长宽比例，对应每个位置有9种achor. 注：这里的滑动窗口其实是3x3的卷积，其padding=1,stride=1得到的规模和feature map一样。 在特征图上3x3的patch对应的感受野两种网络分别：ZF为171，VGG16为228。是问题是这么小的感受野是如何识别比自己大的achor的，这里原论文讲的是可以识别，尽管achor的一部分在感受野外面。 其实就是见微知著，通过局部来预测全局。 特征识别问题对于一张1000x600x3的图像，进行完特征提取之后大约有60x40x9(20k)个anchor，忽略跨越边界的anchor以后，剩下约6k个anchor。 对于RPN生成的候选框之间存在大量重叠，基于候选框的cls得分，采用非极大值抑制，IoU设为0.7，这样每张图片只剩2k个候选框。 通过RPN网络之后，一共会有上万个achor，这里一张图片筛选之后仅仅保留256个，其中的正样本：负样本=1：1，如果正样本的不够128个，那么不足的由负样本来补全。 正样本的选取条件： achor 和 Ground truth 的 $IoU&gt;0.7$ ； achor 和 Ground truth 的 $IoU$ 最大。 当第二个条件没办法满足时，使用第一个条件。 负样本的选取条件： achor 和 Ground truth 的 $IoU&lt;0.3$ ； achor 和 Ground truth 的 $IoU$ 最小。 对于正负样本之外的部分直接舍去。 损失函数 这里$N_{reg}$ 代表的是achor的位置数不是总数。 对于权重论文里$\\lambda=10$，此时两个分类损失的权重统一近似的搞成$1/N_{cls}$即可。 其他的部分和之前的Fast R-CNN相同。 注意：此损失函数为一个多分类的损失，因为使用二分类时每个achor就仅仅预测一个值。 损失函数为：$L_{cls}=-\\sum\\limits_{i=1}^2 p_i^*\\log(p_i)=-\\log(p_i)$ 例如，对于第一个achor来说，其为真实的样本，于是损失函数计算选正样本的概率0.9，$L_{cls}=-\\log(0.9)$；对于第二个achor来说，其为背景，于是对于的损失函数就选为负样本的概率0.2，$L_{cls}=-\\log(0.2)$ 对于二分类的损失函数的计算公式为： $L_{cls}=- p_i^ \\log(p_i)-(1-p_i^ ) \\log(1-p_i)$ 这里在pytorch的官网给出的代码里面，使用的是二分类的情况。 边界框损失函数的表达式和之前Fast R-CNN是一样的。 Faster R-CNN的训练过程现在是直接采用RPN Loss+ Fast R-CNN Loss的联合训练方法 原论文中采用分别训练RPN以及Fast R-CNN的方法： 利用ImageNet预训练分类模型初始化前置卷积网络层参数，并开始单独训练RPN网络参数； 固定RPN网络独有的卷积层以及全连接层参数，再利用lmageNet预训练分类模型初始化前置卷积网络参数，并利用RPN网络生成的目标建议框去训练Fast RCNN网络参数。 固定利用Fast RCNN训练好的前置卷积网络层参数，去微调RPN网络独有的卷积层以及全连接层参数。 同样保持固定前置卷积网络层参数，去微调Fast RCNN网络的全连接层参数。最后RPN网络与Fast RCNN网络共享前置卷积网络层参数，构成一个统一网络。 总结 框架逐渐简洁，效果也非常好。 PASCAL VOC2012数据集概述 其中对于数据上目标的标注，尤其是语义分割还要将轮廓也要进行标注，比较的非时费力。 如下面的第一行，是对其进行实例分割和语义分割，二者不是完全相同。 第二行主要是进行行为检测的信息，第三行是关于人体部位检测的信息。 之后，我们进入官网进行数据集的下载，其数据集的官网为：http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html 进入到数据集中，其中的类别有20多种。 Vehicles House Animals Other Aeroplane Bottle Bird Person Bicycle Chair Cat Boat Dining Cow Bus Potted plant Dog Car Sofa Horse Motorbike TV/Moniter Sheep Train 这里我们主要关注是Main文件里面的内容，下面的主要是用于图像分割使用的文件了。 这里的.xml是.html文件的一种演变的形式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;annotation&gt; &lt;filename&gt;2012_004331.jpg&lt;/filename&gt; # 文件名 &lt;folder&gt;VOC2012&lt;/folder&gt; # 存在于哪个文件加下 &lt;object&gt; &lt;name&gt;person&lt;/name&gt; &lt;actions&gt; # 这个文件是主要来进行的人类姿态识别的 &lt;jumping&gt;1&lt;/jumping&gt; &lt;other&gt;0&lt;/other&gt; &lt;phoning&gt;0&lt;/phoning&gt; &lt;playinginstrument&gt;0&lt;/playinginstrument&gt; &lt;reading&gt;0&lt;/reading&gt; &lt;ridingbike&gt;0&lt;/ridingbike&gt; &lt;ridinghorse&gt;0&lt;/ridinghorse&gt; &lt;running&gt;0&lt;/running&gt; &lt;takingphoto&gt;0&lt;/takingphoto&gt; &lt;usingcomputer&gt;0&lt;/usingcomputer&gt; &lt;walking&gt;0&lt;/walking&gt; &lt;/actions&gt; &lt;bndbox&gt; # 框出范围 &lt;xmax&gt;208&lt;/xmax&gt; &lt;xmin&gt;102&lt;/xmin&gt; &lt;ymax&gt;230&lt;/ymax&gt; &lt;ymin&gt;25&lt;/ymin&gt; &lt;/bndbox&gt; &lt;difficult&gt;0&lt;/difficult&gt; # 是否容易被检查出来 &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;point&gt; &lt;x&gt;155&lt;/x&gt; &lt;y&gt;119&lt;/y&gt; &lt;/point&gt; &lt;/object&gt; &lt;segmented&gt;0&lt;/segmented&gt; # 是否进行了分割，进行了就是1，反之就是0 &lt;size&gt; &lt;depth&gt;3&lt;/depth&gt; &lt;height&gt;375&lt;/height&gt; &lt;width&gt;500&lt;/width&gt; &lt;/size&gt; # 记录图片的大小 &lt;source&gt; &lt;annotation&gt;PASCAL VOC2012&lt;/annotation&gt; &lt;database&gt;The VOC2012 Database&lt;/database&gt; &lt;image&gt;flickr&lt;/image&gt; &lt;/source&gt;&lt;/annotation&gt; 其次Main文件夹下主要记录的是文件名，其中train val内的文件名书互斥的，最后的文件是进行汇总的文件。 这里载入信息的流程，首先，读取train.txt文件，获取每个的信息（txt文件里面装的其实全是文件的名字）。之后，根据文件名来到JPEGimage文件夹里读取对应的图片的文件。 在我们训练之后，需要进行标注来获得自己的数据集。 标注自己的数据集这里采用的工具是在github上面的文件——LabelImg。安装的话是使用的pip install labelImg. 在使用的过程中，直接输入命令labelImg [IMAGE_PATH] [PRE-DEFINED CLASS FILE]。其中第一个是文件的路径，后面一个是关于这个数据集的类别的标签。 具体是使用步骤如下： 打开项目文件夹-&gt;data-&gt;predefined_classes.txt修改标注类别信息； 打开软件； 设置图像文件所在目录，以及标注文件保存目录； 标注图像，并保存； 若要修改源代码在项目的libs-&gt;labelFile.py文件中修改。 在左边处进行开始画框、保存、切换上下等。之后点击保存，就会保存到对应的annotations文件夹中。 之后还要将文件名也保存到Main文件夹中即可。","link":"/2022/07/02/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Faster-R-CNN%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%E5%92%8CPASCAL-VOC2012%E6%95%B0%E6%8D%AE%E9%9B%86/"},{"title":"FCN网络详细代码实现","text":"hljs.initHighlightingOnLoad(); 本文主要是介绍模型具体模型的实现部分，主要从模型部分的搭建过程，包括backbone和总的FCN搭建的过程，以及自定义数据集部分和计算混淆矩阵得到部分。这里面的难点是重构backbone部分、collate_fn()函数的构建部分以及混淆矩阵的索引计算，源码处理的都是很巧妙的。 如果有不明白的参考大佬的源码。 模型的搭建backbonebackbone部分，这部分其实就是之前讲的ResNet50和ResNet101两个部分。 这边和之前的不太之处在于这里加入了膨胀卷积： 12345678910111213class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000, zero_init_residual=False, groups=1, width_per_group=64, replace_stride_with_dilation=None, norm_layer=None): super(ResNet, self).__init__() ... if replace_stride_with_dilation is None: # each element in the tuple indicates if we should replace # the 2x2 stride with a dilated convolution instead replace_stride_with_dilation = [False, False, False] 默认的情况时三个False，我们在FCN中使用时会将后两位赋值为True，具体的代码如下面所示： 1234def fcn_resnet50(aux, num_classes=21, pretrain_backbone=False): # 'resnet50_imagenet': 'https://download.pytorch.org/models/resnet50-0676ba61.pth' # 'fcn_resnet50_coco': 'https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth' backbone = resnet50(replace_stride_with_dilation=[False, True, True]) 其实就是修改了layer3和layer4的内容。 在构建这两个层的Bottleneck1,Bottleneck2的时候，会将膨胀卷积的参数传递到ResNet的_make_layer()函数内部： 前面我们了，因为使用了膨胀卷积，因此这里就不在对其进行下采样操作，于是就将dilation=stride，然后将stride=1即可。这里的dilation已经被修改成2了。 下面根据下图layer3的结构可知，其第一个Bottleneck1的膨胀卷积为previous_dilation=1，后面5个Bottleneck2的膨胀系数为dilation=2。 这里的dilation已经被修改成2，在构建Layer4的时候，其previous_dilation=2，同样的操作再次self.dilation *= stride 于是就有dilation=4。 构建FCN模型 首先，封装好resnet50构建的函数。其中如果需要导入预训练的权重时，这需要将注释部分的权重的链接下载到本地即可。 之后，定义辅助分类器和主分类器，对于辅助分类器来讲其实就是使用if来构建一个键值对，保存到return_layers。 这里使用的IntermediateLayerGetter函数来对这里的前面的backbone进行重构，来拿到layer3,layer4的输出。 12345678910class IntermediateLayerGetter(nn.ModuleDict): _version = 2 __annotations__ = { &quot;return_layers&quot;: Dict[str, str], } def __init__(self, model: nn.Module, return_layers: Dict[str, str]) -&gt; None: # 先判断一下，这里面的元素是不是model里面模块的子集 if not set(return_layers).issubset([name for name, _ in model.named_children()]): raise ValueError(&quot;return_layers are not present in model&quot;) 首先，遍历这里对应的所有的层的名字，看有没有layer3和layer4的名字。如果没有就直接报错。 之后，重新来构建模型的键值对。 123orig_return_layers = return_layersreturn_layers = {str(k): str(v) for k, v in return_layers.items()}# 保证其为字符串 接着，重构backbone，将其中没有用到模块进行删除操作。 123456789101112# 重新构建backbone，将没有使用到的模块全部删掉layers = OrderedDict()# 建立了一个有序的字典集for name, module in model.named_children(): layers[name] = module # 如果这里的model里的name在return_layer中出现了 # 将return_layer里面的对应项删去 if name in return_layers: del return_layers[name] # return_layers为空的 if not return_layers: break 回到本模型来看，在return_layers里面的就是layer3,layer4两个，对应没有辅助分类器的就是仅仅有layer4一个了，于是在将layer删去以后就直接重构结束了。 这里return_layer的值为: 1{'layer4':'out'; 'layer3':'aux'} 这步操作的意图是将backbone里的进行重构，return_layer里面的元素被重构完，就关闭通道，不接受后面的layer。 12super(IntermediateLayerGetter, self).__init__(layers)self.return_layers = orig_return_layers 最后，在foward()函数里进行重新构建，输出的out是个字典，在此代码，如果这里加入了辅助分类器，则其输出值就为： 1{'out': xxx; 'aux': xx} 这里的xxx其实就是对应的层输出的值。 12345678def forward(self, x: Tensor) -&gt; Dict[str, Tensor]: out = OrderedDict() for name, module in self.items(): x = module(x) if name in self.return_layers: out_name = self.return_layers[name] out[out_name] = x return out 将backbone部分处理好之后，我们来处理后面的FCNHead的内容，构建对应的类如下： 123456789101112class FCNHead(nn.Sequential): def __init__(self, in_channels, channels): inter_channels = in_channels // 4 layers = [ nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False), nn.BatchNorm2d(inter_channels), nn.ReLU(), nn.Dropout(0.1), nn.Conv2d(inter_channels, channels, 1) ] super(FCNHead, self).__init__(*layers) 之后构建将分类器的部分加入到对应的代码中可得： 构建好分类器之后，将backbone、classifier、aux_classes来实例化FCN网络。下面来介绍FCN网络的具体的构建方法。 首先，进行网络的初始化操作，参数为上面提到的三个参数。 之后，进行前向传递操作，注意这里的输出不是直接输出的Tensor的值，而是直接输出的对应的有序键值对{key:val(Tensor)}. 12345678910111213141516171819202122def forward(self, x: Tensor) -&gt; Dict[str, Tensor]: input_shape = x.shape[-2:] # contract: features is a dict of tensors features = self.backbone(x) result = OrderedDict() # 最后的输出 x = features[&quot;out&quot;] x = self.classifier(x) # 原论文中虽然使用的是ConvTranspose2d，但权重是冻结的，所以就是一个bilinear插值 x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False) result[&quot;out&quot;] = x # 考虑辅助分类器的情况 if self.aux_classifier is not None: x = features[&quot;aux&quot;] x = self.aux_classifier(x) # 原论文中虽然使用的是ConvTranspose2d，但权重是冻结的，所以就是一个bilinear插值 x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False) result[&quot;aux&quot;] = x return result 自定义读取数据集首先来看VOCSegmentation类的初始化操作。 voc_root：为数据集的文件夹的路径。 year=2012：为对应数据集的年份，VOC数据集还有一个是2007年的。 transforms=None：为对应的预处理的方法，这里训练集和测试集是不一样的。 txt_name: str = &quot;train.txt&quot;：为此时读取的训练集的文件还是测试集的文件。之前在目标检测篇里有讲过这个数据集。 在确定了名称之后，其开始进行路径的拼接工作，得到一系列的路径。 这里是读取文件部分的代码，可以参考借鉴的是分行来读取文件的代码。 12with open(os.path.join(txt_path), &quot;r&quot;) as f: file_names = [x.strip() for x in f.readlines() if len(x.strip()) &gt; 0] 下面是读取图片image和标签mask的操作： 在__getitem__()函数里带定义根据索引来读取图片，并且来进行图像的处理，transforms处理部分在最开始讲解使用的那个部分，分训练和测试定义了不同的处理方式。 这里的target文件其实就是对应的标签，其使用Image打开之后其实是一个调色板模式，使用个单通道的数据，而且其对应的数值就是对应的类别值。 下面来看collate_fn()函数定义的是数据打包的方式，首先将数据按照batch进行打包操作 将我们进行打包操作，同时cat_list是对图片进行填充操作，尤其是对应测试集，没有进行整体的resize操作，因此需要对空白的地方进行切片操作。 在本例中batch=4，于是就得到一个list，其中有4个tuple，第i个tuple其实就是对应的每个batch在i号位置上的数值。(i=0,1,2,3) 下面是cat_list函数的具体的实现过程： 12345678def cat_list(images, fill_value=0): # 计算该batch数据中，channel, h, w的最大值 max_size = tuple(max(s) for s in zip(*[img.shape for img in images])) batch_shape = (len(images),) + max_size batched_imgs = images[0].new(*batch_shape).fill_(fill_value) for img, pad_img in zip(images, batched_imgs): pad_img[..., :img.shape[-2], :img.shape[-1]].copy_(img) return batched_imgs 第一步是读取最大的长宽参数，然后将batch参数放到最前面。 第二步就是进行填充操作，这里的images是Tensor类型的参数，利用其new()方法传入非关键字参数*batch_shape=(4,3,480,480)来创建一个大小为batch_shape里面内容填充fill_value. 第三步就是将里面对应的内容进行填充，将img的内容填充到pad_img相应的位置上。 混淆矩阵计算评估指标首先，复习之前测试函数evaluate()： 12345678910111213141516171819def evaluate(model, data_loader, device, num_classes): model.eval() confmat = utils.ConfusionMatrix(num_classes) # 创建混淆矩阵的对象 metric_logger = utils.MetricLogger(delimiter=&quot; &quot;) header = 'Test:' with torch.no_grad(): for image, target in metric_logger.log_every(data_loader, 100, header): image, target = image.to(device), target.to(device) output = model(image) # 输出是一个有序大的字典集合 output = output['out'] # 这里取出主分类器但对于的输出 confmat.update(target.flatten(), output.argmax(1).flatten()) confmat.reduce_from_all_processes() return confmat 将预测和真实的结果先进行展平操作，在传入到混淆矩阵，调用update()函数来进行更新矩阵。 下面是ConfusionMatrix的具体的实现过程，首先是update函数： 1234567891011def update(self, a, b): n = self.num_classes if self.mat is None: # 创建混淆矩阵 self.mat = torch.zeros((n, n), dtype=torch.int64, device=a.device) with torch.no_grad(): # 寻找GT中为目标的像素索引 k = (a &gt;= 0) &amp; (a &lt; n) # 统计像素真实类别a[k]被预测成类别b[k]的个数(这里的做法很巧妙) inds = n * a[k].to(torch.int64) + b[k] self.mat += torch.bincount(inds, minlength=n**2).reshape(n, n) 首先，是确定对应的值类别数和混淆矩阵，如果之前没有就根据输入的向量重新创建一个新的。 之后，寻找对应真实目标出的索引值。其中代码中的k是一个向量，返回的元素是bool类型的，其主要是代表的是在我们类别标签0 ~ n-1之内的有效，对应255的标签代表的不是没有意义就是难以预测的，这样就选择性的去忽略掉这种情况。 a[k]就是取a中对应位置为true的内容。 然后，这里我们计算出来的混淆矩阵其实是一个向量，之后再将其展平成为一个矩阵的，那现在有确定一些每个元素在混淆向量上面的索引值inds = n * a[k].to(torch.int64) + b[k] 。 例如，最后的3代入公式就得出其对应的索引值为 $3\\times4+2=15$，即填写到最后那那个元素对应的中。第一个元素对应的为$0 \\times 4 +1=1$ 对应的是第二个位置，含义是真实标签为第一个元素，但是实际预测成立第二个元素。 最后，统计呈现的频次，放到混淆向量对应的索引inds上。最后还原成矩阵的形式，将其加载之前的混淆矩阵上。 1self.mat += torch.bincount(inds, minlength=n**2).reshape(n, n) 在遍历完一个epoch之后，就开始取打印对应评价指标，这里我们重载了对应的打印的方法。 1234567891011def __str__(self): acc_global, acc, iu = self.compute() return ( 'global correct: {:.1f}\\n' 'average row correct: {}\\n' 'IoU: {}\\n' 'mean IoU: {:.1f}').format( acc_global.item() * 100, ['{:.1f}'.format(i) for i in (acc * 100).tolist()], ['{:.1f}'.format(i) for i in (iu * 100).tolist()], iu.mean().item() * 100) 这里调用了compute()方法，这个方法主要就是计算对应的评价指标的，具体代码如下： 123456789def compute(self): h = self.mat.float() # 计算全局预测准确率(混淆矩阵的对角线为预测正确的个数) acc_global = torch.diag(h).sum() / h.sum() # 计算每个类别的准确率 acc = torch.diag(h) / h.sum(1) # 计算每个类别预测与真实目标的iou iu = torch.diag(h) / (h.sum(1) + h.sum(0) - torch.diag(h)) return acc_global, acc, iu 这边用到的相关的评价指标，我们可以参考前一篇博客。 sum(1)计算列和，sum(0)计算行和，sum()计算全局之和。","link":"/2022/07/05/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/FCN%E7%BD%91%E7%BB%9C%E8%AF%A6%E7%BB%86%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"FCN语义分割网络理论及简要代码","text":"hljs.initHighlightingOnLoad(); 本文首先介绍的是FCN的理论部分，其中FC层CNN化是一个亮点，下面介绍了3种不如的结构FCN-32s、FCN-16s 、FCN-8s。由于这篇文章是15年的论文，当是主要的分类网络是VGG，如今分别网络的百花齐放，因此我们仅仅基于原文的框架，但backnone使用的是resnet-50。代码部分简单的介绍了代码的训练部分和代码如何使用，具体的模型搭建、数据集处理和混淆矩阵计算的内容请看下篇。 如果有不明白的，参考大佬的源码。 基本理论概述FCN的全称为Fully Convolution Network. 是首个端对端的针对像素级预测的全卷积神经网络。 这里对比PASCAL VOC上表现，无论计算时间和和准确率，都是比之前好不少的。 其基本的原来是提高卷积操作将不断地进行下采样，得到一个21个channel地向量(算上背景一共有21类)，然后将其进行上采样使得其大小和原来地图片相似。针对每个pixel进行softmax，取最大的类别作为我们的这个pixel的预测值。 在当时，分类网络一般会在最后直接展平，然后接上一个全连接层，因此这样就是对输入的图片的大小有一定的限制，如图必须是96x96的图片才行。 FC层CNN化换成一般的全卷积之后，其最后的输出不一定是一个向量，只一个2D的矩阵。将其转换成热力图heat map的形式就为上上面所示，其对猫的tabby cat的部分由很强的注意力。 对于VGG16而言，我们使用较多是D架构。这里使用了5个max pooling层一共下采样了32倍，之后我们将会重点关注的是Maxpool3和Maxpool4这两层。 下面介绍将全连接层卷积化的过程。 这两个的参数量是一样的(忽略偏置)，但是对于卷积而言，其可以通过padding来控制输出向量的大小。如padding=3，则得到的H和W是不变的。 不同结构的FCN-Xs 这里主要呈现是不同的FCN下的效果图，对比可以采用常采用的倍率越小，其效果就越好，测试发现通过8倍的上采样还原到原图的FCN-8s网络的效果是最好的。 但是这个图片对于问题的其三种结构的描述不是很好，下面来精细的来看具体三种结果的表现形式。 这里原论文在Backbone的第一个卷积层的位置，将padding设置成为100，这样做的目的是当图片的大小小于192时，如果直接输入会造成其在FC6处的大小已经小于7了，无法使用7x7的卷积了。 但是这种做法相当的不自然，其实在FC6处可以将7x7换成3x3也好。而且padding=100会无端的增加计算量，而且恢复到原来的图片之后还要进行一下裁剪crop操作。 并且当图片小于32x32时，没出Backbone时估计就出错了，但是小于32的图片就算做了语义分割，其效果估计也很差劲。每次这个情况没必要考虑。因此这里我们将FC6的7x7换成3x3，并且图片的大小大于32就不会有问题了。 图片输入进来，经过VGG16的Backbone之后，H、W缩小了32倍、channels=512； 之后将进入FC6层这里7x7的卷积对于的padding=3，其对应的(H,W)不变，channels=4096。 然后FC7层输出后的结果和上一层时相同的，下面进入一个1x1的Conv层其输出为num_cls=20+1。 最后进行上采样操作，使用的是基于双线性插值的转置卷积。 在原理的论文里，其是将这个上采样给冻结着了，原因这个训练和不训练的效果是差不多的。 up的理解是，其上采样率过大，造成其效果非常差劲。在U-Net里面，每次上采样的倍率都是2倍。 这里对应FCN-16s的结构，前面和FCN-32s是一样的知道先进行了一个2倍率的上采样； 之后是将Maxpool4对应的feature map提取出来，进行1x1卷积来变换通道数，然后和主线相加。 最后进行16倍率的上采样。 前面的部分和FCN-16s相似，将输出进行两倍率的上采样使得和maxpool3 对应的feature map的H、W相同的。 提取maxpool3 对应的feature map，使用1x1的卷积变更通道数后，和主线相加。 最后进行8倍率的上采样即可。 损失计算 这里其实就是每个pixel单独计算的交叉熵损失。 总结：上述即为FCN的网络的主要的原理，因为发文时间比较的早，但是最好的分类的网络估计就是VGG了，而当下分类的网络不断的更新，出现了如ResNet、VIT等结构也再不断改进着FCN的backbone。 在代码的实现环节，pytorch源码使用的是resnet-50来作为的BackBone，并且使用了膨胀卷积的技术，这点和原来的论文里面的网络有所不同。 代码实现概述首先来看pytorch给出的源码的实现，其中pytorch官方的使用的backbone是基于resnet50的，并且已经使用了膨胀卷积，这里和原论文的VGG16不同。 layer1和layer2分别对应的是conv_2和conv_3。 layer3和layer4使用的是Bottleneck1和Bottleneck2在一起堆叠的方式来表现的。 这里的Bottleneck1的做法是将原来的3x3和残差部分的1x1部分的结构进行stride由2改成了1，不进行下采样stride=2操作，取而代之的是将3x3卷积改成膨胀卷积。 同样的Bottleneck2也是使用膨胀系数为2的膨胀卷积。 下面进入FC层，这里也对原来的网络进行了很大的修改。 首先通过一个3x3的卷积来将channel由2048-&gt;512，并且不改变H、W=60 之后1x1卷积来修改channel由512-&gt;num_classes。 最后使用双线性插值来恢复到原来的大小。 这里旁边的是一个辅助的分类器，其输入主要来自于layer的输出60x60x1024，防止误差梯度无法传递到浅层。但是一般可以直接删除来提高网络的性能。 代码的使用本源码主要来自于pytorch官方的torchvision文件下，项目的地址是：https://github.com/pytorch/vision/tree/main/torchvision/models/segmentation 文件的主要的结构： 12345678├── src: 模型的backbone以及FCN的搭建├── train_utils: 训练、验证以及多GPU训练相关模块├── my_dataset.py: 自定义dataset用于读取VOC数据集├── train.py: 以fcn_resnet50(这里使用了Dilated/Atrous Convolution)进行训练├── train_multi_GPU.py: 针对使用多GPU的用户使用├── predict.py: 简易的预测脚本，使用训练好的权重进行预测测试├── validation.py: 利用训练好的权重验证/测试数据的mIoU等指标，并生成record_mAP.txt文件└── pascal_voc_classes.json: pascal_voc标签文件 预训练权重的下载： 注意：官方提供的预训练权重是在COCO上预训练得到的，训练时只针对和PASCAL VOC相同的类别进行了训练，所以类别数是21(包括背景) 这里可能是将COCO和PASCAL VOC相同的类别进行训练的。 fcn_resnet50: https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth fcn_resnet101: https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth 注意，下载的预训练权重记得要重命名，比如在train.py中读取的是fcn_resnet50_coco.pth文件， 不是fcn_resnet50_coco-1167a1af.pth 训练方法： 确保提前准备好数据集 确保提前下载好对应预训练模型权重 若要使用单GPU或者CPU训练，直接使用train.py训练脚本 若要使用多GPU训练，使用torchrun --nproc_per_node=8 train_multi_GPU.py指令,nproc_per_node参数为使用GPU数量 如果想指定使用哪些GPU设备可在指令前加上CUDA_VISIBLE_DEVICES=0,3(例如我只要使用设备中的第1块和第4块GPU设备) CUDA_VISIBLE_DEVICES=0,3 torchrun --nproc_per_node=2 train_multi_GPU.py 具体步骤Step1：设置训练时需要的参数1234567891011121314151617181920212223242526272829303132333435def parse_args(): import argparse parser = argparse.ArgumentParser(description=&quot;pytorch fcn training&quot;) parser.add_argument(&quot;--data-path&quot;, default=&quot;/data/&quot;, help=&quot;VOCdevkit root&quot;) # 设置路径 parser.add_argument(&quot;--num-classes&quot;, default=20, type=int) # 去掉背景后的类别数 parser.add_argument(&quot;--aux&quot;, default=True, type=bool, help=&quot;auxilier loss&quot;) # 是否使用辅助分类器 parser.add_argument(&quot;--device&quot;, default=&quot;cuda&quot;, help=&quot;training device&quot;) # 设置训练所用的设备 parser.add_argument(&quot;-b&quot;, &quot;--batch-size&quot;, default=4, type=int) # 设置一个batch的大小，根据GPU现存来考虑 parser.add_argument(&quot;--epochs&quot;, default=30, type=int, metavar=&quot;N&quot;, help=&quot;number of total epochs to train&quot;) # 设置循环的次数 parser.add_argument('--lr', default=0.0001, type=float, help='initial learning rate') parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum') parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float, metavar='W', help='weight decay (default: 1e-4)', dest='weight_decay') parser.add_argument('--print-freq', default=10, type=int, help='print frequency') parser.add_argument('--resume', default='', help='resume from checkpoint') parser.add_argument('--start-epoch', default=0, type=int, metavar='N', help='start epoch') # Mixed precision training parameters parser.add_argument(&quot;--amp&quot;, default=False, type=bool, help=&quot;Use torch.cuda.amp for mixed precision training&quot;) args = parser.parse_args() return args Step2：数据预处理为数据预处理的两个类，第一个是处理训练数据的类，第二个是处理验证数据的类。 1234567891011121314151617class SegmentationPresetTrain: def __init__(self, base_size, crop_size, hflip_prob=0.5, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)): min_size = int(0.5 * base_size) max_size = int(2.0 * base_size) trans = [T.RandomResize(min_size, max_size)] if hflip_prob &gt; 0: trans.append(T.RandomHorizontalFlip(hflip_prob)) trans.extend([ T.RandomCrop(crop_size), T.ToTensor(), T.Normalize(mean=mean, std=std), ]) self.transforms = T.Compose(trans) def __call__(self, img, target): return self.transforms(img, target) 其中的base_size为基础的边长，min_size为最小边长，max_size为最大边长。这里是将image和target一起进行缩放。 下面进行的是随机裁剪操作： 这里在裁剪之前就首先来判断一些这个图片的目标尺寸和当下的尺寸那个大，如果目标尺寸大于当下尺寸中长宽中的一个，就给那个小的填充0，对应的给target里面会填充255，255在语义分割里就是没有意义的意思。 对于难以分类的部分也是使用的255来标记，这样在训练的时候就会直接忽略。 下面是ToTensor操作，其实就是把[0,255]-&gt;[0,1]. 对于验证的过程，其实也是差不多的，就是不需要进行随机的剪裁操作了。 1234567891011121314151617class SegmentationPresetEval: def __init__(self, base_size, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)): self.transforms = T.Compose([ T.RandomResize(base_size, base_size), T.ToTensor(), T.Normalize(mean=mean, std=std), ]) def __call__(self, img, target): return self.transforms(img, target) # train=true就进行训练集的数据增强，反之就是进行测试集的数据增强 def get_transform(train): base_size = 520 crop_size = 480 return SegmentationPresetTrain(base_size, crop_size) if train else SegmentationPresetEval(base_size) Step3：创建模型这里有三个重要的参数： aux：bool类型的参数，是否使用辅助分类器； num_classes：int类型，一共有多好个类，不算背景； pretrain=True：bool类型，是否使用预训练模型，默认是需要使用。 1234567891011121314151617181920212223def create_model(aux, num_classes, pretrain=True): # 创建模型，其实就是将模型类进行实例化 model = fcn_resnet50(aux=aux, num_classes=num_classes) if pretrain: # 将文件载入到模型之中 weights_dict = torch.load(&quot;./fcn_resnet50_coco.pth&quot;, map_location='cpu') # 当类别数为21时，就不需要的进行修改类别数的操作了 if num_classes != 21: # 官方提供的预训练权重是21类(包括背景) # 如果训练自己的数据集，将和类别相关的权重删除，防止权重shape不一致报错 for k in list(weights_dict.keys()): if &quot;classifier.4&quot; in k: # 这里的&quot;classifier.4&quot;就是个分类个数相关的权重 del weights_dict[k] missing_keys, unexpected_keys = model.load_state_dict(weights_dict, strict=False) if len(missing_keys) != 0 or len(unexpected_keys) != 0: print(&quot;missing_keys: &quot;, missing_keys) print(&quot;unexpected_keys: &quot;, unexpected_keys) return model 其中model.load_state_dict的返回值有两个，一个时确实的权重missing_keys，另一个是多余的权重unexpected_keys。 Step4：关于训练函数的主程序注意： VOCSegmentation是定义在数据处理文件的类，这里仅仅是调用，具体后面会说。 其中的backbone就是resnet50，classifier其实就是FC_Head。 create_lr_scheduler是一种学习率的更新策略，这里的策略是先缓慢的增长到指定的学习率，之后再慢慢的下降。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103def main(args): device = torch.device(args.device if torch.cuda.is_available() else &quot;cpu&quot;) batch_size = args.batch_size # segmentation nun_classes + background num_classes = args.num_classes + 1 # 用来保存训练以及验证过程中信息 results_file = &quot;results{}.txt&quot;.format(datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)) # VOCdevkit -&gt; VOC2012 -&gt; ImageSets -&gt; Segmentation -&gt; train.txt train_dataset = VOCSegmentation(args.data_path, year=&quot;2012&quot;, transforms=get_transform(train=True), txt_name=&quot;train.txt&quot;) # VOCdevkit -&gt; VOC2012 -&gt; ImageSets -&gt; Segmentation -&gt; val.txt val_dataset = VOCSegmentation(args.data_path, year=&quot;2012&quot;, transforms=get_transform(train=False), txt_name=&quot;val.txt&quot;) num_workers = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 8]) # 这里是确定训练的核数 train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True, collate_fn=train_dataset.collate_fn) val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=num_workers, pin_memory=True, collate_fn=val_dataset.collate_fn) # 创建模型 model = create_model(aux=args.aux, num_classes=num_classes) model.to(device) # 记录所有有梯度可以进行优化的参数 # 其中的backbone就是resnet50 # classifier其实就是FC_Head params_to_optimize = [ {&quot;params&quot;: [p for p in model.backbone.parameters() if p.requires_grad]}, {&quot;params&quot;: [p for p in model.classifier.parameters() if p.requires_grad]} ] if args.aux: params = [p for p in model.aux_classifier.parameters() if p.requires_grad] # 和大模型的学习率不一样，这里是在单独设置学习率是全局的10倍 params_to_optimize.append({&quot;params&quot;: params, &quot;lr&quot;: args.lr * 10}) optimizer = torch.optim.SGD( params_to_optimize, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay ) scaler = torch.cuda.amp.GradScaler() if args.amp else None # 创建学习率更新策略，这里是每个step更新一次(不是每个epoch) lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), args.epochs, warmup=True) # if args.resume: checkpoint = torch.load(args.resume, map_location='cpu') model.load_state_dict(checkpoint['model']) optimizer.load_state_dict(checkpoint['optimizer']) lr_scheduler.load_state_dict(checkpoint['lr_scheduler']) args.start_epoch = checkpoint['epoch'] + 1 if args.amp: scaler.load_state_dict(checkpoint[&quot;scaler&quot;]) start_time = time.time() # 开始训练 for epoch in range(args.start_epoch, args.epochs): mean_loss, lr = train_one_epoch(model, optimizer, train_loader, device, epoch, lr_scheduler=lr_scheduler, print_freq=args.print_freq, scaler=scaler) # 用验证值来更新混淆矩阵 confmat = evaluate(model, val_loader, device=device, num_classes=num_classes) val_info = str(confmat) print(val_info) # write into txt with open(results_file, &quot;a&quot;) as f: # 记录每个epoch对应的train_loss、lr以及验证集各指标 train_info = f&quot;[epoch: {epoch}]\\n&quot; \\ f&quot;train_loss: {mean_loss:.4f}\\n&quot; \\ f&quot;lr: {lr:.6f}\\n&quot; f.write(train_info + val_info + &quot;\\n\\n&quot;) save_file = {&quot;model&quot;: model.state_dict(), &quot;optimizer&quot;: optimizer.state_dict(), &quot;lr_scheduler&quot;: lr_scheduler.state_dict(), &quot;epoch&quot;: epoch, &quot;args&quot;: args} if args.amp: save_file[&quot;scaler&quot;] = scaler.state_dict() torch.save(save_file, &quot;save_weights/model_{}.pth&quot;.format(epoch)) total_time = time.time() - start_time total_time_str = str(datetime.timedelta(seconds=int(total_time))) print(&quot;training time {}&quot;.format(total_time_str)) 重要的封装函数损失函数这里是上面遇见的到的损失函数的具体的实现： 1234567891011def criterion(inputs, target): losses = {} for name, x in inputs.items(): # 忽略target中值为255的像素，255的像素是目标边缘或者padding填充 losses[name] = nn.functional.cross_entropy(x, target, ignore_index=255) if len(losses) == 1: return losses['out'] # 如果有辅助分类器于是将乘以权重0.5后，加在主分类器之后 return losses['out'] + 0.5 * losses['aux'] 训练一代的函数这里将上面训练的过程直接封装成一个函数如下，和以往不同的是，之前是每个epoch会出现进行学习率的更新，而这里是每一步就更新一次学习率。 123456789101112131415161718192021222324252627def train_one_epoch(model, optimizer, data_loader, device, epoch, lr_scheduler, print_freq=10, scaler=None): model.train() metric_logger = utils.MetricLogger(delimiter=&quot; &quot;) metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}')) header = 'Epoch: [{}]'.format(epoch) for image, target in metric_logger.log_every(data_loader, print_freq, header): image, target = image.to(device), target.to(device) with torch.cuda.amp.autocast(enabled=scaler is not None): output = model(image) loss = criterion(output, target) optimizer.zero_grad() if scaler is not None: scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() else: loss.backward() optimizer.step() lr_scheduler.step() lr = optimizer.param_groups[0][&quot;lr&quot;] metric_logger.update(loss=loss.item(), lr=lr) return metric_logger.meters[&quot;loss&quot;].global_avg, 返回的时训练的平均损失和学习率。 验证函数下面为验证函数的具体形式，首先时建立混淆矩阵confmat如下， 123456789101112131415161718def evaluate(model, data_loader, device, num_classes): model.eval() confmat = utils.ConfusionMatrix(num_classes) metric_logger = utils.MetricLogger(delimiter=&quot; &quot;) header = 'Test:' with torch.no_grad(): for image, target in metric_logger.log_every(data_loader, 100, header): image, target = image.to(device), target.to(device) output = model(image) output = output['out'] confmat.update(target.flatten(), output.argmax(1).flatten()) # 这里将预测最大概率的那个类作为最后的预测值 # 然后计算与预测值和目标值之间的插值来对最后混淆矩阵进行更新 confmat.reduce_from_all_processes() return confmat 预测函数 在预测过程中，一般不使用辅助分类器，aux=False. palette调色板文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def main(): aux = False # inference time not need aux_classifier classes = 20 # 自己训练好的权重的名称 weights_path = &quot;./save_weights/model_29.pth&quot; # 自己下载的图片的名称 img_path = &quot;./test.jpg&quot; # 导入json,其实就是调色板 palette_path = &quot;./palette.json&quot; assert os.path.exists(weights_path), f&quot;weights {weights_path} not found.&quot; assert os.path.exists(img_path), f&quot;image {img_path} not found.&quot; assert os.path.exists(palette_path), f&quot;palette {palette_path} not found.&quot; with open(palette_path, &quot;rb&quot;) as f: pallette_dict = json.load(f) pallette = [] for v in pallette_dict.values(): pallette += v # get devices device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(&quot;using {} device.&quot;.format(device)) # create model model = fcn_resnet50(aux=aux, num_classes=classes+1) # delete weights about aux_classifier weights_dict = torch.load(weights_path, map_location='cpu')['model'] for k in list(weights_dict.keys()): # 遍历删去辅助分类器的内容 if &quot;aux&quot; in k: del weights_dict[k] # load weights model.load_state_dict(weights_dict) model.to(device) # load image original_img = Image.open(img_path) # from pil image to tensor and normalize data_transform = transforms.Compose([transforms.Resize(520), transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]) img = data_transform(original_img) # expand batch dimension # 就是增加一个batch维度 img = torch.unsqueeze(img, dim=0) model.eval() # 进入验证模式 with torch.no_grad(): # init model img_height, img_width = img.shape[-2:] init_img = torch.zeros((1, 3, img_height, img_width), device=device) model(init_img) t_start = time_synchronized() output = model(img.to(device)) t_end = time_synchronized() print(&quot;inference+NMS time: {}&quot;.format(t_end - t_start)) prediction = output['out'].argmax(1).squeeze(0) prediction = prediction.to(&quot;cpu&quot;).numpy().astype(np.uint8) mask = Image.fromarray(prediction) mask.putpalette(pallette) mask.save(&quot;test_result.png&quot;)","link":"/2022/07/05/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA%E5%8F%8A%E7%AE%80%E8%A6%81%E4%BB%A3%E7%A0%81/"},{"title":"DeepLab Vx语义分割网络及代码实现","text":"hljs.initHighlightingOnLoad(); 本文主要理论部分分别介绍了DeepLab v1、DeepLab v2、DeepLab v3模型的主要架构，解决的主要问题如空间不变性和下采样丢失信息等，以及为了解决文中提到的问题采取的手段。在代码实现部分，Pytorch主要是进行了是基于FCN网络来修改的。在backbone部分可以选择resnet和mobilenet v3，本文主要讲解的是resent部分。在ASPP部分，是基于FCNHead的框架来搭建的。 DeepLab V1 主要的问题首先，文章总结了当前情况下语义分割存在的问题，其中主要包括下采样操作会造成分辨率的下降，其次就是无法保证空间不变性，因为在分类网络中，一般都是要满足空间不变性的，就是图片旋转平移变化之后其预测的结果是不变的，但是对于语义分割而言，不可以出现空间不变性。 对于上述的问题，本文给出的解决方案是使用膨胀卷积来保证又足够的分辨率，其次就是使用Fully-connected CRF(Conditional Random Field)，但是这个在早期的语义分割里面使用较多，但是在v3开始就不在使用了。 网络的优势 速度更快，论文中说是因为采用了膨胀卷积的原因，但fully-connected CRFs很耗时； 准确率更高，相比之前最好的网络提升了7.2个点； 模型结构简单，主要由DCNNs (Deep Convolutional Nerual Networcks) 和CRFs联级构成。 这里面常见的结构又以下几种，包括MSC、CRF、LargeFOV单个结构，但本文我们仅仅讲MSC、LargeFOV. Large FOV 在保证Mean IoU不下降的前提下，去加快模型的训练速度。 网络的backbone也是当是效果最好的VGG16网络。 这里也是使用了全连接FC层化为卷积的操作，使用的是kernel_size=7x7,channels=4096的卷积网络。但是这样这样做为成为本文的一个计算的瓶颈。于是如下表所示，会有一个对卷积核进行下采样得到kernel_size=4x4的情况。 当我们这里的kernel_size=4之后，会将对应的感受野原来的一半，于是就会出现Mean_IoU降低的情况，同时其读取速度和占用的内存都会升高。 之后，通过提高膨胀系数input_stride=8，于是就会出现感受野恢复到原来情况。 最后，继续将卷积核的尺寸下降到kernel_size=4，其中膨胀系数上升到input_stride=12，同时卷积核个数下降到channels=1024，最后得到的运算速度又运算速度和Mean_IoU都有所上升。 于是LargeFOV 就等价于一个卷积核为kernel_size=3，膨胀系数为12的卷积。 最后的配置图如下图： 这里的backbone为VGG网络，但是有部分也是进行了修改： 第一个Maxpool，将原来的kernel_size=2-&gt;3。 其中前三个下采样操作的倍率为8倍。 MSc(Multi-Scale) 其实就是融合多个尺度上的数据，其实这里原论文的作者不是很推荐，作者比较推荐去使用CRF。 这里是将原图尺度和前面4个maxpool尺度进行融合，最后提高间级都转化为28x28xnum_class. DeepLab v2 相比于v1其主要的提升在于其换了backbone，2016年分类领域的重要作品resent出世，其效果力压VGG，于是好多问题的backbone就投向了resnet，其次就是其引入了aspp结构。 主要的问题这里其实和之前的v1大致相同，基本的问题有三个： 分辨率会被降低，(主要是由于下采样stride&gt;1的层导致的)； 目标的多尺度问题； DCNNs的不变性(invarience)会降低定位的精度。 在v1的基础上增加了多尺度的问题。 对应的解决方法 针对分辨率被降低的问题，一般就是将最后的几个Maxpooling层的stride设置成1(如果是通过卷积下采样的，比如resnet，同样将stride设置成1即可)，配合使用膨胀卷积。 就是和前面一样，将下采样的卷积层的stride=1，配合膨胀卷积来使用。 针对目标多尺度的问题，最容易想到的就是将图像缩放到多个尺度分别通过网络进行推理，最后将多个结果进行融合即可。这样做虽然有用但是计算量太大了。为了解决这个问题，DeepLab V2中提出了ASPP模块(atrous spatial pyramid pooling)。 针对DCNNs不变性导致定位精度降低的问题，和DeepLab V1差不多还是通过CRFs解决，不过这里用的是fully connected pairwise CRF，相比V1里的fully connected CRF要更高效点。 网络的优势 运算速度会更快； 其准确率会更高，并且在当是state-of-art； 模型的结构简单，但是还是原来的DCNNs+CRF的联级。 ASPP(atrous spatial pyramid pooling) 如上图所示，是将图片经过不同的膨胀卷积得到不同尺度的特征，之后将不同尺度的特征进行并联。 这里有两种ASPP结构，和LargeFOV相比的结构如下表所示。 ASPP-S对应的膨胀系数为 $r=\\{2,4,8,12\\}$ ； ASPP-L对应的膨胀系数为 $r=\\{6,12,18,24\\}$； 需要注意的是，上图的backbone是针对一般的VGG16的，在resnet为backbone的网络中，其只有一个3x3的膨胀卷积，没有后面那两个全连接层。 消融实验 上图的主要的方法包括，MSC代表多尺度操作、COCO代表是否进行预训练操作、Aug代表是否进行数据增强、LargeFOV、ASPP、CRF是主要来解决空间不变性的方法。 MSc中将原来的图像变成scale={0.5,0.75,1}，之后的融合操作就去上述三个输出里面的最大值，相比原来提升了两个点。 COCO就是将其在COCO数据集上进行预训练操作，相比之前提升了两个点。 Aug就是对数据进行增强操作，其实就是对数据进行0.5-1.5倍的缩放。 LargeFOV对最后的结果的提升不是很明显。 ASPP和CRF对最后的提升有1.5个点左右。相比之下CRF的提升就不是很明显了，但是在v1中是可以提上4个点左右。 将VGG16换成resnet101大概可以提升3个点。 学习策略的设计 这里提高更改学习率的策略就可以提高3个点的提升。 learing\\_rate=lr\\times(1-\\frac{iter}{max\\_iter})^{power} 作者的炼丹能力太强了。 网络的结构 这里和FCN其实很像，large3之前基本上照抄的resnet-101，后面就重新修改的网络，将膨胀卷积加入到网络之中了。 如右图所示，其主要的layer3,layer4主要的变化是取消了下采样，换成了对应的膨胀卷积，其中在layer3里面得到膨胀系数为2，在layer4里面的膨胀系数为4，前面没有膨胀卷积，因此不会出现gridding effect的现象。 下面接一个ASPP操作的，将其输入到四个带偏置的卷积，其输出的维度就是分类的个数。 我估计这里的膨胀卷积应该会有padding，要不然不会出现输入和输出一样的尺寸的情况。 DeepLab V3概述 引入了Multi-grid的思想，之前在v2里面膨胀系数都是随意进行实现的，在v3中为了避免出现gridding effect这里重新设计了膨胀系数。 改进之前的ASPP结构。 移除了CRF结构，因为CPF结构在v2里面有时候就效果非常提升不如在v1结构中明显了。 以上分别是如何获取多尺度信息的方法： 第一种是将图片缩放到不同的结构类型，分别进行的特征提取后再进行融合merge。 第二种是将适用encoder-decoder架构，这种架构的代表网络是U-Net，先进行下采样，然后上采样的时候不断融合之前的信息。 第三种是先进行下采样，之后提高膨胀卷积来恢复到原来的大小，改架构的代表就是DeepLab v1。 第四种是引入ASPP架构来获取多尺度信息融合的能力，该架构的代表是DeepLab v2。 DeepLab v3的两种结构 其实本文构建了两个模型，但是最后github代码复现比较多的还是ASPP的模型，up猜想ASPP比较消耗内存，可能由于当是的内存不多才用了第一个模型。 下面来分别看两个模型： cascaded model中前面的4个层对应的就是ResNet结构中的layer1,layer2,layer3,layer4 由于layer1是没有进行下采样的，进行下采样的是layer1之前的maxpool层，于是其图中标注的通道数有问题。 其次就是，由于当是显卡内存的问题，其之前在训练是将下采样率为16，验证的时候设置为8，来节约缓存开销，增大训练过程中的batch_size。 这里的膨胀系数有特定的计算公式$膨胀系数=rate \\times multi_grid$ 后面的几个层block5,6,7在结构上和block4是相同的，都是残差块拼接的结构，就是膨胀系数不同而已。 ASPP model 这个模型乍一看是其实和之前的DeepLab v2很类似，但是其在ASPP模块的结构上面进行了调整。 这里一共有5个分支，分别是Conv1x1、Conv3x3_rate=6、Conv3x3_rate=12、Conv3x3_rate=18、全局pooling。最后提高一个Concat拼接和一个Conv1x1。 如下图所示为二者的对比图，其中对应v3来说，当其下采样率为8时，对应的膨胀系数要翻倍。 相比之下，v2的ASPP结构就显得很简陋。 Multi-grid 这里由上面可知，block5,6,7的结构和之前一样，都是三个卷积相连的残差结构，于是就有Multi-Grid的参数有三个，这三个的膨胀系数计算的公式为：$膨胀系数=rate \\times multi_grid$ 。 对于cascade model 主要采用的是$(1,2,1)$的Multi-grid，此时效果最好。 对于ASPP model 主要采用的是$(1,2,4)$的Multi-grid，此时效果最好。 消融实验cascaded model MS对应的放大的倍率，$sclaes=\\{0.5,0.75,1.0,1.25,1.5,1.75\\}$，这里使用MS之后可以提高0.8个百分点。 OS其实是out_stride就是下采样率的大小，将在显存允许的情况下，将16倍变成8倍就科研提高1.5个百分点。 Flip即为延水平方向反转的操作，可以提高0.4个点。 ASPP model OS=8提高了1.3个百分点，MS提高了1个百分点，Flip提高了1个百分点，COCO数据集上的进行预训练操作，可以提高3百分点。 训练细节 如上图所示，相比DeepLab v2-CRF ,DeepLab v3的在训练的效果上提升的了6个百分点，在消融实验中，仅仅实验MS+改进的ASPP其实也不至于就提升6个点，于是就是在训练的过程进行了一些tick。 crop_size：代表的是输入到网络中的大小，如果图片大于crop_size就将其进行随机的剪裁操作。 增大crop_size就会可以提高9个百分点。 训练的时候还原回到原来的尺度之后再来计算损失，在DeepLab v2中是真实的标签也进行缩放，先计算损失然后再进行上采样。 这样做的原因时但是的算例不足，这样做的可以加快计算速度。 如果还原到原来到尺寸之后再来计算损失，就会比原来提高1.2个百分点。 fine-tuning (微调) 这里就是在训练的过程中选择性的冻结某些层。本文在训练的过程中，选择性的冻结BN层就会达到很好的效果，提升1.3个百分点。 Pytorch 官方实现的DeepLab v3 Pytorch的代码是没有使用Multi-Grid的。 多了一个FCNHead辅助训练分支，可以选择不使用。 无论是训练还是验证output_stride都使用的8。 ASPP中三个膨胀卷积分支的膨胀系数是12,24,36。 以下是这个DeepLab v3的网络图，这里我们从细节的地方来对其进行分析。 前面的三层已经下采样了8倍了，因此这里不是很需要再次进行下采样了，原论文是下采样16倍，因此其在layer3出还是需要再次进行下采样操作。因此在layer3,4处就将stride=1不进行下采样操作。 backbone出来以后就进入ASPP层，出来之后我们进入一个类似于FCN Head的结构将channel=num_class，最后进行双线性插值上采样输出。 DeepLab v3的pytorch代码实现本项目主要来自于pytorch官方的源码：https://github.com/pytorch/vision/tree/main/torchvision/models/segmentation 环境的配置 Python3.6/3.7/3.8 Pytorch1.10 Ubuntu或Centos(Windows暂不支持多GPU训练) 最好使用GPU训练 详细环境配置见requirements.txt 文件的结构12345678├── src: 模型的backbone以及DeepLabv3的搭建├── train_utils: 训练、验证以及多GPU训练相关模块├── my_dataset.py: 自定义dataset用于读取VOC数据集├── train.py: 以deeplabv3_resnet50为例进行训练├── train_multi_GPU.py: 针对使用多GPU的用户使用├── predict.py: 简易的预测脚本，使用训练好的权重进行预测测试├── validation.py: 利用训练好的权重验证/测试数据的mIoU等指标，并生成record_mAP.txt文件└── pascal_voc_classes.json: pascal_voc标签文件 预训练权重的下载 注意：官方提供的预训练权重是在COCO上预训练得到的，训练时只针对和PASCAL VOC相同的类别进行了训练，所以类别数是21(包括背景) deeplabv3_resnet50: https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth deeplabv3_resnet101: https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth deeplabv3_mobilenetv3_large_coco: https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth 注意，下载的预训练权重记得要重命名，比如在train.py中读取的是deeplabv3_resnet50_coco.pth文件， 不是deeplabv3_resnet50_coco-cd0a2569.pth 其他的大部分和之前的FCN类似，比如如何构建数据集、混淆矩阵、以及如何进行训练和评估等，本文主要讲解和之前不一样的部分，例如模型的搭建、学习率更新策略的设计等。 学习率更新策略的实现下面是创建学习率更新算法的主要代码： 12345678910111213141516171819202122232425def create_lr_scheduler(optimizer, num_step: int, epochs: int, warmup=True, warmup_epochs=1, warmup_factor=1e-3): assert num_step &gt; 0 and epochs &gt; 0 if warmup is False: warmup_epochs = 0 def f(x): &quot;&quot;&quot; 根据step数返回一个学习率倍率因子， 注意在训练开始之前，pytorch会提前调用一次lr_scheduler.step()方法 &quot;&quot;&quot; if warmup is True and x &lt;= (warmup_epochs * num_step): alpha = float(x) / (warmup_epochs * num_step) # warmup过程中lr倍率因子从warmup_factor -&gt; 1 return warmup_factor * (1 - alpha) + alpha else: # warmup后lr倍率因子从1 -&gt; 0 # 参考deeplab_v2: Learning rate policy return (1 - (x - warmup_epochs * num_step) / ((epochs - warmup_epochs) * num_step)) ** 0.9 return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=f) 输入的参数 num_step：每个epoch里面有多少步； epoch：这个训练一共有多少循环epoch； warmup=True：是否需要进行热身训练，一般情况下都是为True的； warmup_epochs=1：热身训练持续的多少个循环epoch，默认是1； warmup_factor=1e-3：在热身阶段就是将学习率从warmup_factor逐渐递增到1的一个过程。 内置实现函数 开始的时候，默认情况是进行warmup的，于是将学习率从warmup_factor逐渐递增到1，到第二个epoch之后就是按照DeepLab v2里给出的策略进行训练。 12345678910111213# 创建学习率更新策略，这里是每个step更新一次(不是每个epoch)lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), args.epochs, warmup=True)# 学习率变化的可视化import matplotlib.pyplot as pltlr_list = []for _ in range(args.epochs): for _ in range(len(train_loader)): lr_scheduler.step() lr = optimizer.param_groups[0][&quot;lr&quot;] lr_list.append(lr)plt.plot(range(len(lr_list)), lr_list)plt.show() 模型的创建整体模型的搭建 上面为创建模型的主要代码，其中大部分和之前的FCN很像，我猜想可能是开发模型的那些人想要让代码复用性更好，方便模型和框架上的统一才这样做的。其中就比如DeepLab v3中本来就没有用辅助分类器，但是这个模型就加了辅助分类器。 这里的导入预训练的部分其实就是和之前的效果一样。 先导入在COCO数据集上预先训练好的模型权重。 之后删去分类的部分，因为其对应的类别肯能和自己的任务不同。 最后就剩余权重导入到模型中去。 下面我们进入第一步创建deeplabv3_resnet模型的代码，该代码主要在deeplabv3_model.py的文件下。 123456789101112131415161718192021222324252627def deeplabv3_resnet50(aux, num_classes=21, pretrain_backbone=False): # 'resnet50_imagenet': 'https://download.pytorch.org/models/resnet50-0676ba61.pth' # 'deeplabv3_resnet50_coco': 'https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth' backbone = resnet50(replace_stride_with_dilation=[False, True, True]) if pretrain_backbone: # 载入resnet50 backbone预训练权重 backbone.load_state_dict(torch.load(&quot;resnet50.pth&quot;, map_location='cpu')) out_inplanes = 2048 aux_inplanes = 1024 return_layers = {'layer4': 'out'} if aux: return_layers['layer3'] = 'aux' backbone = IntermediateLayerGetter(backbone, return_layers=return_layers) aux_classifier = None # why using aux: https://github.com/pytorch/vision/issues/4292 if aux: aux_classifier = FCNHead(aux_inplanes, num_classes) classifier = DeepLabHead(out_inplanes, num_classes) model = DeepLabV3(backbone, classifier, aux_classifier) return model 如果不想适应之前的coco数据集的预训练模型，可以自己导入resnet-50在imagenet数据集上的数据来进行训练。 之后将就是重构backbone，将没有用到的模块删去。 然后使用DeepLabHead模块来构建辅助分类器和主分类器。 ASPP结构也是包含在DeepLabHead的结构里面的。 最后将分类器、辅助分类器、backbone来一同构建DeepLab V3大模型。 这里的是实现的过程和之前的FCN网络相同，其具体实现的代码如下： 1234567891011121314151617181920212223242526272829class DeepLabV3(nn.Module): __constants__ = ['aux_classifier'] def __init__(self, backbone, classifier, aux_classifier=None): super(DeepLabV3, self).__init__() self.backbone = backbone self.classifier = classifier self.aux_classifier = aux_classifier def forward(self, x: Tensor) -&gt; Dict[str, Tensor]: input_shape = x.shape[-2:] # contract: features is a dict of tensors features = self.backbone(x) result = OrderedDict() x = features[&quot;out&quot;] x = self.classifier(x) # 使用双线性插值还原回原图尺度 x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False) result[&quot;out&quot;] = x if self.aux_classifier is not None: x = features[&quot;aux&quot;] x = self.aux_classifier(x) # 使用双线性插值还原回原图尺度 x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False) result[&quot;aux&quot;] = x return result 这里使用mobilenetv3来实现的代码和resnet略微不同，这里不再细讲。 之前论文的作者讲过，转置卷积和双线性插值的效果相同，但是插值的计算速度快。 由于前面的部分之前已经有所介绍了，现在我们直接跳入到DeepLabHead结构中。 这里的DeepLabHead层的结构是直接继承自nn.Sequential的。 在Sequential中他写了相应的forward函数，我们如果不需要重写的话，就可以只写相应的层，不去重写对应的forward函数。 123456789class DeepLabHead(nn.Sequential): def __init__(self, in_channels: int, num_classes: int) -&gt; None: super(DeepLabHead, self).__init__( ASPP(in_channels, [12, 24, 36]), nn.Conv2d(256, 256, 3, padding=1, bias=False), nn.BatchNorm2d(256), nn.ReLU(), nn.Conv2d(256, num_classes, 1) ) 这个结构就是按照之前的给出的结构来直接搭建的，并且这个类是不需要重写前向传递函数的。 首先将backbone里面的信息输入到ASPP里面进行多尺度融合； 然后将其输出输入到一个Conv3x3的网络进行信息提取； 之后通过一个Conv1x1的卷积，其实是作用和全连接层类似，将通道数变成和类别数一样； 最后将输出进行二维插值还原到原来的尺寸。 ASPP结构的实现下面我们来对ASPP的实现进行分析。 这里的输入参数为输入通道的通道数in_channels和膨胀系数atrous_rates。 后面建立第一个分支Conv1x1模块的部分。 然后分别来构建其余的几个带有膨胀系数的Conv3x3的块，这里首先atrous_rates列表化，然后遍历每个系数，来创建不同的ASPPConv块。其实现的代码如下： 1234567class ASPPConv(nn.Sequential): def __init__(self, in_channels: int, out_channels: int, dilation: int) -&gt; None: super(ASPPConv, self).__init__( nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU() ) 最后再加入一个全局的池化层，其代码如下： 12345678class ASPPPooling(nn.Sequential): def __init__(self, in_channels: int, out_channels: int) -&gt; None: super(ASPPPooling, self).__init__( nn.AdaptiveAvgPool2d(1), nn.Conv2d(in_channels, out_channels, 1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU() ) 这里将上述创建好的几个并联的模块放到nn.ModuleList中，再创建一个映射层来融合上面五个通道中的输出。 最后，实现前向传播函数，其中遍历上述nn.ModuleList里面的所有的模块，计算x通过上面五个结构之后的输出，将输出concatenate后导入到信息融合层中处理得到最后的输出。","link":"/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/DeepLab-Vx%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"LR-ASPP语义分割网络及代码实现","text":"hljs.initHighlightingOnLoad(); LR-ASPP基于MobileNetv3中提出的，非常适合于移动端上的步部署。 其backnone部分是一个mobilenet v3网络在构建时主要就其feature部分的stride=2的部分提取出来，Head部分优点类似于之前的FCN网络。 基本理论首先，我们来回顾一下之前学习的语义分割网络。 尽管速度非常快，但是其预测得到的mIoU就相比之下非常低。因此研究就是再精度和速度之间进行取舍的。 左边是MobileNetv3网络，右边就是一个分割头Segmentation Head. 对于MobileNetv3网络部分，为了打造一个轻量级的语义分割网络，这里进行16倍的下采样。 对于Segmentation Head部分，上面进行了一个Conv1x1来进行通道的调整，下面进行了一个类似于SEnet的自注意力机制。将两部分相乘后进行一次2倍的双线性插值的上采样，之后将通道数有128变成num_class。最后，将下采样八倍的特征层引过来，通过Conv1x1来讲通道数变成num_class，和主特征图相加后进行八倍的上采样。 Pytorch实现LR-ASPP的主要代码以下是实现Pytorch网络的总图，其主要的是模块分为两部分，一个MobileNetv3的具体实现的部分，另一部分是Segmentation Head的部分。 MobileNetv3部分加入膨胀卷积后的MobileNetv3的实现部分，由于仅仅需要下采样16倍即可，因此倒数第四层的stride=1，并且从这层开始后面的层全变成rate=2的膨胀卷积。 Segmentation Head的部分这里其实进行了一个类似于SE-Net的通道自注意力机制层，类似于早期FCN结构，先进行2倍的上采样，之后再和MobileNetv3部分8倍的下采样层进行融合操作，之后将融合的结构进行8倍的上采样。 注：这里的num_class是包含背景类别的。 具体代码实现这里语义分割系列的训练和测试代码几乎大同小异，因此此处不在进行赘述，下面主要就模型的建立部分进行介绍。 首先，在train.py里的创建模型函数的代码如下： 12345678910111213141516171819def create_model(num_classes, pretrain=True): model = lraspp_mobilenetv3_large(num_classes=num_classes) if pretrain: weights_dict = torch.load(&quot;./lraspp_mobilenet_v3_large.pth&quot;, map_location='cpu') if num_classes != 21: # 官方提供的预训练权重是21类(包括背景) # 如果训练自己的数据集，将和类别相关的权重删除，防止权重shape不一致报错 for k in list(weights_dict.keys()): if &quot;low_classifier&quot; in k or &quot;high_classifier&quot; in k: del weights_dict[k] missing_keys, unexpected_keys = model.load_state_dict(weights_dict, strict=False) if len(missing_keys) != 0 or len(unexpected_keys) != 0: print(&quot;missing_keys: &quot;, missing_keys) print(&quot;unexpected_keys: &quot;, unexpected_keys) return model 这里和之前一样，我们可以载入基于coco数据集预训练得到全局的数据集。也可以单独导入在mobilenet在Imagenet上的预训练权重。 下面是创立mobilenetv3的代码： 123456789101112131415161718192021222324def lraspp_mobilenetv3_large(num_classes=21, pretrain_backbone=False): # 'mobilenetv3_large_imagenet': 'https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth' # 'lraspp_mobilenet_v3_large_coco': 'https://download.pytorch.org/models/lraspp_mobilenet_v3_large-d234d4ea.pth' backbone = mobilenet_v3_large(dilated=True) if pretrain_backbone: # 载入mobilenetv3 large backbone预训练权重 backbone.load_state_dict(torch.load(&quot;mobilenet_v3_large.pth&quot;, map_location='cpu')) backbone = backbone.features # Gather the indices of blocks which are strided. These are the locations of C1, ..., Cn-1 blocks. # The first and last blocks are always included because they are the C0 (conv1) and Cn. stage_indices = [0] + [i for i, b in enumerate(backbone) if getattr(b, &quot;is_strided&quot;, False)] + [len(backbone) - 1] low_pos = stage_indices[-4] # use C2 here which has output_stride = 8 high_pos = stage_indices[-1] # use C5 which has output_stride = 16 low_channels = backbone[low_pos].out_channels high_channels = backbone[high_pos].out_channels return_layers = {str(low_pos): &quot;low&quot;, str(high_pos): &quot;high&quot;} backbone = IntermediateLayerGetter(backbone, return_layers=return_layers) model = LRASPP(backbone, low_channels, high_channels, num_classes) return 这里我们在做好导入权重的部分之后，就将features的部分进项提取。 首先，通过第一个命令主要是将我们feature层的首尾已经stride=2的层取出来，这里self.is_strided = cnf.stride &gt; 1. 之后，就是将对应的提取出下采样8倍的层和下采样16倍的层。并取出其对应的out_channels 12low_pos = stage_indices[-4] # use C2 here which has output_stride = 8high_pos = stage_indices[-1] # use C5 which has output_stride = 16 最后，就直接将我们的网络进行重构操作。 下面是构建LRASPP类的代码： 12345678910111213141516171819202122232425model = LRASPP(backbone, low_channels, high_channels, num_classes)class LRASPP(nn.Module): __constants__ = ['aux_classifier'] def __init__(self, backbone: nn.Module, low_channels: int, high_channels: int, num_classes: int, inter_channels: int = 128) -&gt; None: super(LRASPP, self).__init__() self.backbone = backbone self.classifier = LRASPPHead(low_channels, high_channels, num_classes, inter_channels) def forward(self, x: Tensor) -&gt; Dict[str, Tensor]: input_shape = x.shape[-2:] features = self.backbone(x) out = self.classifier(features) out = F.interpolate(out, size=input_shape, mode=&quot;bilinear&quot;, align_corners=False) result = OrderedDict() result[&quot;out&quot;] = out return result 其主要的输入为backbone、low_channels、high_channels、num_class. 这里的backnone部分为就是之前对定义的那个mobilenet v3，之后classifer部分就是Segmentation部分。其对应的类为LRASPPHead。 首先，取出对应的高和宽的参数； 之后，一次向着backbone和classifier进行传播； 最后，进行一次线性插值，将结果记录在一个有序字典集result中。 下面是LRASPPHead具体的实现部分的代码： 123456789101112131415161718192021222324252627282930class LRASPPHead(nn.Module): def __init__(self, low_channels: int, high_channels: int, num_classes: int, inter_channels: int) -&gt; None: super(LRASPPHead, self).__init__() self.cbr = nn.Sequential( nn.Conv2d(high_channels, inter_channels, 1, bias=False), nn.BatchNorm2d(inter_channels), nn.ReLU(inplace=True) ) self.scale = nn.Sequential( nn.AdaptiveAvgPool2d(1), nn.Conv2d(high_channels, inter_channels, 1, bias=False), nn.Sigmoid() ) self.low_classifier = nn.Conv2d(low_channels, num_classes, 1) self.high_classifier = nn.Conv2d(inter_channels, num_classes, 1) def forward(self, inputs: Dict[str, Tensor]) -&gt; Tensor: low = inputs[&quot;low&quot;] high = inputs[&quot;high&quot;] x = self.cbr(high) s = self.scale(high) x = x * s x = F.interpolate(x, size=low.shape[-2:], mode=&quot;bilinear&quot;, align_corners=False) return self.low_classifier(low) + self.high_classifier(x) 上述网络和代码的对应关系如下：","link":"/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/LR-ASPP%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"U-Net网络及代码实现","text":"hljs.initHighlightingOnLoad(); 本文简单介绍关于U-Net网络的内容，并基于 Pytorch 进行实现。这里对U-Net进行一定程度上的修改，增加了padding使得其输入和输出相等，方便之后的改进操作。 概述下图就是著名的U-Net网络主要发表在著名的上午影像期刊的MICCAI上面，由于发表时是2015年，因此其对应的一些网络的搭建比较简单。 本文的结构是典型的Encoder-Decoder类型的，encoder部分对应的是contracting path部分，而decoder对应的expansive的部分。 上图反应出几个明显的缺点： 首先，这是一个比较早期的工作，BN层还没有广泛地适用。 其次，就是原论文对于维度地把握不是很到位，图像的H,W在进行残差层的时候经常有拼接不上的情况。并且输入和输出的维度对不上。现在经常对卷积层进行padding操作。 对于我们高分辨率的图像来说，其主要的操作是将图片分块处理，否则显存是明显不足的。之后将相邻框选时要有重叠的部分，这样可以更好的对边界部分进行分割。 如下图所示，为真实图片和一般的实例分割与语义分割的效果图，可以发现在细胞边界部分处效果不是很稳定。 于是在训练的时候将细胞和细胞之间的边界的区域在损失函数里训练的权重值增大。但是文章作者并没有进行消融实验，具体的效果定的量分析。 具体的代码实现本项目主要参考的开源仓库有如下两个： https://github.com/milesial/Pytorch-UNet https://github.com/pytorch/vision 其环境的配置、代码的训练和测试的部分都与之前的FCN、DeepLab v3、LR-ASPP都是很相似，于是这里就不多赘述，将关注的重点放在模型的搭建上。 代码文件的主要结构： 1234567├── src: 搭建U-Net模型代码├── train_utils: 训练、验证以及多GPU训练相关模块├── my_dataset.py: 自定义dataset用于读取DRIVE数据集(视网膜血管分割)├── train.py: 以单GPU为例进行训练├── train_multi_GPU.py: 针对使用多GPU的用户使用├── predict.py: 简易的预测脚本，使用训练好的权重进行预测测试└── compute_mean_std.py: 统计数据集各通道的均值和标准差 up的GitHub仓库对应的地址为：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/75f81bff3f2ca53866ece59042ad0a473f2fb930/pytorch_segmentation/unet 上面有本项目使用的数据集，源代码资源。 模型的搭建模型的结构如图，这里按照上述两个比较权威的开源仓库来进行绘制的，基于经验双线性插值的速度比装置卷积的速度快，于是上采样部分就基于上线性插值来对网络机进行构建。 值得注意的是，这里的下采样还是直接使用Maxpool 2x2。每个网络都固定，都是一个下采样接两个卷积操作。 FCN网络上说直接下采样会造成分割时清晰度的下降，于是使用膨胀卷积。 由于这里U-Net网络的模块比较好，这里按照模块来对网络进行不同的操作。 下采样网络块首先，构建的是下采样层的操作。 构建每个下采样之后都会接上两个卷积的操作。 123456789101112class DoubleConv(nn.Sequential): def __init__(self, in_channels, out_channels, mid_channels=None): if mid_channels is None: mid_channels = out_channels super(DoubleConv, self).__init__( nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(mid_channels), nn.ReLU(inplace=True), nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True) ) 这里和之前的DeepLabv3一样，对应不需要重写前向传播的函数，就直接继承nn.Sequenttial即可。 这里有个重要的参数就是mid_channels，就是一般情况下两个卷积输入的in_channels，out_channels和两个卷积之间的mid_channels都是一样，因此一般情况下这个参数为设为None。但是也有特殊情况，就是我们使用双线性插值时，因为双线性插值不同于转置卷积可以修改通道的维度，于是我们就要在这个两个卷积层上修改输出的参数out_channels=in_channels//2. 下面将一个Maxpool和之前连续卷积层DoubleConv进行合并： 123456class Down(nn.Sequential): def __init__(self, in_channels, out_channels): super(Down, self).__init__( nn.MaxPool2d(2, stride=2), DoubleConv(in_channels, out_channels) ) 于是就将下采样层构建完毕，下面来构建上采样网络块。 上采样网络块其中上采样层也用到了两个连续的卷积操作，但是对应使用双线性插值的块由于其不能改变维度，因此要尝试在DoubleConv上将维度进行修改。 1234567891011121314151617181920212223class Up(nn.Module): def __init__(self, in_channels, out_channels, bilinear=True): super(Up, self).__init__() if bilinear: self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) self.conv = DoubleConv(in_channels, out_channels, in_channels // 2) else: self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2) self.conv = DoubleConv(in_channels, out_channels) def forward(self, x1: torch.Tensor, x2: torch.Tensor) -&gt; torch.Tensor: x1 = self.up(x1) # [N, C, H, W] diff_y = x2.size()[2] - x1.size()[2] diff_x = x2.size()[3] - x1.size()[3] # padding_left, padding_right, padding_top, padding_bottom x1 = F.pad(x1, [diff_x // 2, diff_x - diff_x // 2, diff_y // 2, diff_y - diff_y // 2]) x = torch.cat([x2, x1], dim=1) x = self.conv(x) return x 这里下采样的倍率为16，但是对应输入的图片的尺寸不一定为16的倍数，由于pytorch的下采样机制是向下取整的。于是就会出现上采样之后的尺寸小于之前图片的尺寸，导致没办法进行拼接。例如，7x7下采样后变成3x3，然后上采样可得6x6，为了满足拼接的要求，就将6x6的进行一个padding操作变成1x1. 最后，将输出层的就是一个不同的普通的1x1卷积来修改一下空间。 12345class OutConv(nn.Sequential): def __init__(self, in_channels, num_classes): super(OutConv, self).__init__( nn.Conv2d(in_channels, num_classes, kernel_size=1) ) 构建整体的网络下面基于之前给出的网络图来构建整体的U-Net网络如下： 123456789101112131415161718192021222324252627282930313233343536class UNet(nn.Module): def __init__(self, in_channels: int = 1, num_classes: int = 2, bilinear: bool = True, base_c: int = 64): super(UNet, self).__init__() self.in_channels = in_channels self.num_classes = num_classes self.bilinear = bilinear self.in_conv = DoubleConv(in_channels, base_c) self.down1 = Down(base_c, base_c * 2) self.down2 = Down(base_c * 2, base_c * 4) self.down3 = Down(base_c * 4, base_c * 8) factor = 2 if bilinear else 1 self.down4 = Down(base_c * 8, base_c * 16 // factor) self.up1 = Up(base_c * 16, base_c * 8 // factor, bilinear) self.up2 = Up(base_c * 8, base_c * 4 // factor, bilinear) self.up3 = Up(base_c * 4, base_c * 2 // factor, bilinear) self.up4 = Up(base_c * 2, base_c, bilinear) self.out_conv = OutConv(base_c, num_classes) def forward(self, x: torch.Tensor) -&gt; Dict[str, torch.Tensor]: x1 = self.in_conv(x) x2 = self.down1(x1) x3 = self.down2(x2) x4 = self.down3(x3) x5 = self.down4(x4) x = self.up1(x5, x4) x = self.up2(x, x3) x = self.up3(x, x2) x = self.up4(x, x1) logits = self.out_conv(x) return {&quot;out&quot;: logits} 实验表明，双线性插值和转置卷积的效果其实是产不多，但是双线性插值的运算速度要比之前转置卷积的速度要快。但是作者使用的数据集是一个比较小的数据集，可能在小的数据集上面的二者的效果是一直的，大的数据集上还有待检验。 其次，就是在up层的参数，本质问题还是上采样无法进行通道变换的问题。 自定义数据集 train：代表才是的数据集是训练集还是测试集，bool类型，为True代表是训练集，反之为测试集。 root：代表给出的数据集的目录路径； tranforms：代表对图片处理的方式； 在__init__里进行了一系列的路径的操作，来确定来得出图片的路径，标签的路径等。 之后检查图片的名称和格式是否正确。 下面为__geitem__操作的具体代码，这里开始时我们将图片转换为RGB图片，将manual转化为灰度图片。 这里和我们的习惯不同，一般情况下对应背景区域为0，对于前景区域为1，对于不感兴趣的区域为255。 于是这里将manual的值除以255，然后将roi_mask区域里面的不感兴趣设为255，背景变成0，最后和manual进行拼接最后得到我们的所要的mask。 后面的部分基本也和FCN比较的类似，此处不在赘述。 Dice LossDice similary coefficient主要用于度量两个几何的相似性的。 Dice=\\dfrac{2|X\\bigcap Y|}{|X|+|Y|}在语义分割任务里，X和Y的范围都是$[0,1]$之间的。当X和Y相似时，$Dice$的上下就相等结果为1，反之分子就0，$Dice$ 就等于0。 Dice\\ Loss = 1-\\dfrac {2|X\\bigcap Y|}{|X|+|Y|} 但是上述的结构仅仅限于在训练的时候这样做，在测试过程中我们一般选择概率最大的标签，因此测试过程预测出每个部分的值就是0或者1。对于上面的矩阵，将大于0.5的预测成为1，将小于0.5的预测成为0。 训练集计算Dice具体地代码的实现如下： 这里在计算的时候，我们是针对某个类别标签来单独计算，之后再来求平均值的。在计算某个标签的值的时候，将这个标签的值搞成1，不是这个标签的值不论背景还是不关注的统统示为0，之后来单独计算某个标签的Disc Loss. 具体实现的过程见我们的build_target的代码： 其中输入参数中ignore_index为不关注的数据的索引值，这里的ignore_index就为255. 12345678910111213def build_target(target: torch.Tensor, num_classes: int = 2, ignore_index: int = -100): &quot;&quot;&quot;build target for dice coefficient&quot;&quot;&quot; dice_target = target.clone() if ignore_index &gt;= 0: ignore_mask = torch.eq(target, ignore_index) dice_target[ignore_mask] = 0 # [N, H, W] -&gt; [N, H, W, C] dice_target = nn.functional.one_hot(dice_target, num_classes).float() dice_target[ignore_mask] = ignore_index else: dice_target = nn.functional.one_hot(dice_target, num_classes).float() return dice_target.permute(0, 3, 1, 2) 首先，将不关心的255变成0。 然后，构建不同类别对应的one-hot编码值，这里直接调用nn.Functional代码来直接产生的编码值。 之后，将我们不关心的部分恢复成255. 最后，由于上述操作之后，其维度就变成$[N,H,W]$-&gt;$[N,H,W,C]$，于是就需要将维度进行调整dice_target.permute(0, 3, 1, 2) 计算号target之后，将target,x导入到dice_loss函数中计算损失： 12345def dice_loss(x: torch.Tensor, target: torch.Tensor, multiclass: bool = False, ignore_index: int = -100): # Dice loss (objective to minimize) between 0 and 1 x = nn.functional.softmax(x, dim=1) fn = multiclass_dice_coeff if multiclass else dice_coeff return 1 - fn(x, target, ignore_index=ignore_index) 首先，对输入的x在channel方向计算softmax来计算其分到各个标签的概率。 之后，multiclass为True的话就计算multiclass_dice_coeff反之就直接计算dice_coeff。 最后，得到disc之后，再用1-dice就是对应的dice loss了。 1234567def multiclass_dice_coeff(x: torch.Tensor, target: torch.Tensor, ignore_index: int = -100, epsilon=1e-6): &quot;&quot;&quot;Average of Dice coefficient for all classes&quot;&quot;&quot; dice = 0. for channel in range(x.shape[1]): dice += dice_coeff(x[:, channel, ...], target[:, channel, ...], ignore_index, epsilon) return dice / x.shape[1] 这里计算其实就是分别计算每个类别dice，而求平均。 下面就是根据之前的计算公式来计算一个图片对应的dice值。 123456789101112131415161718192021def dice_coeff(x: torch.Tensor, target: torch.Tensor, ignore_index: int = -100, epsilon=1e-6): # Average of Dice coefficient for all batches, or for a single mask # 计算一个batch中所有图片某个类别的dice_coefficient d = 0. batch_size = x.shape[0] for i in range(batch_size): x_i = x[i].reshape(-1) t_i = target[i].reshape(-1) if ignore_index &gt;= 0: # 找出mask中不为ignore_index的区域 roi_mask = torch.ne(t_i, ignore_index) x_i = x_i[roi_mask] t_i = t_i[roi_mask] inter = torch.dot(x_i, t_i) sets_sum = torch.sum(x_i) + torch.sum(t_i) if sets_sum == 0: sets_sum = 2 * inter d += (2 * inter + epsilon) / (sets_sum + epsilon) return d / batch_size 这里输入的数据是一个batch的，因此需要通过一个for循环来讲单独取出对应每一张图片。 然后，找出mask中不为ignore_index的区域的索引值roi_mask。 最后，按照之前公式里面的计算的方法，计算dice，并按照batch_size取平均值。 验证集计算Disc 这里讲预测值在类别的维度上取最大值(pred.argmax(dim=1)，这里计算也是0和1来计算的，并不是像训练集那样通过概率分数来计算的。 然后进行one_hot编码，再进行修改维度排列的顺序permute(0, 3, 1, 2)。 1234567891011121314151617class DiceCoefficient(object): def __init__(self, num_classes: int = 2, ignore_index: int = -100): self.cumulative_dice = None self.num_classes = num_classes self.ignore_index = ignore_index self.count = None def update(self, pred, target): if self.cumulative_dice is None: self.cumulative_dice = torch.zeros(1, dtype=pred.dtype, device=pred.device) if self.count is None: self.count = torch.zeros(1, dtype=pred.dtype, device=pred.device) # compute the Dice score, ignoring background pred = F.one_hot(pred.argmax(dim=1), self.num_classes).permute(0, 3, 1, 2).float() dice_target = build_target(target, self.num_classes, self.ignore_index) self.cumulative_dice += multiclass_dice_coeff(pred[:, 1:], dice_target[:, 1:], ignore_index=self.ignore_index) self.count += 1 注意：pred[:, 1:]的索引是从1开始取的，因此这里是忽略了背景值的。 最后，通过成员函数来计算dice的均值。 123456def value(self): if self.count == 0: return 0 else: return self.cumulative_dice / self.count # self.count为累计的样本个数","link":"/2022/07/08/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/U-Net%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"Meta Learning概述","text":"hljs.initHighlightingOnLoad(); 在工业界研究模型的参数的时候，一般都是一个模型放到几千张GPU上来跑，但是在学习一个人有时候都分布到一个GPU，于是就会造成我们在选参数的时候相当的小心谨慎。 Machine learning 的回顾下面我们来首先来复习一下机器学习的主要内容。 其本质就是通过学习来学到一个带有很多未知参数的函数，第一步定义网络架构，其实本质上就是一个函数。 第二步就是定义好损失函数，就是我们通过定义好的函数(网络)来进行预测，定义预测是和真实值之间的距离，求和即可。 第三步就是使用梯度策略来学习，得到最好的一个网络参数。 Introduction of Meta Learning 这里的Learning algorithm 本质上也是函数，输入为训练的样本，输出为对应的模型(函数)。 但是现阶段的模型里面学习的算法部分目前还是人手工选定的。 于是我们类比之前的机器学习的方法来定义meta learning的三个步骤。 Step1：定义可以学习的内容 这里可以学习的内容包含：模型的架构、超参数、学习率等。这里将这些可学习的项定义为$\\phi$ (learning components)。 这里的Components其实也是五花八门的，这里李老师的意思是对于这里不同的component，对于的学习方法可能是不同的。 Step2：定义损失函数 我们喂给模型的数据是不同的训练任务，比如要训练一个二元分类器，其主要的样本就是不同的二元分类的任务，其中包括有苹果和橘子的分类、还有自行车和汽车的分类等。 在每个任务里面有分成，训练集和测试集。 $\\theta^{1*}$：代表是的提高适用$F_{\\phi}$算法，在训练集中学习到的参数； 之后我们将训练出的$f_{\\theta^{1}}$用在测试集的样本，并将其和真实的*Ground Truth进行比对来得到在Task1 上的损失$l^1$。 基于Task2的训练集数据，算法$F_{\\phi}$又可以得到一个bike和car的分类器，之后在测试数据的检验下，得到对应的损失$l^2$ 最后，将$F_\\phi$应用到不同的任务上面可得到整体的损失如下： L(\\phi)=\\sum_{n=1}^{N} l^n其中N是训练任务的个数。 在机器学习的问题中，我们计算损失是通过训练集来计算的，而在元学习里面，一个很大的不同就是，其损失函数是使用测试资料来计算的。 Step3：优化参数 优化时就是对损失函数计算梯度，但是如果损失函数时不可导，于是就是使用强化学习或者遗传进化算法来强行train。 其整体的架构如下所示： 这里分成训练任务和测试任务，每一种任务有分成训练资料和测试资料两个部分。 训练的过程中，基于Training Task的train set 得到分类器，然后基于Training Task的test set得到损失函数。通过学习得到学习算法 $F_{\\phi^*}$ 测试过程中，使用Testing Task里面train set，代入到学习算法里得到一个分类器，之后将Testing Task里面test set代入分离器中，观察效果。 测试任务是我们真正关心的，需要有好结果的任务，而训练任务不可以和测试任务相同或很相关。 小样本学习其实是基于元学习的，通过元学习来优化得出一个小样本的分类器或回归器。 ML和Meta learning的区别 首先，针对学习的内容来看，ML是学习一个函数，而Meta Learning学习的是一种获得函数的策略。 之后，针对训练的数据，ML里面的训练数据是一个任务的训练集，而Meta Learning里面的训练集数多个任务里的训练集和测试集，这里为了方便区分我们将训练集部分叫做Support set 将测试集部分叫做Query set. 这里将Meta Learning叫做Across-task Training(跨任务学习)，将ML叫做Within-task Training。 之后，在损失函数方面，ML是一个任务计算出来的，但是Meta-Learning是一下子多个任务在测试集上计算出来的。 最后，在Learning to initialize的文章里面将Across-task training 称为outer Loop将Within-task Training叫做inner Loop。 上述讲的都是二者的差别，但是二者也有相同的地方，比如都会出来overfitting的情况。 而且这里Meta Learning也是需要调整参数的。同时Meta Learning也是需要Development task. 一般的机器学习的方法是需要Development task，其实也就是叫做Val task，一般是不允许在test set是直接调参数的，那是tick。 What is learnable in a learning algorithm?学习初始值Gradient Descent 模型可以学习的参数里面，首先要看的就是 $\\theta^0$ ，如何找到一个好的初始化参数来加快模型的收敛。 目前最经典的学习初始化参数的方法就是Model Agnostic Meta Learning (MAML) 。 但是训练过程中其实也是需要调参和设置随机种子的。 自监督学习里面，对于没有给标签的情况来讲，一般有两种要解决方法，一种是类似于BERT那样，做填空题一样的方法来解决，其次就是使用对比学习和遮盖的方法MAE，来解决。 这里讲到预训练的目的是：因为我们Meta-Learning的目的其实优化初值，而通过预训练的参数其实就是变相的得到一组好的初始值来加快收敛。 但是两者之前也有一些区别，因为自监督的学习是不使用到标签数据的，而Meta Learning在训练是时候都要进行使用。 当Self-supervised learning还没有被正式的提出来的时候，我们所认为的预训练就是从其他的任务里训练出一种参数，作为初始值来进行预训练，这种方法也称为多任务学习。这个思路其实和Meta Learning很像。Domain adaptation or transfer learning. MAML为什么好？ 这里我们思考为什么MAML的效果会如此的好，原因是MAML是Feature Rense的，其Outer loop是尽可能的去接近我们的最后的结果的，之后inner loop是很容易就得到各自的最大值的。 在这个paper里面有另外一种方法——ANIL。 更多的细节和Meta Learning的变形，参考下面的几个视频。 学习learning rate和优化的架构上面讨论的其实对初始状态小的参数进行学习，下面将要讨论的是如何学习学习率的参数。 这里在很早之前就有一些关于相关的研究了，这里将优化器和学习率作为学习对象，在训练集上进行train，之后在测试集上进行测试操作。但是当激活函数换成RELU之后就会出现崩掉。 学习优化的网络架构当学习的目标变成Network架构的话，就是我们常说的Network Architecture Search(NAS)。 但是这里的架构的选择是无法进行求导的，于是就是使用强化学习来强行做，强行优化。 除了可以选择强化学习的方法，这里其实也可以使用进化算法。 但是其实我们也是可以对我们模型进行微分的，比如这里使用的DARTS. 学习数据增强的方法 具体地可以参考上面的文献。 给不同的数据赋予不同的权重，因为有的时候如使用SVM模型时，这个越接近margin的值对分类的贡献愈大，因此其权重应该越来越大。但是有的时候接近margin的值可能是噪声数据，可以忽略的问题，将其权重缩小。因此这里可以通过学习来进一步的学习这些权重的分布。 Beyond Gradient Descent不使用梯度下降的Meta-Learning，于是机器就发明了新的算法。 到目前为止，其实就是将训练和测试分成了两个阶段。但是metric-based的方法是就是将训练和测试过程合在一起来进行训练。 ApplicationsFew-shot Image Classification 这里的N-ways K-shot classification的主要的含义是有N个任务，每个任务有K个类别。 在Meta learning里面，如何快速找到这么多的任务呢？这里使用的是Omniglot数据来进行寻找。 这里将一个文字让20个人来进行书写。 从里面选出来20个文字，于是就得到一个20ways 1shot。测试数据就是这20个文字里面其中的一个。 N ways K class：就是在训练集选择N个文字，每个文字取K的例子，在测试集选择N个文字，每个文字取K的例子。","link":"/2022/07/12/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Meta-Learning%E6%A6%82%E8%BF%B0/"},{"title":"Deep Learning on Point Clouds for 3D Scene Understanding","text":"hljs.initHighlightingOnLoad(); 本文主要跟随PointNet和PointNet++的作者来理解如何处理点元的数据，并应用PointNet到3D目标检测和场景理解上。 3D Representation : Point Cloud三维数据的主要的表征方法有一下的几种，依次是点云(主要是通过传感器直接获取的三维数据，相当于一种原始的数据)、网格(主要是用在计算机图形学里面，是一种很适合建模和渲染的格式)、体素或栅格(主要是通过每一个小的单元来代表是否有内容，其中的八叉树是一个非常节省空间的存储方式)、RGBD(主要也用于可视化的部分，使用多个图片的表达更加直观。) 在上述形式中，使用点云进行传感是最好的： 点元是传感器得到的原始的数据，方便处理； 点元的表达形式比较的简单，相比另外的三个形式还有选择体素的大小或者选择网格面片的形式。 Previous Work在早些时候是通过人工的方式来设计点云的特征，来进行学习的。但是这些特征是基于了具体的问题进行的假设，没办法将其推广与进行细节上的优化。 早期的工作就是类比了CNN，先将点云进行体素上的扩展，因为体素的实际比较的规整，然后利用3D-CNN进行学习。 但是这样做有一个很大的缺点： 首先，其时间上的复杂度和空间上的复杂度都是很大的$O(N^3)$. 其次，如果需要很高的精度，就需要将这个体素的精度调整的很高，导致计算十分的缓慢。 最后，体素的扫描仅仅停留在表面，内部还是空心的，会导致识别上出错。 Projection：后来有人适应二维投影的方法进行识别，但是如果选择的角度不好，其训练的效果也就不佳。 Featrue extraction：这个方法是先通过手工的方法来进行提取，之后通过全连接的方法识别，但是其效果也不是很好。 如何直接在点云是实现特征的提取？ PointNet 这里PointNet就是实现了端对端的特征提取，输入点云的数据，然后自动的为我们进行分类分割和语义的理解。 就是利用一个同一的框架来进行上游的特征的提取，方便适应不同的下游任务。 模型的设计遵守两个点云的主要形式性质： 位置的不敏感的性(permutation Invariance)：点云其实是一个无序的集合。 平移不变性(Transformation Invariance)：点云的选装本质上不影响分类的结果。 permutation Invariance 如上图所示，如果将点云的信息都存储在一个矩阵里面，那么将其位置进行变换之后，这个矩阵依然表示的是同一点云。 那如何来通过一个将其$n!$个矩阵统一编码？ 这里适应的是对称函数，因此函数具有很好的不变性。 但是这样处理又产生了新的问题——如何用神经网络来构造上述的对称函数。 方法1：直接对点云的三维数据的进行取最值的操作，但是这样太过简单粗暴了，会损失很多有用的信息。 方法2：先将三维数据转换到高维空间上，其实就是将channel=3-&gt;1024，这样高维空间的信息是冗余的，之后进行取最值的操作，丢失掉一些冗余的信息，这样就减少的信息的丢失。 而且一组复合函数中，主要一个是对称的，整个函数就也变成对称的函数。 实际使用时，将编码器$h$选择了MLP，将$g$使用了maxpooling，将编码器$\\gamma$选用了MLP。 下面思考的这个点云网络，即使用神经网络可否完全涵盖所有的对称函数，二者之间是什么样的关系。 在理论上，如果函数在Hausdorff空间上是连续的话，通过增加神经网络的宽度和广度即可实现拟合所有的函数。 实际操作的难度不提，就理论而言是其效果是非常好的。 Transformation Invariance 这里T-Net的任务就是生成对应的变换的参数，之后输入到Transform模型里面，将整体的点云变成一个统一的位姿，这样的话就满足之前的平移不变性。 Transformer 其实是可以使用一个矩阵的乘法来确定的。这里是将点云整体进行旋转操作，其实也可以对点云进行编码操作，之后对编码之后的特征进行旋转操作。 这里我们可以将对变换矩阵进行正则化，使得矩阵尽可能接近于一个正交的矩阵。 PointNet 网络 上图为点云的分类网络，就是将首先将点云进行全局的旋转操作，之后将对点云进行特征编码操作，接着对编码之后的结果进行进一步的编码，然后全局池化得到一个全局的信息，最后进行分类。 对应点云的分割问题来说，其实就是对每个点进行单独的分类的任务。这里是将全局的向量分别输入到点的向量中去，然后进行特征的提取进而进行分类操作。 上图为三维的场景的分割实例。 在内存和运算速度上，其实现在的结果是远远好于之前的结果的。因此这个框架适合在硬件上进行部署操作的。 上面的效果可以看出，PointNet在点云确实的情况下具有很强的鲁棒性，那么为什么上述的效果具有很强的鲁棒性呢？ 如上所示，使用上述的可视化操作，PointNet的全局的池化操作时选出结合轮廓点，这样的话就算是缺少相关的点，其使用的效果也是鲁棒的。 PointNet++ 和这边的3D-CNN相比： PointNet要么就是对全局的信息进行处理，要么就是对单个点进行处理，没有一个对局部的部分点进行操作的模块。 其次就是平移不变性上又移动的局限，如果全局的点被整体的向右进行平移的操作之后就会出现分类的结果和原来不同。单个的物体可以使用归一化操作，但是对一个整体的场景而言，不知道要具体以那个物体作为归一化的基准。 针对上述的局限性，提出了新一代网络PointNet++ 网络基本架构 主要的操作是将整体分成多个小型的区域，每个小区域分别使用PointNet网络，并且不断地进行迭代。于是就满足了上述地性质： 多级特征学习，Hierarchical feature learning. 平移不变性，Translation invariant，由于是对局部的小特征的局部坐标进行的，于是就会有局部的不变性。 位置顺序无关性，permutation Invariance. 首先选择出来一个小的区域，将其点集进行局部归一化，之后通过一个PointNet，在新的空间上得到对应的特征点。于是多次操作就得到一个新的特征点集。 将上述的特征点进行多层局部特征的提取之后再进行分类操作。 同理进行将上述的操作进行上采样或者插值，进而得到分割后的点云图片。 参数选择对于CNN来说，卷积核的大小是可调的超参数，目前的相关研究表明，卷积核越小，效果就越好。 对于PointNet++而言，应该如何选择这个区域的大小？ 和图片相比不同的是，点云的采样时不均匀的，而图片时均匀的NxN的网络。对于点云来说时离相机近的采样密度大，但是离相机远的采样的密度小。 这里进行实验，不断地减小点的数量可以发现其效果的下降速度要快于原始的PointNet网络。 模型的修改上是将鲁棒的进行采样密度的进行识别。这里使用的是Mult-scale的方式，将一系列的半径组来进行识别的，然后将其聚合在一起，类似于InceptionNet. 之后测试可得其对于整体的场景的分割个局部的场景的分割都具有较好的鲁棒性。 如上图所示，a,c虽然几何外形不相似，但是是同一个类，a,b的外形相同，但是是不同的类。 因此提取的特征需要学习到物体表面的性质变化，而不是整个空间的位置。 3D网络在场景理解上的应用 其主要的应用主要几种在两个方面，一个是3D物体识别、另一个是流场的识别。 3D Object Detection 第一种解决的思路是基于图片来进行的，主要是一个3D Proposal Network+classification 来进行的。 但是这样做的缺点是3D的搜索空间大，因此计算的量也较大，同时其较小的物体的搜索的效果较差，效果也是有限的。 使用RGBD的图片来对物体进行估计，但是这样需要增加一些和大小相关的先验知识。同时投影也具有很大的局限性，对于估计来说有较大的误差。 基于视锥的3D物体识别 这里采取的主要得到方式是，通过3D的目标识别获取Bounding Box，之后得到3D的视锥，然后借助PointNet来完成在3D空间内的定位操作。 上面的问题主要面临的挑战是其具有很多的前景遮挡和背景的干扰在其中，我们识别的点仅仅是其中的一小部分。 下面就是主要的pipeline，首先2D确定主要的位置，建立相应的视锥面，之后使用PointNet进行分割，在视锥的范围只能来寻找三维的点云，最后基石使用PointNet来精确的确定其具体的范围，获得精确的bounding box。 相比汽车而言，其对于行人的检测效果更好，其主要的原因和显然，就是人太小的，3D很难检测，但是2D就有更高的检测的特征。 这里的主要意思可能是将原来的2D信息转换成为3D的信息，这样的话就可以很好的对图像的信息的进行理解。 对于点云的问题，其可以很好的对其进行归一化操作。","link":"/2022/08/26/Point%20Cloud/Deep-Learning-on-Point-Clouds-for-3D-Scene-Understanding/"},{"title":"图神经网络——中科院课程","text":"hljs.initHighlightingOnLoad(); 本文主要是参考的中科院沈老师的课程，主要是从CNN向GNN过渡，讨论了一些基础的理论已经图网络的表达能力。 CNN基本理论CNN的产生和发展卷积神经网络是在全连接网络的基础上发展的，因为全连接层的自由度太大，卷积网络相当于给其增加了很多先验的信息，使其方便训练，并且在图片领域获得很好的发展。 主要早图像分类、目标识别、机器翻译等欧式空间的数据中获得巨大的成功。 之后TCNN在时间序列数据上的表现超越了之前的RNN，总结发现CNN其实可以学习到很多的局部特征的信息，之后将这些局部的信息进行堆叠成为一个层次化的结构。 尽管卷积神经网路的最希望学习到的是东西是具有平移不变性、旋转不变性和尺度不变性，但是在实际的学习的过程中，其仅仅可以保证平移不变性，不过仅仅平移不变性的满足就已经使得网络具有强大的学习功能了。 如上图所示，其卷积核的形状如有图所示，当遇到相似的结构进行学习的时候，就会卷积乘除一个较大的值，这里就相当于做了目标提取的工作。 但是上述的讨论其实都是基于欧式空间的，Hinton和LeCun思考，如何让网络去适应非欧式空间的数据。 其中非欧空间里面具有代表性的结构是： 图结构Graph； 流形Manifold； 欧式空间：是由欧式距离定义出来的空间上连个点的距离叫做欧式空间。 其中的欧式距离具有三个主要的性质，包括非负，对称和三角不等式。 但是图上面使用最短路径来定于距离的时候，其不满足三角不等式的性质，因此其是非欧的距离。 于是非欧的数据给卷积的定义提出了挑战。 从CNN到GNN对于欧式空间来说，卷积很好的定义计算欧式空间数据(如网格)的算子。但是对所有非欧式空间的算子而言，卷积还是无法作为运算的算子来对非欧式空间进行计算。 其实，对于图像而言就是一个标准的格子网络如上图所示，其满足欧式距离的全部的要求。 我们PS进行图像处理其实就是和卷积的本质是类似的，就是对图像的局部和全局进行操作。 卷积的定义卷积本质是就是一个数学上的操作，将两个函数$f,g$进行卷积可以的得出另一个函数$h$，这里$h$相比$f$更加平滑。 首先是一个信号与系统中的例子，其本质就是一个一维的连续卷积。 之后是一个图像处理中的例子，其本质是一个二维的连续卷积。 这里其实有个误区，在真实的卷积的上将卷积的右下角来乘以图像的左上角的值，反着来乘的，而不是一般理解上的对应位相乘。不过其实对应学习算法来说，其卷积核的数值是可变的，通过学习获取的，因此这里其实就随便了。 如果是单单的使用使用CNN，其实并不需要对卷积理解太多。 图卷积GNN的基本理论GNN的定义目前的现有的定义方法存在两种，一种是基于谱的方法，另外一种是基于离散空间的方法。但是经过了几年的发展，发现两种方法其实是一样的，基于谱的方法其实是基于卷积的方法的特殊的情况。 谱方法：其实谱的本质就是一种空间变换。 谱方法的主要思路：通过图上的傅里叶变换来定义的卷积核。 缺点：卷积核在谱域里面是连续的，但是在节点域里面不是局部化的，这一点导致这个方法逐渐被弃用。 空间域的方法：定义了在节点域的卷积。 主要的挑战：节点域的邻接节点的相邻个数是不同的。 空间域方法的主要思路：通过求一个节点和其邻接点的加权平均值，来定义其节点上的卷积。 谱方法基本定义 首先，定义一个图结构，其主要有三个元素节点$V$，边$E$，权重$W$三个部分。 其中，定义节点的个数为$n=|V|$，于是得到加权的邻接矩阵$R^{n\\times n}$，其中权重$W\\in R^{n\\times n}$。 每个节点都有一个属于自己的属性向量，这里设属性向量是一个$R^{d\\times1}$ 的矩阵值，将其合并可得$X\\in R^{n \\times d}$ ，即每个行向量为一个节点对应的属性向量，每个列向量为定义在节点上的一个信号。 之后，来定义图的Laplacian矩阵。 首先，定义矩阵$D$，其本质上就是一个对角阵。 当定义的图是有向图时，$D_{ii}=\\sum_jW_{ij}$，即和$i$节点相连的边发权重之和； 当定义的图为无向图时，$D_{ii}$就是这个节点的度。 然后，定义拉普拉斯矩阵 $L=D-W$。 $L$ 本质上时一个Laplace算子，其在图上沿着边的方向进行求导之后的矩阵。 $L$ 算子主要刻画的是信号的平滑性。 之后，对矩阵进行标准化处理，主要的操作方法有两种： $L=I-WD^{-1}$ 单边标准化，在随机行走用的很多。 $L=I-D^{-\\frac 1 2}WD^{-\\frac 1 2}$ 对称标准化，数学性质更好。 图傅里叶变换 傅里叶变化的主要思想：就是将所有的时域上的信号都换成一系列周期信号的叠加。在这里面仅仅只有每个信号上的系数不同，相当于是使用一系列的周期信号作为基底。 对应传统的傅里叶变换是主要针对的是时域上的数据，对应图上的傅里叶变换则处理的就是图上的信息。 对于图的傅里叶变换来说，首先是对 $L$ 矩阵进行求特征值的处理 由于$L$的对称性，则为设对称矩阵，于是其对应的特征向量为相互正交的orthonormal，记为$\\{ u_l\\}^n_{l=1}$ ； 每个基对应的频率就为$\\{\\lambda_l \\}^n_{l=1}$ 是个非负数； 这里特征向量对应的特征值越大的，对应的信号的频率就越高，于是就成为了所谓的频率。 于是就可以将图的Laplace矩阵对角化可得：$L=U\\Lambda U^T$ 其中，$U=[u_1,u_2,…u_n]$，并且$\\Lambda=diag([\\lambda_1,…,\\lambda_n])$ 观察可得，当我们将Laplace矩阵 $L=D-W$ 乘以一个$[1,1,…,1]$的矩阵后，就可以为0，于是就有$L[1,1,….,1]^T=0\\cdot[1,1,….,1]^T$。 因此对应Laplace矩阵，一定会有一个特征值为0，对应的特征向量为全1矩阵。 由于这个特征向量为全一，于是对应的频率就为0，对应的特征值为0，因此就有可以将频率等效特征值了。 在得到傅里叶变化的基之后，这里就将给出的向量的坐标，通过图傅里叶变换转化到谱域上，得到谱域上的坐标值。 上面分别给出了傅里叶的正变换和逆变换过程。 卷积定理：两个信号的卷积可以看成两个信号的傅里叶变换后的带点积。 于是，这里根据上述的卷积定理可得，一个给定的信号$x$，另一个信号$y$作为滤波器，其实就是定义卷积神经网络里面的卷积核，于是将卷积计算可以转化成频域的点积运算。 其实本质上是因为在谱域的计算比较简单，转化成谱域方便计算，之后再通过线性变换将其转换回去即可。 这里$U^Ty$就是对应的参数，基于上述，将上述式子进项相应的化简可得： x*_Gy=U((U^Tx)\\cdot(U^Ty))\\\\ \\Rightarrow x*_Gy=Ug_\\theta U^Tx 这里首先定义$U^Ty=[\\theta_0,\\theta_1…,\\theta_{n-1}]^T$ ，其是一个向量值，对应的点程可以将其转化成为一个矩阵乘法的过程，设矩阵为$g_\\theta=diag([\\theta_0,…,\\theta_n-1])$ 。于是就会有上图中的三个步骤。这里的$g_\\theta$其实就要学习的参数。 首先，将节点域转化为谱域； 之后，在谱域里面进行卷积操作； 最后，使用图卷积的逆变换将谱域上的卷积结果转换到节点域上面。 于是就诞生了基于谱的卷积神经网路领域。 谱方法缺点 求基特征向量和特征矩阵其本质就是一个比较复杂的问题，不是特别的容易，这点极大的限制了这个方法的推广。 其次就算可以计算的出来对应的特征向量，但是其特征向量拼成的矩阵U也是一个满的矩阵，将节点域转换到谱域的计算也是$O(n^2)$的复杂度。 最后在节点域上是不是局部的。打个比方，相对照片上的人修改一下眉毛，就会造成其修改出来的图片鼻子也被修改的了，而卷积操作的时候，其仅仅会对周围的一个3x3的小的邻域上面就是一定的修改，不会出现牵一发而动全身的现象。 对谱方法的改进ChebyNet这里我们使用多项式方法，来将滤波器进行参数近似，于是得到 其中，当$K\\ge n$时，等号就成立了；当$K &lt; n$ 时，此时仅能保证约等于，因为参数的次数不够。 这里可以训练的参数为$\\beta_k$，代入化简时可以将变换的$U$矩阵约掉。 在改进之后，出现了以下的有点： 首先，不需要求解邻接矩阵了，这对于减小计算量来说是十分有客观的。 其次，由于$L$ 矩阵是系数的矩阵，因此其对于计算复杂度的减小来说是十分客观，从$O(n^2)$ 转化成为 $O(|E|)$ ，即对应的复杂度仅仅和网络里边的个数有关，和节点的个数无关。 最后，就是可以实现在节点域上的局部化，这里卷积被严格的限制在一个半径为K的一个球里面。 $k=1$时代表他对应的一阶邻居，k=0是代表的就是他自身。这边有时间可以看一下Laplace的矩阵对应的理论。 这里CheyNet相当于对之前滤波器空间进行了一定的限制包括： 将滤波器的形式仅仅控制到多项式的形式； 其次将参数的个数进行限制，一般的情况下，其参数的个数$k&lt;n$，这就使得其自由度极大的减小。 谱方法进一步的改进 之前是对滤波器的形式进行限制，于是就使得变换矩阵$U$被消去，这里我们的关注待点放到了U的上面。 适应小波变换的基来代替正弦变换的基，来进一步改进U的形式。 这里可以看出，小波是稀疏的，仅仅在对应的位置上是非0的，其他的部分都是0；而傅里叶变换是稠密的，周期变化的。 由于小波的稀疏性，于是就会有其具有一定的局部性，就是其仅仅可以控制离他很近的一小片的区域，对应的很大的区域是无法进行控制的。而傅里叶则相反。 于是基于上述的表述，将傅里叶变换的偏置换算成为小波的偏置。 于是就得出了一个新的神经网络的形式，为图小波神经网络。 这里p为上一层特征参数的维度，q是下一层特征参数的维度，于是计算的复杂度就是为$O(npq)$是十分复杂的参数的维度。在实际训练的过程中效果驱使不怎么样。 需要进一步的改进，因为之前的卷积是和特征变换放在一起来完成的，这里就将卷积和特征变换分开来做，即进行进一步的解耦，具体的结构如下图所示。 先进行的是特征的变换，就是将其维度进行转换。 后进行的是图卷积的变换。 于是计算的复杂度，就从原来的$O(npq)$转换成为$O(n+p*q)$了。 实验的效果如下： 实现论文中的结果如下图所示。 空间方法相比谱方法，空间方法的数学公式没有太多，比较适合工程师应用。其本质是基于类比的方法。 基于CNN的空间方法 这个方法的本质就是将CNN进行分解，提取出来他主要的做的几个步骤，看哪些步骤可以为图网络来使用，将可以使用的步骤保留，修改不可以适应的步骤。 Step1：确定邻域，这里如上图所示邻域的大小为3x3。 Step2：在邻域的内部确定顺序，其实我们默认是从上到下、从左向右的顺序，预定俗称的顺序，因此对这一步其实并没有感觉。 Step3：参数共享，相当于卷积神经网络在全连接的基础上增加对卷积核结构的上的限制，于是其才会有较好的结构好训练，但是在其表达上是弱于全连接的神经网络的。 对应图神经网络来说： Step1：确定邻居，这里上对每个点选择固定数量的邻居，就是从和这个节点直接相连的节点里面，选出距离最近的n个节点，因此只要度量距离的定义一出来就确定了一种邻域的划分。 如果一阶邻接点的个数不足，就使用二阶和三阶来凑数即可。但是前提是要先对距离进行定义。 Step2：邻域的顺序的确定，首先要确定距离的度量指标，然后分别是先一阶邻接点开始遍历排序，由小到大排列，如果有二阶邻接点的话，就继续往后排列。 Srep3：最后参数共享即可。 进一步的改进——Graph SAGE问题的由来是排序的问题会比较的复杂，比如户口本上的户主的问题，以及领导名字排序的问题(解决的办法是如果领导名字的笔划少，就按照笔划的顺序来进行排列，否则如果姓名的拼音字母小就按照拼音字母来排序)。 由于定义顺序比较的复杂，这里采取GraphSAGE的方法，主要包含两步： 首先，对应节点的选择上，采取的是随机游走采样的方法进行采样。 之后，将采样获得的点进行聚合，其实就是求平均。 具有的公式见上图所示，就是这里的上一层的所有邻接点的信号进行聚合； 然后将上一层的邻接点节点值和聚会后的聚合值一起合并，组成新的节点值。 这里的聚合值其实有很多的表示方法，可以是$\\max,\\min,\\sum,mean$ 等等，也可以使用LSTM或Transformer模型。 这篇文章的Idea还不错，但是支撑其高引用的是其图网络的数据集。 于是在此基础上，有提出了GCN的方法。 图卷积神经网络——GCN的提出这篇文章的主体的结构是十分的简单的，但是其为了显得他的工作看起来很有深度，于是其说自己是从谱方法的ChebyNet里面一路推理得出的，其主要是ChebyNet的一阶$k=1$近似的方法。 但是其并不是完全参考的谱方法，这篇文章被记住的原因是简单。 这边主要的步骤有两个： 首先，进行特征变换，其实就是变换矩阵的维度，其中$X \\in R^{n\\times d_0},W^{(0)} \\in R^{d_0 \\times d_1},W^{(1)}\\in R^{d_1\\times d_2}$ 之后，做完一层特征变换要过一次激活函数。 最后，这里的$\\hat{A}$ 是代表一次聚合，可以是对邻居求最大/最小/平均。 类比CNN，CNN里面的卷积核其实就是一种特征提取器或者是滤波器，是一个3x3的参数但是其可以堆叠成多个通道。 但是图网络GCN是刻画的是对应中心节点而言周围节点对其的重要性，即权重值，是固定的没有参数可以学，而且仅仅只有一个通道。于是可以学习的参数只有特征变化的参数，而且聚合的范围仅仅只有邻接的一个节点。 尽管这篇文章有以上的缺点，但是其比较的简单，好理解，并且其效果比较查，因此经常被拿来做Baseline来对比。 GCN的进一步改进——GAT在GCN中，由于$\\hat{A}$ 编码是硬编码的，无法修改，于是GAT通过引入Attention机制来对其进行参数化，进而提高使用的具体的效果。 在之前分析中，其聚合矩阵或Laplacian的固定的，在GAT中时通过学习获取的。 在GAT中，首先将每个节点的特征向量进行特征变换统一维度，之后将变换之后的特征向量进行self-Attention机制的自监督学习操作，学习两者之间的相似度$\\alpha_{ij}$来作为权重值 。 这里为了防止学习权重值过大，这里进行归一化处理。 这里有两个参数，一个是卷积变换的参数，另一个是特征变换的参数。并且由于卷积和特征变换可以将其做成多头的注意力机制。只有数据量足够多，其就可以有很好的效果。 另一种改进——MoNet 这篇文章上2018年CVPR上的一篇文章，其中主要的贡献是给空间方法一个一般化的定义方式； 所谓的空间方法就是定义多个核函数，之后测量每个节点之间的相似度。 之前的几篇文章其实都是在度量节点之间的相似度指标，这里可以将上述的核方法建立一个混合的模型。 计算卷积的过程可以看成：不同的方法乘以自己权重值的和，并通过学习来获取这些权重值。 谱方法和空间方法的关系这里基于MoNet给出来的主要的想法，我们类比SVM中定义相似度和核方法来对比分析中 主要的区别： 对于谱方法其本质相当于是通过核函数来进行显示的空间变换，将其转化到一个线性(欧式)空间上去处理，之后又将其换算回到之前的节点空间上，即逆变换。 不仅知道变换的核函数，知道如何转换到对应的空间上，同时又要知道如何将结果从对应空间上变回来。 对于空间方法其本质就是在现有的空间上定义出来一个相似度的公式，即kernel matrix (又叫做知识嵌入矩阵)，直接计算相似度即可。 在SVM里面其实也是，进行空间上的变换其实和直接定义相似度函数(相似度矩阵)是一样的，只要保证定义在原空间定义的相似度函数满足一定的要求就行，不需要进行变换和逆变换。 于是回看上述的MoNet的方法，其代表的空间方法其本质就是定义很多kernel function，定义的相似度函数其实就是上述kernel function的加权，其中这个权重向量需要学习获取。 下面将上述的谱方法的公式进行化简： 谱CNN：其可以将矩阵分解成n个基底，于是就化简成为多个基底相乘的加权和，权重可以理解成在不同谱空间上的坐标。于是就化简成MoNet的表达形式。 ChebyNet：将多项式进行展开，于是也可以化简成为MoNet的形式。 GCN：其本质就是仅仅使用ChebyNet前面的两阶参数，于是就形成上述MoNet的形式。但是值得注意的是，这两项的权重值是共享的。 值得思考的是，GCN的参数最少，但是其效果确实最好的，为什么？ 搞研究多让自己的脑子转，少让自己的GPU转。 下面来解释为什么上面的两个方法不如下面的GCN好的原因。 引入平滑滤波器的概念，定义了上述的描述平滑性的公式。其中$L$ 标注化之后的Laplacian矩阵。如果是标准化之前，就可以在右边去掉对应的分母项。 $x_u,x_v$可以看成是$x$的分量，$x$是一串信号向量。 $A_{uv}$ 对应的是邻接矩阵在对应位置上的系数，右边相连为1，否则就为0。 因此可得，在有边相连的两个节点的取值相差越小，越相似，则计算值就越小，越平滑。反之，二者取值相差越大，计算值越大，平滑性越差。 也可以解释为连边的节点尽可能的要相似。 根据特征值的定义：$u_i\\lambda_i=Lu_i\\ \\Rightarrow \\ \\lambda_i=u_i^TLu_i$ 。 于是$\\lambda_i$就可以看作是$u_i$的频率，或平滑度。 eg. $u_i=(1,1,…,1)^T$对应的$\\lambda_i=0$，即由于信号全称都没有变化，对应物理意义就是频率。 于是就引出了基础滤波器的概念，将 $u_iu_i^T$ 作为基础滤波器。 首先，可以将图信号$x$分解为上述的形式。 之后，将上述的基础滤波器乘到$x$上，由于正交性就将其他信号过滤，仅仅留下当前的信号基下的分量$\\alpha_iu_i$。 于是回到之前的谱CNN上： 这里的谱CNN就相当于一系列的基础滤波器的加权之和。 那么ChebyNet这种滤波的效果不好？ 因为这里使用的$L^k$对应的特征值就为$\\lambda_i^k$，相当于是个高通的滤波器。 在ChebyNet里面有很多的高通项，这样就会造成低频信号被过滤，导致整体的效果变差。 于是GCN设计了低通滤波器，仅仅保留前两项，在实际的实验效果是很好的。 谱CNN其本质上是一个单元的过滤器。 ChebyNet是一个高通的过滤器，阻止低频信号的通过。 GCN的一种低通滤波器，阻止高频信号的通过。 Graph Pooling在神经网络里面不仅仅只有卷积，还有Pooling池化，也叫下采样。在图神经网络中也叫聚合操作。目前主要的研究方法分为两种，一种是图的粗化，将相似度高的节点进行合并，另一种是节点的选择法，计算节点的重要性指标，将重要性强的节点选出来，来取代这一组节点。 原先的方法是先对图上的节点进行一次聚类，然后将类型的节点进行聚合操作。其中聚合的办法包括求最大最小以及求平均等。于是这个阶段人们乐此不疲的尝试各种图聚类的方法来提高Pooling的效果。 后来一篇论文Hierarchical graph representation的方法主要是将聚类的部分和聚合部分合二为一，然后进行端对端的学习，相当于是一种软聚类来学习一种相似性的参数来将表示是否进行聚类。于是之前对聚类方法的研究就没了意义。 具体的操作就是训练一个MLP，将节点的属性特征作为输入值，输出的是一个重要性的参数值。 比较子图的重要性参数，用参数值最高的节点来表征整个子图，放到原来的图中。 但是目前这个聚合比较有争议，因为有些任务如节点级别的任务，Image上的像素分类是不需要pooling的，但是如果做的是整个图的分类是需要pooling的。近年来，如化学结构的发现，蛋白质结构的发现，交通流识别等都是图分类的任务，是需要Pooling。 图神经网络的表达能力概述Expressive Power of Graph Nerual Networks——图神经网络以外的故事。在表达性方面，确实在一定程度上掀起了一些讨论，本来以为其和卷积神经网络一样可以掀起一次热潮，但是其仅仅掀起了一波论文，因为对其带来改变的领域里面。 图半监督学习是图网络标准研究的问题，就是一些节点上有内容，一些节点上没有内容，于是通过半监督学习来给没有内容的节点打上标签。在电商和社交网络上有较多的引用，但是在知识图谱上的效果目前还是未知。 目前，图网络的研究还是基于经验(先验知识)，启发式(瞎想瞎猜)，实验试错(就是运气好试出来)，其实这也会是科研的基本套路，当年神经网络、CNN等也是被人们称为炼金术被人质疑。 截至目前也没有很好的对表达性的解释，而对于神经网络而言，当年是先研究的他的表达性，先使用单层的神经网络来进行逻辑上符号的解释，什么“或”、“与”、“非”，但是单层无法表示“异或”的逻辑，而将其变成双层之后就可以表达，进而证明了在一定的条件下，神经网络可以拟合满足一定条件的任何函数，即神经网络具有很强的表达性，于是就将其作为一种通用的表示器来使用。 曾经图网络被用做经验性的化学性质预测，就是给定一个分子式和化学分子中每个原子的属性，对应的将是否有毒等标签输入进行训练，预测给定化学分子式来判读其是否有毒。一度在Nature上面发了数篇，引发了一定的争议。还有做地震预测的，证明其表达能力还可以。 表达能力的定义于是很多人就会问，何为表达能力，这里有两种解释。 第一种就是利用编码能力来表征，通过看网络以表征多少东西，即可以用多少位的二进制编码来表示。eg. 5个bits可以表征32个类别状态。 另一种就是用近似器的近似能力来进行理解，这里以神经网络为例： 一层感知机不是一个通用的近似器，他连异或都搞不定。 多层感知机给我们提供了一个通用的近似器，并且其表征能力是随着层数呈现指数上升的特点，如果增加节点的数目则是呈现线性上升，这也就是为什么深度学习可以这么成功。 应用下图是利用不同层数的GCN进行分类的问题，如果使用单层的GCN是没办法区分上述这么多的节点。 如果将GCN的层数增加到两层，于是就可以将上述多有的节点进行区分。 同时存在一种网络，无论你的GCN层数有多深，都是没办法区分所以的节点。 具体的例子如下图所示，给出的两种结构是不一样的，但是GCN不管怎么做也无法区分上述的两种网络。 原因是GCN主要刻画的是一个以一个节点为中心展开的树状结构，相当于是用一个树来刻画一个图结构，上述以每个节点展开的树形结构都是相同的。其表达能力是存在上限的。 下面如何检测两个图是同构的，怎样检测出来？这里使用比较多的方法是WL测试。 WL测试(同构测试) 主要的方法的步骤为： 使用TF方法，信息检索里面的一种办法： 首先比较的是每个节点的节点值的频次，如第一个图有1个1、3个2、2个6，第二个图2个1、1个2、3个6，于是结构都不需要比九已经判断出两个图不一样，不是同构的。 之后如果频次相同，就将节点值的旁边标记上各个邻接节点值，然后再次进行比较。 如果一阶邻居也相同，就比较二阶、三阶等邻居，不断重复下去。 如果不断重复无穷大次还是没有比较出来，于是就是同构，但是如果中间有一次对不上，于是就不同构了。因此这个测试的主要目的是证伪，不是证实。 由上面的图可知，WL测试的内核其实是一个树状的结构，其是一个rooted subtree的结构，就是求邻接点求导二阶邻接点就又得到的是自己本身的情况。 基于这种情况GCN在设计是就没有求一阶邻接点以上的节点，其实不想卷积网络不断增加深度可以是表达能力指数上升，图卷积的随着邻接点的阶数不断升高，其表达存在上限。 Connection Between GNN and WL test学有余力的同学可以来看一下。 在论文里又个很重要的概念，即表达能力如何验证，就是看在训练集的准确性。 表达能力强的网络，在训练集上拟合的效果就是越强，来一个更复杂的东西就可以拟合的更近。如二次函数的表达能力就超越一次函数，在训练集上拟合的更好。 随着训练次数的增加，看训练集最后的结果拟合的能力能力上限越高，其表达性就越强。 而整理泛化能力的效果是看的是建立在测试集test set 上的结构。(不是验证集也不是训练集)。 对应一些神经网络，其表达能力强，但是现在的优化技术不是很强，导致其train不好，在测试集上的泛化能力很差，即过拟合了，典型的例子就是全连接神经网络。 表达能力是网络能力的上限，随着优化理论的深入，训练能力的不算增强，其泛化能力会越来越好，于是就网络的表达能力才是衡量网络能力的最终标准。 科研可以随风起舞，但是不能跟风跑。 这里对表达能力的研究其实就是让我们对GNN的能力有个客观的理论上的理解。 GNN对于图分类来说，已经被证实是无法做到通用近似器。 GNN对于节点的分类来说，是可以做到通用的分类器的。对于真实世界的图来说，就算不用节点处的属性特征也是可以通过WL test区分出来的，并做到通用的分类器的。 对于特定类型的任务来说，追求通用的表达能力其实也是不现实的，因为在通用的表达能力上CNN要比GCN高很多，但是对于这种特殊的问题来说，GCN的效果会更好。 对于比较卷的红海来说，要思考是否要继续内卷，自己的优势在能力，什么时候全身而退。 我们真正需要的是，通过相似的对象，映射处一个相似的表达，方便下游任务的图神经网络，如图上的预训练、对比学习、自监督等。 有人可能会问，不同的图之间可否实现迁移学习？从工程师的角度来看，就是二话不说直接GPU去试试，一般情况是又效果的额，但是效果不一定好，因为毕竟图结构相差过大的话，迁移过去一样不是很大。 图神经网络的发展其实近期也走到了尾声，这五年是蓬勃发展的时期。如果你是搞理论的，很不幸现在肯就剩下几个难啃的骨头问题了，但是如果你是搞应用的，那么现在才是刚刚开始，未来可期。","link":"/2022/08/26/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E4%B8%AD%E7%A7%91%E9%99%A2%E8%AF%BE%E7%A8%8B/"},{"title":"图神经网络——人大课程","text":"hljs.initHighlightingOnLoad(); 本文主要整理了人大的魏老师关于图神经网络的研究以及一些讨论，总的来讲其主要偏数学一点，并且图神经网络的研究还是处于瓶颈期。 以下是本节课程的主要的内容。 图神经网络的应用案例 还有一些网络结构不太像图，但是也可以近似的看成是图。 图网络的概述图的定义 在图论的研究中，经常使用一些矩阵来对图进行表征学习，其中具有代表性的矩阵有邻接矩阵、拉普拉斯矩阵以及节点的特征矩阵。 首先来看邻接矩阵，对于无向图而言，邻接矩阵就是刻画节点之间是否相连，如果有相连的情况就为1，否则就是为0。对带权的无向图而言，邻接矩阵上面的值就换成两个相连节点之间的边的权重值。 对于无向图而言，上述矩阵就是一个对称的矩阵。对于有有向图而言，由于其节点的边是单向的，于是就不是对称的矩阵。 在图网络的研究中，一般将其假设为一个无向图来研究和讨论。 然后我们来看度数矩阵，这个度数矩阵，主要刻画的是和每个节点相连的邻接点的个数。其中度数矩阵是一个对角矩阵。 同时，在不带权的无向图中，其对数矩阵对角线上的值其实就是邻接矩阵对应行的行和。$D_{ii}=\\sum_jA_{ij}$ 然后，对矩阵进行归一化可得： 进而使用度数矩阵来求解标准化之后的邻接矩阵如下： 注意这里老师的PPT写错了，倒数两行的这边没有对称。 最后来求解最重要的标准化后的拉普拉斯矩阵。 这边老师较快的讲解了其主要的矩阵，细节的部分可以参考沈华伟老师的图网络的课程，就是拉普拉斯是先有了一般的拉普拉斯矩阵$L=D-A$，之后再进行的归一化操作，而且归一化有两种一种是不对称的归一化$L=I-D^{-1}A$，另一种是对称的归一化操作$L=I-D^{-1/2}AD^{-1/2}$ 。 在实际的工程应用的时候，每个节点都会伴随着很多的特征，每个属性特征就可以写成一个$f$ 维的特征向量，于是将所有的特征向量进行拼接就可以得出一个特征矩阵$X \\in R^{n \\times f}$ 。 有了特征矩阵之后，就可以将其和图的拓扑结构联系在一起，来学习预测节点和整个图的某些性质。 图卷积网络GCN——图网络的革命图网络真正的火起来是建立在GCN的设计和发现上，其主要的创新在于其引入节点和一阶邻域节点的聚合操作，类别CNN设计出树状的卷积核结构来解决图上的聚合问题。 其主要的消息传递机制如下： $P$ 矩阵的上面加了波浪线，其实就是在原图的每个节点上增加了自环后矩阵。如果用之前沈老师的思路来理解就是将图结构对应的拉普拉斯矩阵用一个矩阵多项式来近似，这个GCN仅仅应一个一次的矩阵多项式来逼近。 $H^{(l)}$代表的是上一层的特征矩阵，是上一层的所有的节点向量拼接成的。 $W^{(l)}$ 代表的是$l$转换到$l+1$层的特征变换矩阵，因为一次图卷积主要包含两个步骤，先聚合之后进行特征变换，再将结果过一次激活函数RELU就得到下一层的结果。 上图为了简单所示，将上面的特征矩阵换成一个单位阵。 在聚合的时候，先自环，后计算归一化的系数，其实简化来说就是除以两个节点的度开根号： X(0,1)'=\\dfrac {X(0,1)} {\\sqrt{deg(V_0)} \\sqrt{deg(V_1)}} 上述度数的计算是加上自环之后的。 对应节点0来，使用求和的聚合方法来计算，就可以得出节点0聚合之后的结果： X_0=[\\dfrac 1 {\\sqrt{4}\\sqrt{4}},\\dfrac 1 {\\sqrt{4}\\sqrt{3}},\\dfrac 1 {\\sqrt{4}\\sqrt{5}},\\dfrac 1 {\\sqrt{4}\\sqrt{2}},0,0 ]类似的图神经网路和卷积神经网络有一定的相似之处： 但是二者也是有一定的区别： 首先，GCN仅仅只有一个通道，而CNN可以定义多个通道； 其次，CNN的权重是需要学的，但是GCN的权重是根据图的结构固定的，其仅仅和节点的度有关。 图神经网络的任务 节点分类的任务，同时也是一种半监督学习的任务，其本质上就是一直一些节点的标签，通过算法来预测未标记的节点上的标签。 连接预测任务，其本质上也就是用来预测两个点是否有节点相连的问题。主要用在商品推荐的任务上面。 社区发现任务，其本质上就是进行图聚类任务。 交通预测，就是将每个地标简化成一个节点，交通流量其实就是边上的权重参数。 药物研发，本质就是将化学有机物的化学结构输入，输出的是对应的化学性质，目前是图网络的主要应用。之前对应药物结构的研究是就与NLP里面的文本结构来进行的，将药物结构转化成一种文本形式。 目前在50个原子之内的研究还是可以的。但对于的超大分子的蛋白质还是有一定的。 图网络的三个不同视角滤波器——GNN的谱域解释图信号在图神经网络之前就有关于图信号处理的相关的研究，因此图神经网络的研究其实相比之下比不是很新鲜的研究方向。 这里可以使用图信号处理的思想来看带图网络问题。 图网络结构式基于地图上面的路网图的； 节点属性是基于测量到当地的实际温度，有一定的测量噪声在里面。 因此，想要通过该节点的邻居节点的温度来对其测量值进行Smooth平滑处理，图信号处理。 通过将图信号乘以对应的拉普拉斯矩阵$L$，来将图信号从中心节向邻接点上面转移。 第一种乘以 $2I-L$ 得到的邻接点上面的图信号是正的； 第二种乘以 $L$ 的得到的邻接点上面的图信号是负的。 图傅里叶变换 得到的特征值$\\lambda_i \\in[0,2]$，并且是可以取到0的，在沈老师的课中，这个参数对应的是信号的变换的频率。 图傅里叶变换相当于将图信号从原来的特征空间变换到以$\\{u_i\\}_{i=1}^n$为基底的正交的向量空间上去。 矩阵论里面关于线性变换的部分需要复习一下。 如左图所示，其本质上是将将一个信号用多种不同频率的正弦信号来逼近出来。相当于将时域上的信号变到频域上不同信号的线性组合。 如右图所示，是一个和时域相关的比较简单的图，求解其拉普拉斯矩阵的特征值和特征向量可得图上所示。 当$\\lambda_0=0$时，其对应的特征向量是一个const向量，可以看出其基本是不变的，看成其频率就是0； 随着特征向量的变大，其求得特征向量的频率也在不断变大，并且其对应的特征值是正交的； 最大的特征值$\\lambda_n=2$时，因此频率最大的向量，向量的值时一正一负交替变化的。 Ring Graph的意义就时将正无穷和负无穷相连的实数轴。 图傅里叶变化和傅里叶变化时等价的。 其本质的变化时首先从节点域(空域)变换到频域，之后在频域上进行滤波操作，然后再将滤波之后的信号变回到节点域上。 这里举个例子就是给一个图信号增加了白噪声。然后使用一个低通滤波器将白噪声去除后可以近似的还原之前的原始信号。 图网络在节点域上节点分类的问题有相当多的应用。 同异配图是在图学习里面比较重要的内容。 同配图：连有边的点，其之间性质是比较相似的，以美国两个党派之间的关系网络为例。 异配图：连有边的点，其之间的性质是相反的，这里以公司之间的上下层之间的归关系为例。 对于同配图来说，其使用比较多的是低通滤波器，对应的特征向量是全1向量，最后可以预测出每个节点的值都是相同的。 对于异配图来说，其使用较多的是高通滤波器，对应的特征向量是一正一负交错的，于是预测出来的每个节点的值是相反的。 图卷积和滤波器 之前沈老师的课程里面也是有这个的，图卷积在数学公式上可以转换为图滤波的表达方式。 在真实的使用过程中，求解特征向量的过程是需要很多的求解特征根和特征向量的操作，计算量过大。 现在一般都是通过矩阵多项式来近似求出滤波器的表达式的。 可以观察到我们滤波器对应的特征矩阵是对角阵，比较适合矩阵多项式的化简操作。 ChebyNet和GCN在沈老师的课上没有仔细说，这个网络上基于函数逼近的理论来提出的，于是在函数的比较暗逼近里面用的比较多的多项式就是chebyshev多项式。 chebyshev多项式拟合的误差一范数最小。 但是很可惜，由于chebyshev多项式通高频阻低频的性质使得使用上述方法计算得到的结果其实并不是很好。 在此基础上，我们仅使用前两阶的多项式来进行拟合，于是得到了GCN网络。 不仅仅使用的次数减小了，并且参数的数量也大大的减小的了。 $D^{-1/2}AD^{1/2}$的前面加了$I$，就相当于每个加自环。 在实际的实验的过程就会发现，其仅仅在只有两层的时候会出现较好的效果，这就是所谓的过平滑问题。 在我们进行才重归一化的前后，对应的滤波器的函数都是一个线性的低通滤波器。 当我们将的层数逐渐的变多后，得到滤波函数不断地累乘，其低通的效果不断地累计，使得高频的信号被彻底的过滤。 于是出现的上述过平滑的现象，随着层数的上升，对应效果会变得越来越差。 上图是去年来最小的工作，利用最简单的多项式基来进行参数上使得学习。 但是尽管其得到的参数是相比之前的参数有很大的提高，但是这个模型没有可解释可解释性，学习不到很好滤波器。 BernNet 对应滤波器而言，其值本来是不可以小于0的，因为小于零会造成信号在正负之间不停的抖动，不稳定。因此要最起码保证信号在$[0,2]$上是大于等于0的。 由于上述的多项式的基是正负之间相互转化的，因此就会造成我们不能仅单单的控制其权重的数值，最好的方法是找一个多项式，使其满足在$[0,2]$上面保证其有非负的性质。 其结构近似于一般的二项分布。 没有其他别的改进，仅仅就是换了一个多项式基。 这里我感觉其基函数的形式其实和小波变换比较的类似，就是仅仅在一小块是有值的，其他的地方全是0，每个位置上的数值仅仅对应了一个基函数的值。 这里实验RELU激活函数进行重参数化，使得其参数不要小于0即可。 Actor数据集，其他的数据集的效果不太理想，最后的效果还不如一个MLP，即图结构加了反而还变差了。 这里通过图网络学习到的东西其实就是一个滤波器。 通过对比学习到的系数和滤波器的形状，二者比较的接近，因此可以得出二者的可解释性是比较强的。 随机游走——GNN的空域解释随机游走和Cheerger不等式 相当于以一定的概率在图中的节点之间随机的转移，这里可以借助马尔可夫过程来实现这个过程的刻画。 在随机过程里面曾经讲到过，对应特殊的一类图来说，其在图上面存在稳态分布。 对于无向图而言，其稳态的分布可以写出来，就是每个节点上的度数除以两倍的边数。因此稳态的分布其实和起始节点是无关的。 Cheerger不等式的常见的应用 这个不等式主要刻画的问题为，从$u$使用K步到达$v$转移的概率距离节点$v$稳态的概率是存在上届的，即收敛的。 这个不等式构建了随机游走和图的拉普拉斯矩阵、图傅里叶变化之间的联系。 对于这张图的直观的解释就是，收敛到稳态的速度越慢，找到好的社区的概率就是越小。因为左边图中的节点比不容易跑到右边去的。 相比之前来说，其主要的区别是在之前的基础上增加了一些边，其收敛的速度也大大加快，但是找到的社区的质量也不断地下降。 GCN和随机游走 这里将网络在不断展开，并且去掉中间的激活函数。 然后将$P=D^{-1/2}AD^{-1/2}$代入到里面，相同的地方合并，于是上述的第K层的节点表达式就转换称为K步随机游走概率分布关系。 于是就解释了为什么会出现过平滑的问题，因为K步游走之后会逐渐的走向稳态，而忘记了初始化上节点的分布信息。 如果增加残差，那效果怎么样？ 增加Residual Connection和不加是一样的，这里会出现Lazy随机游走，最终也是会收敛到稳态； 上述的过程的转移规律为：回到自己的概率是0.5，转移到邻接点的概率平分余下的0.5。 加入残差连接可能在一定的程度上缓解过平滑的现象，但是总的来说其最终还是会陷入到稳态分布。 上述的方法是都是没有增加激活函数的情况，那么如果我们增加激活函数后过平滑现象可否进一步的改善？答案只会加剧上述过平滑的形象。 Simple and Deep Graph Convolutional Networks以上以在空域主要面对的问题，魏老师给出的解决的办法如下 主要的修改在两个方面： 残差网络是连接的初始化的$H^{(0)}$，而不是上一层。 对于特征变换矩阵是增加了单位映射，这一步其实相当于在特征变换地方进行了一个残差连接，即不进行特征变换，直接连到下一层。 首先来看使用初始节点值的残差网络，这里有个新的名字叫做带重启的随机游走。 就是增加了初始节点的残差就会造成我们会以一定的概率返回初始位置，这样就会让节点试试不会忘记初始值的信息，避免收敛到稳态造成的过平滑现象。 但看这个带重启的随机游走可能让人感觉有点陌生，但是他的另外一个名字就很熟悉——PageRank。 之后是单位映射的主要内容。 这个单位映射也相当于是一个残差连接的过程，就是相当于有一定的概率不进行特征变换直接将其连接到下一层。 上面的数据集是Cora数据集，其主要解决的论文引用之间的问题。 上面的数据集是PPI数据集，其主要是解决蛋白质属性的问题。 优化函数——GNN Deep Unfolding其主要的思路就是使用更好的能量函数来作为loss function，来更好的解决图网络的学习和优化上面的问题，使其更好更快的收敛。 用优化函数的角度来理解GCN 这个问题再沈老师的课课程上也讲到过，其实就是要控制连边相连的节点要尽可能地相似。 于是，狄利克雷能力函数其实际意义上就对应着同配图的假设，使得邻居节点的特征具有相关性。 将这个优化函数进行近端梯度下降得到的表达式加上激活函数就和GCN是一样的了。 沈老师课上讲的这个函数就相当于证明了谱域的方法和空域的方法具有一定的相似性，构建了沟通二者的桥梁。 但是这个函数可以一直进行优化直到0，这也就意味着其在最后收敛的时候，右边相连的节点其性质基本一样，即进入一个稳态分布和初始无关。那么，就会出现过平滑的现象。 这里为了解决上述由于收敛到稳态而忘记初始节点的稳态，这里在后面增加了正则化的项，就是让其在收敛的过程中既要满足能量函数最小，也要满足我们的不要忘记初始的信息。 于是我们对上述优化函数进行求导操作可得： 这个式子其实和之前GCNII里面的使用利用初始节点进行残差的表达式时一样的，这个优化函数其实在2004年就已经提出，这里魏老师相当于研究了之前的一些研究，在其基础上增加了一些改进。 于是就有以下的问题有待解决。 GNN Inspired by Classical Iterative Algorithms在此基础上，提出了下面的工作。 这里主要是将损失函数里面的拉普拉斯矩阵$L$换成能量函数$\\gamma(L)$ ，主要代表的传播的速率，赋予了简单的物理意义。 并且$\\gamma(L)$是半正定的，要不然就会造成损失函数为非凸的，不收敛。 当$\\gamma(L)=2I-L$时，此时就是的能量函数就有为相加的，同号。 这样的情况下其邻居节点的特征具有负相关，满足异配图的假设。 在损失函数的部分增加一个负数的惩罚项，之后使用近端梯度下降的方法求解可得的表达式里面相当于过了一个RELU函数。 这样就可以在损失函数里面找到RELU函数的可解释性。 对上面的函数的进行特征值分解得到一个对角线函数，解得一系列的滤波器。 将前面的条件代入到滤波器中，可得滤波器的范围是$h(\\lambda)\\in[0,1]$； 这样就和之前BernNet里面的模型参数$\\{\\theta_k\\}^K_{k=0}$ 中的 $\\theta_k \\ge 0 \\Leftrightarrow h(\\lambda)\\ge0$。 设计上述的函数来关注每条边的Smooth程度，使用切线方向来代表在切点方向来代表此处对应的函数值。 这对每个边进项细化操作就对应了GAT中的注意力机制。 因为上述的方法中，我们可以决定每条边的Smooth程度，因此在异配图上使用的效果会比较的好。 展望和总结 关于图机器学习的假设： 这里传统的机器学习是基于训练数据和测试数据的基本数据分布式相近相似的。 但是图机器学习的假设目前还不是明确，节点之间使用边进行连接的含义不是很明确的，例如同配图代表相邻的节点之间是相似的，而异配图代表相邻的节点之间是不相似的，那么到底是相似还是不相似，目前还不是很明确。 在高效计算上，其还是不想深度学习那样可以进行并行计算。 图神经网络的应用还没有被明确的开发出来，CNN——CV，transformer——NLP，但GNN——？(分子图) Q&amp;A 对于有向图而言，其边是单向的，因此其对应的邻接矩阵不是对称，进而特征值分解的结果不是正交的，于是对用有向图的谱分解上应用是比较困难的。尽管有向图上面的信息是要比无向图多的，但是其实际的效果更差。 对于无向图来说，其加上权重之后效果会更好。 transformer对于节点数很多的GNN，其适应性也不是很强，而且相似度的计算也会比较的复杂，计算得到的结果比较的平均。","link":"/2022/08/26/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E4%BA%BA%E5%A4%A7%E8%AF%BE%E7%A8%8B/"},{"title":"有限元分析与应用——应用部分","text":"hljs.initHighlightingOnLoad(); 本课程主要来源于清华大学曾攀老师的网课，这部分是第二部分应用的部分。主要包含杆梁的有限元方法、连续结构的有限元分析——空间问题和几何问题、有限元方法方法的基本性质、高阶复杂单元、有限元方法的应用领域。 Chapter 7 杆、梁的有限元分析7.1 杆单元的构建及MATLAB编程 使用几何方程来求应变场函数 下面是使用的不同的方法来获得的刚度方程。 7.2 局部坐标中的平面纯弯曲梁单元构建及MATLAB编程 7.3 局部坐标系中的一般梁单元构建 7.4 平面梁单元的坐标变换 7.5 分布力的处理 7.6 门型框架结构的实例分析及MATLAB编程 Chapter 8 连续结构的有限元分析——平面问题8.1 平面3节点矩形单元的MATLAB编程 8.2 平面4节点矩形单元的MATLAB编程 8.3 轴对称单元 8.4 分布力的处理 8.5 平面矩形薄板的分析和MATLAB编程 Chapter 9 连续结构的有限元分析——空间问题9.1 空间4节点四面体单元及MATLAB编程 9.2 空间8节点正六面体单元及MATLAB编程 9.3 参数单元的原理 9.4 数值积分 9.5 典型空间问题的MATLAB编程 Chapter 10 有限元方法的基本性质10.1 节点编号与存储带宽 有限元方法的核心就是组装刚度方程。 10.2 形状函数矩阵与刚度矩阵的性质 10.3 边界条件的处理和支反力的计算 10.4 位移函数构造与收敛性要求 常数项要存在。 10.5 $C_0$型单元和$C_1$型单元 10.6 单元的拼片实验 10.7 有限元分析数值解的精度和性质 使用有限元方法计算的值总体上是偏小的。 10.8 单元应力结果的误差和平均处理 10.9 控制误差和提高精度的h方法和p方法 Chapter 11 高阶及复杂单元11.1 1D高阶单元 11.2 2D高阶单元 11.3 3D高阶单元 11.4 基于薄板理论的弯曲板单元 11.5 子结构与超级单元 Chapter 12 有限元分析的应用领域引论12.1 结构振动的有限元分析：基本原理 12.2 结构振动的有限元分析实例 12.3 弹塑性问题的有限元分析：基本原理 12.4 弹塑性问题的有限元分析：非线性方程求解 12.5 传热问题的有限元分析：基本原理 12.6 传热问题的有限元分析实例 12.7 热应力问题的有限元分析：基本原理 12.8 热应力问题的有限元分析实例","link":"/2022/08/26/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E5%BA%94%E7%94%A8%E9%83%A8%E5%88%86/"},{"title":"有限元分析与应用——理论部分","text":"hljs.initHighlightingOnLoad(); 本课程主要来源于清华大学曾攀老师的网课，这部分是第一部分理论的部分。主要包含引论、基于直接刚度法的杆系有限元方法、针对复杂几何形变的力学描述、变形体方程的求解的试函数、基于试函数的经典方法和有限元方法。 Chapter 1 引论1.1 力学的分类：质点、刚体、变形体 质点力学主要是将物体简化成为一个点。 由于分析的对象变成刚体，在将其简化到质心的同时，也要考虑物体的转动。 以下我们要分析变形的特性，对应变形体而言其主要分成简单形状和复杂形状两个性质。 首先来分析简单形状构件，包括材料力学和结构力学。 材料力学主要是分析简单的变形体在微小变形的下的情况。 结构力学和材料力学基本相似，就是结构力学的构建数量更多，并且因此得到的线性方程组的数量更大。 其次来分析复杂形状构件，包括弹性力学和弹塑性力学。 弹性力学对应的在小变形的情况，取出一个微元体来分析，但是一般是得不到解析解的，一般是数值方法得到数值解。 弹塑性力学在弹性力学的基础上还考虑了弹性变化范围以外的部分，其求解更加困难。 1.2 变形体力学的要点 对材料的力学分析上，需要进行材料的拉伸实验，进而得到拉伸的曲线。 在进行实验设计时，这里设计三组实验，通过上面的实验得出了三个曲线，然后定义了应力$\\sigma$和应变$\\varepsilon$ ，于是上述的三个曲线就可以合并形成一条曲线，这条曲线就很好的刻画了材料的力学性质。 其中$E$代表的是原来的一维材料的杨氏模量。 下面得到了变形体的三大变量：位移、应力、应变。 同时也得到了三大力学方程：平衡方程、物理方程、几何方程。 这三大类方程主要是微分方程。 1.3 微分方程求解的方法 根据上面的问题得到方程式如图所示。 方法一：解析法 根据上述的结果可得一个位移的二次方程如图所示，然后根据边界条件计算待定的系数。 方法二：近似方法(差分) 将其分成五个节点，对每个节点来列出一维的差分方程如下。 将得到的边界条件代入到对应的节点中： 解得上述节点出的解为： (u_1,u_2,u_3,u_4)^T=\\dfrac {PL^2} {AE}(0.16, 0.28, 0.36,0.4)^T 这里为了提高精度可以增加节点的数量。 这里位移矩阵的n-1行n-1列处的值为-1，于是接出来的结果如图所示。 方法三：近似方法(试函数) 其实就是给定一个满足边界条件的待定系数函数，将其代入到控制方程里，优化参数使得残差函数最小。 和之前的节点法相同，其也是可以使用多个试函数来进行逼近。 总结 将上述的几种方法进行对比可得，下面的从求解的精度和特点进行比较。 对于是函数而言其使用的难点就是获得可以满足全局边界条件的试函数，只要试函数确定，后面就很简单了。 1.4 函数逼近问题 这种方法类似于函数拟合。 这种方法类似于分段线性插值。 分析和讨论 全域展开：对于1D问题，其基底函数还是比较好找的，但是对于2D、3D问题，其基底函数就不是很容易获得了。 子域展开：在分段点处的连续性和可导性较差，其逼近的效果还是不错的。这个方法的主要问题是如何针对2D、3D问题来构造合适的试函数。 1.5 针对复杂域上的构造函数或级数 对于2D的问题而言。 规则的几何域上可以使用全域的方法，其试函数的构造是比较容易的，也可以使用子域的方法； 复杂的不规则问题就仅仅只能使用一般的子域的方法，因为全域的试函数无法找到。 对于3D的问题和2D问题类似。 1.6 有限元的核心：针对复杂几何域的分片函数逼近 将上述规范化的子域叫做单元，其中包括两节点的杆，三节点的三角形和八节点的3D块。 利用上述单元来拼出规范化的形状。 将常用的1D、2D、3D单元构建单元库。 1.7 发展历史 Chapter 2 基于直接刚度法的杆系有限元方法2.1 弹簧的力学分析原理首先定义了基于端点的描述，之后定义节点的描述方法来描述弹簧微元的受力。 下面方程里面从左向右依次是矩阵系数，节点位移，节点力。 以下给出一个实际分析的例子。 这里的$F_2$为外部作用到B点是的外力，之后将这些转化称为矩阵方程并进行合并，组成一个系统。 这里由于$u_1,u_3=0$于是就将对应的矩阵系数的行和列划掉。 2.2 弹簧单元和杆单元的比较首先，来看整体的端点上的物理方程如下。 可以通过刚度系数的转换来用弹簧的平衡方程计算杆的平衡方程。 接下来根据上述的关系来推广到弹簧单元和杆单元。 对比弹簧来分析杆的受力情况。 2.3 杆单元的坐标变换 以上我们的坐标系取得是杆的轴线方向，但是在实际的结构功，我们需要将整体合成到一个方程里面去就需要获得将所有的杆的坐标系进行统一。 将坐标变换之后结果写成矩阵形式可得如下表达式。 下面将2D的情况向着3D情况推广可得。 2.4 四杆结构的有限元分析 将每个杆看作是一个单元，将其和节点的编号对应的表格列出如下。 由于第二根杆是由节点3指向节点2的，于是就会由其节点的余弦为-1的情况。 下面对每个单元进行矩阵描述，得到对应的刚度矩阵。 尽管二号矩阵和4号矩阵的形式一样，但是其对应的自由度是不一样的，对应的节点是不一样的。 其实这里也就是将刚度矩阵按照节点的顺序进行拼接，这里的主要多的方法是先确定好节点的排列顺序，之后按照节点来拼接矩阵，接着将计算节点力，这里主要计算的是节点处的外力，因为内力都被消去了。 下面进行的是节点方程的求解过程。 这里代入边界条件，支座处的位移为0，将位移为0的相关的行和列划去可得简化后的方程，然后进行求解即可。 Chapter 3 针对复杂几何变形体的力学描述3.1 力学描述的基本思路及变形基本假设变形体可以按照结合形状来划分可以分为简单几何形状和复杂几何形状，针对的是材料力学和弹性力学的主要的研究。 为了将注意力几种在处理复杂几何形状上，这里将针对材料的性质进行假定。 但是针对复合材料，我们可以将各向异性进行放松；针对弹塑性材料，我们可以将线弹性的假设进行放松等。 3.2 指标记法 这里使用的是默认的表示法，$F_1$就对应$x_1$轴的分量，$F_2$就对应$x_2$轴的分量，$F_3$就对应$x_3$轴的分量。 对于哑指标来说，有默认的爱因斯坦求和约定。 voigit标记法，就是将一个高维的张量简写称为一个低维的形式，如下面就将一个二维的张量转换为一维的列阵。 这里的Voigt准则仅仅是规则的一种，也可以按照习惯的顺序来进行书写。 3.3 复杂变形体描述的建模思路 这里将复杂的变形体分成了内部的描述和外部的描述，对于内部就是建立对于的微元体，对于外部表面则要根据其几何边界和受力边界来构建三大变量和三大方程。 2D问题的应力的建模 第一个下标是方向，第二个下标是受力面的法线方向。 3D问题的应力建模 3.4 平衡方程的构建以下对微元体进行受力分析可得下图，其中由于微元取得足够小，因此其微元体内部的材料可以看成是均匀分布的。 对于平面来说，可以在两个方向和一个转动方向来建立力学平衡方程式。 其中方程中带有坐标增量的部分可以使用Talyor展开。 使用Tayor展开，消去高次项。 以上为在x方向上的受力分析，下面来进行y方向的进行分析。 其中前面两项式由于$x,y$坐标引起的梯度变化引起的，他们由跟微元的体积力达到平衡。 对于力矩平衡，这里取的式微元的中心求力矩的，这样就可以将体积力约去，于是化简的结果就是剪应力互等定律。 这里将其整理成指标的形式，在加上哑变量的自定求和于是得到了指标形式的表达式。 3.5 几何方程的构建如下图所示，为变形前后的对比图，首先计算的是相对伸长量，这里由于是微元，因此$PA,P’A’$的角度造成的横向的位移就可以忽略不记。 然后计算的是夹角的变换，需要计算角度$\\alpha,\\beta$ 的值。这里就是利用的小角近似，用$\\tan \\alpha$来近似$\\alpha$ 。 对上上面得到计算的结构进行总结可得： 上述的三个分量中，仅仅由两个是独立的，另一个是相关的。 上述的方程里面仅仅只有满足这个变形的协调条件的才是实际变形的情况，在下图里面只有第4个才是真正的变形情况。 3.6 物理方程的构建物理方程的本质就是广义的胡克定律。 在分母位置上的是泊松效应的主方向，如图所示主方向是$x$方向。 将实际的应力一分为3，进而得到了2D问题的本构方程。 于是将上述的形式化成指标形式可得： 其逆行式转化为指标形式可得： 上述张量的表达在纸上是写不出来的，只能用下标来进行表示。 3.7 边界条件这里的边界分为力的边界和位移的边界，一般也将空的地方也认为成是里的边界，只不过对应的力为0. 上面表达式的意思是，上述的两个边界没有搭接也没有间隙。 位移边界 力的边界 在$x$方向的平衡条件，同理可以$y$方向和力矩平衡的方向。 Chapter 4 针对复杂几何形状变形体的力学描述24.1 几种问题的讨论首先对之前学习的有关问题如给定的问题、三大类变量、三大类方程、边界条件进行复习和总结。 下面来引出主要讨论的三大问题：平面应力、平面应变、刚体位移。 平面应力 由于在全部的力都作用到$xoy$ 因此其在平面上面的变形为0，但是由于考虑到泊松效应，其$z$方向上可能会产生形变——应变$\\varepsilon_{zz}$ 。 简单归纳以下平面问题的基本变量。 平面应变 由于是一个无限长的边等截面柱体，因此其在$z$方向上的位移为0，应变为0，于是就对应的剪切力也就为0，但是其对应的应力就不一定为0了。 下面来简单的归纳上述的平面应变问题。 上述两种问题直接的联系。 平面的刚体位移 刚体在平面移动时，其内部不存在应变仅仅在外部有力的作用。 4.2 简单拉杆问题的完整弹性力学求解这里使用前面的三大类变量和三大类方程来完整的解决这个简单的拉杆问题。 上面的问题是一个简单的一维问题，于是将可得： 下面分别使用材料力学和弹性力学的三大类变量和三大类方程来求解的结果。 弹性力学的解是一个分布，而材料力学仅仅求得的时右端的结果。 4.3 平面纯弯梁的描述及求解 这一部分和材料力学里面求解的情况时一样。 确定了基本的变量之后，下面我们来建立三大方程。 首先是平衡方程的建立 之后是几何方程的建立 由于我们在前面进行微元分析的时候已经使用的了均布载荷了，于是这里的边界仅仅考虑在支座处的受力。 4.4 空间弹性问题的完整描述 这里解决空间问题的主要的方法是一种是取出微元体来进行分析，另一种是将2D问题进行三维推广。 首先是在变量方面。 之后是平衡方程的方面。 然后是几何方程方面。 接下来是物理方程上面。 最后是在边界条件方面。 3D问题的指标形式的书写。 4.5 关于张量的理解 在这里向量的模长其实就是一个不变量，利用整个不变量来定义强度的准则。 将上述的2D的坐标变换问题转换成3D的情况。 Chapter 5 变形体方程求解的试函数方法的原理5.1 变形体(弹性)力学方程求解方法分类及试函数方法 下面为几个主要的误差计算方法。 5.2 平面弯曲梁的求解的试函数方法——残值处理法 Galerkin加权方法 残值最小二乘法 由于所取的基底是相同的，于是就两种方法最后求得的结果是相同的。 5.3 如何降低对试函数的高阶导数及边界条件的要求 前面的问题取得是正弦和余弦，因此可导性是很好的。 这里是将所有的变量全部代入换算成位移。 5.4 平面弯曲梁求解的能量原理本讲主要解决的是如何降低对试函数导数的要求。 5.5 最小势能原理的变分方法 5.6 一般问题的虚功原理 Chapter 6 基于试函数的经典方法和有限元方法6.1 基于试函数的经典方法和有限元方法 离散主要分为自然离散、人工离散、混合离散三种。 6.2 有限元方法的基本步骤 6.3 试函数经典方法及有限元方法的比较","link":"/2022/08/26/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/"},{"title":"第1章 控制系统状态空间表达式","text":"hljs.initHighlightingOnLoad(); 本文是现代控制理论的第一章，主要讲解的是控制系统状态空间的表达式。","link":"/2022/08/26/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E7%AC%AC1%E7%AB%A0-%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"Gmsh 教程","text":"hljs.initHighlightingOnLoad(); 本个教程主要参考的是Gmsh网格划分介绍。其余建议参考其官方网站的上面的教程，官网上面提供了基于不同语言的具体的教程。 这里作者在Geometry比较喜欢使用OpenCASCADE内核，默认是使用的Built-in模式。设置的是时候直接在UI界面里点击即可，就会在对应的.geo文件里面出现。 基础知识主要分成几何文件的创建和网格生成的工作。 创建几何元素创建点Point 这里可以直接在geo里面来编辑，也可以使用在UI界面里来创建。 12345678dx=0.1;w=2.0;h=1.0;Point(1)={0.0, 0.0, 0.0, dx};Point(2)={w, 0.0, 0.0, dx};Point(3)={w, h, 0.0, dx};Point(4)={0.0, h, 0.0, dx}; 使用UI界面的方法就是： 这里我们其实两个方法都差不多，因此没啥可以推荐的，我个人推荐的是如果两种方法相似，我优先使用的是写命令的方法。 创建线Line这里也是可以直接使用鼠标选点的方法来取点，也可以使用代码，使用代码时主要时写出对应两个点的索引即可。 1234Line(1) = {4, 3};Line(2) = {3, 2};Line(3) = {2, 1};Line(4) = {1, 4}; 如果要使用UI界面，就是直接选择需要划线的点，依次选点即可。 但是，在实际使用的时候，效果并不是很理想，点十分的难选中。这里还是推荐使用代码来进行建模。 创建suface使用代码创建时就是Curve Loop命令，里面的内容就是对应的索引值。 1Curve Loop(1) = {4, 1, 2, 3}; 这里可以选择UI界面的Plane surface，然后选中对应的目标即可，但是依旧是那个问题，我的软件里面选择目标非常困难，没有自动的选择和定位。 这里我推荐直接显示对应的几何元素，这样就很方便我们了解对应的元素index，方便直接写代码。 出现上述的虚线就是代表我们的面添加完成。 创建物理元素添加Physical groups Curve这里是将几何元素进行物理上的命名，来服务之后的网格上的划分。这里优先使用UI界面，但是代码还是要知道其具体的含义。 这里的代码其实.geo也不叫代码，其实就类似于.json文件一样，是一种存储信息的一种格式，其有自己的语法。 1234Physical Curve(&quot;left&quot;, 5) = {4};Physical Curve(&quot;right&quot;, 6) = {2};Physical Curve(&quot;top&quot;, 7) = {1};Physical Curve(&quot;bottom&quot;, 8) = {3}; 添加Physical groups surface同样的方法，来创建物理元素上的surface信息，其对应的代码如下所示。 1Physical Surface(&quot;block&quot;, 9) = {1}; 网格的创建和修改网格的创建上述信息设置好之后，点击Mesh-&gt;2D即可生成对应的网格信息。 此时划分网格之后.geo里面的内容不在增加，因为这里划分网格的信息会自动的保存在.msh文件中。 网格密度的修改如果感觉上述网格划分的结构比较粗，希望对网格划分的结构进行细化，那么就需要调整最开始的dx参数。 这里我们将dx=0.05，观察网格划分的效果。 这里我们将dx=0.01，观察到网格划分的效果。 也可以定义每个边上的有限单元的数量来进行修改。 上述操作对应的代码是： 1Transfinite Curve {4} = 21 Using Progression 1; 得到的效果如下所示。 于是就会发现，被修改的那一边上的网格比较的密集，如果要对全局的网格都进行修改的话，就将上述四个边都进行修改。 如果是要对每个边都进行如下的操作，就将其对应的边的index都写进了： 1Transfinite Curve {4, 3, 2, 1} = 21 Using Progression 1; 得到效果如下所示。 修改网格的类型上述方法默认划分的网格是三角型的网格，但是有时我们需要四边形、六边形等高阶的网格。这里就是需要修改网格的类型，以下是修改网格类型的几个方法。 第一种方法，就是修改网格的阶数，将其从最初的一阶网格修改成二阶或者三阶，但是一般情况下一些有限元软件是不支持三阶的，一般都搞成二阶网格即可。 此时就变成了一个6节点二阶三角形的网格，但是上述步骤一定要在我们生成二阶网格之后才可以进行，否则无法进行。 第二种方法，我们拿他来生成四边形的网格如下，打开tool里面的options，选择网格部分进行修改。 基于上述的就该就得到了四边形的网格。 三维BOX的网格划分按照同样的方法，我们可以进行对三维box进行划分的实例。 创建几何元素首先，绘制基本的点元和基本的线元，这里我们通过对应的命令了创建。在后面的教程里面，我们也会通过python的命令来进行创建。 123456789101112131415161718192021222324252627282930313233//+SetFactory(&quot;OpenCASCADE&quot;);dx=0.1;w=2.0;h=1.0;Point(1)={0.0, 0.0, 0.0, dx};Point(2)={w, 0.0, 0.0, dx};Point(3)={w, h, 0.0, dx};Point(4)={0.0, h, 0.0, dx};Point(5)={0.0, 0.0, w, dx};Point(6)={w, 0.0, w, dx};Point(7)={w, h, w, dx};Point(8)={0.0, h, w, dx};Line(1) = {1, 2};Line(2) = {2, 3};Line(3) = {3, 4};Line(4) = {4, 1};Line(5) = {5, 6};Line(6) = {6, 7};Line(7) = {7, 8};Line(8) = {8, 5};Line(9) = {1, 5};Line(10) = {8, 4};Line(11) = {2, 6};Line(12) = {7, 3}; 之后，我们创建相关的表面surface特征。注意在创建surface语句里面，我们对应的index上面Line的index，不是前面的对应的前面点对应的index。 123456789101112131415// 这里的index对应的是上面直线的index// 不是点对应的indexCurve Loop(1) = {8, 5, 6, 7};Curve Loop(2) = {4, 1, 2, 3};Curve Loop(3) = {4, 9, 8, 10};Curve Loop(4) = {2, 11, 6, 12};Curve Loop(5) = {3, 10, 7, 12};Curve Loop(6) = {1, 9, 5, 11};Plane Surface(1) = {1};Plane Surface(2) = {2};Plane Surface(3) = {3};Plane Surface(4) = {4};Plane Surface(5) = {5};Plane Surface(6) = {6}; 注意，选中的参数只有按下e键才算真正的创建成功。 下面和之前有所不同，这里我们创建一个体素的几何模型Volume。 通过UI界面操作得到的代码为： 12Surface Loop(1) = {1, 3, 2, 6, 4, 5};Volume(1) = {1}; 创建物理元素这里添加的物理元素和之前不同，这里主要是添加的Surface而不是Curve。之后给volume也要添加对应的物理元素。 对应的代码如下： 123Physical Surface(&quot;left&quot;, 13) = {1};Physical Surface(&quot;right&quot;, 14) = {2};Physical Volume(&quot;block&quot;, 15) = {1}; 网格的生成和修改网格的生成和之前相似，直接点击Mesh即可生成。 网格的修改和之前是一样的，都是直接到options里面的Mesh里进行修改参数，具体参数修改如下： 但是上述的划分发生了报错，于是我们更换网格的生成配置。 得到的效果如下： 网格的保存如果要是保存称为4.0版本以上的格式就直接选择save mesh即可，但是如果要保存成为2.0版本的就需要进行修改格式为Export即可。 下面是保存成为2.0格式的方法： 首先点击Export，这候选择格式，这里还是选择.msh的格式，之后会弹出一个窗口来设置和编辑导出的结果。 之后，将保存成为的格式数据设置为Version 2 ASCII即可。 再4.0保存的文件里面是离散的保存着记录的节点的坐标参数，但是在2.0之前是在一块都记录着参数，方便查阅。4.0的特点是节省内存的开销。 基于Python的命令流通过上面的教程，我们已经对Gmsh几何文件里面的内容的含义有了初步的理解，并且也了解了UI界面的基本的使用。现在进行的主要是如何通过Python来从外部调用Gmsh来导入几何模型，并划分网格。 这部分的教程主要是基于官网上面的demo来进行学习。下面先整理以下每个demo对应的主要的内容，方便以后参考。 t1: Geometry basics, elementary entities, physical groups t2: Transformations, extruded geometries, volumes t3: Extruded meshes, parameters, options t4: Built-in functions, holes in surfaces, annotations, entity colors t5: Mesh sizes, loops, holes in volumes t6: Transfinite meshes t7: Background meshes t8: Post-processing and animations t9: Plugins t10: Mesh size fields t11: Unstructured quadrangular meshes t12: Cross-patch meshing with compounds t13: Remeshing an STL file without an underlying CAD model t14: Homology and cohomology computation t15: Embedded points, lines and surfaces t16: Constructive Solid Geometry, OpenCASCADE geometry kernel t17: Anisotropic background mesh t18: Periodic meshes t19: Thrusections, fillets, pipes, mesh size from curvature t20: STEP import and manipulation, geometry partitioning t21: Mesh partitioning 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import gmshimport sys# 在调用API之前都要进行初始化gmsh.initialize()# 然后就是创建一个模型并且将其命名为&quot;t1&quot;gmsh.model.add(&quot;t1&quot;)# 此处的python提供了直接支持CAD模型的内核。# built-in 内核是本教程主要使用的内核，其支持的API函数有`gmsh.model.geo`的前缀# ================================创建点元素====================================# 这里在模型里面最基本的元素是点，# 创建点使用的API为 gmsh.model.geo.addPoint()# - 前面的3个参数为坐标值(x,y,z)# - 第4个参数是网格点之间的间距# - 第5个参数为point的标签，或者是索引，一般是正整数lc = 1e-2gmsh.model.geo.addPoint(0, 0, 0, lc, 1)# 注意这里含有另外的一个模型occ# gmsh.model.occ.add_point()# 这里使用了驼峰命名法`addPoint()`# 但是也有另外的一个函数名`add_point()`,两者是可以互换的。# 其次，网格大小将根据设定的网格间距通过插值的方法获得的。# 其他的方法就是使用通用的网格格式字段来解决具体见 t10.py# 还有一个特殊的情况就是使用背景网格background mesh t7.py# 如果没有提供目标网格尺寸，则将根据模型整体尺寸对模型使用默认的均匀粗尺寸。gmsh.model.geo.addPoint(.1, 0, 0, lc, 2)gmsh.model.geo.addPoint(.1, .3, 0, lc, 3)# 如果没有显式提供标记，则会自动创建一个新标记，并由函数返回:p4 = gmsh.model.geo.addPoint(0, .3, 0, lc)# ================================创建直线元素====================================# 曲线是Gmsh的第二种元素实体，在曲线中，直线是最简单的。# 使用内置内核创建直线段的API遵循相同的约定:# - 前两个参数是点索引tag(直线的起始点和结束点)，# - 最后一个(可选的)是直线的tag。# 这里曲线的标签和索引是相对于直线独立的，因此这个我们也可以使用标签1# 每种元素的标签都是相互独立。gmsh.model.geo.addLine(1, 2, 1)gmsh.model.geo.addLine(3, 2, 2)gmsh.model.geo.addLine(3, p4, 3)gmsh.model.geo.addLine(4, 1, p4)# ================================创建曲面元素====================================# 曲面是Gmsh的第三种元素实体，# 为了利用上面的四个直线定义一个简单的矩形曲面，这里需要定义一个简单的曲线环# 曲线环路是由一组有序的连接曲线定义的，每条曲线都有一个符号(取决于曲线形成环路的方向)。# - 创建曲线循环的API函数的第一个参数是一组整数，# - 第二个(可选)参数是curve loop标记(在曲线循环中必须是唯一的):gmsh.model.geo.addCurveLoop([4, 1, -2, 3], 1)# 然后，我们可以将曲面定义为一个曲线循环列表# (这里只有一个，代表外部轮廓，因为没有孔——参见' t4.py'的一个带有孔的曲面的例子):gmsh.model.geo.addPlaneSurface([1], 1)# ================================进行网格化====================================# 在对它们进行网格化之前(更一般地说，在它们被内置CAD内核函数之外的API函数使用之前)，# CAD实体必须与 Gmsh模型同步，后者将创建相关的 Gmsh数据结构。# 就是说之前创建是CAD实体，不是 Gmsh模型，需要将其联系在一起# 实现同步的API：gmsh.model.geo.synchronize()# 同步可以在任何时候调用，但它们涉及大量的计算量;# 因此，虽然您可以在每个CAD命令之后同步内部CAD数据，但通常最好是尽量减少同步点的数量。# 在这个层面是，Gmsh已经知道了显示矩形surface 1 并且绘制网格。# 一个可选的步骤：将几何元素变成具有物理意义的组# 例如定义一些数学属性(“域”、“边界”)、功能属性(“左翼”、“机身”)或材料属性(“钢”、“碳”)，那么就需要一个可选步骤。# 这样的组在Gmsh中称为“物理组”。# 默认情况下，如果定义了物理组，Gmsh将只在输出文件中导出至少属于一个物理组的网格元素。# (要强制Gmsh保存所有元素，无论它们是否属于物理组，设置' Mesh.SaveAll()选项为1。)# 物理组也由标签tag，但是是严格的正int，并且在每个维度(0D、1D、2D或3D)都应该是唯一的。# 也可以给物理组命名，具体请看下面的API# 首先，定义的是边界曲线left, right, bottom -&gt; Line 1,2,4# - 第一个参数dim, 第二个参数是被定义元素实体的tag, 第三个参数是这个物理组的tag=-1# - 第四个是name, 就是直接给物理命名gmsh.model.addPhysicalGroup(1, [1, 2, 4], 5)# 之后，定义一个物理曲面，并将其命名为 My surfacegmsh.model.addPhysicalGroup(2, [1], name=&quot;My surface&quot;)# 最后，我们生成网格2Dgmsh.model.mesh.generate(2)# 将其保存# gmsh.write(&quot;t1.msh&quot;)# 注意，在默认的情况下，这里将会将我们物理组信息将会保存到.msh文件中# Gmsh将只在输出网格文件中导出那些至少属于一个物理组的元素。如果要全部导出# gmsh.option.setNumber(&quot;Mesh.SaveAll&quot;, 1)# 默认情况下，Gmsh以最新版本的Gmsh网格文件格式(' MSH'格式)保存网格。# 通过指定具有不同扩展名的文件名，可以将网格保存为其他网格格式。例如# gmsh.write(&quot;t1.unv&quot;)# 您也可以保存网格在旧版本的MSH格式:简单设置gmsh.option.setNumber(&quot;Mesh.MshFileVersion&quot;, 2)gmsh.write(&quot;t1.msh&quot;)# 对于任何版本号' x'。# 作为一种替代方法，你也可以不显式指定格式，只选择一个带有'.msh2’或‘.msh4的扩展。# 为了可视化模型，我们可以运行图形用户界面# Here we run it only if &quot;-nopopup&quot; is not provided in the# command line arguments:if '-nopopup' not in sys.argv: gmsh.fltk.run()# 在3.0之后，在原有内置的核的基础上，又添加了内置的OCC CAD内核# 在调用的时候，增加 `gmsh.model.occ' 的前缀# Different CAD kernels have different features. With OpenCASCADE, instead of# defining the surface by successively defining 4 points, 4 curves and 1 curve# loop, one can define the rectangular surface directly with# gmsh.model.occ.addRectangle(.2, 0, 0, .1, .3)# 在OCC的内核里面，可以直接绘制矩形的内核# 之后进行同步模型的操作# gmsh.model.occ.synchronize()# 获取对应的点矩阵的操作可以是# gmsh.model.getBoundary().# 最后，结束使用 Gmsh Python API:gmsh.finalize() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157# ------------------------------------------------------------------------------## Gmsh Python tutorial 2## Transformations, extruded geometries, volumes## ------------------------------------------------------------------------------import gmshimport sysimport math# If sys.argv is passed to gmsh.initialize(), Gmsh will parse the command line# in the same way as the standalone Gmsh app:gmsh.initialize(sys.argv)gmsh.model.add(&quot;t2&quot;)# 整理重复第一个实验的例子# Copied from `t1.py'...lc = 1e-2gmsh.model.geo.addPoint(0, 0, 0, lc, 1)gmsh.model.geo.addPoint(.1, 0, 0, lc, 2)gmsh.model.geo.addPoint(.1, .3, 0, lc, 3)gmsh.model.geo.addPoint(0, .3, 0, lc, 4)gmsh.model.geo.addLine(1, 2, 1)gmsh.model.geo.addLine(3, 2, 2)gmsh.model.geo.addLine(3, 4, 3)gmsh.model.geo.addLine(4, 1, 4)gmsh.model.geo.addCurveLoop([4, 1, -2, 3], 1)gmsh.model.geo.addPlaneSurface([1], 1)gmsh.model.geo.synchronize()gmsh.model.addPhysicalGroup(1, [1, 2, 4], 5)gmsh.model.addPhysicalGroup(2, [1], name=&quot;My surface&quot;)# 这里在第一个基础上面增加了新的点和曲线gmsh.model.geo.addPoint(0, .4, 0, lc, 5)gmsh.model.geo.addLine(4, 5, 5)# Gmsh也提供旋转变换的工具，针对实际的元素和副本# 首先，是旋转变换# - 参数1：向量vector 主要是代表(dim, tag)# - 参数2：vector，主要代表(dx,dy,dz)具体的平移量# 下面以一个点为例gmsh.model.geo.translate([(0, 5)], -0.02, 0, 0)# 下面是一个旋转的例子# - 参数1：(dim, tag)# - 参数2：旋转中心(0, 0.3, 0)# - 参数3：旋转方向(0, 0, 1)# - 参数4：旋转角度 -pi / 4gmsh.model.geo.rotate([(0, 5)], 0, 0.3, 0, 0, 0, 1, - math.pi / 4)# Point3可以倍复制，之后平移0.05个单位# copy() 输入是(dim, tag) 返回是另一个向量对(dim, tag)ov = gmsh.model.geo.copy([(0, 3)])gmsh.model.geo.translate(ov, 0, 0.05, 0)# 使用拷贝点的标签来创建新的点# The new point tag is available in ov[0][1], and can be used to create new# lines:gmsh.model.geo.addLine(3, ov[0][1], 7)gmsh.model.geo.addLine(ov[0][1], 5, 8)gmsh.model.geo.addCurveLoop([5, -8, -7, 3], 10)gmsh.model.geo.addPlaneSurface([10], 11)# 以同样的方式，我们可以平移表面1和 11的拷贝ov = gmsh.model.geo.copy([(2, 1), (2, 11)])gmsh.model.geo.translate(ov, 0.12, 0, 0)print(&quot;New surfaces &quot; + str(ov[0][1]) + &quot; and &quot; + str(ov[1][1]))# 卷是Gmsh中的第四种基本实体。就像我们定义曲线环来构建曲面一样，我们也必须定义曲面环# (即。`shell `)来构建卷。下面的体积没有孔，因此由一个表面环组成:gmsh.model.geo.addPoint(0., 0.3, 0.12, lc, 100)gmsh.model.geo.addPoint(0.1, 0.3, 0.12, lc, 101)gmsh.model.geo.addPoint(0.1, 0.35, 0.12, lc, 102)# 只有输入一下的命令才可以将我们上述的命令同步的到UI界面gmsh.model.geo.synchronize()xyz = gmsh.model.get_value(0, 5, [])print(xyz)# 整理获取的是 tag = 5个点的坐标gmsh.model.geo.addPoint(xyz[0], xyz[1], 0.12, 103)# 创建一些新的线gmsh.model.geo.addLine(4, 100, 110)gmsh.model.geo.addLine(3, 101, 111)gmsh.model.geo.addLine(6, 102, 112)gmsh.model.geo.addLine(5, 103, 113)gmsh.model.geo.addLine(103, 100, 114)gmsh.model.geo.addLine(100, 101, 115)gmsh.model.geo.addLine(101, 102, 116)gmsh.model.geo.addLine(102, 103, 117)gmsh.model.geo.addCurveLoop([115, -111, 3, 110], 118)# 这里的正负号是方向约束# 其本质是要将点进行首尾连接gmsh.model.geo.addPlaneSurface([118], 119)gmsh.model.geo.addCurveLoop([111, 116, -112, -7], 120)gmsh.model.geo.addPlaneSurface([120], 121)gmsh.model.geo.addCurveLoop([112, 117, -113, -8], 122)gmsh.model.geo.addPlaneSurface([122], 123)gmsh.model.geo.addCurveLoop([114, -110, 5, 113], 124)gmsh.model.geo.addPlaneSurface([124], 125)gmsh.model.geo.addCurveLoop([115, 116, 117, 114], 126)gmsh.model.geo.addPlaneSurface([126], 127)gmsh.model.geo.addSurfaceLoop([127, 119, 121, 123, 125, 11], 128)gmsh.model.geo.addVolume([128], 129)# 当一个体积可以从一个表面挤出时，通常直接使用`extrude() `函数比手动创建所有的点、# 曲线和表面更容易。# 例如，下面的命令沿z轴挤压表面11并自动创建一个新的体积(以及所有需要的点、曲线和表面)。# 其实就是以 表面11为地面，得到一个主柱体# 正如预期的那样，该函数接受(dim, tag)对的向量作为输入，# 同时接受变换向量，并返回(dim, tag)对的向量作为输出ov2 = gmsh.model.geo.extrude([ov[1]], 0, 0, 0.12)# 与几何点相关的网格尺寸可以通过传递对应点的(dim, tag)对向量来设置:gmsh.model.geo.mesh.setSize([(0, 103), (0, 105), (0, 109), (0, 102), (0, 28), (0, 24), (0, 6), (0, 5)], lc * 3)gmsh.model.geo.synchronize()# We group volumes 129 and 130 in a single physical group with tag `1' and name# &quot;The volume&quot;:gmsh.model.addPhysicalGroup(3, [129, 130], 1, &quot;The volume&quot;)# We finally generate and save the mesh:gmsh.model.mesh.generate(3)# 请注意，如果转换工具可以方便地创建复杂的几何图形，# 它有时也有助于生成“平面”几何图形，具有所有基本实体的显式表示。# 使用内置的CAD内核，这可以通过将模型保存在 “Gmsh unrolling GEO”格式:# gmsh.write(&quot;t2.geo_unrolled&quot;);# With the OpenCASCADE CAD kernel, unrolling the geometry can be achieved by# exporting in the `OpenCASCADE BRep' format:# gmsh.write(&quot;t2.brep&quot;);# (OpenCASCADE geometries can also be exported as STEP files.)# 值得注意的是，Gmsh从来没有将几何数据转换为通用表示:对几何实体的所有操作都是通过相关的CAD内核本地执行的。# 因此，我们不能将内置内核构造的几何图形导出为OpenCASCADE BRep文件;# 或将OpenCASCADE模型导出为unroll GEO文件。# Launch the GUI to see the results:if '-nopopup' not in sys.argv: gmsh.fltk.run()gmsh.finalize()","link":"/2022/09/04/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/Gmsh-%E6%95%99%E7%A8%8B/"},{"title":"APDL Learning 1","text":"hljs.initHighlightingOnLoad(); 本课程主要参考的是教程的一系列视频，主要的作用是打基础的操作，此视频通俗易懂，但是就是案例比较的少，如果需要深度的了解还要参考其他的课程。 标量参数参数说明主要的参数的分类：标量参数、数组参数(包括数值、字符和表数组)。 主要的用途： 赋值； 批量数据处理(运算/读写)； 不必声明参数的类型，这点和C++不同； 使用为声明的参数赋”极小值“(约为2E-100)； 无论是整型还是实型都是按照双精度储存； 数组参数必须先定义后使用。 命名规则 参数名不超过8个字符，并以字母开头。 参数名中只能出现字母，数字和下划线。 避免以下划线开头，以下划线开头/结尾的参数为系统隐含参数。 参数名不分大小写，如“RAD”和“Rad”是一样的。所有的参数都以大写形式存储。 不能使用宏专用局部参数名: ARG1~ARG9和AR10~AR99 不能使用由*ABBR命令定义的缩写。 避免使用ANSYS标识: DOF：TEMP, UX,PRES等； 常用：ALL, PICK,STAT等； 用户定义：如用ETABLE命令定义的； 数组类型：如CHAR，ARRAY，TABLE等。 定义参数 命令*SET 定义； 赋值号 “=” 定义； GUI菜单定义：Utility Menu &gt; Parameters &gt; Scalar Parameters 启动时驱动命令的定义 利用 *GET 命令或函数提取ANSYS数据库数据赋值定义 ANSYS 存储的是一个参数的实际值(数字或字符串)，而不是参数名。 其实可以直接是在GUI界面里定义参数。 Entity，这个关键字主要是指节点、单元、面、实体等。 item1，主要是对象的项目名，即位移、应力、应变。 下面命令的第一行其实就是：将节点1的坐标赋值给$x_1$变量。 nsort命令是将后面的等效应力s进行应力排序。 ! 后面的内容是针对语句的说明，其实就是注释。 参数的删除参数删除的主要的方法有两个，一个是在菜单里删除，另一个是直接使用命令的方法来进行删除，命令的方式就是直接将上面的进行赋空操作。 注意：\\prep是前处理的声明符号，即表达的是当前的操作是处于前处理的的和过程内。 blc4 ,,,w,h其实就是代表着建立一个长方形的操作。 最后就是，如果w,h被修改了，但是长方形的形状是不会被修改的。 数组参数概述 标量参数，它只有一个值——数字或者字符； ANSYS也提供数组参数，它有若干个值。数字数组和字符数组都是有效的； 行列面下标从1开始的连续整数； 数组元素为整型或实型数； 这里比较特殊的是Table数据，其包含第0行和第0列，并且常用于一般的描述随时间变换的变量，例如上图的里面力学参数就是这样，对于没有的参数会直接进行参数的自动插值补全的操作。 定义方法首先是通过GUI来进行定义，主要可以编辑的参数是数组的类型和数组的维度参数，如下所示。 其中在Edit界面里进行编辑，在add界面里进行定义。 下面主要是使用命令的方式来进行定义，关键词是*DIM之后的几个参数依次是： 数组的名称 数组的类型 数组的维度 上面的做法仅仅是将我们的参数进行定义，但是数组的赋值还需要其他的命令来进行计算。 赋值定义 单个数组的元素——和Scalar变量相同 多个数组元素的赋值——按照下标索引号进行赋值 A(1)=1,2,3,4 交互式编辑数组(*VEDIT) 填充数组变量(*VFILL) 用数据文件赋值ARRAY (*VREAD命令) 用数据文件赋值TABLE (*TREAD命令) 上述的索引DTAB(1,1)的第一个1代表是整行的意思，类似于matlab的1:end的作用。 DATA的意思是数据填充，依次填入下面的几个数。 RAMP的意思是增量填充，第一个数初始值，第二个是公差。 RAND的意思是随机数填充，在第一个和第二个之间的随机数来填充。 上面的程序需要使用命令整体读取的操作来进行； 3F6.1可能是6位浮点数，并且小数点有一维。 time``X-Coo代表的是第0列和第0行； 对于字符数组是无法是使用GUI界面来实现赋值的，必须通过命令行赋值符号的的方法。 可视化 这个命令的主要的作用是使用列表的方式，将所有的参数都显示出来。 除了字符型的数据，都是可以使用一般的这个命令显示出来。 参数的存储 SCALAR代表存储内容是标量，scalar是存储文件名，sav是后缀名。 参数的恢复 删除ARRAY参数 获取数据库的操作 数组的操作 *VFUN的功能和函数计算是相似的，就是对当前的数组进行函数操作。 主要的作用就是对整个数列进行扫描，主要的作用是求解数列的最大和最小值的等统计问题。 下面是主要的数学计算的运算命令。 宏的使用APDL (ANSYS参数设计语言）最强有力的特征之一是创建宏的能力。 宏就是一系列贮存在一个文件中的ANSYS命令，并且能象一个ANSYS命令一样来运行。常用宏功能： 它可以如同ANSYS命令一样具有变量。·分支和循环用来控制一系列命令。 交互式特征如图形拾取，提示，以及对话框。 宏可以嵌套一一个宏引用第二个宏，第二个宏引用第三个宏，等等，一直可嵌套20级。 用于创建用户命令 调用对象:ANSYS命令、GUI函数或将值传给宏参数 文件名和扩展名规则 文件名不能超过32个字符。 文件名不能以数字开头 扩展名不能超过8个字符 扩展名应为.mac的宏等同于ANSYS命令 不能使用扩展名.MAC(用于ANSYS内部宏) 文件名或文件扩展名中不能包含空格 不能包含当前文件系统禁止使用的字符 宏的创建 和之前不同的是这里指定了arg1的类型。 宏的运行和主要命令 流程控制 Do-loop循环控制 条件分支 无条件分支 宏嵌套 重复执行命令 *EXIT的作用是直接将循环停止； *CYCLE的作用是继续循环操作；","link":"/2022/09/30/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-1/"},{"title":"APDL Learning 2","text":"hljs.initHighlightingOnLoad(); 本教程参考的是水哥Ansys的教程，本教程讲的十分的详细，建议学习。 本节主要讲解的是变量的命名原则和运算、流程控制类命令、GET命令详解、APDL函数命令。 概述 $相当于是一个回车的作用，这样处理主要是为了减少代码的程度。 !主要是处理注释信息的。 变量命名原则及运算 参数类型分类：变量、数组 变量类型:数值型和字符型 参数赋值可不事先指定参数类型，直接赋值 下面是对于的参数化的命令流，这样方便修改模型的参数。 变量的命名原则 参数必须以字母开头，长度不能超过32字符 参数名只能包含字母、数字和下划线，不能出现其他符号，如@、# 这里的#在APDL里的意思是乘法的含义。 下划线不能作为名字的开头或者结尾 避开宏文件参数专用名：ARG1~ARG9、 AR10～AR99 这里面是宏文件的专用名。 禁用ANSYS函数命令带有的标识符号，如ET、Kdist等 APDL里面的函数库的内容不要重名。 参数名应尽可能具有可读性，慎用常用于循环标识符号 变量的赋值、查询和删除 水哥的建议是，对于比较的复杂的程序，当我们使用完相关的变量之后的是需要将没用的变量进行删除操作，这样防止程序在后面产生歧义。 针对变量的查询的问题，这里主要是用来查看变量是否导入成功，有时变量并没有导入成功，但是我们这边也不知道。其作用类似print() 变量运算 变量运算：基本运算、数学函数； 基本运算：加、减、乘、除。 =：是赋值操作；==：是等于操作。 案例 数值型和字符型变量的动态替换：_%_%； 作用：相同的前缀字符局部以数字表达变量； 在变量的命名时，一定要有一定的规律可循，方便阅读。 上述运算符主要用于： 建模工作量大； 外部输入参数多； 需要灵活使用循环命令的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465! ==========================! 标准的预处理模板! ==========================finish! 结束上一个任务/filname,wangjia! 保存的本任务的名称/prep7! 开始前处理任务! ===========================! 单元材料参数的定义! et,1,beam188! ===========================!上旋节点建模csys,1!半径r1=2500$r2=5629$r3=8755$r4=11878r5=14996$r6=18108$r7=21212$r8=24308r9=27394$r10=30496$r11=3351$r12=36580r13=39614$r14=41406!高度h1=0$h2=-82$h3=-227$h4=-46$h5=-707$h6=-1041$h7=-1438h8=-1897$h9=-2419$h10=-3003$h11=-3649$h12=-4357$h13=-5126$h14=-5611! 第一圈n,1,r1,10,h1! 定义第一个节点,半径是r1,角度是10°,高度是h1! 创建循环来创建的剩余的节点*DO, i, 1, 8n, i+1, r1, 10+40*i, h1*ENDDO! 在建立第二圈时需要获得第一圈最大的编号*get, node1, node, 0, num, maxd! 取出最大的节点编号，并赋值给node1! 第二圈n, node1+1, r2, 10, h2*do, i, 2, 18n, node1+i, r2, 10+20*(i-1), h3*enddo*get,node2, node, 0, num, maxd! 第三圈n, node2+1, r3, 10, h3*do, i, 2, 18n, node2+i, r3, 10+20*(i-1), h3*enddo*get,node3, node, 0, num, maxd! 第四到六圈，因为其性质时相同的，于是将其写在一起*do, j, 4, 6k=j-1n, node%k%+1, r%j%, 10, h%j%*do, i, 2, 36n, node%k%+i, r%j%, 10+(i-1)*10, h%j%*enddo*get, node%j%, node, 0, num, maxd*enddo 上述得到的效果： 变量运算修改启动文件 要点梳理： 默认的角度的是弧度制的，通过命令的来进行转换，如果想要的每次打开都是角度值的话，可以在启动文件来进行修改。 其次的就是在启动文件里面的添加预定义的变量或者修改角度值的问题，其实上述的问题基本的思路是一样的。 流程控制类命令 流程控制：决定命令运行的次数、顺序； 作用：强化逻辑，增加可读性，减少冗余度； 类别： *GO 无条件分支； *IF-*IFelse-*Else-*Endif条件判断分支； *DO-*Enddo 循环 *Dowhile 循环 *Repeat 重复命令 *IF流程控制基本概念 根据判断条件来确定后续命令执行的情况； 作用：强化逻辑，增加可读性，减少冗余度； Vale相当于一个Bool表达式，其可以是值也可以是表达式。 一般情况下，可以使用单次判定，就使用单次判定，这样的话逻辑清楚，关系简答。 一般情况下，前面的六个使用较多，基本可以解决所有的问题。 在嵌套的时候，要有意识的进行缩进操作。 最好不要嵌套太多，这样的话可读性太差。 案例这里主要的完成的任务是给出对应的混凝土的等级，得出对应的弹性模量参数。 具体的创建代码如下： 123456789101112131415161718192021222324252627282930313233343536373839Finsish/clear/prep7 ! 进入前处理界面D=4 ! 弹簧的直径C=8 ! 弹簧的旋绕比N=10 ! 弹簧的圈数dz=C*D ! 弹簧的中径t=dz/2.5 ! 弹簧节距(螺距)*if,t,lt,D,thent=d !节距的最小值为簧丝直径，拉伸弹簧的t=D*endif! ============================! 2.创建一圈螺旋线csys,1 ! 设置当前坐标系为主坐标系k,1,dz/2,0,-t/2 k,2,dz/2,180 ! 创建两个关键点l,1,2 ! 创建半圈螺旋线csys,0 ! 设置直角坐标系lsymm,z,1lsymm,y,2,,,,,1 ! 利用对称性生成另一外半圈的螺旋线nummrg,all,cm,l1,line ! 合并关键点并将另外两条线定义为组件! ============================! 3.螺旋线端部创建簧丝界面kwpave,1wprota, ,90 ! 移动工作平面，并对其进行旋转cyl4,,,d/2 ! 创建直接为D的圆面! ============================! 4.沿着L1路径创建体、复制体等vdrag,1,,,,,,l1 ! 拖拉创建体vgen,n,all,,,,,t ! 复制体N次nummrg,kp ! 合并关键点wpcsys ! 工作平面归位 *Do 控制命令基本概念这里Do循环的作用和其他语言里面的for很相似。 含义：通过指定的次数来循环操作执行命令； 功能：减小编程篇幅、节约建模时间、增加可读性。 VINC相当于循环变量之间的间隔；当其为正时，为顺序遍历，当其为负时，为逆序遍历。 Abing_1为中间的循环语句； 当重复的次数超过三次时，应该考虑循环操作。 循环的次数太多，就会造成代码的可读性变差。 案例 最后的效果如图所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990*AFUN,DEG! 将全局的换成角度制Finish/clear/prep7f=40/7 ! 定义矢高8mSpan=40 ! 定义跨度Kn=8 ! 定义沿环的分割的分数Kn=8Nx=6 ! 定义环杆的圈数Nx=6! ======================================! 2.计算节点的坐标的位置，并定义节点csys,2 ! 转换为球面坐标系R=(Span*Span/4+f*f)/(2*f) ! 根据矢高和跨度来计算曲面的半径RDPha=Atn(Span/2/Sqrt(R*R-Span*Span/4))/Nx! 计算相邻两环之间对应的夹角DphaN,1,R,0,90 ! 定义顶点1号节点，坐标为(R,0,90)*DO,i,1,Nx ! 对称区的节点循环，第i圈可分为Kn*i份 *DO,j,1,Kn*i x=R ! 输入x,y,z y=(j-1)*360/(Kn*i) z=90-i*DPha N,1+Kn*(i-1)*i/2+j,x,y,z ! 输入每个点的编号 *ENDDO*ENDDO! ======================================Numnode=1+Kn*(Nx-1)/2+Kn*Nx ! 定义最大的节点! 3.定义单元的类型和参数ET,1,BEAM188 ! 定义弹性模量EXMP,EX,1,2.06e11 ! 定义材料的泊松比MP,DENS,1,7850 ! 定义材料的密度参数SECTYPE,1,BEAM,CTUBE !！定义第一类单元截面为圆管截面SECOFFSET,CENTSECDATA, 0.147/2,0.152/2,8 ! 截面为152*5的圆管的截面外径152，内径147! 这里的1代表的是第一类材料! ======================================! 4.定义单元的连接TYPE,1 ! 设置单元的类型号为 1MAT,1 ! 设置材料的属性号为 1SECNUM,1 ! 设置截面号为 1! 环向杆连接*DO,i,1,Nx ! 第1~Nx圈的节点循环 *DO,j,1,Kn*i-1 ! 第1~Kn*i-1对称区的节点循环 E,1+Kn*(i-1)*i/2+j, 1+Kn*(i-1)*i/2+j+1 ! 连接相邻节点 *ENDDO E,1+Kn*(i-1)*i/2+Kn*i,1+Kn*(i-1)*i/2+1*ENDDO! 径向的单元连接*DO,i,1,Kn ! 对各个对称区进行循环 E,1,1+i*ENDDO*DO,i,1,Nx-1 ! 从内圈里面的第二圈开始循环*DO,j,1,Kn ! 对各个循环区开始循环 *DO,k,1,i+1 ! 对循环区内的杆开始循环 *IF,k,EQ,i+1,THEN ! 判断是否是当前对称区内最后一根杆 *IF,j,EQ,Kn,THEN ! 判断是否是最后一个对称区 E,1+Kn*(i-1)*i/2+1,1+Kn*(i+1)*i/2+(j-1)*(i+1)+k ! 将第一个节点和最后一个节点连杆 *ELSE E,1+Kn*(i-1)*i/2+(j-1)*i+k,1+Kn*(i+1)*i/2+(j-1)*(i+1)+k ! 一般区内最后一根连杆 *ENDIF *ELSE E,1+Kn*(i-1)*i/2+(j-1)*i+k,1+Kn*(i+1)*i/2+(j-1)*(i+1)+k ! 一般正向连杆 *ENDIF*ENDDO *DO,k,1,i E,1+Kn*(i-1)*i/2+(j-1)*i+k,1+Kn*(i+1)*i/2+(j-1)*(i+1)+k+1 ! 一般负向连杆*ENDDO*ENDDO*ENDDO!(5)定义边界约束*DO,i,1,1+kn*(Nx-1)*Nx/2+Kn*Nx *IF,i,GT,1+kn*(Nx-1)*Nx/2,then D,i,all,0*ENDIF*ENDDO *GET命令详解基本概念其实*GET命令是一种功能命令，也是函数命令的一种。 主要功能是查询获取命令、并且广泛用于前处理和后处理； 参数化编程中，如何获取当前模型中最大的关键点编码？ 123! 开始新的关键点的建立*Get,Kn_max,kp,0,num,maxdK,Kn_max+1,x1,y1,z1 上面的命令主要进行的是将上面模型中最大关键点的编号记录在上述的Kn_max。 上述是前处理过程常用的方法。 这边需要学会查看帮助文档，下面是两个常见的任务，使用对应Get命令来实现： 目标1：获取当前选择任务集中关键点的最大编号； 1*Get,Par,kp,0,num,max 这个在Help里面找到前处理的部分查询。 目标2：获取已知节点num_node在x方向上的位移； 1*Get,Par,node,num_node,u,x 这个在Help的后处理部分可以找到 案例本案例主要是获取模态分析之后的阻尼值。 这里主要是涉及到排序相关的内容，在get的时候需要进行sort操作。 APDL函数命令基本概述 一个完整的分析主要包含前处理、求解、后处理三部分。 前处理：包含有限元的材料的定义、几何模型的绘制。 求解：包含求解类型的设置、求解器的设置、分析和输出的设置。 后处理：分为两种，通用后处理、节点整个时间历程的后处理过程。其中通用后处理主要包换是静态节点的位移和变形问题。动态的后处理顾名思义是测量其在整个历程的变化的基本的过程。 \\prep7是前处理的关键词； \\solu是求解阶段的关键词； \\post1是通用后处理关键词，\\post26是时间历程处理的关键词。 前处理以下是水哥归类的六大类前处理的过程，主要是包含材料、单元、坐标系、模型建立、网格划分、载荷和约束。 如果我们是导入的模型来进行建模，那么坐标系这边就没有之前那么重要了，但是如果在APDL里面进行建模，那就比较重要，因为在建模的时候会涉及到欧式坐标转球坐标或柱坐标的问题。 在建模的部分主要分成了下面的七个部分，本章主要侧重的是布尔运算和元素选择，元素选择的命令很重要。 材料定义 单元定义 坐标系的定义 建立模型这里的内容比较的多，但是其是有规律可循的，这里以BOOL运算为例来介绍。 L:直线；K:关键点；A:面；V:体。 gen:复制命令组，\\SB:减法族，*glue:粘贴族，*overlap:切割族，*dele:删除族。 *SEL:选择族，非常的重要。 Loc是根据给出的坐标来进行选择。 上述的操作，主要是将之前左右的边界删去。 先选对应的直线，之后选择依附于直线的所有的节点； NSLL中N代表的是节点，L代表的是对应的直线，于是上述的基本的问题就是将选择依附于直线的节点。 其他辅助命令 ALLSEL命令：一般适用于用户对模型进行选择操作后，如果需要恢复到默认状态，采用该命令，特别是求解前，应采用 Allsel， all 对模型进行选择复位，不然很容易求解失败。 *Plot 族命令：该类命令主要是针对当我们采用选择族命令对模型进行选择后，我们需要对选择的元素进行单独显示，以方便我们进行下一步操作，例： 12Asel,s,loc,x,10,100 !选择 x 方向坐标为 10 到 100 的面Aplot !单独显示这些面 压缩和重新编号：所谓压缩，也即是当两个节点完全重合（坐标相同）时，可以采用这个命令合并为一个节点，这种情况时常发生在进行复制操作过程当中。 123Nummrg, node !合并同位置的节点Nummrg, kp !合并同位置的关键点Nummrg, all !尽量不要使用这个命令 重新编号功能主要使用于节点合并之后，一般和 Nummrg 命令搭配使用，常见格式如下： 1Numcmp,all Cm命令：在很多情况下需要搭配前面介绍的选择族命令，通过选定特定的元素，采用Cm 命令命名，组建一个新的集合。 求解网格划分 网格划分的主要的步骤：属性划分、大小控制、划分网格、网格清除(为了防止网格划分的效果不好，但是又无法进行撤销的问题，只能直接删除。) 载荷和约束 在点和面上通过循环的方法来进行的施加荷载。 关于均布荷载的施加 均布荷载是常见的荷载类型，其施加方式一般采用 Sfa 或者 Sfe，这里唯一需要的是便是荷载的方向问题。 如果采用 Sfa 命令，则方向与面的法向相关，默认荷载方向与法向相反，而如果采用 Sfe 命令，则方向与单元序号相关，具体需查询单元解释，例如， c++181的单元说明如下图。 关于 Sfcum 命令 该命令直接主要控制荷载加载方式，一般软件默认针对同一元素施加的同一种类型荷载，后者施加会覆盖前者施加，如果有的时候我们需要进行叠加，就可以使用该命令。 关于重力加速度ANSYS 中重力加速度的施加采用 Acel 命令， 使用该命令需要注意三个方面： 单位的确定。 当采用 N-mm 单位制时，重力加速度应为 9800，当采用 N-m 单位制时，重力加速度应为 9.8。 方向的确定。在 ANSYS 经典环境下，一个比较特殊的是重力加速度的方向与实际方向是相反的，例如我们实际重力加速度为-Z 方向，但是我们施加的时候加速度值则采用正值， 这主要与动力方程的建立有关，可查看相关专著。 1Acel,,,9800 !重力加速度施加 重力加速度的删除。当前面一个荷载步考虑重力荷载工况后，如果下一步计算我们不需要考虑重力，这时候需要对重力加速度进行复位， APDL 并无直接删除的相关命令，可通过指定重力加速度为 0 来等效。 关于荷载与约束的删除 删除命令使用格式： *dele，可简称为 dele 族，使用单元、节点、关键点、线和面。 求解器的设计 Static 或者 0，代表静力分析； Buckle 或者 1，代表屈曲分析； Modal 或者 2，代表模态分析； Harmic 或者 3，代表谐响应分析； Trans 或者 4，代表瞬态分析； Substr 或者 5，代表子结构分析； Spectr 或者 6，代表谱分析。 下面时比较重要的命令。 Neqit主要针对的是非线性问题的求解，来设置最小的迭代长度。 Solve求解当前的问题。 上述命令里面好多事针对非线性的，于是3※都是最好要记住的。 后处理节点结果和单元结果 节点解：节点的位移解，通过{K}{X}={F}得到的，最为原始的解； 单元解：单元的应力应变，是节点解派生得到的派生解，是不连续的。 节点单元解：节点的应力应变，派生解的平均化显示。 后处理命令依据处理单元对象而划分 梁单元：单元表(Etable，Esort，Plls)； 壳单元：位移、应力、壳单元内力； 实体单元：面操作(高级)。 SET，相当于是指针获取读取结果数据； 对于5的要尽可能记住，3\\以下指导有就好。 通用的后处理 有限元后处理的操作比如将模型设置成为一个整体的结合，这些操作主要是需要经验积累来学习总结。 案例液压机主牌坊的计算问题 模型建立(了解)第一种网格划分的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100! ============================! 定于主要的单元类型et,1,solid186et,2,surf154! ============================! 定义使用到的材料属性mp,ex,1,2.1e11! 定义杨氏模量mp,prxy,1,0.2! ============================! 相关的几何参数! APDL的单位制为mr1=2.25r2=4.5H=17D=3.4Pres=400e6div1=6div2=40arc_div1=20! ============================! 开始建模操作! 内圈的四个节点k,1,-r2,0.5*Hk,2,-r1,0.5*Hk,3,r1,0.5*Hk,4,r2,0.5*Hk,5,0,0.5*H+r1k,6,0,0.5*H+r2! 对关键点进行连线操作l,1,2l,3,4larc,2,3,5,r1 !建立圆弧larc,1,4,6,r2al,1,3,2,4 !由线生成面! 基于几何参数定义下拱梁的6个关键点k,7,-1*r2,-0.5*hk,8,-1*r1,-0.5*hk,9,r1,-0.5*hk,10,r2,-0.5*hk,11,0,-1*(r2+0.5*h)k,12,0,-1*(r1+0.5*h)l,7,8l,9,10larc,7,10,11,r2larc,8,9,12,r1al,5,6,7,8blc4,-1*r2,-0.5*h,r1,hblc4,r1,-0.5*h,r1,haglue,all ! 将所有的面之间进行线性粘连操作! 进行拉伸整体的操作*get,kp_num,kp,0,num,maxdk,kp_num+1,-r2,0.5*H,Dl,1,kp_num+1! 返回上一步操作对应的编号ll1=_returnallsel,all! 选择全部的元素进行拉伸操作VDRAG,all,,,,,,ll1! ============================! 下面开始进行网格划分lsel,s,loc,y,0.5*h! 选择y是-0.5*h的线lsel,a,loc,y,-0.5*h! 选择y是-0.5*h的线lsel,r,loc,z,0! 控制是选择z=0的线lesize,all,,,div1! 将上述选择好的线变成6等分lsel,s,loc,x,-r1lsel,a,loc,x,-r2lsel,a,loc,x,r1lsel,a,loc,x,r2lsel,r,loc,z,0! 选择z=0上对应的x发现上的短线lesize,all,,,div2! 将上述的短线划分为40份! 选择划分好的弧线lsel,s,loc,y,0.5*h+0.1,0.5*h+r2lsel,a,loc,y,0.5*h-0.1,-0.5*h-r2lsel,r,loc,z,0lesize,all,,,arc_div1esize,d/10allsel,all! 扫掠划分vsweep,all 第二种建模的方法 123456789101112131415161718192021222324252627282930313233! 第二中建模的方法wpoffs,,0.5*h! 首先，设定工作平面cyl4,,,r1,0,r2,180,d! 绘制圆柱面wpoffs,r1! 修改工作平面blc4,,,r2-r1,-0.5*h,d! 绘制圆柱体wpcsys,-1! 工作面归位vsel,s,loc,y,0,0.5*hvgen,2,all,,,-r2-r1! 选择长方体，之后将其复制allsel,allvsymm,y,all! 对称操作，y轴为对称轴vglue,all! 将两部分合在一起! 选择并且划分网格lsel,s,loc,x,r1lsel,a,loc,x,r2lsel,a,loc,x,-r1lsel,a,loc,x,-r2lsel,r,loc,z,0lesize,all,,,div2*0.5allsel,allesize,h/div2/4vsweep,all 加载和求解模块","link":"/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-2/"},{"title":"APDL Learning 3","text":"hljs.initHighlightingOnLoad(); 本教程参考的是水哥Ansys的教程，本教程讲的十分的详细，建议学习。 本节主要讲解的是变量的功能单元模块、数组与变量、文件的读入与写出和宏文件。 功能单元模块基本理论 上述的函数命令是比较重要的，最好直接记住。 其中比较重要的命令有： n=nnear(n1)返回是距离节点n1最近的节点编号。 n=node(x,y,z)返回的是(x,y,z)对应节点的编号，获取节点的编号之后，可以通过GET命令来获取的相应的位移。 实例：已建立Node1,Node2，现在需要新建一个坐标为Node1和Node2平均值得节点Node3. 初始得方法： 1234567891011*Get,x1,node,num,node1,loc,x !获取节点Node1x方向坐标值*Get,y1,node,num,node1,loc,y !获取节点Node1 Y方向坐标值*Get,z1,node,num,node1,loc,z !获取节点Node1Z方向坐标值*Get,x2,node,num,node2,loc,x !获取节点Node2x方向坐标值*Get,y2,node,num,node2,loc,y !获取节点Node2 Y方向坐标值*Get,z2,node,num,node2,loc,z !获取节点Node2z方向坐标值xx=(x1+x2)/2 !新建节点x方向坐标yy=(y1+y2)/2 !新建节点Y方向坐标zz=(z1+z2)/2 !新建节点z方向坐标n,node3,xx,yy,zz !新建节点Node3 简化之后得方法： 1234Xx=(nx(nodel)+nx(node2))/2Yy=(ny(nodel)+ny(node2))/2Zz=(nz(node1)+nz(node2))/2n,node3,xx,yy,zz !新建节点Node3 根据上述的命令可得，NX()命令可以看作是*GET,par,node,0,loc,x。 _Return是一种特殊的功能命令，返回函数作用值，并存于指定的变量中。 下面是常见的明亮的返回值： 案例，线动成面，参数化建模。 123456789L,101,568Q1=_Return !返回生成线的编号，并赋值给变量Q1L,587,125Q2=_Return !返回生成线的编号，并赋值给变量Q2L,124,586Q3=_Return !返回生成线的编号，并赋值给变量Q3L,101,568Q4=_Return !返回生成线的编号，并赋值给变量Q4AL，Q1，Q2，Q3，Q4 !生成面 案例分析筏板地基弹簧的建模 这个例子比较简单，实际工程上的网格不可能是这么均匀。 但是在划分单元的时候，可能会出现不同类型的节点，三角形的节点或是四边形的节点单元。如果为三角形的单元，那么其获取得到的第四个节点的值和第三个是相同的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100finish/clear/prep7! 设计单元et,1,shell181et,3,combin39keyopt,3,4,0keyopt,3,3,3keyopt,3,1,0keyopt,3,2,1! 定义材料mp,ex,1,3,25e4 ! C40弹性模量mp,dens,1,2600e-12 ! 密度mp,prxy,1,0.2ESF=200 ! 弹性地基的刚度blc4,,,80000,100000esize,2000amesh,allallsel,all!=============================*get,tmmax,node,,num,max ! 整个模型的最大的节点号esel,s,type,,1 ! 选择c++的单元nsle,s,corner ! 选择全部的交点单元! 下面就是求解每个单元上的弹簧的刚度*get,ntol,node,,count ! 节点总数*get,etol,elem,,count ! 单元总数*get,nmax,node,,num,max ! 最大节点号! dim好像是数组的定义! 上面get获取的是数组的维度*dim,nodno,,ntol ! 存储节点单元*dim,nodk,,nmax ! 存储各节点面积、弹簧单元8*dim,eleno,,etol ! 存储单元号! 获取各个单元号*get,e1,elem,,num,mineleno(1)=e1*do,i,2,etole1=elnext(n1) ! 获取当前节点下一个单元的编号eleno(i)=e1*enddo! 获取各个节点号*get,n1,node,,num,minnodno(1)=n1*do,i,2,ntoln1=ndnext(n1) ! 获取当前节点下一个节点的编号nodno(i)=n1*enddo! 获取每个节点的对应的面积*do,i,1,etolei=eleno(i)n1=nelem(ei,1) ! 获取ei单元的第1个节点n2=nelem(ei,2) ! 获取ei单元的第2个节点n3=nelem(ei,3) ! 获取ei单元的第3个节点n4=nelem(ei,4) ! 获取ei单元的第4个节点*get,ai,elem,ei,area*if,n3,ne,n4,thenai=ai/4.0! 如果3和4节点值不同，那就是四边形nodk(n1)=nodk(n1)+ainodk(n2)=nodk(n2)+ainodk(n3)=nodk(n3)+ainodk(n4)=nodk(n4)+ai*elseai=ai/3.0nodk(n1)=nodk(n1)+ainodk(n2)=nodk(n2)+ainodk(n3)=nodk(n3)+ai*endif*enddo! 求得单元得刚度*do,i,1,nmaxnodk(i)=nodk(i)*ESF*enddo*do,i,1,ntolni=nodno(i)r,i+1,0.01,nodk(ni)*0.01*enddo! 创建弹簧单元type,3*do,i,1,ntolni=nodno(i)n,tmmax+i,nx(ni),ny(ni),nz(ni)-2000 ! 创建节点单元(重合)! 向下偏移2000，增强客观性real,i+1! 注意此处生成弹簧单元节点的顺序，改变了顺序也即e,ni,tmmax+i*enddonsel,s,,,tmmax+1,tmmax+ntolallsel,alleplot 数组和变量基本概念 定义一个变量，可以存储多个数据。 数组分类： 一维数组：一行数据或者一列数据，可以进行矢量运算； 二维数组：行和列的组成，有M行和N列，每行元素是通过$(i,j)$ 位置坐标进行索引的。 数组和变量是可以互相转换的。 三维数组：行、列、面组成，二维空间过渡到三维空间，每个面为一个二维的数组组成，通过$(i,j,k)$来进行索引。 其实平时三维数组不怎么用，循环嵌套比较的麻烦。 数组的定义 Type是我们定义数组的类似，主要分为array、Char、Table三个类型；这三个类型的主要案例可以见第一的学习教程。 Imax、Jmax、Kmax其实是用来定义数组的大小和维度用的。 Var1、Var2、Var3只要是在处理Table类型的数据时才会用到。 案例 123456*Dim,nodenum,array,15!定义数组Nodenum,维数为15*1*1，一维数组*Dim,nodenum,array,15,5!定义数组Nodenum,维数为15*5*1，二维数组*Dim,nodenum,array,15,5,6!定义数组Nodenum,维数为15*5*6，三维数组 在实际的使用的过程中，可以使用低维数组解决的问题就不要使用高维数组。因为低维的数组索引比较的方便。 123456789*get,tmmax,node,,num,max !整个模型的最大节点号esel,s,type,,1nsle,s,corner*get,ntol,node,,count!节点总数*get,etol,elem,,count !单元总数*get,nmax,node,,num,max !最大节点号*dim,nodno,,ntol !存储节点号*dim,nodk,,nmax !存储各节点面积、弹簧刚度*dim,eleno,,etol !存储单元号 数组的删除对于临时组建的数组，如果后续不再利用，需要及时进行删除操作。数组的删除与变量类似，采用“=”进行赋空值进行删除，对于字符型数组，则赋值为””。删除时只需要删除变量名的第一个元素即可，例如： 1234*Dim,nodeNum,array,13,4,3 !定义数值型数组，名为nodeNum，为一个三维数组nodeNum(1,1,1)=!删除数组 数组的赋值数组的赋值其实有两种方法： 直接在APDL中采用”=”的形式赋值，此时经常需要采用结合循环操作*DO使用。 利用*Vread命令，通过文件的写入的方法进行赋值。 主要查看数组，防止出现过多的错误，因为不同的写入的方法，得到的结果是不一样的。 “=”赋值法： 单个元素的赋值； 列矢量进行赋值(位数最好不要长过10)。 案例 现有数组名为Knum，其值为Knum = [24 6810 12141618]T，则在APDL中的实现方法如下： 123456789*Dim,Knum,array,9,1,1!定义一维数组KnumKnum(1)=2,4,6,8,10,12,14,16,18!通过列矢量赋值的方式赋值给数组*Do,I,1,9!通过*do循环，依次赋值给Knum的元素Knum(i)=2*I!进行数组的赋值*Enddo 输入矩阵K： K=\\left[\\begin{array}{ccc}1 & 3 & 5 \\\\ 4 & 6 & 8 \\\\ 7 & 9 & 11\\end{array}\\right]12345678910*Dim,Knum,array,3,3,1!定义二维数组KnumKnum(1,1)=1,4,7!通过列矢量的方式赋值给数组Knum(1,2)=3,6,9Knum(1,3)=5,8,11*Do,j,1,3!通过*do循环赋值给数组*Do,1,1,3Knum(j,i)=3*(J-1)+1+2*(i-1)*Enddo*Enddo 一般情况下，如果非外部文件导入的数值，皆有数值规律可循,这时可考虑采用*do进行赋值操作，当然，如果数据不多，依然可以采用列矢量甚至单个数值赋值的方法进行，数据越多，采用循环的优势就越大。 数组的查看 数值赋值完毕后，不应急于进行下一步操作，而应对数组进行查看，以确定定义的数组达到了预定的要求，特别是针对通过*vread方式从外部文件写入数据的数组，很多时候由于*Vread格式问题，数据没能正确导入，导致后续操作出现错误。 查看数组的方式有两种，一种通过*Status命令进行查看，另外一种通过菜单栏UtilityMenu—-—Parameters——Array Parameters——Define/Edit。 这里水哥比较推荐使用GUI的方法来进行查看。 时间历程变量和数组的转换 时间历程后处理变量只存在于数据库中，离开后处理模块，会被软件从当前数据库中删除，只能为一维数量。 数组存在于程序运行全过程，可以为一维、二维、三维。 数组的值一直存在，除非你关闭了ANSYS。 变量不可通过命令流的方式导出，但可手动保存为CSV格式用excel打开。 但是当程序里面的变量过多时，每个都需要进行单独保存。 数组可通过*Vread、*Vwrite导入或者写出。 主要的操作有：时间历程变量赋值给数组和数组赋值给变量两种。 时间历程变量赋值给数组(用的多) 在使用的时候，一般关注的是前两个参数，最终数组的名称和时间历程后处理的编号，后面的两个参数使用的不是很多。 数组赋值给时间历程变量 文件的读入和写出这里的命令不是很多，但是对应研究是相当重要的。 地震时程分析，需要读入地震波数据； 结构反应谱分析，需要读入反应谱数据； 时间历程后处理，需要将结果数据导出并采用第三方数据软件对结果进行绘制美化。 文件的读入和写出主要包含三个方面的内容：数据格式、文件读入、文件写出。 文件读入文件读入的基本格式123456789101112*Create,dataread,mac!创建宏文件，名为dataread，名称可更改*dim,Elcentro,,2600!创建读入数据的数组*vread,Elcentro(1,1),Elcentro,txt,,ijk!读入文件Elcentro.txt的数据(f6.3)!读入格式*End!结束宏文件的创建Dataread!运行宏文件 具体命令1*Vread,ParP,Frname,Ext,--,Label,n1,n2,n3,Nskip ParP是读入数据的赋值对象数组，使用前需采用*dim命令进行定义； Frname为带路径的文件名，注意路径不能有中文名，如果是放在工作目录下，则直接写文件名字即可; Ext是文件的扩展名； Label是取值顺序标识字符，分别为IJK、IKJ、JIK、JKI、KIJ、KJI，默认为IJK； 其实就是先写入行还是先写入列。 nl、n2、n3分别为根据取值顺序标识符所采用的取值； Nskip为读入数据文件时需要跳过的开始行数，默认为0，表示从第一行开始读入数据。 ANSYS中读取数据总是按照行进行，最后结果的不同只是和写入数组顺序以及读取的数值个数有关!未匹配到的数据会以0代替。 案例对比 首先，读取是从AA(1,1)开始的。 ijk,6,5的意思是先读入列，并且每列是读取6个数字。注意这里读取原来文件里面的数据都是按照行来读取的。 (5f3.0)：读取文件时，是按照行的顺序来读入的，5代表每次读入5个数据每个数据的长度为3，空格就是直接忽略了。 (4f3.0)：就是读取时，每行仅仅读取4个数，最后的数就不读了。 读入数据之后再按照列的顺序写入到数组内。 读完之后发现其最后的数不够了，于是就使用0来进行补全。 (5f5.0)的含义是，每行读取5个数据，每个数据的长度为5，包含空格也占了一位数，后面发现仅仅读了三个就不够了，于是使用0来进行补齐。 读入到数组的时候，仅仅读入前三列的内容，后面的没有内容读入就使用0来进行补齐。 这里改变写入数组的列数4，将读取的5个数的前四个写入，最后一个写入到下一行中。 AA(6,5)定义的是6行五列，这里写入先写行，并且一次就如6个元素，超过每每行所能容纳的5个元素的上限，就报错了。 改成这样的话就可以了，每次写入5个元素即可。 数组读入后，最好要进行查看操作，防止出现错误。 总结 确定读入数据的维度，如行数m以及列数n。 定义数组，维数为m*n， *dim,parp,array,m,n 采用*vread命令，并且采用JIK的顺序 *vread,parp(1,1),data,txt,,jik,n,m 文件写出文件写出的基本格式 数据格式紧挨*Vwrite和*Vread命令； 主要的10种数据格式： I格式、F格式、E格式、G格式、D格式、L格式、A格式、H格式、X格式、/(斜杠)格式。实际上90%的格式都是F格式。 F格式 F格式又称之为小数型格式，为最常用的格式，童鞋们应重点掌握。其使用形式为Fw.d，其中w各数值占的总位数，d输出数据的小数位数(小数点后的位数)。 注意事项 向右靠齐，没有的使用空格来补全。像第二个是输入的位数大于了4位，于是就是不进行输出了，全部使用空格来进行不去操作。 对应小数部分，给定的位数多了就是补0，少了就将相关的位数进行舍去。 I格式 由于这个格式用的比较的少，在这里就简单略过了。 X格式 具体命令1*Vwrite，Par1 ,Par2， Par3，Par4，Par5,Par6, , ， Par19 其中，Par1~Par19是依次写出的19个参数或者参数，在使用*Vwrite进行数据写出之前，必须需用*Cfopen命令打开或者创建一个数据文件，*Cfclos则为关闭文件，需配对使用。 1*Cfopen,Fname,Ext,--,Loc 与读入命令*Vread相类似，*Vwrite同样不能作为已知的APDL命令直接输入命令窗口使用，必须作为外部宏文件命令使用，其也有固定的使用格式。 数据写出按行写出! 12345678910*create,datawrite,mac !创建宏文件名字Datawrite*cfopen,filedada,txt !创建写出文件的文件名字filedata*do,i,1,2600 !利用*do命令逐个写出数组的数据aa=variable(i) !将具体的数值赋值给变量AA*vwrite,aa !写出变量AA的数值(f6.3) !写出格式*enddo !结束循环*cfclose !关闭文件*end !宏文件创建完毕Datawrite !运行宏文件 这里将数组里面的内容导入到一个变量，然后再写入到文件中。 案例【例】数据库已经定义数组nodenum,采用*Vwrite写出到数据文件，文件名为 Nodenum.txt 1234567891011121314151617/prep7*dim,nodenum,array,20,5!给数组nodenum赋值*do,J,1,20 *do,I,1,5 Nodenum(j,i)=5*(j-1)+i*enddo *enddo*enddo *create,datawrite,mac*cfopen,dda,txt*do,j,1,20*vwrite,nodenum(1,1),nodenum(1,2), nodenum(1,3),nodenum(1,4), nodenum(1,5)(5F8.2)*enddo*cfclose*enddatawrite 对应时间历程数据的存储问题： 首先，用*get获取总共的时间num步骤； 之后，建立数组*dim,ux,array,num*； 最后，使用*Vget命令将变量的值转化成为数组。 1234567891011121314*dim,Uy2,array,29Vget,Uy2,4*status,Uy2*create,Uy2write,mac*cfopen,Uy2,txt*do,i,1,29aa=uy2(i)*vwrite,aa(f7.4)*enddocfclose*endUy2write 宏文件无参数的宏文件基本概念 记录一些列频繁使用命令的集合，后缀名为Mac； 命令的模块化，通过对模块的重新命名，自定义ANSYS命令方式集体调用； 宏文件一般存放于工作目录下。 下面事宏文件的创建，之间再命令流里面进行创建的。 12345678*Create,BLC4-Creat,mac !创建宏文件/prep7Blc4...4,5,5Sphere,1Vsbv,1,2Finish*End !结束宏文件创建BLC4-Creat !运行宏文件 当然，也是可以不写前缀和后缀的内容，将主要的内容复制粘贴到对应的.txt文件中，之后将.txt文件进行改名处理.mac。 但是，上述的方法比较的复杂，需要很多的操作。水哥建议使用命令流的方法。 使用宏文件的主要的有点： 大幅度减少程序篇幅，增加程序可读性。 提高程序运行效率，针对前处理建模阶段。 二次开发需要。 某些特殊命令必须采用宏文件执行。 宏文件的命名 文件名的字符不能操超过32个字符； 文件名不可以使用数字作为开头，不能包含空格； 命名时要避免的采用在APDL中已经参在过的命令； 水哥建议，在实际的使用的时候，要将工程常用的元素引入到命名中，就是将我们常用词汇的缩写引入到命令当中。 宏文件的创建方式 在外部的文档编写器，保存为.mac形式； 采用*create命令。 案例梁单元内力图的绘制 其实workbench其实就是使用了一些宏文件，将常用的操作变成宏文件，进而封装成一个工具条。 带参数的宏文件基本概念宏文件的变量主要有全局变量和局部变量两种： 宏文件外部输入变量——全局变量； 宏文件内部定义变量——局部变量； 带参数的宏文件的定义 通过外部输入变量，实现很多参数化宏文件的定制 一个宏命令，最多可同时输入19个变量，代号分别为ARG1~ARG19 案例地址反应谱宏文件的创建 案例自定义阶乘函数 自定义工具条 其实是将常用的命令进行封装，有点类似于宏文件，提高仿真的效率。 工具条里面的选项是平时常用的工具，而不是将所有的命令全部做成工具条。 工具条的制作1*Abbr , Abbr_name, string Abbr_name：工具条名称； String：工具条所代表的命令(可以是宏文件)。 工具条的嵌套 最好不要嵌套的超过3层，这里的嵌套就是相当打开下一级的工具条。","link":"/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-3/"},{"title":"VIT模型基础及代码实现","text":"hljs.initHighlightingOnLoad(); 本文首先简单介绍self-attention机制，之后关注其在CV领域的应用VIT模型进行深入的介绍，最后对VIT的各个模块进行代码实现。本文仅仅涉及的是模型部分的实现，对于训练部分其对于小数据集的效果不是很好，于是本文不再复现。 self-Attention 机制概述 tranformer的引入主要是针对语言模型的，只要解决之前的语言模型中的几个问题： RNN，LSTM无法实现并行化，只有将前面的计算好之后才可以计算后面的节点； RNN的记忆时间比较的短，而LSTM主要解决的就是RNN的记忆比较短的问题； transformer模型的精髓就是三个图和三个公式。 单self-attention模块下面引入李宏毅老师的视频课来具体的进行介绍： $W^{q}、W^{k}、W^{v}$ 在代码里面是通过全连接成实现的，其中这三个矩阵在整个网络中是共享的参数，主要的作用是来进行编码，是可以学习的参数。 $q^i=a^iW^q$ 是用来匹配的项； $k^i=a^iW^k$是被匹配的关键词； $v^i=a^iW^v$ 是用来储存信息的编码项； 这些矩阵运算是可以通过矩阵的拼接来实现并行化的操作。 计算完$q,k,v$之后，将每个$q^i$取匹配其余所有的$k$，这里的相似度的计算是通过点积来定义的，将每个$q^i$和其余的$k$向量进行点积得到项相似度。 计算点积的操作和编码的过程是一样的，都是可以通过矩阵拼接来并行计算。 最后将上述的结果相加即可，于是self-attention 层就将输入的$a_1,a_2$转化成为$b_1,b_2$。 这里可以将上述的self-attention抽象成为一个模块更好理解。 Multii-head Self-Attention引入一个2-head的情况，来进行分析，其本质就是通过矩阵运算(线性映射)来将之前的几个$q,k,v$分解成为多个，其他求解相似度的方法和之前相似。 上图为了方便理解，就直接将前面的$q,k,v$进行平均的拆分。 根据第二个下标将上述的$q,k,v$归结不同的head集合里去，之后对不同的head分别计算相似度值。比如将$q^{1,1}$和$q^{2,1}$这种第二个下标相同的放到同一个head集合去。 同样的，通过矩阵拼接操作可以实现并行计算。 之后根据第一个上标重新将计算的得到的相似度重新进行分类和拼接操作，本质就是将之前在不同head计算的相似度的结果还原回去。 将还原回去的结果重新进行拼接操作。如将$b_{1,1}$和$b_{1,2}$进行拼接，将$b_{2,1}$和$b_{2,2}$拼接。 将不同head计算的结果重新进行拼接的之后，通过一个线性映射$W^O$来进行数据融合。 同时$W^O$的另一个作用是为了保证，multi-head attention的向量的长度保持不变。 总结可以发现，这里的multi-head机制其实和之前的ResNeXt的对应的Group Convolution类似。 将其也可以抽象成一个模块如下图所示。 Positional Encoding位置编码问题的产生： 将之后的$a_2,a_3$进行位置上的交换操作，重新计算相似度的编码其实对$b_1$来说是不受影响的，这样就是造成奇异和实际情况不符，因此这里引入位置编码。 位置编码的设置方法主要有两种： 使用可训练到的位置编码； 使用公式定义好的位置编码，典型的就是余弦位置编码。 但是其实两种方式得到位置编码效果是一样的，VIT模型目前使用的是可以训练的位置编码。 Vision Transformer 其本质是将一个图片分块，将一个$16\\times16$的patch看成一个单词。 实验的效果如下： 首先是在GOOGLE的JFT数据上进行预训练，之后到ImageNet里面迁移学习。 其他就是在ImageNet21K上进行预训练，之后在ImageNet上面进行迁移。 文章主要的对比的模型主要包含以下几种： 纯CNN模型：ResNet101、ResNet152、ResNet50等； Hybrid模型：传统的CNN和Transformer混合模型，比如增加通道self-attention机制的SE-Net、CBAM等； 纯transformer模型：VIT、Swin-transformer等。 模型搭建 基本原理就是将图片分成多个 $16\\times 16$ patch。 每个patch需要通过一个Linear的网络进行编码(Embedding)操作，得到一个向量(token)；这里因为需要进行分类操作，需要在最前面增加一个class token，其长度和patch token是相同的。 将这些token配合时间编码(位置信息)输入到Transformer Encoder里面，其主要就是将这个Encoder的block重复堆叠L次。 最后通过Multi-head机制输出对应class信息。 Embedding层下面将这些层分开进行介绍，首先是Embedding层。 输入：大小为[num_token,token_dim]的二维矩阵，即token的向量序列。 在实现patch间的分块操作是通过卷积来实现的，通过$16 \\times 16$ 的卷积核，stride=16 ，其中卷积核的channel=768，之后将[H,W]进行展平。 上面的class token其实就是在原来token的基础上，增加了参数来代表类别参数。 在VIT中，位置编码使用的是可以学习的位置编码，这个编码是采用与token一样的长度，将其直接加在之前的token上即可。 上述实验的结果可知，对于位置编码而言，其有无的差别比较大，但是相应的位置编码的种类的差别其实不是很大，因此一般情况下，就用1D的位置编码即可。 以上是不同编码位置上的余弦相似度，这里采用的patch是$32 \\times32$ 的，因此其是$7\\times7$的形式。 其实就是通过学习的方法学习得到的位置编码，将其展平之后的结果图，可以发现在同一行和同一列上的相似度会比较的大。 Transformer Encoder层 在Attention里面的Norm默认是Layer Norm。 Norm层的结果会输入到Multi-Head层中，之后通过一个Dropout层(代码实现是用的是DropPath)。 一说DropPath的效果会比一般的Dropout要好很多。 MLP和Multi-Head层采用的都是残差连接的方式。 MLP Block是先将维度升高成为原来的4倍，之后将再进行将为操作变回原来的维度。 MLP head层 对于训练比较的大的模型而言，其在末端包含了多个全连接层； 之后对网络进行迁移或者是直接在小数据集上使用的时候，会把全连接层的层数减少。 vIt-B/16模型的整体架构 class torken和Position Embedding 是一个可以训练的参数值； 之后需要经过12层Transformer Encoder层和一个layer Norm层； Layer Norm之后，对于分类任务来讲，将第一个class torken单独提取出来，输出到MLP Head层里面； 对于Image Net和自己的数据集而言，其实就是可以不用Pre-logits层。 VIT常用的三个模型的参数 上述参数的说明： Layers是Transformer Encoder中重复堆叠Encoder Block的次数； Hidden Size是通过Embedding层后每个token的dim(向量的长度)； MLP size是Transformer Encoder中MLP Block第一个全连接的节点个数(是Hidden Size的四倍)； Heads代表Transformer中Multi-Head Attention的heads数 Hybrid 模型详解模型基本架构 Hybrid混合模型，就是将传统CNN特征提取和Transformer进行结合，这里使用的是R50作为特征提取器； R50和原始的ResNet不同，其中的卷积层主要采取的StdConv2d而不是Conv2d，并且需要将所有的BatchNorm层换成GroupNorm； 把stage4中的3个Block移到stage3里面，原始的R50有[3,4,6,3]四个下采样，但是实际的情况是将其转化成为3个下采样层，最后两个层直接进行合并。 补充关于几种归一化 BN，LN，IN，GN从学术化上解释差异： BatchNorm：batch方向做归一化，算NHW的均值 LayerNorm：channel方向做归一化，算CHW的均值 InstanceNorm：一个channel内做归一化，算H*W的均值 GroupNorm：将channel方向分group，然后每个group内做归一化，算(C//G)HW的均值 LN 和 IN 在视觉识别上的成功率都是很有限的，对于训练序列模型（RNN/LSTM）或生成模型（GAN）很有效。 所以，在视觉领域，BN用的比较多，GN就是为了改善BN的不足而来的。 GN 把通道分为组，并计算每一组之内的均值和方差，以进行归一化。GN 的计算与批量大小无关，其精度也在各种批量大小下保持稳定。可以看到，GN和LN很像。 结果对比 在训练的此时比较少的情况下，Hybrid模型的效果会更好； 反之ViT模型会好于Hybrid模型。 对比发现，ViT对算例的耗费很大，实际工程可能用不起这种模型。 VIT代码实现 随机深度的代码实现这段代码的主要的功能是实现随机深度的,具体的讲解可以参考EifficentNet，这里不再赘述。 12345678910111213141516171819202122232425262728def drop_path(x, drop_prob: float = 0., training: bool = False): &quot;&quot;&quot; Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks). This is the same as the DropConnect impl I created for EfficientNet, etc networks, however, the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper... See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use 'survival rate' as the argument. &quot;&quot;&quot; if drop_prob == 0. or not training: return x keep_prob = 1 - drop_prob shape = (x.shape[0],) + (1,) * (x.ndim - 1) # work with diff dim tensors, not just 2D ConvNets random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device) random_tensor.floor_() # binarize output = x.div(keep_prob) * random_tensor return class DropPath(nn.Module): &quot;&quot;&quot; Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks). &quot;&quot;&quot; def __init__(self, drop_prob=None): super(DropPath, self).__init__() self.drop_prob = drop_prob def forward(self, x): return drop_path(x, self.drop_prob, self.training) PatchEmbed 部分的代码实现本部分的主要的功能就是将图片分成不同的patch块，然后将每个块变成一个向量。 12345678910111213141516171819202122232425class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_c=3, embed_dim=768, norm_layer=None) -&gt; None: super().__init__() img_size = (img_size, img_size) patch_size = (patch_size, patch_size) self.img_size = img_size self.patch_size = patch_size self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1]) self.num_patches = self.grid_size[0]*self.grid_size[1] # 定义卷积层 self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size) self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity() def forward(self, x): B, C, H, W = x.shape assert H == self.img_size[0] and W == self.img_size[1], \\ f&quot;Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).&quot; # flatten: [B, C, H, W] -&gt; [B, C, HW] x = self.proj(x).flatten(2) # transpose: [B, C, HW] -&gt; [B, HW, C] x = x.transpose(1, 2) x = self.norm(x) return x Transformer Encoder层的实现attention block的实现本部分主要实现Transformer Encoder层，其主要是将Patch Embedding的内容进行注意力机制处理。 其中需要注意的要点有： multi-head的是将一个整的向量进行等分：[0,1,2,3,4,5]-&gt;[0,1] [2,3] [4,5] ； 其中很多reshape ,permute,transpose也是为了方便计算相似度； @在pytorch里面是矩阵相乘的意思。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Attention(nn.Module): def __init__(self, dim, # 输入torken的dim num_heads=8, qkv_bias=False, qk_scale=None, attn_drop_ratio=0, proj_drop_ratio=0 ) -&gt; None: super().__init__() self.num_heads = num_heads head_dim = dim // num_heads # model的dim / head = q_dim = k_dim = v_dim self.scale = qk_scale or head_dim ** -0.5 # qk_scale默认是None,于是自己计算一下,如果传入了，就使用传入的。 # 这里对应的就是相似度公式中除以sqrt(d_k) self.qkv = nn.Linear(dim, dim*3, bias=qkv_bias) # 计算得到qkv,也可以使用三个dim-&gt;dim的MLP self.attn_drop = nn.Dropout(attn_drop_ratio) # 将多个head的结果拼接之后，需要进行一部映射操作 self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_drop_ratio) def forward(self, x): # [batch_size, num_patches + 1, total_embed_dim] B, N, C = x.shape # qkv(): -&gt; [batch_size, num_patches + 1, 3 * total_embed_dim] # qkv其实就是将3个q、k、v堆叠起来的得到的-&gt;3*total_embed_dim # reshape: -&gt; [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head] # 将qkv三个拆开，并且根据head数将q,k,v向量进行拆分[0,1,2,1]-&gt;[0,1][2,1] # permute: -&gt; [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head] qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) # [batch_size, num_heads, num_patches + 1, embed_dim_per_head] q, k, v = qkv[0], qkv[1], qkv[2] # make torchscript happy (cannot use tensor as tuple) # 上述的处理其实主要是为了方便切片获取元素，并计算相似度 # transpose: -&gt; [batch_size, num_heads, embed_dim_per_head, num_patches + 1] # @: (矩阵乘法操作)multiply -&gt; # 矩阵乘法之后结果的维度 -&gt; [batch_size, num_heads, num_patches + 1, num_patches + 1] attn = (q @ k.transpose(-2, -1)) * self.scale # scale其实就是1/sqrt(d_k),相当于进行了归一化的处理 attn = attn.softmax(dim=-1) # dim=-1其实就是对每一行的数据的进行处理 attn = self.attn_drop(attn) # @: multiply -&gt; # 矩阵乘法之后结果的维度 -&gt; [batch_size, num_heads, num_patches + 1, embed_dim_per_head] # transpose: -&gt; [batch_size, num_patches + 1, num_heads, embed_dim_per_head] # reshape: -&gt; [batch_size, num_patches + 1, total_embed_dim] # reshape的结果其实就是对num_head进行拼接 x = (attn @ v).transpose(1, 2).reshape(B, N, C) x = self.proj(x) x = self.proj_drop(x) return x MLP Block的代码实现本部分主要是将attention之后代码进行全连接的操作。 123456789101112131415161718class Mlp(nn.Module): def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.0) -&gt; None: super().__init__() out_features = out_features or in_features hidden_features = hidden_features or in_features self.fc1 = nn.Linear(in_features, hidden_features) self.act = act_layer() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(drop) def forward(self, x): # 原始的网络其实是先上采样到原来的四倍，之后恢复 x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x Encoder Block的搭建 将上述所有的层进行汇总可得下面的类，其就是注意力机制的编码层。 12345678910111213141516171819202122232425262728class Block(nn.Module): def __init__(self, dim, num_heads, mlp_ratio=4, # 在默认的条件下，mlp层扩展的倍数 qkv_bias=False, qk_scale=None, drop_ratio=0.0, attn_drop_ratio=0.0, drop_path_ratio=0.0, act_layer=nn.GELU, norm_layer=nn.LayerNorm ) -&gt; None: super().__init__() self.norm1 = norm_layer(dim) self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio) # 实例化multi-head注意力 self.drop_path = DropPath(drop_path_ratio) if drop_path_ratio &gt; 0.0 else nn.Identity() # 如果大于drop_path_ratio时，会使用Drop_path_ratio的操作 self.norm2 = norm_layer(dim) mlp_hidden_dim = int(dim*mlp_ratio) self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio) def forward(self, x): x = x + self.drop_path(self.attn(self.norm1(x))) x = x + self.drop_path(self.mlp(self.norm2(x))) return x Vision Transformer层的实现主要参数： img_size (int, tuple): input image size patch_size (int, tuple): patch size in_c (int): number of input channels num_classes (int): number of classes for classification head embed_dim (int): embedding dimension depth (int): depth of transformer num_heads (int): number of attention heads mlp_ratio (int): ratio of mlp hidden dim to embedding dim qkv_bias (bool): enable bias for qkv if True qk_scale (float): override default qk scale of head_dim ** -0.5 if set representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set，其主要的作用是是否构建pre-logits层。 distilled (bool): model includes a distillation token and head as in DeiT models，其主要和DeiT模型相关，这里可以不用考虑这个参数。 drop_ratio (float): dropout rate attn_drop_ratio (float): attention dropout rate drop_path_ratio (float): stochastic depth rate embed_layer (nn.Module): patch embedding layer norm_layer: (nn.Module): normalization layer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_c=3, num_classes=1000, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, qkv_bias=True, qk_scale=None, representation_size=None, distilled=False, drop_ratio=0., attn_drop_ratio=0., drop_path_ratio=0., embed_layer=PatchEmbed, norm_layer=None, act_layer=None): super(VisionTransformer, self).__init__() self.num_classes = num_classes self.num_features = self.embed_dim = embed_dim # num_features 在不同的模型里面是保持一致的 self.num_tokens = 2 if distilled else 1 # 这里可以不用管，将tokens看作是1即可 norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6) # 默认norm_layer是None，这里使用partial方法给其进行赋值 act_layer = act_layer or nn.GELU self.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim, ) num_patches = self.patch_embed.num_patches # 这里的num_patches其实就是14*14=196 # 构建class_token self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) # 这里的第一个维度的是为了后续进行concante拼接而加上去的 self.dist_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) if distilled else None # 增加位置编码 self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim)) self.pos_drop = nn.Dropout(p=drop_ratio) dpr = [x.item() for x in torch.linspace(0, drop_path_ratio, depth)] # 如果采取drop_path时，随着层数的增加drop_ratio不断地增大，但是默认时0.0 self.blocks = nn.Sequential( *[Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale, drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i], norm_layer=norm_layer, act_layer=act_layer) for i in range(depth)] ) self.norm = norm_layer(embed_dim) # Representation layer if representation_size and not distilled: self.has_logits = True self.num_features = representation_size # 采取有序字典集的方法来对模型进行构建 # 其只要的层就只有两层 self.pre_logits = nn.Sequential(OrderedDict([ (&quot;fc&quot;, nn.Linear(embed_dim, representation_size)), (&quot;act&quot;, nn.Tanh()) ])) else: self.has_logits = False self.pre_logits = nn.Identity() # Classifier head(s) 分类head其实就是一个Linear层 self.head = nn.Linear(self.num_features, num_classes) if num_classes &gt; 0 else nn.Identity() self.head_dist = None if distilled: self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes &gt; 0 else nn.Identity() # Weight init # 权重初始化的部分 nn.init.trunc_normal_(self.pos_embed, std=0.02) if self.dist_token is not None: nn.init.trunc_normal_(self.dist_token, std=0.02) nn.init.trunc_normal_(self.cls_token, std=0.02) self.apply(_init_vit_weights) # 前向特征提取的函数 def forward_features(self, x): # [B, C, H, W] -&gt; [B, num_patches, embed_dim] x = self.patch_embed(x) # [B, 196, 768] # [1, 1, 768] -&gt; [B, 1, 768] cls_token = self.cls_token.expand(x.shape[0], -1, -1) # 这里的操作其实是将class_token在Batch方向进行扩充 if self.dist_token is None: x = torch.cat((cls_token, x), dim=1) # [B, 197, 768] # 将class进行扩充操作 else: x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1), x), dim=1) x = self.pos_drop(x + self.pos_embed) # 堆叠Encoder x = self.blocks(x) # Layer_norm x = self.norm(x) if self.dist_token is None: # 仅仅将class_token部分提取出来进行分类 return self.pre_logits(x[:, 0]) else: return x[:, 0], x[:, 1] # 前向传播函数 def forward(self, x): x = self.forward_features(x) if self.head_dist is not None: x, x_dist = self.head(x[0]), self.head_dist(x[1]) if self.training and not torch.jit.is_scripting(): # during inference, return the average of both classifier predictions return x, x_dist else: return (x + x_dist) / 2 else: x = self.head(x) return x# 初始化函数def _init_vit_weights(m): &quot;&quot;&quot; ViT weight initialization :param m: module &quot;&quot;&quot; if isinstance(m, nn.Linear): nn.init.trunc_normal_(m.weight, std=.01) if m.bias is not None: nn.init.zeros_(m.bias) elif isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=&quot;fan_out&quot;) if m.bias is not None: nn.init.zeros_(m.bias) elif isinstance(m, nn.LayerNorm): nn.init.zeros_(m.bias) nn.init.ones_(m.weight) VIT的模型需要相当多的数据才可以训练的起来，因此其需要的千万级的数据量才可能看得到效果，一般使用的时候都是直接使用其在ImageNet上面的预先训练好的权重，而不是自己训练的重新开始训练。","link":"/2022/12/26/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VIT%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"}],"tags":[{"name":"Typora","slug":"Typora","link":"/tags/Typora/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"auto-encoder","slug":"auto-encoder","link":"/tags/auto-encoder/"},{"name":"生成模型","slug":"生成模型","link":"/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"},{"name":"无监督学习","slug":"无监督学习","link":"/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","link":"/tags/Generative-Adversarial-Networks/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"GAN实战","slug":"GAN实战","link":"/tags/GAN%E5%AE%9E%E6%88%98/"},{"name":"Latex","slug":"Latex","link":"/tags/Latex/"},{"name":"SLAM","slug":"SLAM","link":"/tags/SLAM/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"object detection","slug":"object-detection","link":"/tags/object-detection/"},{"name":"机械振动","slug":"机械振动","link":"/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"},{"name":"图像分类","slug":"图像分类","link":"/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"latex","slug":"latex","link":"/tags/latex/"},{"name":"论文写作","slug":"论文写作","link":"/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"},{"name":"IEEE投稿","slug":"IEEE投稿","link":"/tags/IEEE%E6%8A%95%E7%A8%BF/"},{"name":"科研","slug":"科研","link":"/tags/%E7%A7%91%E7%A0%94/"},{"name":"控制理论","slug":"控制理论","link":"/tags/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"},{"name":"control theory","slug":"control-theory","link":"/tags/control-theory/"},{"name":"自注意力机制","slug":"自注意力机制","link":"/tags/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"},{"name":"Pytorch","slug":"Pytorch","link":"/tags/Pytorch/"},{"name":"Transformer","slug":"Transformer","link":"/tags/Transformer/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"图神经网络","slug":"图神经网络","link":"/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Graph","slug":"Graph","link":"/tags/Graph/"},{"name":"Neural Networks","slug":"Neural-Networks","link":"/tags/Neural-Networks/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"目标检测","slug":"目标检测","link":"/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"语义分割","slug":"语义分割","link":"/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"},{"name":"Machine learning","slug":"Machine-learning","link":"/tags/Machine-learning/"},{"name":"Deep learning","slug":"Deep-learning","link":"/tags/Deep-learning/"},{"name":"point cloud","slug":"point-cloud","link":"/tags/point-cloud/"},{"name":"Finite Element Analysis","slug":"Finite-Element-Analysis","link":"/tags/Finite-Element-Analysis/"},{"name":"有限元分析","slug":"有限元分析","link":"/tags/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90/"},{"name":"ANSYS","slug":"ANSYS","link":"/tags/ANSYS/"}],"categories":[{"name":"Typora","slug":"Typora","link":"/categories/Typora/"},{"name":"auto-encoder","slug":"auto-encoder","link":"/categories/auto-encoder/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","link":"/categories/Generative-Adversarial-Networks/"},{"name":"PyTorch教程与源码讲解","slug":"PyTorch教程与源码讲解","link":"/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"},{"name":"Latex","slug":"Latex","link":"/categories/Latex/"},{"name":"SLAM","slug":"SLAM","link":"/categories/SLAM/"},{"name":"opencv","slug":"opencv","link":"/categories/opencv/"},{"name":"振动力学","slug":"振动力学","link":"/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"},{"name":"图像分类网络及Pytorch实现","slug":"图像分类网络及Pytorch实现","link":"/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"},{"name":"科研入门笔记","slug":"科研入门笔记","link":"/categories/%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"name":"现代控制理论","slug":"现代控制理论","link":"/categories/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"},{"name":"自注意力机制和Transformer","slug":"自注意力机制和Transformer","link":"/categories/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/"},{"name":"图神经网络","slug":"图神经网络","link":"/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"机器学习基石","slug":"机器学习基石","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/"},{"name":"目标检测与pytorch实现","slug":"目标检测与pytorch实现","link":"/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Epytorch%E5%AE%9E%E7%8E%B0/"},{"name":"语义分割及Pytorch实现","slug":"语义分割及Pytorch实现","link":"/categories/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"},{"name":"高级机器学习","slug":"高级机器学习","link":"/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Point Cloud","slug":"Point-Cloud","link":"/categories/Point-Cloud/"},{"name":"Finite Element Analysis","slug":"Finite-Element-Analysis","link":"/categories/Finite-Element-Analysis/"}]}