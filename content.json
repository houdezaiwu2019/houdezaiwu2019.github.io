{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/01/18/hello-world/"},{"title":"Typora入门","text":"本文主要从目录设置、标题设置、特殊的标记符号、导入公式和列表以及图片图床的设置与排版来进行整理。 目录篇代码：[TOC] 标题篇对于Typora来说，主要分为快捷键方法和一般的直接写代码的方法，这里我比较推荐的还是直接写代码的方法，但是新手入门还是比较推荐先使用快捷键来进行入门。 标题的代码：==#+空格+内容== 这里有几个#就是几级标题 123# 一级标题## 二级标题### 三级标题 标题的快捷键：Ctrl+(数字) Ctrl+0 &lt;=&gt; 一般段落 Ctrl+1 &lt;=&gt; 一级标题 Ctrl+2 &lt;=&gt; 二级标题 连续两次Ctrl+同一个数字：取消标题操作 Ctrl+ +/-：代表标题的升级和降级 标记符号篇标记符号这里主要讲的是加粗、斜体、下滑线、高亮和内置公式与代码。 加粗：快捷键==Ctrl+B==，代码**text** 斜体：快捷键==Ctrl+I==，代码*text* 下滑线：快捷键==Ctrl+U==，代码**&lt;u&gt;text&lt;/u&gt;** 高亮：代码==text== 内置代码：快捷键==Ctrl+Shift+`==，代码`` 代码块：快捷键==Ctrl+Shift+K==， 代码: “```”+语言(c++/python/java) “```” 内置公式：代码\\aplha，这里使用的是latex代码进行标记的。 公式块：快捷键==Ctrl+Shift+M==，代码$$$ $$$ 1234$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}引用：快捷键==Ctrl+Shift+Q，代码&gt;+空格+text 书籍是人类进步的阶梯。——高尔基 超级链接：代码[blibli](https://www.bilibili.com) [text](#name) eg1. blibli 的链接 eg2.目录 的链接 脚注：代码text[^name],之后在后面[^name]:text 1,这里添加成功后，后面会出现回车 ↩符号。 上标：代码X^2 下标：代码H~2~o 注意这里需要的一些额外的设置： 列表篇有序列表：快捷键==Ctrl+Shift+[==，代码1.+空格+text 无序列表：快捷键==Ctrl+Shift+]==，代码-+空格+text 注意：无序列表如果想切换到下一级时可以直接按==tab== 表格：快捷键==Ctrl+T==，之后弹出对话框，自己来选择需要的行数和列数。 今天 明天 早饭 午饭 晚饭 上述表格的源代码： 12345| | 今天 | 明天 || :--: | :--- | :--: || 早饭 | | || 午饭 | | || 晚饭 | | | 这里还是用快捷键吧，使用代码太麻烦了。 图片篇本地路径导入图片 一般来说，图片使用的是绝对路径，如下图所示为直接截图并粘贴等到的图片的路径。但这种语言不是md的语言。 &lt;img src=&quot;C:\\Users\\dell\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220118215115730.png&quot; alt=&quot;image-20220118215115730&quot; style=&quot;zoom:50%;&quot; /&gt;。 这里的路径是Typora自行生成的，但实际输入的时候要输入代码![]()。 也可以用相对路径，代码是![](./+name.png/jpg) ./代表的是当前的文件夹。 ../代表的是上一级文件夹。 ![](./pic01.png) 对于.md来说，保存图片一般使用的是保存图片的链接，这样可以减小文件的空间（相比Word）。但这样会造成修改了文件或者图片的路径以及清除的C盘的缓存文件时会造成无法显示的问题。 利用图床导入图片这里有个比较矛盾的问题，使用GitHub的图床的话会造成国内没有VPN的用户无法访问，但是使用一般的七牛云的话要花钱，因此再三考虑我们使用码云gitee来作图床（弊端是图片的大小不能超过1M）。 将插入图片的无任何操作-&gt;上传图片 根据picgo的位置来配置路径。并且这里还要下载一个node.js，下载过程这里省略。 到picgo中下载gitee的插件，这里我们使用的是第三个，当然其他的两个也是可以的，但以下将围绕第三个gitee-uploader来配置。 在gitee里面创建仓库，注意创建时一定要点击初始化，只有这样才可以上传图片。如果没有点，那么创建好仓库时也可以点初始化。 要生成一个token，打开gitee的设置，点击生成令牌。点击设置-&gt;安全设置-&gt;私人令牌 设置权限，起个名字点击生成。注意令牌只弹出一次，最好找个记事本记录下来，防止自己忘记。 配置picgo，打开图床设置-&gt;gitee。 注意，这里自己仓库命名repo格式：用户名/仓库名。 但是之前遇到了问题，上传的图片在本地无法显示，其中的原因是gitee设置的是私有的，可以在仓库的管理界面更改。 Typora图片排版这里图片排版需要我们掌握一点点HTML(Hyper Text Markup Language)的语法知识。 图注 12345678# 这里为上面图片的HTML代码&lt;center&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; // 这里&lt;br&gt;的意思是回车，如果没有br会和图片是并排的 图注&lt;/center&gt; 因此，要实现下面两个图片并排的效果，就可以直接将图片的放一起即可，如果实现连个图片的上下排列，这是需要在之间加一个&lt;br&gt;即可 这里的&lt;center&gt;是默认图片居中的意思。导入图片默认的情况就是都是居中的，如果要改成左对齐则将&lt;center&gt;--&gt;&gt;&lt;left&gt;即可实现，同理右对齐就用&lt;right&gt;。 图 晚安 123456789&lt;center&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; 图 晚安 &lt;img src=&quot;http://latex.codecogs.com/gif.latex? a^2&quot;&gt;&lt;/center&gt; 这里使用的是latex代码的形式来显示图注，虽然不是很好看，但是只是可以显示。","link":"/2022/01/21/Typora%E5%85%A5%E9%97%A8/"},{"title":"张量的创建与运算","text":"张量是一种特殊的数据结构，它于数组和矩阵很相似。我们用张量来标记模型的输入、输出和模型的参数。 张量（Tensor）和数组非常的相似，但是Tensor可以实现在硬件的加速。 tensors and NumPy 数组可以共享同一个内存。 hljs.initHighlightingOnLoad(); 初始化张量12import torchimport numpy as np 通过列表初始化 12345data = [ [1,2],[3,4] ]x_data = torch.tensor(data)type(data) # &lt;class 'list'&gt;type(x_data) # &lt;class 'torch.Tensor'&gt; 通过数组初始化 1234np_array = np.array(data)x_np = torch.from_numpy(np_array)# 默认的数据类型为 torch.float32 从另一个张量中初始化一个新的张量 1234567891011121314x_ones = torch.ones_like(x_data) # retains the properties of x_dataprint(f&quot;Ones Tensor: \\n {x_ones} \\n&quot;)x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_dataprint(f&quot;Random Tensor: \\n {x_rand} \\n&quot;)output:Ones Tensor: tensor([[1, 1], [1, 1]])Random Tensor: tensor([[0.4557, 0.7406], [0.5935, 0.1859]]) 用随机数或常值生成 12345678shape = ( 2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape)print(f&quot;Random Tensor: \\n {rand_tensor} \\n&quot;)print(f&quot;Ones Tensor: \\n {ones_tensor} \\n&quot;)print(f&quot;Zeros Tensor: \\n {zeros_tensor}&quot;) 这里的shape可以(2,3) or (2,3,) or [2,3] or [2,3,] Tensor的属性123456789101112tensor = torch.rand(3,4)tensor.shape # 形状 torch.Size([3, 4])tensor.dtype # 数据类型 torch.float32tensor.device # 使用的设备 device(type='cpu')print(f&quot;Shape of tensor: {tensor.shape}&quot;)print(f&quot;Datatype of tensor: {tensor.dtype}&quot;)print(f&quot;Device tensor is stored on: {tensor.device}&quot;)Shape of tensor: Datatype of tensor: torch.float32Device tensor is stored on: cpu Tensor的操作Tensor的主要操作包含100种包含矩阵运算、切片等。具体的操作API点击这里。 常用的操作如下： 关于Tensor的操作 is_tensor(x)判断是否为Tensor 123&gt;&gt;&gt; x=torch.tensor([1,2,3])&gt;&gt;&gt; torch.is_tensor(x)True is_nonzero(x)判断单一元素的Tensor是否为0 12345678910111213141516&gt;&gt;&gt; torch.is_nonzero(torch.tensor([0.]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1.5]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([False]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([3]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1, 3, 5]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with more than one value is ambiguous&gt;&gt;&gt; torch.is_nonzero(torch.tensor([]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with no values is ambiguous nueml(x)统计张量里的元素数目 123456&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4, 5)&gt;&gt;&gt; torch.numel(a)120&gt;&gt;&gt; a = torch.zeros(4,4)&gt;&gt;&gt; torch.numel(a)16 创建Tensor操作 tensor(x)创建张量 from_numpy(a)也是创建张量，但是不同的是此方法的创建的tensor和array是共享内存的。 1234567&gt;&gt;&gt; a = numpy.array([1, 2, 3])&gt;&gt;&gt; t = torch.from_numpy(a)&gt;&gt;&gt; ttensor([ 1, 2, 3])&gt;&gt;&gt; t[0] = -1&gt;&gt;&gt; aarray([-1, 2, 3]) zeros() 创建全0矩阵 torch.zeros(size, , out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 主要参数： *size：形状可以是元组、列表、切片等。 requires_grad=False：是否要求梯度。 dtype=None:默认是None,因为set_default_tensor_type()函数可以设置默认的dtype()类型。 arange()和range()函数都是用于一维计数，配合for来使用，基本的功能也是继承numpy和python的基本语法。 arange-&gt;[start, end)，size=$\\lceil \\frac{end-start}{step} \\rceil$，并且start、end、step —&gt;&gt; int range-&gt;[start, end]，size=$\\lfloor \\frac{end-start}{step} \\rfloor+1$，并且start、end、step —&gt;&gt; float eye(n,m=None) 单位矩阵 full(size,fill_value ) 就是用某个数值来填充某个size的张量。同样的还有full_like() 索引、切片、旋转以及聚合的操作 cat(tensors, dim=0) 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; x = torch.randn(2, 3)&gt;&gt;&gt; xtensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 0)tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 1)tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; x1 = torch.randn(2, 3)&gt;&gt;&gt; x2 = torch.randn(2, 2)&gt;&gt;&gt; s = torch.cat((x1,x2),dim=1)&gt;&gt;&gt; stensor([[-0.5980, 0.2570, 1.1660, -0.0306, -1.0363], [ 0.2817, -0.1498, -0.6464, -0.3204, -1.6839]])# 这里dim=1上是不同的dim=0上是相同的，因此可以实现在dim=1上的切片，dim=0是用来对齐的。&gt;&gt;&gt; x3 = torch.randn(3, 2)&gt;&gt;&gt; s = torch.cat([x2,x3],dim=0)&gt;&gt;&gt; stensor([[-0.0306, -1.0363], [-0.3204, -1.6839], [-0.0858, 0.9804], [ 0.1920, -0.1728], [ 1.0318, -1.6507]])","link":"/2022/01/23/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%BF%90%E7%AE%97/"},{"title":"第一章绪论","text":"振动力学是力学专业的重要专业基础课，由此开始进入动力学的研究范畴，在航空航天、机械、土木等许多工程领域有着重要的应用背景。本文为第一章绪论，初步的介绍基本概念、学习目的、问题的提法、振动模型的建立以及系统的分类。 1.1 基本概念与学习目的 一般力学的对象主要是有限自由度系统的运动及其控制，有时它包含一个或多个无限自由度子系统。它包括运动稳定性理论、振动理论、动力系统理论、多体系统力学、机械动力学等。包括理论力学、振动力学、非线性力学。 固体力学是研究可变形固体在外界因素作用下所产生的应力、应变、位移和破坏等的力学分支。固体力学在力学中形成较早，应用也较广。包括材料力学、弹性力学、塑性力学、非线性介质力学。 流体力学是研究流体{液体和气体)的力学运动规律及其应用的学科。主要研究在各种力的作用下，流体本身的状态，以及流体和固体壁面,流体和流体间、流体与其他运动形态之间的相互作用的力学分支。包括流体力学、高等流体力学。 定义： 从广义上讲，如果表征一种运动的物理量作时而增大时而减小的反复变化，就可以称这种运动为振动 如果变化的物理量是一些机械量或力学量，例如物体的位移、速度、加速度、应力及应变等等，这种振动便称为机械振动 振动是自然界最普遍的现象之一 各种物理现象，诸如声、光、热等都包含振动 (1）心脏的搏动、耳膜和声带的振动，(2）桥梁和建筑物在风和地震作用下的振动,(3)飞机和轮船航行中的振动，（4）机床和刀具在加工时的振动 振动力学：借助数学、物理、实验和计算技术，探讨各种振动现象，阐明振动的基本规律，以便克服振动的消极因素，利用其积极因素，为合理解决各种振动问题提供理论依据。 学习的目的： 运用振动理论去创造和设计新型的振动设备、仪器及自动化装置 掌握振动的基本理论和分析方法，用以确定和限制振动对工程结构和机械产品的性能、寿命和安全的有害影响 1.2振动问题的提法 通常的研究对象被称作系统 它可以是一个零部件、一台机器、一个完整的工程结构 外部的激振力等因素被称作激励（输入） 系统发生的振动称为响应（输出） 振动的问题可以分为三类： 已知激励和系统，求响应（正问题） 动力响应分析，一般是建立微分方程，数值方法求解即可。 主要任务在于验算结构、产品等在工作时的动力响应（如变形、位移、应力等）是否满足预定的安全要求和其它要求 在产品设计阶段，对具体设计方案进行动力响应验算，若不符合要求再作修改，直到达到要求而最终确定设计方案，这一过程就是所谓的振动设计 这里比如响应中的反应设计的安全，加速度反应设计的舒适性特性。 高层建筑要有抗震要求，潜艇要有声学要求。 火箭-&gt;细长杆，尾端燃料推进器会给火箭本体造成振动（轴向、弯曲、扭振），从而影响卫星，因此火箭和推进器之间要加减震适配器。 第二类：已知和响应，求系统（第一个问题） 系统识别，系统辨识 求系统，主要是指获得对于系统的物理参数（如质量、刚数等）和系统关于振动的固有特性（如固有频率、主振型等）的认识 以估计物理参数为任务的叫做物理参数辨识，以估计系统振动固有特性为任务的叫做模态参数辨识或者试验模态分析 激励-&gt;卫星的姿态调整；响应-&gt;卫星的传感器（包括陀螺仪、端板上的加速度传感器） 机械臂本身的参数辨识 ; 空间机械臂抓取,输入(激励)为抓取前各个关节的力矩和加速度信息,输出(响应)为抓取后的力矩和加速度—&gt;&gt;得出被抓取的碎片的质量和惯量. 第三类：已知系统和响应，求激励（第二个逆问题） 环境预测 例如:为了避免产品在公路运输中的损坏，需要通过实地行车记录汽车振动和产品振动，以估计运输过程中是怎样的一种振动环境，运输过程对于产品是怎样的一种激励，这样才能有根据地为产品设计可靠的减震包装 对于火箭来说，系统的响应为传感器的输出，系统为火箭，反推激励-&gt;升空过程中的空气振动。 对于坦克来说，发射的炮弹为响应，坦克系统，反推地面环境对系统发射炮弹的激励。 相比之下，逆问题的求解要比正问题复杂，正问题建立ODE和PDE，再用数值方法求解即可。 1.3力学模型 振动系统的三要素：质量、刚度、阻尼 质量是感受惯性（包括转动惯量）的元件 刚度是感受弹性的元件 阻尼是耗能元件 描述振动系统的两类力学模型:（一般是建立数学模型） 连续系统模型（无限多自由度系统，分布参数系统） 结构参数（质量，刚度，阻尼等）在空间上连续分布 数学工具：偏微分方程 求解是将PDE离散化转化为ODE 离散系统模型（多自由度系统，单自由度系统） 结构参数为集中参量 数学工具：常微分方程 1.4振动及系统的分类按照微分方程的形式可以分为： 线性振动：描述其运动的方程为线性微分方程，相应的系统称为线性系统。线性系统的一个重要特性是线性叠加原理成立 非线性振动：描述其运动的方程为非线性微分方程，相应的系统称为非线性系统。对于非线性振动，线性叠加原理不成立 理论上，线性振动有统一的解决方法；而非线性振动就没有统一的方法。 按照激励的有无和性质可以分为： 固有振动：无激励时系统所有可能的运动集合（不是现实的振动，仅反映系统关于振动的固有属性) 自由振动：激励消失后系统所做的振动（现实的振动) 强迫振动：系统在外部激励作用下所做的振动 随机振动：系统在非确定性的随机激励下所做的振动，例如行驶在公路上的汽车的振动，激励无法使用函数来表示，只能用一个随机过程来表示 自激振动：系统受其自身运动诱发出来的激励作用而产生和维持的振动例如提琴发出的乐声，切削加工的高频振动，机翼的颤振等 参数振动：激励以系统本身的参数随时间变化的形式出现的振动，例如秋千被越荡越高。秋千受到的激励以摆长随时间变化的形式出现，而摆长的变化由人体的下蹲及站立造成。","link":"/2022/01/23/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BB%AA%E8%AE%BA/"},{"title":"Latex公式排版快速教程","text":"src=\"//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js\"> hljs.initHighlightingOnLoad(); 本文主要关注Latex在公式排版的技巧，并且配合Markdown更好的编辑公式。主要包含希腊字母、上下标、分式与根式、运算符、标注、箭头、括号与定界符、多行公式、大括号、矩阵以及实战书写几个公式。 typora有些latex字符是不识别的，因此可能出现一些乱码问题。 行内公式创建行内的公式的方法有三种： 美元号：a+b=b+a 小括号：\\( a+b=b+a\\) math环境：\\begin{math} a+b=b+a \\end{math} 行间公式创建行间公式的主要方法有： 双美元号：$$ $$ 中括号：\\[a+b=b+a\\] displaymath环境：\\begin{displaymath} a+b=b+a \\end{displaymath} equation环境(自动生成编号)：\\begin{equation} a+b=b+a \\end{equation}，同时可以对生成的公式用\\label进行交叉引用，如下图所示。 equation*环境(不自动生成编号)：\\begin{equation*} a+b=b+a \\end{equation*}，同时可以对生成的公式用\\label进行交叉引用，如下图所示。 此时交叉引用的编号为小结的编号。 带星号的equation环境需要使用amsmath宏包。 1\\usepackage{amsmath} 希腊字母输入方法：\\+字母的拼写 常用的希腊字母表 对于有大写的字母来说，直接将首字母大写即可得到大写的希腊字母，对于没有大写的字母如$\\alpha$和$\\beta$，如果首字母大写对应的是$\\Alpha$和$\\Beta$即AB。 对于变体字的输入，直接在前面加var即可。 上下标 一般来说，上下标直接使用^和_即可。 对于斜体的要加大括号，否则就会只对第一个有效。 1234$ a^2 , a_2 x^{y+z},p_{ij},p_ij$ a^2 , a_2, \\, x^{y+z},p_{ij},p_ij 英文字母只有在表示变量(或单一字符的函数名称，如f(r))时才可使用斜体，其余情况都应使用罗马体(直立体)。 1234567$ x_i 此时为斜体 x_{\\rm i} 此时为直立体roman x_{\\mathrm i} \\rm is short for \\mathrm x_{\\text i} \\text{e} ,\\text{i} 自然对数和虚数单位也要为直立体$ x_i, i=1,2...n\\\\ x_{\\rm i} ,i是input\\\\ x_{\\mathrm i},x_{\\text i}\\\\ \\text{A B},\\rm{AB}\\\\ \\text{e} 自然对数,\\text{i} 虚数单位 \\text{}和\\rm{}的区别是前者支持空格，后者不支持空格。 分式于根式\\frac(fraction,分数) 12345$ \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y} \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}$ 单个字符可以不用大括号，原理与上面相似。 如果感觉嵌套时的字符比较小的话，可以用\\dfrac{}{}. \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y}\\\\ \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}\\sqrt[]{}(square root,平方根) 123$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z}$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z} 对于非平方根的数在\\sqrt后加[]来自定义。 普通运算符12345678910$ +- \\times,\\cdot,\\div \\pm,\\mp &gt;&lt;,\\ge,\\le,\\gg,\\ll,\\ne,\\approx,\\equiv \\cap,\\cup,\\in,\\notin,\\subseteq,\\subsetneqq,\\subnsetneqq \\varnothing,\\forall,\\exists,\\nexists\\because,\\therefore \\mathbb R,\\R,\\Q,\\N,\\Z_+ \\mathcal F,\\mathscr F$ $\\pm$ ：\\pm(plus-mius 正负号) $\\mp$：\\mp(mius-plus 负正号) $\\ge$：\\ge(greater than or equal 大于等于) $\\le$：\\le(less than or equal 大于等于) $\\gg,\\ll$：\\gg,\\ll（远大于,远小于） $\\ne$：\\ne（not equal, 不等于） $\\approx$：\\approx(approximate, 约等于) $\\equiv$：\\equiv(equivalent, 恒等的) $\\cap,\\cup$：\\cap，\\cup（交集，并集） $\\in,\\notin$：\\in,\\notin（属于，不属于） $\\subseteq,\\subsetneqq,\\subsetneq$：\\subseteq,\\subsetneqq,\\subsetneq（子集，真子集） $\\supseteq,\\supsetneqq,\\supsetneq$：\\suqseteq,\\suqsetneqq,\\suqsetneq（与上面相反） $\\varnothing,\\forall$：\\varnothing（空集）,\\forall(与任意的) $\\exists,\\nexists$：\\exists,\\nexists（存在，不存在） $\\because,\\therefore$：\\because,\\therefore（因为，所以） $\\R,\\Q,\\N,\\Z$：\\R,\\Q,\\N,\\Z对于数集来说特有的字符，可以直接使用\\转义即可，但是除了数集以外的其他字符就无法使用了。完整写法为：\\mathbb R $\\mathcal F,\\mathscr F$：\\mathcal F,\\mathscr F（花体字符） 以下为上面字符的运行结果。 +-\\\\ \\times,\\cdot,\\div\\\\ \\pm,\\mp\\\\ >","link":"/2022/01/24/Latex/Latex%E5%85%AC%E5%BC%8F%E6%8E%92%E7%89%88%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B/"},{"title":"第二章单自由度系统振动_第一部分","text":"单自由度系统振动的第一部分，主要讲的是无阻尼自由振动、能量法、瑞利法以及等效刚度与质量。 无阻尼的自由振动令$x$为位移，以质量块静平衡位置为原点，$\\lambda$为静变形。受到初始扰动时，由牛顿第二定律，得： m\\ddot x(t) = mg - k(\\lambda+x(t))在静平衡时的位置：$mg = k\\lambda$ 则物体的振动或自由振动的微分方程为： m\\ddot x(t)+kx(t)=0令：$\\omega_0=\\sqrt \\frac{k}{m}$ 固有频率，单位：弧度/秒（rad/s) 则有微分方程为：$\\ddot x(t) + \\omega_0^2x(t)=0 \\Rightarrow$ 对应得特征方程为：$ms^2+k=0 \\Rightarrow$ 特征根：$s_{1,2}=\\pm i\\omega_0$ $s_1、s_2$都满足特征方程，因此通解可以写为 \\begin{align} x(t) &= A_1e^{s_1t}+A_2 e^{s_2t}\\\\ &=A_1e^{i\\omega t}+A_2 e^{-i\\omega t}\\\\ &= c_1 \\cos (\\omega_0t) +c_2 \\sin (\\omega_0t)\\\\ &= A \\sin (\\omega_0t+\\varphi) \\end{align}$c_1和c_2$为新常数，主要由初始条件来决定 振幅：$A=\\sqrt {(c_1^2+c_2^2)}$ 初相位：$\\varphi=tg^{-1} \\left (\\dfrac {c1}{c2} \\right )$ $\\omega_0$ ：系统固有的数值特征，与系统是否振动以及如何振动无关。 $A,\\varphi$：非系统固有数字特征，与系统所受激励和初始状态有关。 考虑系统在初始扰动下的自由振动，设$t=\\tau$的初始位移和初始速度为：$x(\\tau)=x_\\tau \\qquad \\dot x(\\tau)=\\dot x_\\tau$ 则令： c_1=b_1 \\cos(\\omega_0 \\tau)-b_2\\sin (\\omega_0\\tau)\\\\ c_2=b_1 \\sin(\\omega_0 \\tau)-b_2\\cos (\\omega_0\\tau)带入得：$b_1=x_\\tau \\quad b_2=\\dfrac{\\dot x_\\tau}{\\omega_0}$ 并且$\\tau$时刻后得自由振动的解为： x(t) = x_\\tau \\cos \\omega_0(t-\\tau) +\\frac{\\dot x_\\tau}{\\omega_0} \\sin \\omega_0(t-\\tau)\\\\带入零时刻的初始条件$x(0)=x_0 \\qquad \\dot x(0)=\\dot x_0$可得： x(t) = x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)=A\\sin(\\omega_0t+\\varphi)此时的振幅为$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}$，相位为$\\varphi=tg^{-1} \\dfrac{x_0\\omega_0}{\\dot x_0}$ 无阻尼的质量弹簧系统受到初始扰动后，其自由振动是以$\\omega_0$为振动顿率的简谐振动,并且永无休止。 初始条件的说明：初始条件是外界能量转入的一种方式， 有初始位移即转入了弹性势能。 有初始速度即转入了动能，用锤子敲击的脉冲就是输入了动能。 如图所示：可以得出， 弹簧的刚度为蓝色最大、黑色最小。 刚度越大、圆频率$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 越大，周期（$T=\\dfrac{2\\pi}{\\omega_0}$）越小。 由此得出圆频率的另一种计算方法： 由于在静止情况下$mg=k\\lambda$ 可得：$\\omega_0=\\sqrt{\\dfrac{k}{m}}=\\sqrt{\\dfrac{g}{\\lambda}}$ 对于不易得到m和k 的系统，若能测出静变形$\\lambda$，则用该式计算较为方便。 无阻尼振动的计算实例 首先，我们规定的原点一般为静平衡位置，这样可以时建模得到了微分方程为齐次的，在原长处建模时，微分方程为非齐次的。 m\\ddot x+kx=0\\\\ 如果以原长的位置进行建模：\\\\ m\\ddot x+k x=mg 由题可得振动的频率为：$\\omega_0=\\sqrt{\\dfrac{gk}{W}}=19.6\\,rad/s$ 重物匀速下降时处于静平衡位置，若将坐标原点取在绳被卡住瞬时重物所在位置，则t=0时有，$x_0=0\\quad \\dot x_0=v$ 于是带入振动方程： \\begin{align} x(t) &= x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)\\\\ &=\\dfrac{v}{\\omega_0} \\sin(\\omega_0t)=12.8\\sin(19.6t) (cm) \\end{align} 求绳子的最大张力，一定时是绳子在最底部时的。绳中最大张力等于静张力与因为振动引起动的张力之和： T_{max}=T_s+kA=W+kA\\\\ =1.47\\times10^5+0.74\\times10^5=2.21\\times10^5 动张力几乎是静张力的一半 由于$kA=k\\dfrac{v}{\\omega_0}=v\\sqrt{km}$ 为了减少振动引起的动张力，应当降低升降系统的刚度。尽管这样可能会造成A过大舒适性下降，但是由于加速度减小，安全性得到保证。 首先，取平衡位置，以梁承受重物静平衡位置为坐标原点（就像相当于将重物平稳的放在上面产生的静变形为$\\lambda$） 由材料力学得：$\\lambda=\\dfrac{mgl^3}{48EJ}$ 自由振动频率：$\\omega_0=\\sqrt{\\dfrac{g}{\\lambda}}=\\sqrt {\\dfrac{48EJ}{ml^3}}$ 撞击时刻为零时刻，则t=0 时，有：$x_0=-\\lambda\\quad\\dot x_0=\\sqrt{2gh}$ 自由振动振幅：$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}=\\sqrt{\\lambda^2+2h\\lambda}$ 梁的最大扰度：$\\lambda_{max}=A+\\lambda$ 由牛顿第二定律： I\\ddot \\theta(t)+k_\\theta \\theta(t)=0\\\\ \\ddot \\theta(t)+\\omega_0^2\\theta(t)=0 则扭振的固有频率为$\\omega_0=\\sqrt{\\dfrac{k_\\theta}{I}}$ 总结：由上例可看出，除坐标不同外，角振动与直线振动的数学描述完全相同。如果在弹簧质量系统中将m、k 称为广义质量及广义刚度，则弹簧质量系统的有关结论完全适用于角振动。以后不加特别声明时，弹簧质量系统是广义的。 从上两例还可看出，单自由度无阻尼系统总包含着惯性元件和弹性元件两种基本元件。 惯性元件是感受加速度的元件，它表现为系统的质量或转动惯量； 弹性元件是产生使系统恢复原来状态的恢复力的元件，它表现为具有刚度或扭转刚度的弹性体。 同一个系统中，若惯性增加，则使固有频率降低，而若刚度增加，则固有频率增大。 求复摆在平衡位置附近做微振动时的微分方程和固有频率。这里我们考虑的振动都是微振动（$\\sin \\theta \\approx \\theta$ )。 首先，由牛顿定律：$I_0\\ddot \\theta(t)+mga\\sin \\theta(t)=0$ 得出固有频率$\\omega_0=\\sqrt{\\dfrac{mga}{I_0}}$ 若已测出物体的固有频率，则可求出$\\omega_0$，再由移轴定理，可得物质绕质心的转动惯量：$I_c=I_0-ma^2$ 实验确定复杂形状物体的转动惯量的一个方法。 以静平衡位置为坐标原点建立坐标系，振动固有频率：$\\omega_0=\\sqrt{\\dfrac{K}{m}}=70rad/s$ 振动初始条件：$kx_0=mg\\times\\sin30° \\ \\Rightarrow x_0=-0.1cm$ 由题初始速度为$\\dot x_0=0$，则运动方程为$x(t)=-0.1\\cos(70t) cm$ 如果系统竖直放置，振动频率是否改变？不改变，因为质量是不变的，只有原长会改变。 能量法 对于不计阻尼即认为没有能量损失的单自由度系统，可利用能量守恒原理建立自由振动微分方程，或直接求出固有频率。 无阻尼系统为保守系统，其机械能守恒，即动能T 和势能V 之和保持不变，即：$T+V=const$ \\dfrac{d}{dt} (T+V)=0 当原点在静平衡位置的情况： 则总的势能为： V=-mgx+\\int_0^xk(\\lambda+x)\\,dx\\\\=-mgx+k\\lambda x+\\frac 1 2 k x^2 =\\frac 1 2 kx^2 则总的能量的为：$T+V=\\dfrac 1 2 k x^2+\\dfrac 1 2m \\dot x^2$ $\\dfrac{d}{dt} (T+V)=(m\\ddot x +kx)\\dot x=0 \\,\\Rightarrow \\, m\\ddot x(t)+kx(t)=0$ 能量法的步骤：(1)列方程，(2)求固有频率 如果将坐标原点不是取在系统的静平衡位置，而是取在弹簧为自由长时的位置，此时由能量之和的导数为零可得： $m\\ddot x \\dot x-mg\\dot x +kx \\dot x=0 \\, \\Rightarrow \\, m\\ddot x(t)+kx(t)=mg$ 设新的坐标$y=x-\\dfrac {mg} k =x- \\lambda \\ \\Rightarrow \\ m\\ddot y(t)+ky(t)=0$ 如果重力的影响仅是改变了惯性元件的静平衡位置，那么将坐标原点取在静平衡位置上，方程中就不会出现重力项。 由于$T+V=const$，则有$T_{max}= V_{max}\\Rightarrow\\frac 1 2m \\dot x_{max}^2=\\frac 1 2 k x_{max}^2$ 即有$\\dot x_{max}=\\omega_0x_{max}$，带入$x(t)= A \\sin (\\omega_0t+\\varphi) $，可得$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 对于转动：$\\dot \\theta_{max}=\\omega_0\\theta_{max}$ (1) 倒摆作微幅振动时的固有频率(2) 摆球$m=0.9kg$时，测得频率f为1.5HZ，$m=1.8kg$时，测得频率f为0.75HZ，问摆球质量为多少千克时恰使系统处于不稳定平衡状态？ 解法一：静平衡位置如左图，广义坐标为$\\theta$ 势能：由于是微振动，正弦遵循小角近似，但是余弦不遵循 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}-m g l(1-\\cos \\theta)\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}-m g l\\left(1-\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} \\theta^{2}-m g l \\theta^{2}\\right)=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 微分方程为：$T_{max}=U_{max} \\Rightarrow \\frac{1}{2} m l^{2} \\dot{\\theta}_{\\max }^{2}=\\dfrac{1}{2}\\left(k a^{2}-m g l\\right) \\theta_{\\max }^{2}$ 求固有频率：$\\dot \\theta_{max}=\\omega_0\\theta_{max} \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 这里我们将$ m l^{2}$视为等效质量，$\\left(k a^{2}-m g l\\right) $视为等效刚度。 解法二：静平衡位置如右图，广义坐标为$\\theta$ 势能：由于是微振动，这里用小角近似 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}+m g l\\cos \\theta\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}+m g l\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} -m g l \\right)\\theta^{2}+mgl \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 由于$\\frac{d}{d t}(T+U)=0 \\Rightarrow\\ 2 m l^{2} \\dot{\\theta} \\ddot{\\theta}+2 \\theta\\left(k a^{2}-m g l\\right) \\dot{\\theta}=0$ 则有：$2 m l^{2} \\ddot{\\theta}+2\\left(k a^{2}-m g l\\right) \\theta=0 \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 确定系统微振动的固有频率。 广义坐标：圆柱微转角$\\theta$，圆柱做一般运动， 由柯希尼定理，动能：$T=\\frac{1}{2}\\left(\\frac{3}{2} m R^{2}\\right) \\dot{\\theta}^{2}$ C点为瞬心 A点速度：$v_{A}=(R+a) \\dot{\\theta} \\ \\Rightarrow \\ x_{A}=(R+a) \\theta$ B点的速度：$v_{B}=(R-b) \\dot{\\theta}\\ \\Rightarrow \\ x_{B}=(R-b) \\theta$ 则势能为：$U=\\dfrac{1}{2}\\left(2 k_{1}\\right)(R+a)^{2} \\theta^{2}+\\dfrac{1}{2}\\left(2 k_{2}\\right)(R-b)^{2} \\theta^{2}$ 由于$T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{\\theta}_{\\max }=\\omega_{0} \\theta_{\\max }$ \\begin{align} \\omega_{0}^{2}&=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}\\\\ &=\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right] \\end{align}解得固有频率为：$\\omega_{0}=\\sqrt{\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right]}$ 坐标原点设在静平衡位置，因为计算势能的时候预先压缩造成的重力势能和弹性势能一定会被约掉，得出其次动力学方程。 因此，广义的坐标：质量块的垂直位移x 动能： \\begin{align} T&=\\frac{1}{2} m \\dot{x}^{2}+\\dfrac{1}{2} M\\left(\\dfrac{1}{2} \\dot{x}\\right)^{2}+\\frac{1}{2}\\left(\\dfrac{1}{2} M R^{2}\\right)\\left(\\dfrac{\\dot{x}}{2 R}\\right)^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{1}{4} M+\\frac{1}{8} M\\right) \\dot{x}^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{3}{8} M\\right) \\dot{x}^{2} \\end{align} 势能：$U=\\dfrac{1}{2} k_{2} x^{2}+\\dfrac{1}{2} k_{1}\\left(\\dfrac{1}{2} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{2}+\\dfrac{1}{4} k_{1}\\right) x^{2}$ 由能量守恒可知： $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max }$ 解得：$\\omega_{0}=\\sqrt{\\dfrac{2 k_{1}+8 k_{2}}{3 M+8 m}}$ 瑞利法利用能量法求解固有频率时，对于系统的动能的计算只考虑了惯性元件的动能，而忽略不计弹性元件的质量所具有的动能，因此算出的固有频率是实际值的上限。 这种简化方法在许多场合中都能满足要求，但有些工程问题中，弹性元件本身的质量因占系统总质量相当大的比例而不能忽略，否则算出的固有频率明显偏高。 当弹簧的质量的质量不是远小于小车的质量时，就无法忽略弹簧的质量，因此这里用等效的质量来分析。 系统最大的势能：$V_{\\max }=\\frac{1}{2} k x_{\\max }^{2}$ $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max } \\quad \\Rightarrow \\quad \\omega_{0}=\\sqrt{\\dfrac{k}{m+m_{t}}}$ 若忽略 $m_t$ ，则$\\omega_0$增大，因此忽略弹簧动能所算出的固有频率是实际值的上限。 瑞利法求解等效的质量是通过积分来求解的。 等效质量与等效阻尼方法一：能量法求解 选定广义位移坐标后，将系统得动能、势能写成如下形式：$T=\\dfrac{1}{2} M_{e} \\dot{x}^{2} ,\\, V=\\dfrac{1}{2} K_{e} x^{2}$ 当 $\\dot x,x$分别取最大值时：$T \\rightarrow T_{\\max }， \\ V \\rightarrow V_{\\max }$ ，可以得出：$\\omega_{0}=\\sqrt{\\dfrac{K_{e}} {M_e}}$ $K_e$：简化系统的等效刚度；$M_e$：简化系统的等效质量。 等效的含义是指简化前后的系统的动能和势能分别相等。 主要步骤： 选定广义坐标 将动能和势能写成标准形式 根据系数写出等效刚度和等效阻尼 动能：$T=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2} \\Rightarrow M_{e}=m l^{2}$ 势能：$V=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\Rightarrow K_{e}=k a^{2}-m g l$ 固有频率：$\\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 势能：$U=\\frac{1}{2}\\left[\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}\\right] \\theta^{2}$ 等效刚度：$K_{e}=\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}$ 则固有频率为：$\\omega_{0}^{2}=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}$ 方法二：定义法 等效刚度：使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 等效质量：使系统在选定的坐标上产生单位加速度而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效质量。 使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 串联弹簧的刚度的倒数是原来各个弹簧刚度倒数的总和 并联弹簧的刚度是原来各个弹簧刚度的总和。 求：系统对于坐标x 的等效质量和等效刚度。 方法1：能量法 动能：$T=\\dfrac{1}{2} m_{1} \\dot{x}^{2}+\\dfrac{1}{2} m_{2}\\left(\\dfrac{l_{2}}{l_{1}} \\dot{x}\\right)^{2}=\\dfrac{1}{2}\\left(m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}\\right) \\dot{x}^{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 势能：$V=\\dfrac{1}{2} k_{1} x^{2}+\\dfrac{1}{2} k_{2}\\left(\\dfrac{l_{3}}{l_{1}} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}\\right) x^{2}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 方法二：定义法 设使系统在x方向产生单位加速度需要施加力P，则在m1、m2上产生惯性力，对支座取矩： $P l_{1}=\\left(m_{1} \\cdot 1\\right) l_{1}+\\left(m_{2} \\cdot \\dfrac{l_{2}}{l_{1}}\\right) l_{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 画虚线是夸张化的m，其实其位移非常的为微小，在零时刻产生了单位加速度$\\ddot x=1$，$m_1,m_2$在平衡位置静平衡位置：重力和弹簧预变形相互抵消，因此弹力可以忽略。 设使系统在x坐标上产生单位位移需要施加力P，则在k1、k2处将产生弹性恢复力，对支点取矩： $P l_{1}=\\left(k_{1} \\cdot 1\\right) l_{1}+\\left(k_{2} \\cdot \\dfrac{l_{3}}{l_{1}}\\right) l_{3}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 等效质量(惯性力)：动态求解(达朗贝尔原理)； 等效刚度(静力平衡：静态求解(列静力学方程)。","link":"/2022/01/27/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"Latex期刊论文的排版","text":"本文主要针对与IEEE的一个Latex模板，主要从模板下载、语句解释、插入图片、插入公式、插入算法图、插入引用等方面来讲解如何使用模板。该教程属于简易教程，深入学习请看后续的详细教程。视频参考 Latex模板下载 模板下载:IEEE模板:http://www.ieee.org/publications_standards/publications/authors/author_templates.html 通用模板:https://www.overleaf.com/ 其他方法:百度,csdn等网页找 Latex的核心思想就是内容与格式分离 模板的基本语句解释 \\begin{document}是文件的开始，之前为导言区，可以加入各种各样的宏包。 \\begin{document}之后到\\begin{abstract}之前用来写作者信息，联系方式以及致谢等信息。 \\begin{IEEEkeywords} 后面写关键词。 \\section{Introduction} 之后为介绍综述部分。 \\subsection{name} 为子标题部分。 \\section{References Section} 参考文献部分。 \\begin{IEEEbiography} 开始作者生平部分。 插入图片 首先，导入宏包 \\usepackage{graphicx}。 其次，导入代码块，其中的后缀名可以去查看详细的教程。 最后，编辑图片的大小样式。 插入公式公式部分主要的内容参考之前的专门写公式那篇博客](https://houdezaiwu2019.github.io/2022/01/24/Latex/Latex公式排版快速教程/))。 首先，导入宏包 \\usepackage{amsmath,amsfonts} 其次，行间公式如图，文章终会自行标号，也可以自行标号\\tag{1.1}。 \\begin{equation} \\label{deqn_ex1} x = \\sum_{i=0}^{n} 2{i} Q. \\tag{1.1} \\end{equation} 最后，行内的公式的写法是在$ $之间直接写即可，如$x^2+y^2=0$ 插入参考文献实用办法插入参考文献 首先，引入宏包 \\usepackage[colorlinks,linkeolor-black,anchorcolor-black,citecolor-black]{hyperref }%用于调整多个参考文献的间距。直接用就好。 模板的插入方法，直接插入。 也可以自己使用BibTex格式的文件来插入，但是在实际编译的过程中要记得将BibTex文件也进行编译。 到百度上下载一个BibTex的文件。 引用BIb文件。 以下为BibTex文件的内容。 12345678@article{2021Exploiting,title={Exploiting Vector Attention and Contextual Prior for Ultrasound Image Segmentation},author={ Xu, L. and Gao, S. and Shi, L. and Wei, B. and He, Y. },journal={Neurocomputing},volume={454},number={1},year={2021},} 引用，BibTex也要编译，否则出现的是？，但是目前TexStduio我还没有找到在哪里编译BibTex文件。 插入算法图 首先，导入宏包 \\usepackage[ruled,linesnumbered]{algorithm2e}。 之后，导入算法块即可。 工具补充 补充好用网页:手写公式转latex https://editor.codecogs.com/ 手写符号，转latex表达 https://detexify.kirelabs.org/classify/html 截图看公式 https://mathpix.com/ 手写表格，转latex表达 https://www.tablesgenerator.com/","link":"/2022/01/25/Latex/Latex%E6%9C%9F%E5%88%8A%E8%AE%BA%E6%96%87%E7%9A%84%E6%8E%92%E7%89%88/"},{"title":"AlexNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); 本文首先详解AlexNet网络，计算每一层网络的维度并且整理了花数据集。之后，通过Pytorch对网络进行复现，主要从模型搭建、设置GPU、数据预处理、加载数据、配置损失函数和优化器、模型保存、模型训练验证与测试等方面进行实现。 AlexNet的详解AlexNet是2012年ISLVRC 2012 (lmageNet Large Scale Visual RecognitionChallenge）竞赛的冠军网络，分类准确率由传统的70%+提升到80%+。它是由Hinton和他的学生Alex Krizhevsky设计的。也是在那年之后，深度学习开始迅速发展。 AlexNet网络简介ISLVRC 2012训练集:1,281,167张已标注图片；验证集:50,000张已标注图片；测试集:100,000张未标注图片。 AlexNet的结构图 该网络的亮点在于: 首次利用GPU进行网络加速训练。 使用了ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数。 因为Sigmoid函数会出现梯度消失，梯度爆炸。 使用了LRN局部响应归一化。 在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。 过拟合：根本原因是特征维度过多，模型假设过于复杂，参数过多，训练数据过少，噪声过多，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。过度的拟合了训练数据，而没有考虑到泛化能力。 使用Dropout的方式在网络正向传播过程中随机失活一部分神经元。 回顾：经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1网络分层计算 第一层（Conv1）： 这里是运用了GPU的并行计算的功能，将96层分成了两部分进行计算。 通道数：input_channels = 3；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 11; stride = 4; padding = [1,2] 输入输出的尺寸数：input_size=[224,224,3]; output_size=[55,55,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(224-11+(1+2))}{4}+1=55 第二层（Maxpool1）：只是改变高度宽度，不改变深度。 通道数：input_channels = 96；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[55,55,96]; output_size=[27,27,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(55-3+0)}{2}+1=27 第三层（Conv2）： 通道数：input_channels = 96；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 5; stride = 1; padding = 2 输入输出的尺寸数：input_size=[27,27,96]; output_size=[27,27,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-5+4)}{1}+1=27 第四层（Maxpool2）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[27,27,256]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-3+0)}{2}+1=13 第五层（Conv3）： 通道数：input_channels = 256；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 384；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 384；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,384]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[13,13,256]; output_size=[6,6,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+0)}{2}+1=6 后三层接了三个全连接层，注意最后数据集有1000类，因此最后一个全连接层有1000个节点，如果我们的数据集有10类，最后的全连接层就10个节点。 layer_name kernel_size output_channels padding stride Conv1 11 96 [1,2] 4 Maxpool1 3 None 0 2 Conv2 5 256 [2,2] 1 Maxpool2 3 None 0 2 Conv3 3 384 [1,1] 1 Conv4 3 384 [1,1] 1 Conv5 3 256 [1,1] 1 Maxpool3 3 None 0 2 FC1 2048 None None None FC2 2048 None None None FC3 1000 None None None 数据集(flowers) （1）在data_set文件夹下创建新文件夹”flower_data” （2）点击链接下载花分类数据集 （3）解压数据集到flower_data文件夹下 （4）执行”split_data.py”脚本自动将数据集划分成训练集train和验证集val 1234├── flower_data ├── flower_photos（解压的数据集文件夹，3670个样本） ├── train（生成的训练集，3306个样本） └── val（生成的验证集，364个样本） AlexNet网络的pytorch实现模型的搭建 对于网络层比较多的结构来说，一般用在网络比较多的时候，且网络结构比较简单，没有跳跃连接等复杂的结构。 padding=tuple/int：如果tuple(1,2),代表上下方各补一行0，左右补两列0。但是，如果出现上述的计算出来的下一层的[H,W]不为0时，自动舍弃一行或一列零来满足最后结果为整数。 1nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2) 如果要左侧补一列，右侧补两列，上侧补一行，右侧补两行。要使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True): 减小使用内存，提高性能的参数。 self.modules()：返回一个迭代器，遍历网络中所有的模块； 关于初始化，目前版本的pytorch其实是可以自动进行初始化的。初始化时，对于卷积层使用恺明初始化，对于一般的全连接层使用正态分布初始化，偏差全部初始化为0。 1234567891011121314def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) 对于展开成为全连接层来说，保证第0位batch不变, start_dim=1$[batch\\ , channel\\ , weight\\ , height] \\rightarrow [batch\\ , num]$ 1x = torch.flatten(x, start_dim=1) # 也可以用view 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weight=False): super(AlexNet, self).__init__() # 卷积层合集 self.feature = nn.Sequential( # input [3,224,224] nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2), # output [48,55,55] # 如果出现上述的计算出来的下一层的[H,W]不为0时， # 自动舍弃一行零来满足最后结果为整数 # 或者使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [48,27,27] nn.Conv2d(48, 128, kernel_size=5, padding=2), # output [128,27,27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,13,13] nn.Conv2d(128, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 128, kernel_size=3, padding=1), # output [128,13,13] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,6,6] ) # 全连接层合集 self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(128*6*6, 2048), nn.ReLU(inplace=True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), nn.ReLU(inplace=True), nn.Linear(2048, num_classes), ) if init_weight: self._initialize_weights() # 一般情况下时自动进行初始化的 def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) def forward(self, x): x = self.feature(x) x = torch.flatten(x, start_dim=1) # [batch channel weight height] start_dim=1 # 就是保证第0位batch不变-&gt;[batch num] # 也可以用view x = self.classifier(x) return x 设置GPU设备1device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 数据预处理12345678910111213data_transform = { &quot;train&quot;: transforms.Compose([ transforms.RandomResizedCrop(224), # 随机截取大小为224的图片 transforms.RandomHorizontalFlip(), # 随机翻转 transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]), &quot;val&quot;: transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])} 这里我们将预处理部分分成“train”和”val”两部分，将其封装称为一个字典。 transforms.RandomResizedCrop(224)：随机截取一定大小的图片。 transforms.RandomHorizontalFlip()：对图片数据进行随机反转。 transforms.ToTensor()：将数据转化为Tensor，维度按照torch要求的排列$[batch\\ , channel\\ , weight\\ , height]$。 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))：将图片数据标准化。 加载数据12345678910# 获得绝对路径data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))# os.getcwd()获得当前位置的目录# ./.代表返回上一层目录 ../..代表返回上两层目录# 获得花的数据data_root = os.path.abspath(os.getcwd())image_path = data_root + &quot;/data_set/flower_data/&quot;train_dataset = datasets.ImageFolder(root=image_path + &quot;/train&quot;, transform=data_transform[&quot;train&quot;])# 求数据即得数据个数train_num = len(train_dataset) os.getcwd()：获得当前位置的目录。 ./.代表返回上一层目录； ../..代表返回上两层目录 os.path.join(os.getcwd(), “../..”)：代表返回上两层目录，其中join()的作用就是将内部路径进行合并，也可以进入当前目录的下的某个文件，join(os.getcwd(), “/xxx/xxx”) ImageFolder：用来以一定方式整理图片的类。 123456789# flower_list得到字典，但是得出的结果是反的flower_list = train_dataset.class_to_idx# 是的字典的val和key交换为位置的一种方法cla_dict = dict((val, key) for key, val in flower_list.items())# 将字典写入到Json文件中json_str = json.dumps(cla_dict, indent=4)with open('class_indices.json', 'w') as json_file: json_file.write(json_str) train_dataset.class_to_idx：得到类别和索引值的字典，此处预测得到的是索引值，想要得到花的名字就需要将key（名称）和value（索引值）交换位置。 json.dumps(cla_dict, indent=4)：将字典值写入到json文件中。 1234567{ &quot;0&quot;: &quot;daisy&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;} 数据的导入和加载12345678910batch_size = 32train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)val_dataset = datasets.ImageFolder(root=image_path + &quot;val&quot;, transform=data_transform[&quot;val&quot;])val_num = len(val_dataset)val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0) 这边和上一章相同，此处不在赘述。 损失函数的计算与优化器配置12345678net = AlexNet(num_classes=5, init_weight=True)net.to(device) # 启动GPUloss_function = torch.nn.CrossEntropyLoss()optimizer = optim.Adam(net.parameters(), lr=0.0002)save_path = '.AlexNet.pth'best_acc = 0.0 # 设置保存最高准确率所对应的参数 模型的训练与验证 net.train(),net.eval()：主要的作用是用来管理Dropout层和BN层，在训练的过程启用上述层，但是在预测的时候还是正常计算，不进行随机失活和BN操作。 训练过程 t1 = time.perf_counter()：用来记录训练的时间。 用来打印进度条的程序。其中，end=’’空字符。 123456# 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 以下是训练过程的代码实现。 123456789101112131415161718192021222324for epoch in range(15): net.train() # 主要针对的Dropout方法 running_loss = 0.0 t1 = time.perf_counter() for step, data in enumerate(train_loader, start=0): images, labels = data images, labels = images.to(device), labels.to(device) # 将梯度初始化为0 optimizer.zero_grad() outputs = net(images) loss = loss_function(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() # 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 print() print(time.perf_counter()-t1) 验证过程1234567891011121314151617# 直接接在上一个for循环中net.eval()acc = 0.0with torch.no_grad(): for data_test in val_loader: test_images, test_labels = data_test test_images, test_labels = test_images.to(device), test_labels.to(device) outputs = net(test_images) predict_y = torch.max(outputs, dim=1)[1] print(predict_y == test_labels) acc += (predict_y == test_labels).sum().item() accurate_test = acc / val_num # 只保存最好的结果 if accurate_test &gt; best_acc: best_acc = accurate_test torch.save(net.state_dict(), save_path) print('[epoch %d] train_loss: %.3f test_accuracy: %3f' % (epoch + 1, running_loss/step, acc / val_num)) 模型测试导入数据1234567891011121314151617181920data_transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# load imageimg = Image.open(&quot;4.jpg&quot;)plt.imshow(img)# [N C H w]img = data_transform(img)# 增加一个维度img = torch.unsqueeze(img, dim=0)# 读取字典try: json_file = open('./class_indices.json', 'r') class_indict = json.load(json_file)except Exception as e: print(e) exit(-1) 导入模型12345678910111213141516# 建立模型model = AlexNet(num_classes=5)# load 权重model_weigh_path = &quot;.AlexNet.pth&quot;model.load_state_dict(torch.load(model_weigh_path))model.eval()with torch.no_grad(): # predict class output = torch.squeeze(model(img)) # 降低维度，将batch一维去掉 predict = torch.softmax(output, dim=0) predict_cla = torch.argmax(predict).numpy()print(class_indict[str(predict_cla)], predict[predict_cla].item())plt.show()","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/AlexNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"Pytorch入门教程及LeNet网络","text":"hljs.initHighlightingOnLoad(); 本篇为Pytorch入门教程，使用的网络为LeNet(1998)网络。主要从网络搭建、导入数据、定义损失函数与优化器、训练与验证模型、模型测试与保存方面进行展示。 建立LeNet网络模型123456789101112131415161718192021222324252627import torchimport torch.nn as nnimport torch.nn.functional as Fclass LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5) self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(32 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) # pytorch [batch, channel, height, width] def forward(self, x): #input(3,32,32) N=(32-5+0)/1+1=28 x = F.relu(self.conv1(x)) #output(16,28,28) N=28/2=14 x = self.pool1(x) #output(16,14,14) N=(14-5+0)/1+1=10 x = F.relu(self.conv2(x)) #output(32,10,10) N=10/2=5 x = self.pool2(x) #output(32,5,5) x = x.view(-1, 32*5*5) #output=32*5*5=800 x = F.relu(self.fc1(x)) #output=120 x = F.relu(self.fc2(x)) #output=84 out = F.relu((self.fc3(x)))#output=10 return out 经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1以下我们进行模型的测试和调试： 12345678910111213141516# 模型的测试import torchX = torch.rand(size=(32, 3, 32, 32), dtype=torch.float32)model = LeNet()print(model)# 打印的结果如下：LeNet( (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (fc1): Linear(in_features=800, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 导入数据 这里我们使用的CIFAR-10数据集，一共由10类。 首先，下载数据集。 torchvision.datasets.xxx() 里面有我们需要很多数据集。 123456# 下载训练数据trainset = torchvision.datasets.CIFAR10( root=&quot;./data&quot;, #数据集下载的位置 train=True, #是否为训练集 transform=transforms,#图像处理函数 download=True) #是否下载 图像的处理函数集 1234transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) Compose([ ])函数的作用是将所有的处理函数合并、打包。 ToTensor()函数的作用是将图片数据转换为张量，维度转化为pytorch标准的维度，同时数据的范围由原来的$[0,255]\\rightarrow[0.0,1.0]$。 Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))的作用是将图片的张量数据进行标准化。 之后，导入数据集。 123456# 导入训练数据trainloader = utils.data.DataLoader( trainset, # 总的训练数据集 batch_size=50, # 一个batch里的样本数 shuffle=True, # 是否打乱顺序 num_workers=0) # 线程数 由于一次训练不可能将训练集所有的参数都选进来进行反向传播，因此我们把一次喂入数据的个数称为batch_size。 数据的测试，使用迭代器获得数据集中的图片和标签。 1234567891011121314151617181920test_data_iter = iter(test_loader)# 迭代器，用来获取test_image, test_label = test_data_iter.next()# 用来获取下一个参数# 显示函数def imshow(img): img = img / 2 + 0.5 # unnormalize 反标准化 npimg = img.numpy() # 转化为numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # 由于ToTensor()改变了数据的维度排列，转化为原来的维度排列 plt.show()# # get some random training imagesdataiter = iter(trainloader)images, labels = dataiter.next()# show imagesimshow(torchvision.utils.make_grid(images))# print labelsprint(' '.join('%5s' % classes[labels[j]] for j in range(4))) 定义损失函数12# 定义损失函数为交叉熵损失函数loss_function = nn.CrossEntropyLoss() 如图，在CrossEntropyLoss()里面已经包含了交叉熵的计算公式，因此就不在需要在网络里定义softmax()层了。 定义优化器这里使用的Adam() 优化器。 1234# 定义优化器（训练参数，学习率）optimizer = optim.Adam(net.parameters(), lr=0.01)# 可变学习率scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1) 训练模型1234567891011121314151617181920212223242526272829303132for epoch in range(5): # 一个epoch即对整个训练集进行一次训练,这里对训练集循5轮 running_loss = 0.0 # 训练误差初始化为0 for step, train_data in enumerate(trainloader, start=0): inputs, labels = train_data inputs, labels = inputs.to(device), labels.to(device) # 清除历史梯度,每一轮训练都要 optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) # 正向传播 loss = loss_function(outputs, labels) # 计算损失 loss.backward() # 反向传播 optimizer.step() # 优化器更新参数 # 打印训练结果 running_loss += loss.item() accuray = 0 test_image, test_label = test_image.to(device), test_label.to(device) if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 enumerate(trainloader, start=0)：返回的是数据集和对应的步数。 关于optimizer.zero_grad() 进行梯度的清零。 12345678910# 传统的方法for i, (image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2. backward optimizer.zero_grad() # reset gradient loss.backward() optimizer.step() 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； optimizer.zero_grad() 清空过往梯度； loss.backward() 反向传播，计算当前梯度； optimizer.step() 根据梯度更新网络参数 1234567891011121314151617# 梯度累加方法for i,(image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2.1 loss regularization loss = loss / accumulation_steps # 2.2 back propagation loss.backward() # 3. update parameters of net if (i+1) % accumulation_steps == 0: # optimizer the net optimizer.step() # update parameters of net optimizer.zero_grad() # reset gradient 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； loss.backward() 反向传播，计算当前梯度； 多次循环步骤 1-2，不清空梯度，使梯度累加在已有梯度上； 梯度累加了一定次数后，先optimizer.step() 根据累计的梯度更新网络参数，然后optimizer.zero_grad() 清空过往梯度，为下一波梯度累加做准备； 总结来说：梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空，不断累加，累加一定次数后，根据累加的梯度更新网络参数，然后清空梯度，进行下一次循环。对于一些GPU内存不足的实验室，这是一个可以扩大batch_size的trick。 模型测试12345678910111213141516# 打印训练结果running_loss += loss.item()accuray = 0# 使用GPUtest_image, test_label = test_image.to(device), test_label.to(device)if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] # _,predit_y = torch.max(outputs, dim=1) # max()返回的是两个维度，首先的最大值，之后是index accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 with torch.no_grad():这里的with是一个上下文管理器，其中的作用是下面的代码都遵循torch.no_grad()。 其次，在预测过程中，不用进行梯度计算，用了反而内存不够，因此使用torch.no_grad()。 tensor.item()：用来获取tensor的数值。 保存模型12save_path = './LeNet.pth'torch.save(net.state_dict(), save_path) 模型测试 首先，对图片进行处理。 123456789101112# 数据预处理transform = transforms.Compose( [transforms.Resize((32, 32)), # 首先需resize成跟训练集图像一样的大小 transforms.ToTensor(), # 转换为torch的对的张量维度 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下im = Image.open('4.jpg')im = transform(im) # 转换成[C, H, W]im = torch.unsqueeze(im, dim=0) # 对数据增加一个新维度，# 因为tensor的维度是[batch, channel, height, width] torch.unsqueeze(im, dim=0)：对数据增加一个新维度，即加一个batch的维度。 之后，实例化网络 123# 实例化网络，加载训练好的模型参数net = LeNet()net.load_state_dict(torch.load('Lenet.pth')) 最后，预测类别 1234567# 预测classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')with torch.no_grad(): outputs = net(im) predict = torch.max(outputs, dim=1)[1].data.numpy()print(classes[int(predict)]) 这里，我们将outputs丢进torch.softmax() ，可得到属于每个类别的概率。 1234567predict = torch.softmax(outputs, dim=1)# dim=1的原因，是因为outputs为两维的，dim=0只有一个# outputs = tensor([[0.0000, 0.0000, 5.4191, 0.4988, 0.0000, 1.3599, 0.0000, 0.2233, 0.0000, 0.0000]])print(predict)# 输出:tensor([[0.0042, 0.0042, 0.9464, 0.0069, 0.0042, 0.0163, 0.0042, 0.0052, 0.0042, 0.0042]])","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Pytorch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8F%8ALeNet%E7%BD%91%E7%BB%9C/"},{"title":"GoogLeNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); GoogLeNet详解简介GoogLeNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task (分类任务)第一名，本文主要从模型的搭建以及pytorch实现上进行介绍。 网络中的亮点： 引入了Inception结构（融合不同尺度的特征信息) 使用1x1的卷积核进行降维以及映射处理 添加两个辅助分类器帮助训练 AlexNet和VGG都只有一个输出层，GoogLeNet有三个输出层(其中两个辅助分类层) 丢弃全连接层，使用平均池化层（大大减少模型参数) Inception结构 如图为原始的一种Inception结构； 主要的区别是之前的VGG主要采取串联的结构，增加模型的深度， Inception主要采取并行的结构，增加的是模型的宽度。 注意：每个分支所得的特征矩阵的高和宽必须是相同的。 如图为改进之后的网络图，这里1$\\times$1的卷积核的主要作用是用来降维的。 这里降维就是将深度降低，即channels数，通过减少深度，进而减少参数量，减少计算量。 辅助分类器(Auxiliary Classifier)The exact structure of the extra network on the side, including the auxiliary classifier, is as follows: An average pooling layer with 5x5 filter size and stride 3, resulting in an 4x4×512 outputfor the (4a), and 4×4×528 for the (4d) stage. $input_{size}=14,\\ output_{size}=\\dfrac{14-5+0}{3}+1=4$ A 1×1 convolution with 128 filters for dimension reduction and rectified linear activation.· A fully connected layer（全连接层） with 1024 units and rectified linear activation（RELU). A dropout layer with 70% ratio of dropped outputs. A linear layer with softmax loss as the classifier (predicting the same 1000 classes as themain classifier, but removed at inference time). 在3$\\times$3卷积之前要进行一个1$\\times$1卷积的降维处理。 上图为下面表格中对于的结构在网络中的位置。 如图，在实际的操作过程中，LocalRespNorm(LPN)层的作用不大，因此可以去掉。 如图相比之下发现，VGG的参数参数过多，是GoogLeNet的20倍。 但VGG的模型搭建简单，并且GoogLeNet辅助分类器的使用和修改比较麻烦，不容易调试，因此一般来说VGG的使用较多。 GoogLeNet的pytorch实现模型搭建因为GoogLeNet的一些结构块的代码复用比较多，因此这里首先创建几个模板文件，以方便之后模型的搭建。 基本卷积块12345678910class BasicCon2vd(nn.Module): def __init__(self, in_channels, out_channels, **kwargs): super(BasicCon2vd, self).__init__() self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, **kwargs) self.relu = nn.ReLU(inplace=True) def forward(self, x): x = self.conv(x) x = self.relu(x) return x 由于卷积层都是伴随着ReLU激活函数来使用的，因此首先建立将二者合并的模板。 通过使用模板搭建的方式，使得网络得结构一目了然，很清晰。 Inception模板的搭建 1234567891011121314151617181920212223242526272829class Inception(nn.Module): def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj): super(Inception, self).__init__() self.branch1 = BasicCon2vd(in_channels, ch1x1, kernel_size=1) self.branch2 = nn.Sequential( BasicCon2vd(in_channels, ch3x3red, kernel_size=1), BasicCon2vd(ch3x3red, ch3x3, kernel_size=3, padding=1) # 将padding=1 使得branch的输入和输出是相同的 ) self.branch3 = nn.Sequential( BasicCon2vd(in_channels, ch5x5red, kernel_size=1), BasicCon2vd(ch5x5red, ch5x5, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) self.branch4 = nn.Sequential( nn.MaxPool2d(kernel_size=3, stride=1, padding=1), BasicCon2vd(in_channels, pool_proj, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) def forward(self, x): branch1 = self.branch1(x) branch2 = self.branch2(x) branch3 = self.branch3(x) branch4 = self.branch4(x) output = [branch1, branch2, branch3, branch4] return torch.cat(output, 1) # 在维度1上面进行叠加和整合, 即在channel上进行拼接 通过不同的padding参数，保证每个branch的输入和输出总是相同的。 最后，在维度dim=1上面进行叠加和整合, 即在channel上进行拼接。 辅助分类器的搭建123456789101112131415161718192021222324252627class InceptionAux(nn.Module): def __init__(self, in_channels, num_classes): super(InceptionAux, self).__init__() self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3) self.conv = BasicConv2d(in_channels, 128, kernel_size=1) # output[batch, 128, 4, 4] self.fc1 = nn.Linear(2048, 1024) self.fc2 = nn.Linear(1024, num_classes) def forward(self, x): # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 x = self.averagePool(x) # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4 x = self.conv(x) # N x 128 x 4 x 4 x = torch.flatten(x, 1) # [batch channel width height] 1 代表在1的维度下进行展平 x = F.dropout(x, 0.5, training=self.training) # self.training model.train()模式下为true 在model.eval()下为False # N x 2048 x = F.relu(self.fc1(x), inplace=True) x = F.dropout(x, 0.5, training=self.training) # N x 1024 x = self.fc2(x) # N x num_classes return x 开始时，在平均池化下采样和卷积之前，一个辅助分类器与第二个辅助分类器的深度是不同的。 dropout层的随机概率p=0.7，但是实际的效果不一定好，因此我们将调整为p=0.5。 当我们实例化个模型model后，可以通过model.train()和model.eval()来控制模型的状态。在model.train()模式下self.training=True，在model.eval()模式下self.training=False GoogLeNet搭建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class GoogLeNet(nn.Module): def __init__(self, num_classes=1000, aux_logits=True, init_weight = False): super(GoogLeNet, self).__init__() self.aux_logits = aux_logits self.conv1 = BasicCon2vd(3, 64, kernel_size=7, stride=7, padding=3) # 计算默认为下取整 该层的作用是将H,W缩小为原来的一半 self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True) # ceil_mode=True时 取整方式变为了上取整 self.conv2 = BasicCon2vd(64, 64, kernel_size=1) self.conv3 = BasicCon2vd(64, 192, kernel_size=3, padding=1) self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32) self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64) self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64) self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64) self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64) self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128) self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128) self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128) if self.aux_logits: self.aux1 = InceptionAux(512, num_classes) self.aux2 = InceptionAux(528, num_classes) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # (1, 1) 这里的(1, 1) &lt;=&gt; (width, Height) 无论输入是多少 输出都为1*1 self.dropout = nn.Dropout(p=0.4) self.fc = nn.Linear(1024, num_classes) if init_weight: self._initialize_weights() def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) def forward(self, x): # N x 3 x 224 x 224 x = self.conv1(x) # N x 64 x 112 x 112 x = self.maxpool1(x) # N x 64 x 56 x 56 x = self.conv2(x) # N x 64 x 56 x 56 x = self.conv3(x) # N x 192 x 56 x 56 x = self.maxpool2(x) # N x 192 x 28 x 28 x = self.inception3a(x) # N x 256 x 28 x 28 x = self.inception3b(x) # N x 480 x 28 x 28 x = self.maxpool3(x) # N x 480 x 14 x 14 x = self.inception4a(x) # N x 512 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux1 = self.aux1(x) x = self.inception4b(x) # N x 512 x 14 x 14 x = self.inception4c(x) # N x 512 x 14 x 14 x = self.inception4d(x) # N x 528 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux2 = self.aux2(x) x = self.inception4e(x) # N x 832 x 14 x 14 x = self.maxpool4(x) # N x 832 x 7 x 7 x = self.inception5a(x) # N x 832 x 7 x 7 x = self.inception5b(x) # N x 1024 x 7 x 7 x = self.avgpool(x) # N x 1024 x 1 x 1 x = torch.flatten(x, 1) # N x 1024 x = self.dropout(x) x = self.fc(x) # N x 1000 (num_classes) if self.training and self.aux_logits: # eval model lose this layer return x, aux2, aux1 return x self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)：ceil_mode=True时 取整方式变为了上取整。 nn.AdaptiveAvgPool2d((1, 1)) ：自适应的池化下采样操作，其中输入参数为一个元组，大小为目标输出的[H,w]值。 模型的训练但部分还是和之前的模型相似的，以下为不同的部分。 1234net = GoogLeNet(num_classes=5, aux_logits=True, init_weights=True) net.to(device) loss_function = nn.CrossEntropyLoss() optimizer = optim.Adam(net.parameters(), lr=0.0003) 首先是定义的模型为GoogLeNet与原来不同。 123456789101112131415for step, data in enumerate(train_bar): images, labels = data optimizer.zero_grad() logits, aux_logits2, aux_logits1 = net(images.to(device)) loss0 = loss_function(logits, labels.to(device)) loss1 = loss_function(aux_logits1, labels.to(device)) loss2 = loss_function(aux_logits2, labels.to(device)) loss = loss0 + loss1 * 0.3 + loss2 * 0.3 loss.backward() optimizer.step() # print statistics running_loss += loss.item() train_bar.desc = &quot;train epoch[{}/{}] loss:{:.3f}&quot;.format(epoch + 1, epochs, loss) 其次是治理的损失函数用三个，训练时分别辅助分类器进行计算，之后再将计算得到的辅助分类器的值进行加权处理。 在训练是，会去计算各种辅助分类器的输出，计算损失函数，之后在验证和测试过程中，就不会再去计算辅助分类器了。 模型测试1234567# create modelmodel = GoogLeNet(num_classes=5, aux_logits=False).to(device)# load model weightsweights_path = &quot;./googleNet.pth&quot;assert os.path.exists(weights_path), &quot;file: '{}' dose not exist.&quot;.format(weights_path)missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device), strict=False) 这里，我们在训练过程中是保存了辅助分类器的参数的，但是在测试时，没有定义辅助分类器，因此将strict=False，默认为True，此时model.load_state_dict() 会返回两个结果，unexpected_keys保留的是之前辅助分类器的层。 最好的结果达到了86%左右。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"VGG网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); VGG网络详解简述VGG在2014年由牛津大学著名研究组VGG (Visual GeometryGroup)提出，斩获该年ImageNet竞赛中Localization Task (定位任务)第一名和Classification Task (分类任务)第二名。本文从模型的搭建与pytorch的实现进行具体的介绍。 VGG网络的几种配置 一般使用的时候，多用D网络。 网络中的亮点: 通过堆叠多个3x3的卷积核来替代大尺度卷积核——(减少所需参数) 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核，代替后拥有相同的感受野。 CNN的感受野在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野(receptive field)。通俗的解释是，输出feature map上的一个单元对应输入层上的区域大小。 感受野的计算公式： F(i)=(F(i+1)-1)\\times Stride+K_{size} $F(i)$为第i层感受野，$Stride$为第i层的步距，$K_{size}$为卷积核或采样核尺寸。 Pool1：Size=2$\\times$2，Stride=2；Conv1：size=3$\\times$3，Stride=2 Feature map：$F=1$ Pool1：$F=(1-1)\\times2+2=2$ Conv1：$F=(2-1)\\times2+3=5$ 验证两个3$\\times$3的卷积核可以代替一个7$\\times$7(Stride=1): Feature map：$F=1$ Conv3$\\times$3(3)：$F=(1-1)\\times1+3=3$ Conv3$\\times$3(2)：$F=(3-1)\\times1+3=5$ Conv3$\\times$3(1)：$F=(5-1)\\times1+3=7$ 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核。使用7x7卷积核所需参数，与堆叠三个3x3卷积核所需参数(假设输入输出channel为C) $7\\times7\\times C \\times C = 49C^2$ $3\\times3\\times C \\times C+3\\times3\\times C \\times C+3\\times3\\times C \\times C=27C^2$ 卷积层的作用是用来提取特征，全连接层的作用的用来分类。 VGG的pytorch实现模型搭建123456cfgs = { 'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], 'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],} 配置VGG的模型list，里面的数字代表Conv层的channel数，“M”代表Maxpool层。 其中cfg为一个dict的数据，Key为不同VGG的类型，Value为list即不同的VGG网络的配置参数。 卷积层的实现12345678910111213def make_features(cfg: list): layers = [] in_channels = 3 for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) layers += [conv2d, nn.ReLU(True)] # 每个卷积函数跟ReLU激活函数都是绑定在一起的。 in_channels = v # 下一层的输入为本层的输出 return nn.Sequential(*layers) 该代码是用来读取配置文件的，由于输入为一张图片，因此输入的in_channels=3。 nn.Sequential(layers)*：实例化非关键字参数实现的。 全连接层的实现12345678910111213self.classifier = nn.Sequential( # 第一个全连接层 nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), # 第二个全连接层 nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), # 第三个全连接层 nn.Linear(2048, class_num) ) 全部的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738class VGG(nn.Module): def __init__(self, features, class_num=1000, init_weights=False): super(VGG, self).__init__() self.features = features self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), nn.Linear(2048, class_num) ) if init_weights: self._initialize_weights() def forward(self, x): # N x 3 x 224 x 224 x = self.features(x) # N x 512 x 7 x 7 # 展平操作，和之前相似 x = torch.flatten(x, start_dim=1) # N x 512*7*7 x = self.classifier(x) return x def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') nn.init.xavier_uniform_(m.weight) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) # nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 模型的实例化123456789def vgg(model_name=&quot;vgg16&quot;, **kwargs): try: cfg = cfgs[model_name] # 得出配置列表参数 except: print(&quot;Warning: model number {} not in cfgs dict!&quot;.format(model_name)) exit(-1) model = VGG(make_features(cfg), **kwargs) return model \\*kwargs*：代表可变字典长度的参数。 模型的训练训练的过程，基本和ALexNet相同。这里由于VGG网络的参数多，训练所需要的数据大，而现实过程中我们的参数不足，因此需要迁移学习的方法来解决比较好。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"ResNeXt网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); ResNeXt网络详解论文题目为Aggregated Residual Transformations for Deep Neural Networks，主要的创新点在于更新了block. 在宽度和深度上性能有了一定的提升。 ResNeXt网络在相同的计算量的情况下相比ResNet来说，错误率更小。 组卷积 本质上是将输入$C_{in}$划分为g个组，每个组$C_{in}/g$层，每个组通过卷积层之后将产生$n/g$层的一个卷积，再将g个组的卷积再拼接以下，就得出了n层的卷积网络。 极端情况$g=C_{in},n=C_{in}$，此时就是DW Conv. (c)首先$1 \\times 1$对进行降维处理，256-&gt;128；之后用组卷积group=32进行卷积，最后$1 \\times 1$进行升维，再和输入进行相加。 (b)先分组，分成32个组，每组channel=4，进行$1 \\times 1$卷积之后，再将每个组进行$3 \\times 3$的组卷积，归并之后其他跟(c)相同。 (a)前面和(b)相同，后面用一个相加来代替归+卷积操作。 理论上三者是等价的，(b)和(c)的等价比较显然，与(a)的等价不好理解。 相加的规则如下图所示，kernel=[1,2]卷积的运算结果如绿线所示。 分组卷积再相加的结果和直接卷积的结果相同。 利用组卷积代替他一般的卷积，得出ResNeXt网络的基本框架。下图的(32$\\times$4d)代表成32个组，每个组conv2_channel=4 如下图所示，作者通过实验来验证为什么要选分组数为32. 这里尽量保持计算量相同的情况下，通过改变不同的分组数和conv_channel，右图设计了几个不同的分组组合。 左面的图代表50和101层网络中，不同分组组合对应得错误率。 对于浅层得block来讲，效果没有很大的提升。 ResNeXt网络的pytorch实现网络的搭建基本和ResNet相同，基本是在ResNet上面的改进。 如右图所示，网络的框架的是相同的，改进主要发生在基本的block上面： 第二个卷积成换成了group=32的组卷积。 第一个卷积层的输入channel是原来ResNet的2倍。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Bottleneck(nn.Module): &quot;&quot;&quot; 注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2， 这么做的好处是能够在top1上提升大概0.5%的准确率。 可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch &quot;&quot;&quot; expansion = 4 def __init__(self, in_channel, out_channel, stride=1, downsample=None, groups=1, width_per_group=64): super(Bottleneck, self).__init__() width = int(out_channel * (width_per_group / 64.)) * groups self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width, kernel_size=1, stride=1, bias=False) # squeeze channels self.bn1 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups, kernel_size=3, stride=stride, bias=False, padding=1) self.bn2 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion, kernel_size=1, stride=1, bias=False) # unsqueeze channels self.bn3 = nn.BatchNorm2d(out_channel*self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) out += identity out = self.relu(out) return out width = int(out_channel \\ (width_per_group / 64.)) * groups*计算的是翻倍以后的ResNeXt网络的out_channel数，如图所示，ResNeXt网络的第一层out_channel=128是ResNet的2倍，根据计算公式 width=(64*(32/64))*32=128 out_channel代表的是残差块的out_channel数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class ResNet(nn.Module): def __init__(self, block, blocks_num, num_classes=1000, include_top=True, groups=1, width_per_group=64): super(ResNet, self).__init__() self.include_top = include_top self.in_channel = 64 self.groups = groups self.width_per_group = width_per_group self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(self.in_channel) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, blocks_num[0]) self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) if self.include_top: self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # output size = (1, 1) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') def _make_layer(self, block, channel, block_num, stride=1): downsample = None if stride != 1 or self.in_channel != channel * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channel * block.expansion)) layers = [] layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride, groups=self.groups, width_per_group=self.width_per_group)) self.in_channel = channel * block.expansion for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) if self.include_top: x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x 相比之前的ResNet增加了groups=1, width_per_group=64 参数，在_make_layer()函数以及初始化的部分都增加上述参数，其余不变。 123456789def resnext50_32x4d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth groups = 32 width_per_group = 4 return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group) 这里我们采用第三种方法，仅仅训练最后一层全连接层的权重。 param.requires_grad = False 这样将前面的参数视之为不可训练的，这样就可以仅仅之训练最后一层的参数了，因为最后一层是重新定义的。 12345678net.load_state_dict(torch.load(model_weight_path, map_location=device))for param in net.parameters(): param.requires_grad = False # change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 数据预测数据的打包过程，这里的我们的首先将图片名称放到一个list中，之后使用batch_img = torch.stack(img_list, dim=0) 将list里面的图片打包成一个batch中。","link":"/2022/02/03/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ResNeXt%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"ResNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); ResNet详解ResNet在2015年由微软实验室提出，斩获当年lmageNet竞赛中分类任务第一名，目标检测第一名。获得coco数据集中目标检测第一名，图像分割第一名。 网络中的亮点: 超深的网络结构(突破1000层) 提出residual模块 使用Batch Normalization加速训练(丢弃dropout) 随着网络的不断加深：梯度消失和梯度爆炸、退化问题。 通过残差结构可以很好的解决上述问题。 residual结构 如图，1x1的卷积层的主要作用是改变channel个数，即进行升维和降维； 注意，求和是时主分支和shoutcut的特征矩阵的形状[H,W]和深度channel必须相同。 左边这副图原本是以输入channel为64，3x3卷积层卷积核数也是64为例的，这里为了方便对比都改成了256。 表格中的乘积代表堆叠几层 下图所示，残差块的结构中残差有实线也有虚线。 实线连接和虚线连接的区别 其中的实线代表相加的二者形状和维度相同，即残差块的输入channel和输出的channel相同； 虚线表示残差块的输入channel和输出channel不同。因为虚线块首先要进行一个维度变化，导致input和shoutcut的维度不同，因此需要一个$kernel\\ size=1\\times1 \\, ,stride = 2$的卷积层来缩减矩阵形状，并且改变通道数来保证形状和维度相同。 一般在迭代的时候，将虚线层放在每次迭代的第一层来改变宽度和维度，第二层以后都为实线层，主要是用来将迭代，不改变任何参跨度和维度。 同理，另一个卷积的结构也适用。 注意原论文中，右侧虚线残差结构的主分支上，第一个1x1卷积层的步距是$stride=2$，第二个3x3卷积层步距是$stride=1$。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是$stride=1$，第二个3x3卷积层步距是$stride=2$，这样能够在ImageNet的top1上提升大概0.5%的准确率。详细可参考Resnet v1.5 综上，我们的残差块的主要的功能是降维缩减为原来的一半，之后将通道数变为原来的两倍。 Batch Normalization详解 Batch Normalization是google团队在2015年论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》提出的。通过该方法能够加速网络的收敛并提升准确率。 Batch Normalization 的目的是使得我们一批(Batch)的feature map满足均值为0，方差为1的规律。 Batch Normalization原理 我们在图像预处理过程中通常会对图像进行标准化处理，这样能够加速网络的收敛，如下图所示。 对于Conv1来说输入的就是满足某一分布的特征矩阵，但对于Conv2而言输入的feature map就不一定满足某一分布规律了（注意这里所说满足某一分布规律并不是指某一个feature map的数据要满足分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律）。 也就是说，卷积Conv1输入以前的满足归一化，输出后不一定还满足之前输入的归一化。同时数据的Normalization是针对feature map的每一个维度在整个训练集上的数据进行的。 Batch Normalization的目的就是使我们的feature map满足均值为0，方差为1的分布规律。 “对于一个拥有d维的输入x，我们将对它的每一个维度进行标准化处理。” 假设我们输入的x是RGB三通道的彩色图像，那么这里的d就是输入图像的channels即d=3，$x^{(1)}$代表的是图片R通道的特征矩阵，依次类推分别是G通道和B通道的。 x = (x^{(1)}, x^{(2)}, x^{(3)}) 标准化处理也就是分别对我们的R通道，G通道，B通道进行处理。上面的公式不用看，原文提供了更加详细的计算公式如下： 由于Normalization后归一化成[0,1]并非是最好的结果，因此这里选择了引入$\\gamma;\\beta$两个超参数一个是 让feature map满足某一分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律，也就是说要计算出整个训练集的feature map然后在进行标准化处理，对于一个大型的数据集明显是不可能的，所以论文中说的是Batch Normalization，也就是我们计算一个Batch数据的feature map然后在进行标准化（batch越大越接近整个数据集的分布，效果越好）。 使用BN时需要注意的问题（1）训练时要将traning参数设置为True，在验证时将trainning参数设置为False。在pytorch中可通过创建模型的model.train()和model.eval()方法控制。 （2）batch size尽可能设置大点，设置小后表现可能很糟糕，设置的越大求的均值和方差越接近整个训练集的均值和方差。 （3）建议将BN层放在卷积层（Conv）和激活层（例如Relu）之间，且卷积层不要使用偏置bias，因为没有用，参考下图推理，即使使用了偏置bias求出的结果也是一样的. 总结如下 迁移学习迁移学习的优势 能够快速训练出一个理想的结果。 当数据集较少时也能训练出理想的效果。传统情况下，网络越深，数据越少，越容易造成过拟合。 迁移学习可以将别人预训练好的模型拿来使用，大大的加速训练的过程。 注意：在使用别人的预训练模型参数时，要注意别人的预处理方式。自己的预处理的方式要与预训练模型的相同。 浅层网络的学习到的信息具有通用性，可以直接迁移到比较复杂的网络中使用，大大减小的训练的时间。 迁移学习的主要目的是，将预训练好的浅层网络的通用的识别信息迁移到我们的要训练的模型里去，使得新的网络也拥有识别底层通用特征得能力。 常见的迁移学习方式：1．载入权重后训练所有参数；2．载入权重后只训练最后几层参数；3．载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层(由于我们最后的一层输出的结点数和类别数可能不等于，因此最后加一层)。 一般情况下，第一种方法的效果是最好的，但相比第二和第三种方法，需要的运算资源较长、花费的时间也较长。 Resnet的pytorch实现模型搭建基本骨架的搭建18和34层结构上的主分支操残差结构的两层卷积网络是一模一样的，50、101、152层的残差结构中的三个卷积网络都不同。 这里现从基本的18层和34层的网络开始搭建。 1234567891011121314151617181920212223242526272829class BasicBlock(nn.Module): expansion = 1 # 通道数的变化，输出是输入的几倍 def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channel) self.relu = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channel) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out += identity out = self.relu(out) return out downsample的作用是区分结果是否为虚线上的的残差结构。 out_channel为主分支上的通道数。 bias=False使用BN层时，偏置是不需要的，设为False. expansion输出是输入的几倍的参数。 以下是50层、101层和152层网络的搭建： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Bottleneck(nn.Module): &quot;&quot;&quot; 注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。 但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2， 这么做的好处是能够在top1上提升大概0.5%的准确率。 可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch &quot;&quot;&quot; expansion = 4 def __init__(self, in_channel, out_channel, stride=1, downsample=None, groups=1, width_per_group=64): super(Bottleneck, self).__init__() width = int(out_channel * (width_per_group / 64.)) * groups self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width, kernel_size=1, stride=1, bias=False) # squeeze channels self.bn1 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups, kernel_size=3, stride=stride, bias=False, padding=1) self.bn2 = nn.BatchNorm2d(width) # ----------------------------------------- self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False) # unsqueeze channels self.bn3 = nn.BatchNorm2d(out_channel * self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample def forward(self, x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) out += identity out = self.relu(out) return out ResNet基本框架1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class ResNet(nn.Module): def __init__(self, block, blocks_num, groups=1, num_classes=1000, include_top=True, width_per_group=64): super(ResNet, self).__init__() self.include_top = include_top self.in_channel = 64 self.groups = groups self.width_per_group = width_per_group self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(self.in_channel) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, blocks_num[0]) self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) if self.include_top: self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # output size = (1, 1) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') def _make_layer(self, block, channel, block_num, stride=1): downsample = None if stride != 1 or self.in_channel != channel * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channel * block.expansion)) layers = [] layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride, groups=self.groups, width_per_group=self.width_per_group)) self.in_channel = channel * block.expansion for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) if self.include_top: # include_top的主要的作用是对于需要在ResNet基础上做扩展的网络，则要将 # include_top设置为False x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x _make_layer(self, block, channel, block_num, stride=1): 输入为block(基本骨架)，channel(输入通道数)，block_num(基本骨架循环的层数) if stride != 1 or self.in_channel != channel $\\times$ block.expansion: 此处的判断逻辑是stride!=1(有H,W的改变)或者输入维度与输出维度不相等(不满足in_channel = channel $\\times$ block.expansion就代表不是第一层)，对于每一个残差结构的第一个来说，其改变的宽度和深度，因此要用考虑虚线连接。之后，几层为一般的实线的结构，不需要if分支设计虚线层。 设计堆叠的实线的残差层。第一层为实线，后几层都为实线。 12345for _ in range(1, block_num): layers.append(block(self.in_channel, channel, groups=self.groups, width_per_group=self.width_per_group)) nn.Sequential(\\layers)* 返回值为非关键字参数。 第一个残差层不改变[H,W]，因此stride设计为1. 12345self.layer1 = self._make_layer(block, 64, blocks_num[0]) # 第一个残差层不改变[H,W]，因此stride设计为1 self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2) 1234567891011121314151617181920212223242526272829303132333435def resnet34(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet34-333f7ec4.pth return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)def resnet50(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet50-19c8e357.pth return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)def resnet101(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)def resnext50_32x4d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth groups = 32 width_per_group = 4 return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group)def resnext101_32x8d(num_classes=1000, include_top=True): # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth groups = 32 width_per_group = 8 return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top, groups=groups, width_per_group=width_per_group) 定义不同类型的网络。 模型训练迁移学习1import torchvision.models.resnet ctrl+左键进入后可以直接看源码。可以下载预训练参数进行的前迁移学习，网址如下： 1234567891011model_urls = { 'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth', 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth', 'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth', 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth', 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth', 'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth', 'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth', 'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth', 'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',} 数据增强处理123456789data_transform = { &quot;train&quot;: transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), &quot;val&quot;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])} 载入预训练模型的方法12345678910111213net = resnet34()# load pretrain weights# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pthmodel_weight_path = &quot;./resnet34-pre.pth&quot;assert os.path.exists(model_weight_path), &quot;file {} does not exist.&quot;.format(model_weight_path)net.load_state_dict(torch.load(model_weight_path, map_location=device))# for param in net.parameters():# param.requires_grad = False# change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 首先，定义网络net = resnet34(); 之后，导入预训练的数据集 12model_weight_path = &quot;./resnet34-pre.pth&quot;net.load_state_dict(torch.load(model_weight_path, map_location=device)) 最后，改变模型最后一层结构。 1234# change fc layer structurein_channel = net.fc.in_featuresnet.fc = nn.Linear(in_channel, 5)net.to(device) 也可以先载入到内存里面，之后将全连接层删去，将其载入到模型中去。 12torch.load(model_weight_path, map_location=device)# 载入到内存 其余的部分跟之前一样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import osimport jsonimport torchimport torch.nn as nnimport torch.optim as optimfrom torchvision import transforms, datasetsfrom tqdm import tqdmfrom model import resnet34def main(): device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(&quot;using {} device.&quot;.format(device)) data_transform = { &quot;train&quot;: transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), &quot;val&quot;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])} data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;)) # get data root path image_path = os.path.join(data_root, &quot;data_set&quot;, &quot;flower_data&quot;) # flower data set path assert os.path.exists(image_path), &quot;{} path does not exist.&quot;.format(image_path) train_dataset = datasets.ImageFolder(root=os.path.join(image_path, &quot;train&quot;), transform=data_transform[&quot;train&quot;]) train_num = len(train_dataset) # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4} flower_list = train_dataset.class_to_idx cla_dict = dict((val, key) for key, val in flower_list.items()) # write dict into json file json_str = json.dumps(cla_dict, indent=4) with open('class_indices.json', 'w') as json_file: json_file.write(json_str) batch_size = 16 nw = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 8]) # number of workers print('Using {} dataloader workers every process'.format(nw)) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=nw) validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, &quot;val&quot;), transform=data_transform[&quot;val&quot;]) val_num = len(validate_dataset) validate_loader = torch.utils.data.DataLoader(validate_dataset, batch_size=batch_size, shuffle=False, num_workers=nw) print(&quot;using {} images for training, {} images for validation.&quot;.format(train_num, val_num)) net = resnet34() # load pretrain weights # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth model_weight_path = &quot;./resnet34-pre.pth&quot; assert os.path.exists(model_weight_path), &quot;file {} does not exist.&quot;.format(model_weight_path) net.load_state_dict(torch.load(model_weight_path, map_location=device)) # for param in net.parameters(): # param.requires_grad = False # change fc layer structure in_channel = net.fc.in_features net.fc = nn.Linear(in_channel, 5) net.to(device) # define loss function loss_function = nn.CrossEntropyLoss() # construct an optimizer params = [p for p in net.parameters() if p.requires_grad] optimizer = optim.Adam(params, lr=0.0001) epochs = 3 best_acc = 0.0 save_path = './resNet34.pth' train_steps = len(train_loader) for epoch in range(epochs): # train net.train() running_loss = 0.0 train_bar = tqdm(train_loader) for step, data in enumerate(train_bar): images, labels = data optimizer.zero_grad() logits = net(images.to(device)) loss = loss_function(logits, labels.to(device)) loss.backward() optimizer.step() # print statistics running_loss += loss.item() train_bar.desc = &quot;train epoch[{}/{}] loss:{:.3f}&quot;.format(epoch + 1, epochs, loss) # validate net.eval() acc = 0.0 # accumulate accurate number / epoch with torch.no_grad(): val_bar = tqdm(validate_loader) for val_data in val_bar: val_images, val_labels = val_data outputs = net(val_images.to(device)) # loss = loss_function(outputs, test_labels) predict_y = torch.max(outputs, dim=1)[1] acc += torch.eq(predict_y, val_labels.to(device)).sum().item() val_bar.desc = &quot;valid epoch[{}/{}]&quot;.format(epoch + 1, epochs) val_accurate = acc / val_num print('[epoch %d] train_loss: %.3f val_accuracy: %.3f' % (epoch + 1, running_loss / train_steps, val_accurate)) if val_accurate &gt; best_acc: best_acc = val_accurate torch.save(net.state_dict(), save_path) print('Finished Training')if __name__ == '__main__': main() 视频参考","link":"/2022/02/03/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ResNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"Latex基础教程（二）","text":"hljs.initHighlightingOnLoad(); 本文主主要包含Latex的表格操、作浮动体的设置、参考文献以及自定义命令的设置，主要参考了B站的latex中文教程-15集从入门到精通包含各种latex操作视频的后9讲。 Latex中的表格123\\begin{tabular}[&lt;垂直对齐方式&gt;]{&lt;列格式说明&gt;} &lt;表项&gt;&amp;&lt;表项&gt;&amp; ...&lt;表项入&gt; \\\\\\end{tabular} 用\\\\\\表示换行 用&amp;表示不同的列 对于格式说明参数主要有： l-本列左对齐 c-本列居中对齐 r-本列右对齐 p{&lt;宽&gt;}-本列宽度固定,能够自动换行 如图，一共五列，因此就有五个格式说明符。 其次，两个列之间加一个竖线加一个”|“，如果加一个双竖线就加一个”||“。 如果要加一个横线了，就在行前或行后加\\hline。 帮助文档的打开 123texdoc booktab # 三线表texdoc longtab # 长表格宏包texdoc tabu # 综合表格宏包 Latex中的浮动体浮动体的创建操作LATEX 预定义了两类浮动体环境figure 和table。习惯上figure 里放图片，table 里放表格，但并没有严格限制，可以在任何一个浮动体里放置文字、公式、表格、图片等等任意内容。 对于一般的图像，有figure浮动体环境。 对于表格，有table浮动体环境。 结果可以看出图像和表格的位置都发生了浮动效果。 给浮动体加属性以table 环境的用法举例： 123\\begin{table}[⟨placement⟩]...\\end{table} ⟨placement⟩ 参数提供了一些符号用来表示浮动体允许排版的位置，如hbp 允许浮动体排版在当前位置、底部或者单独成页。table 和figure 浮动体的默认设置为tbp。 \\caption{...}为设置浮动体的标题。 \\centering为设置图片的居中和偏左偏右。 \\label{...}为设置标签操作，方便后面的应用。 \\ref{...}为引用设置，和标签在一起来实现交叉引用。 这里浮动体的交叉引用和标号是自动完成的。 总结： 浮动体可以实现灵活的分页（避免无法分割的内容产生的页面六百留白） 可以给图表添加标题。 交叉引用。 123456789figure环境(table环境与之类似)\\begin{figure}[&lt;允许位置&gt;]&lt;任意内容&gt;...\\end{figure}&lt;允许位置&gt;参数(默认tbp)% h，此处( here)-代码所在的上下文位置% t，页顶(top)-代码所在页面或之后页面的顶部% b，页底( bottom)一代码所在页面或之后页面的底部% p，独立一页(page)-浮动页面 标题控制( caption、bicaption等宏包) 并排与子图表( subcaption、subfig、floatrow等宏包) 绕排(picinpar、 wrapfig等宏包) Latex中的参考文献thebibliography环境的使用 一次管理，一次使用参考文献格式: 12345\\begin{thebibliography}{编号样本}\\bibitem[记号]{引用标志}文献条目1\\bibitem[记号]{引用标志}文献条目2end{thebibliography}% 其中文献条目包括:作者，题目，出版社，年代，版本，页码等。 如下为一个具体的案例： 123456789101112引用文章\\cite{article1}，引用一本书\\cite{book1}\\begin{thebibliography}{99}\\bibitem{article1}陈立辉,苏伟,蔡川,陈晓云，\\emph{基于LaTex的Meb数堂公式提取方法研究}[7].计算机科学．2014(86)\\bibitem{book1}William H. Press,saul A. Ieukolsky,william T. Vetterling,Brian P. Elanneny.,\\emph{Numerical Recipes 3rd Edition:The Art of scientific Computing}Cambridge University Press,New York ,2007.\\bibitem{latexGuide} Kopka Helmut,w.Daly Patrick,\\emph{Guide to \\LaTeX}, $4^{th}$ Edition.Available at \\texttt{http://www.amazon.com}.\\bibitem{latexMath} Graetzer. George，\\emph{Math Into \\LaTeX},BirkhAtuser Boston;3 edition (June 22，2000).\\end{thebibliography} \\emph{}表示要强调的具体内容。 引用的时候可以采用：\\cite{引用标志1,引用标志2,...}。因此，这样管理参考文献需要给每个参考文献进行详细排版，比较的麻烦，同时也方便文献的跨文献的引用。 因此需要一个可以一次管理多次使用的包。 使用BibTex文件进行参考文献管理 bibtex文件的格式如下： 12345@⟨type⟩{⟨citation⟩, ⟨key1⟩ = {⟨value1⟩}, ⟨key2⟩ = {⟨value2⟩},...} 其中⟨type⟩ 为文献的类别，如article 为学术论文，book 为书籍，incollection 为论文集中的某一篇，等等。 ⟨citation⟩ 为\\cite 命令使用的文献标签。在⟨citation⟩ 之后为条目里的各个字段，以⟨key⟩ = {⟨value⟩} 的形式组织。 我们在此简单列举学术论文里使用较多的BIBTEX 文献条目类别： article 学术论文，必需字段有author, title, journal, year; 可选字段包括volume, number,pages, doi 等； book 书籍，必需字段有author/editor, title, publisher, year; 可选字段包括volume/number,series, address 等； incollection 论文集中的一篇，必需字段有author, title,booktitle, publisher, year; 可选字段包括editor, volume/number, chapter, pages, address 等； inbook 书中的一章，必需字段有author/editor, title,chapter/pages, publisher, year; 可选字段包括volume/number, series, address 等。 具体的使用： 在导言区设置参考文献的格式 1234\\bibliographystyle{plain}%plain unsrt alpha abbrv\\bibliographystyle[round]{plain}% 引用的括号变为圆括号 在正文区设置参考文献 1234567%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\bibliography{test} % 可以不写扩展名\\end{document} 然后bibtex.exe会编译.aux的辅助文件，根据\\citation在.bib文件中选择指定的参考文献，并指定的参考文献按照指定的样式进行排版，生成另一个.bbl辅助文件。 \\cite {xxx}，引用的标志为下图所示。 使用google的相应功能来实现数据库的维护。 在搜索结果中打开引用链接。 打开bibtex可以得到该文件对于的bibtex数据。 将生成的bibtex数据copy到文献数据库中即可。 使用知网导入数据，需要导入zotero的FireFox浏览器。 1.打开浏览器的关联插件； 2.选择需要的文献。 3.在Zotero里选择导出的文献，来执行导出条目的操作。 4.打开test.bib文件 5.引用之后的排版如下： 1234567%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\bibliography{test} % 可以不写扩展名\\end{document} 默认只能显示导入数据库内已经引用的文献。 对于还未引用的文献，可以使用\\nocite{}来显示。 12\\nocite{*} % 表示所有未引用的参考文献\\notice{xxx} % 特定的未引用的参考文献 特别注意，重新编译的时候要手动删除之前的参考文献，否则编译完之后没有变化。 12345678%正文区(文稿区)\\begin{document} 引用一个无人车的文献\\cite{__2021} \\nocite{*} \\bibliography{test} % 可以不写扩展名\\end{document} 输出的结果如下： 使用BibLaTex文件进行参考文献管理biblatex 宏包是一套基于LATEX 宏命令的参考文献解决方案，提供了便捷的格式控制和强大的排序、分类、筛选、多文献表等功能。biblatex 宏包也因其对UTF-8 和中文参考文献的良好支持，被国内较多LATEX 模板采用。 新的TEX参考文献排版引擎biblatex/ biber样式文件(参考文献样式文件—bbx文件，引用样式文件—cbx文件)使用LATEx编写支持根据本地化排版，如: 12biber -l zh__pinyin texfile %用于指定按拼音排序biber -l zh__stroke texfile %用于按笔画排序 配置编译器，将默认的文献工具设置为Biber。 首先是在导言区调用biblatex 宏包。宏包支持以⟨key⟩=⟨value⟩ 形式指定选项，包括参考文献样式style、参考文献著录排序的规则sorting 等。 1\\usepackage[style=numeric,backend=biber]{biblatex} 接着在导言区使用\\addbibresource 命令为biblatex 引入参考文献数据库。与基于BIBTEX的传统方式不同的是，这里需要写完整的文件名。 1\\addbibresource{test.bib} 在正文中使用\\cite 命令引用参考文献。除此之外还可以使用丰富的命令达到不同的引用效果， 如\\citeauthor 和\\citeyear 分别单独引用作者和年份， \\textcite 和\\parencite分别类似natbib 宏包提供的\\citet 和\\citep 命令，以及脚注式引用\\footcite 等。 最后在需要排版参考文献的位置使用命令\\printbibliography 默认的title是英文的Reference，可以通过增加可选参数来修改。 ```latex\\printbibliography[title={参考文献}] 123456789101112 &gt; 重新编译时，要清除上一次生成的辅助文件。- **开源的样式文件**https://gitlab.com/CasperVector/biblatex-caspervector - 先将格式文件拷贝到当前工作目录中。 ![image-20220207232045374](https://gitee.com/houdezaiwu2022/image-bed/raw/master/latex/202202072320093.png) ```latex \\usepackage[style=caspervector,backend=biber,utf8]{biblatex} % 修改导言区的文件，使得引用caspervector样式 但是文章是中英文混排的，需要修改biber.exe的相关配置。 并且修改导言区的宏包配置。 12345678\\usepackage[style=caspervector,backend=biber,utf8,sorting=centy]{biblatex}% sorting=centy 就是按先英文、再中文、再姓名、再标题、再出版年份的顺序进行排序% c——chinese 中文% e——English 英文% n——name 作者姓名% t——title 文献标题% y——year 出版年份 这里需要连续编译两次，来产生正确的编号。 使用.bat进行批处理编译流程。 LaTeX自定义命令和环境\\newcommand一定义命令命令只能由字母组成,不能以 \\end开头 1\\newcommand&lt;命令&gt;[&lt;参数个数&gt;][&lt;首参数默认值&gt;]{&lt;具体定义&gt;} \\newcommand可以是简单字符串替换12%例如:使用\\PRC相当于 People 's Republic of \\emph{China}这一串内容\\newcommand \\PRC{People's Republic of \\emph{china}} \\newcommand也可以使用参数1234567891011%参数个数可以从1到9,使用时用#1,#2,..... .,#9表示\\newcommand \\ loves[2]{#1 喜欢#2}\\newcommand \\hatedby[2]{#2不受#1喜欢}\\begin{document}\\loves{猫儿}{鱼}\\hatedby{猫儿}{萝卜}\\end{document}% 猫儿喜欢鱼% 萝卜不受猫儿喜欢 \\newcommand的参数也可以有默认值123456789%指定参数个数的同时指定了首个参数的默认值，那么这个命令的%第一个参数就成为可选的参数(要使用中括号指定)\\newcommand \\love[3][喜欢]{#2#1#3}\\begin{document}\\love[最爱]{猫儿}{鱼}\\end{document}% 猫儿最爱鱼 \\renewcommand-重定义命令1234%与 \\newcommand 命令作用和用法相同,但只能用于已有命令% \\renewcommand&lt;命令&gt;[&lt;参数个数&gt;][&lt;首参数默认值&gt;]{&lt;具体定义&gt;}\\renewcommand\\abstractname{内容简介}% 将摘要的名称改为内容简介 注意，该命令只能修改已经定义的命令，不能修改还没有的命令，其他地方的使用方法相似。 定义和重定义环境12345% 基本用法和重定义命令类似\\newenvironment{&lt;环境名称&gt;}[&lt;参数个数&gt;][&lt;首参数默认值&gt;] {&lt;环境前定义&gt;}{&lt;环境后定义&gt;}\\renewenvironment{&lt;环境名称&gt;}[&lt;参数个数&gt;][&lt;首参数默认值&gt;]% {&lt;环境前定义&gt;}{&lt;环境后定义&gt;} 为book类中定义摘要( abstract)环境 12345678910111213% 导言\\newenvironment{myabstract}[1][摘要]%{\\small \\begin{center}\\bfseries #1 \\end{center}% \\begin{quotation}}%{\\end{quotation}}% 正文\\begin{document}\\begin{myabstract}[我的摘要]% 我的摘要 -&gt; #1参数 这是一段自定义格式的摘要...\\end{document} 重定义参数的嵌套使用： 123456789101112131415% 环境参数只有&lt;环境前定义&gt;中可以使用参数，% &lt;环境后定义&gt;中不能再使用环境参数。% 如果需要，可以先把前面得到的参数保存在一个命令中，在后面使用:\\newenvironment{Quotation}[1]%{\\newcommand \\quotesource{#1}% \\begin{quotation}}% {\\par \\hfill--- 《textit{\\quotesource}》% \\end{quotation}} % 正文\\begin{document} \\begin{Quotation}{易$\\cdot$乾} 初九,潜龙勿用。 \\end{Quotation}.\\end{document} 总结： 定义命令和环境是进行LaTeX格式定制、达成内容与格式分离且标的利器。 使用自定义的命令和环境把字体、字号、缩进、对齐、间距等各种琐细的内容包装起来，赋以一个有意义的名字,可以使文挡结构清晰、代码整洁、易于维护。 在使用宏定义的功能时，要综合利用各种已有的命令、环境、变量等功能，事实上，前面所介绍的长度变量与盒子、字体字号等内容，大多并丕直接出现在文档正文史，而主要都是用在实现各种结构化的宏定义里。 问题汇总 中文乱码问题。在网上下载了一个中文模板，跑起来没问题，语句测试也没有问题。但是在我的文件里却一再出现乱码。 原因：编码问题。.tex文件要以utf-8格式存储。然后导言区加入： 1\\usepackage[UTF8,noindent]{ctex} 编译器的配置。右侧的Default compiler默认值是pdflatex。这个并不支持中文的。因此将其设置为xelatex。 更多教程请见https://www.bilibili.com/video/BV1Zh411y7ps?p=2","link":"/2022/02/08/Latex/Latex%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B(%E4%BA%8C)/"},{"title":"Latex基础教程(一)","text":"hljs.initHighlightingOnLoad(); 本文主主要包含Latex文件基本结构、如何处理中文、字体字号的设置、文档篇章的设置、特殊字符的输入以及图像的插入和排版，主要参考了B站的latex中文教程-15集从入门到精通包含各种latex操作视频的前8讲。 Latex文件的基本结构导言区 在latex中，我们使用% 来进行注释。 导言区主要进行全局设置 \\title{}设置文章的标题 \\author{}设置文章的的作者 \\date{}设置文章的时间 但是设置的全局的属性是看不到的，要在正文区加\\maketitle才可以显示出来 如果使用的是book类，则输出title是单独在一页的。 1234567% 导言区\\documentclass{book}% report book letter article\\title{My First Document}\\author{Zhengtong Cao}\\date{\\today} 正文区 使用\\begin{}和\\end{}来创建一个环境。 每个文章里最多有一个document环境。 12345678% 正文区\\begin{document} \\maketitle hello, \\LaTeX Let $f(x)$ be define by the formula $f(x)=3x^2+x-1$ \\end{document} 如果两句话之间加一个空行，则相当于一个换行操作。 两段话之间可以加入多个空行，但是现实的时候就只有一个空行了。 这里的空行是实实在在的空行，不可以是注释行。之前错误的以为注释行可以作为一个空行，但是编译出来发现之前的换行消失了。 单 是行内公式，双$$$ $$$的作用是行间公式， \\begin{equation},\\end{equation}环境可以产生带编号的行间公式。 123\\begin{equation} AB^2+BC^2=AC^2\\end{equation} Latex中的中文处理texstdio配置设置编译器为XeLateX 设置默认编码为UTF-8 在导言区导入ctex宏包 未定义符号的定义1234$\\angle$A=90$\\degree$% latex内没有对应的命令\\degree的命令，编译时会显示错误，要在导言区重新定义\\newcommand{\\degree}{^\\circ} latex内没有对应的命令\\degree的命令，要在导言区重新定义，\\newcommand{\\degree}{^\\circ} 由于latex的编译器不同造成的，在typora里就定义了\\degree命令，但在latex里就没有，要重新定义。 中文的输入123456\\usepackage{ctex}\\title{\\heiti \\LaTeX 学习笔记}%\\author{Zhengtong Cao}\\author{\\kaishu 曹政通}\\date{\\today} 字体的设置：\\heiti 黑体、kaishu 楷体。 导入宏包后直接输入即可，无视下面的红色下滑线。 在cmd里输入以下命令，可以弹出ctex的宏包手册。这里也可以直接导入\\ctexart,\\ctexbook等。 1texdoc ctex 可以使用texdoc命令来查看各种文档 12texdoc lshort-zh# 一个latex的简易学习文件，112分钟入门 Latex字体字号的设置 字体族设置字体族主要分为罗马字体\\textrm{Roman Family}；无衬线字体\\textsf{San serif Family}；打字机字体\\texttt{Typewriter} 如图，\\rmfamily 代表以后的字体都是罗马体，如果之后又其他的字体的设置如\\ttfamily 则上个作用自动结束，开始新的作用。 一般使用时会加上{\\rmfamily xxx}来限定字体族的作用范围。 \\rmfamily罗马体，\\sffamily 无衬线字体，\\ttfamily打字机字体。 字体系列设置字体系列主要分为粗细、宽度设置如\\textmd{ Medium Series } 和 \\textbf{ Boldface Series }（字体设置命令） { \\mdseries xxx }和{ \\bfseries xxx } (字体设置声明) 字体形状命令字体形状直立\\textup{upright Shape}、斜体\\textit{Italic Shape}、伪斜体\\textsl{s1anted Shape}、小型大写\\textsc{Small caps Shape}（字体设置命令） { \\upshape Upright shape} {\\itshape Italic shape} {\\slshape Slanted Shape} {\\scshape Small caps Shape}(字体设置声明) 中文字体{\\songti 宋体} {\\heiti 黑体} {\\fangsong 仿宋} {\\kaishu 楷书}中文字体的\\textbf{粗体}（黑体）与\\textit{斜体}（楷体） 字体大小的设置 设置全文的默认字号大小，一般只有种10pt、11pt、12pt 对于\\ctex宏包来说又一些设置自好操作命令。 自定义字体操作 latex的思想时将内容和排版分里，因此经常在导言区设置\\newcommand{}{}来设计字体样式。 Latex文档的篇章结构提纲构建的几个命令： 1234\\chapter{⟨title⟩} %章\\section{⟨title⟩} %节\\subsection{⟨title⟩} %小节\\subsubsection{⟨title⟩} %子小节 其中\\chapter 只在book 和report 文档类有定义。这些命令生成章节标题，并能够自动编号。 article 文档类带编号的层级为\\section / \\subsection / \\subsubsection 三级； report/book 文档类带编号的层级为\\chapter / \\section / \\subsection 三级 如下，对于节操作的一些参数设计： 带可选参数的变体：\\section[⟨short title⟩]{⟨title⟩}标题使用⟨title⟩ 参数，在目录和页眉页脚中使用⟨short title⟩ 参数 带星号的变体：\\section*{⟨title⟩}标题不带编号，也不生成目录项和页眉页脚 分段操作 分段操作一般是插入一个空行，也可以使用\\par,但是多用插入空行的命令。\\\\的作用是换行而不是分段。 \\ctexart 命令 通过\\ctexart 设置布局时section是居中排版的. 使用\\ctexset命令可以自定义ctexart格式。 排版以后的格式如图所示。 目录的生成 在LATEX 中生成目录非常容易，只需在合适的地方使用命令：\\tableofcontents 这个命令会生成单独的一章（book / report）或一节（article），标题默认为“Contents“ \\tableofcontents生成的章节默认不写入目录（\\section*或\\chapter*） Latex中的特殊字符空白符号 空行分段，多个空行等同1个； 自动缩进，绝对不能使用空格代替； 英文中多个空格处理为1个空格，中文中空格将被忽略； 汉字与其它字符的间距会自动由XeLaTeX处理； 禁止使用中文全角空格。 通过命令来生成空格字符： 12345678910111213141516171819202122% 1em(当前字体中M的宽度)产生一个空格的宽度a\\quad b% 2em 产生的两个空格的宽度a\\qquad b% 约为1/6个空格的宽度a\\,b a\\thinspace b% 0.5个空格命令a\\enspace b% 产生一个空格a\\ b% 硬空格a~b% 1pc=12pt=4.218mm % 产生固定宽度值的空白 a\\kern 1pc ba\\kern -1em ba\\hskip 1em ba\\hspace{35pt}b% 占位宽度(根据大括号内的占位符的宽度产生空白)a\\hphantom{xyz}b%弹性长度(即占满整个的空间)a\\hfill b Latex的控制符由于有些符号在Latex中具有特殊的含义，因此输入的时候前面要加\\ (注意，\\\\代表换行操作，因此这里用\\textbackslash来代替) 1\\# \\$ \\% \\{ \\} \\~{} \\_{} \\&amp; \\textbackslash 输出结果如下： Latex排版符号排版中的特殊符号如下： 1\\S \\P \\dag \\ddag \\copyright \\pounds TEX标志符号123456789101112131415% 基本符号\\Tex{} \\LaTeX{} \\LaTeXe{}\\usepackage{xltxtra}% 提供了针对XeTeX的改进并且加入了XeTeX的LOGO% xltxra宏包\\XeLaTeX\\usepackage{texnames}% texnames宏包提供\\AmSTeX{} \\AmS-\\LaTeX{}\\BibTeX{} \\LuaTeX{}\\usepackage{mflogo}% mflogo宏包\\METAFONT{} \\MF{} \\MP{} 输出结果： 引号1`(左引号) '(右引号) ``(左双引号) ''(右双引号) 连字符使用几个减号的累加来代表不同长度的连字符。 1- -- --- 非英文字符12% 非英文字符\\oe \\OE \\ae \\AE \\aa \\AA \\o \\O \\l \\L \\ss \\SS !`?` 重音符号(以o为例)12%重音符号(以o为例)\\`o \\'o \\^o \\''o \\~o \\=o \\.o \\u{o} \\v{o}\\H{o} \\r{o} \\t{o} \\b{o} \\c{o} \\d{o} Latex的图像插入123456%导言区: \\usepackage{graphicx}%语法:\\includegraphics[&lt;选项&gt;]{&lt;文件名&gt;}%格式: EPS,PDF,PNG,JPEG,BMP\\usepackage{graphicx}\\graphicspath{{figures/},{pic/}} %图片在当前目录下的 figures目录 \\includegraphics[&lt;选项&gt;]{&lt;文件名&gt;} 的必选参数为文件名，可选参数为图片的缩放和旋转。 文件名，可以加类型后缀.jpg .png \\graphicspath{ {figures/},{pic/} } 指定图片的搜索路径，多个路径使用，隔开。 hexo 排版中连续两个大括号之间要加空格。 123456789101112% 指定缩放比例\\includegraphics[scale=0.3]{lion}\\includegraphics[scale=0.03]{mountain}\\includegraphics[scale=0.3]{oscilloscope}% 指定固定宽度和高度\\includegraphics[height=2cm]{lion}\\includegraphics[width=2cm]{lion.jpg}% 指定相对的高度和宽度\\includegraphics[width=0.2 \\textwidth]{lion}\\includegraphics[width=0.2 \\textheight]{mountain}% 指定多个参数\\includegraphics[angle=-45,width=0.2\\textwidth]{lion} 细节查看: 1texdoc graphic","link":"/2022/02/08/Latex/Latex%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B(%E4%B8%80)/"},{"title":"第0章绪论","text":"hljs.initHighlightingOnLoad(); 本章主要介绍控制理论的性质、发展、应用以及控制动态系统的几个基本步骤，为以后现代控制理论的学习做铺垫。 0.1 控制理论的性质控制理论的两个目标： 了解基本控制原理； 以数学表达它们，使它们最终能用以计算进入系统的输入，或用以设计自动控制系统。 两个主题：自动控制领域中有两个不同的但又相互联系的主题。 反馈的概念。 最优控制的概念。 0.2 控制理论的发展 20世纪20年代到40年代，马克斯威尔对装有调速器的蒸汽机系统动态特性的分析、马诺斯基对船舶驾驶控制的研究都是控制理论的开拓性工作。 20世纪40年代至50年代，维纳对控制理论作出了创造性的贡献。 20世纪50年代后期到60年代初期是控制理论发展的转折时期。 苏联学者在20世纪50年代对包含非线性特性、饱和作用和受到限制的控制等因素的系统的最优瞬态的研究表现出很大的兴趣。这些学者的研究讨论导致了庞特里亚金的“极大值原理”。 显示控制理论转折时期的另一个里程碑是20世纪50年代后期卡尔曼(卡尔曼——布西)滤波器的发现。 最近25年线性系统理论的研究非常活跃。 20世纪60年代后期和70年代早期，将线性二次型理论推广到无穷维系统(即以偏微分方程、泛函微分方程、积分微分方程和在巴拿赫空间的一般微分方程描述的系统)的工作得到很大进展。 目前研究的是以线性偏微分方程或相对简单的迟延方程描述的只能在空间的边界上加以观察和控制的系统。 20世纪70年代末80年代初，反馈控制的设计问题经历了一个重新修正的过程。随着人工智能的发展和引入了新的计算机结构，控制理和计算机科学的联系愈来愈密切。 0.3控制理论的应用控制系统之所以能得到如此普遍的应用，要归功于 现代仪表化(完备的传感器和执行机构) 便宜的电子硬件 控制理论有处理其模型和输出信号所具有的不确定性动态系统的能力 在控制理论中已完善的各种方法愈来愈得到普遍应用的同时，先进的理论概念的应用却仍集中在像空间工程那样的高技术方面。当然，由于计算机技术的飞速发展和世界性的激烈的工业竞争，这种情况将会改变。 控制概念得到主要应用的一个领域是石油化工生产过程。钢铁行业中热轧厂是最早成功地采用计算机控制的工厂。 0.4 控制一个动态系统的几个基本步骤简单地说，控制一个动态系统有下列四个基本步骤： 建模：为一个系统选择一个数学模型是控制工程中最重要的工作。 系统辨识： 定义为用在一个动态系统上观察到的输入与输出数据来确定它的模型的过程。 当前系统辨识方面的研究集中在下列诸基本问题上：辨识问题的可解性和问题提出的恰当性、对各类模型的参数估计方法。 信号处理：控制理论外面的独立的一门学科，但这两学科之问有许多重叠之处，而控制界曾对信号处理作出了重要贡献，特别是在滤波和平滑的领域。 控制的综合：为控制系统生成控制规律。这些过程的复杂性导致了各种控制研究课题，主要有：","link":"/2022/02/08/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E7%AC%AC0%E7%AB%A0%E7%BB%AA%E8%AE%BA/"}],"tags":[{"name":"Typora","slug":"Typora","link":"/tags/Typora/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"机械振动","slug":"机械振动","link":"/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"},{"name":"Latex","slug":"Latex","link":"/tags/Latex/"},{"name":"图像分类","slug":"图像分类","link":"/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"控制理论","slug":"控制理论","link":"/tags/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"},{"name":"control theory","slug":"control-theory","link":"/tags/control-theory/"}],"categories":[{"name":"Typora","slug":"Typora","link":"/categories/Typora/"},{"name":"PyTorch教程与源码讲解","slug":"PyTorch教程与源码讲解","link":"/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"},{"name":"振动力学","slug":"振动力学","link":"/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"},{"name":"Latex","slug":"Latex","link":"/categories/Latex/"},{"name":"图像分类网络及Pytorch实现","slug":"图像分类网络及Pytorch实现","link":"/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"},{"name":"现代控制理论","slug":"现代控制理论","link":"/categories/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"}]}