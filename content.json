{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/01/18/hello-world/"},{"title":"Typora入门","text":"本文主要从目录设置、标题设置、特殊的标记符号、导入公式和列表以及图片图床的设置与排版来进行整理。 目录篇代码：[TOC] 标题篇对于Typora来说，主要分为快捷键方法和一般的直接写代码的方法，这里我比较推荐的还是直接写代码的方法，但是新手入门还是比较推荐先使用快捷键来进行入门。 标题的代码：==#+空格+内容== 这里有几个#就是几级标题 123# 一级标题## 二级标题### 三级标题 标题的快捷键：Ctrl+(数字) Ctrl+0 &lt;=&gt; 一般段落 Ctrl+1 &lt;=&gt; 一级标题 Ctrl+2 &lt;=&gt; 二级标题 连续两次Ctrl+同一个数字：取消标题操作 Ctrl+ +/-：代表标题的升级和降级 标记符号篇标记符号这里主要讲的是加粗、斜体、下滑线、高亮和内置公式与代码。 加粗：快捷键==Ctrl+B==，代码**text** 斜体：快捷键==Ctrl+I==，代码*text* 下滑线：快捷键==Ctrl+U==，代码**&lt;u&gt;text&lt;/u&gt;** 高亮：代码==text== 内置代码：快捷键==Ctrl+Shift+`==，代码`` 代码块：快捷键==Ctrl+Shift+K==， 代码: “```”+语言(c++/python/java) “```” 内置公式：代码\\aplha，这里使用的是latex代码进行标记的。 公式块：快捷键==Ctrl+Shift+M==，代码$$$ $$$ 1234$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}$$ E_k = \\frac{1}{2}mv^2 \\tag{1.1}引用：快捷键==Ctrl+Shift+Q，代码&gt;+空格+text 书籍是人类进步的阶梯。——高尔基 超级链接：代码[blibli](https://www.bilibili.com) [text](#name) eg1. blibli 的链接 eg2.目录 的链接 脚注：代码text[^name],之后在后面[^name]:text 1,这里添加成功后，后面会出现回车 ↩符号。 上标：代码X^2 下标：代码H~2~o 注意这里需要的一些额外的设置： 列表篇有序列表：快捷键==Ctrl+Shift+[==，代码1.+空格+text 无序列表：快捷键==Ctrl+Shift+]==，代码-+空格+text 注意：无序列表如果想切换到下一级时可以直接按==tab== 表格：快捷键==Ctrl+T==，之后弹出对话框，自己来选择需要的行数和列数。 今天 明天 早饭 午饭 晚饭 上述表格的源代码： 12345| | 今天 | 明天 || :--: | :--- | :--: || 早饭 | | || 午饭 | | || 晚饭 | | | 这里还是用快捷键吧，使用代码太麻烦了。 图片篇本地路径导入图片 一般来说，图片使用的是绝对路径，如下图所示为直接截图并粘贴等到的图片的路径。但这种语言不是md的语言。 &lt;img src=&quot;C:\\Users\\dell\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220118215115730.png&quot; alt=&quot;image-20220118215115730&quot; style=&quot;zoom:50%;&quot; /&gt;。 这里的路径是Typora自行生成的，但实际输入的时候要输入代码![]()。 也可以用相对路径，代码是![](./+name.png/jpg) ./代表的是当前的文件夹。 ../代表的是上一级文件夹。 ![](./pic01.png) 对于.md来说，保存图片一般使用的是保存图片的链接，这样可以减小文件的空间（相比Word）。但这样会造成修改了文件或者图片的路径以及清除的C盘的缓存文件时会造成无法显示的问题。 利用图床导入图片这里有个比较矛盾的问题，使用GitHub的图床的话会造成国内没有VPN的用户无法访问，但是使用一般的七牛云的话要花钱，因此再三考虑我们使用码云gitee来作图床（弊端是图片的大小不能超过1M）。 将插入图片的无任何操作-&gt;上传图片 根据picgo的位置来配置路径。并且这里还要下载一个node.js，下载过程这里省略。 到picgo中下载gitee的插件，这里我们使用的是第三个，当然其他的两个也是可以的，但以下将围绕第三个gitee-uploader来配置。 在gitee里面创建仓库，注意创建时一定要点击初始化，只有这样才可以上传图片。如果没有点，那么创建好仓库时也可以点初始化。 要生成一个token，打开gitee的设置，点击生成令牌。点击设置-&gt;安全设置-&gt;私人令牌 设置权限，起个名字点击生成。注意令牌只弹出一次，最好找个记事本记录下来，防止自己忘记。 配置picgo，打开图床设置-&gt;gitee。 注意，这里自己仓库命名repo格式：用户名/仓库名。 但是之前遇到了问题，上传的图片在本地无法显示，其中的原因是gitee设置的是私有的，可以在仓库的管理界面更改。 Typora图片排版这里图片排版需要我们掌握一点点HTML(Hyper Text Markup Language)的语法知识。 图注 12345678# 这里为上面图片的HTML代码&lt;center&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; // 这里&lt;br&gt;的意思是回车，如果没有br会和图片是并排的 图注&lt;/center&gt; 因此，要实现下面两个图片并排的效果，就可以直接将图片的放一起即可，如果实现连个图片的上下排列，这是需要在之间加一个&lt;br&gt;即可 这里的&lt;center&gt;是默认图片居中的意思。导入图片默认的情况就是都是居中的，如果要改成左对齐则将&lt;center&gt;--&gt;&gt;&lt;left&gt;即可实现，同理右对齐就用&lt;right&gt;。 图 晚安 123456789&lt;center&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;img src='https://gitee.com/houdezaiwu2022/image-bed/raw/master/Typora%E7%9A%84%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E4%BB%A3%E7%A0%81/202201211959259.png' width=25%&gt; &lt;br&gt; 图 晚安 &lt;img src=&quot;http://latex.codecogs.com/gif.latex? a^2&quot;&gt;&lt;/center&gt; 这里使用的是latex代码的形式来显示图注，虽然不是很好看，但是只是可以显示。","link":"/2022/01/21/Typora%E5%85%A5%E9%97%A8/"},{"title":"张量的创建与运算","text":"张量是一种特殊的数据结构，它于数组和矩阵很相似。我们用张量来标记模型的输入、输出和模型的参数。 张量（Tensor）和数组非常的相似，但是Tensor可以实现在硬件的加速。 tensors and NumPy 数组可以共享同一个内存。 hljs.initHighlightingOnLoad(); 初始化张量12import torchimport numpy as np 通过列表初始化 12345data = [ [1,2],[3,4] ]x_data = torch.tensor(data)type(data) # &lt;class 'list'&gt;type(x_data) # &lt;class 'torch.Tensor'&gt; 通过数组初始化 1234np_array = np.array(data)x_np = torch.from_numpy(np_array)# 默认的数据类型为 torch.float32 从另一个张量中初始化一个新的张量 1234567891011121314x_ones = torch.ones_like(x_data) # retains the properties of x_dataprint(f&quot;Ones Tensor: \\n {x_ones} \\n&quot;)x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_dataprint(f&quot;Random Tensor: \\n {x_rand} \\n&quot;)output:Ones Tensor: tensor([[1, 1], [1, 1]])Random Tensor: tensor([[0.4557, 0.7406], [0.5935, 0.1859]]) 用随机数或常值生成 12345678shape = ( 2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape)print(f&quot;Random Tensor: \\n {rand_tensor} \\n&quot;)print(f&quot;Ones Tensor: \\n {ones_tensor} \\n&quot;)print(f&quot;Zeros Tensor: \\n {zeros_tensor}&quot;) 这里的shape可以(2,3) or (2,3,) or [2,3] or [2,3,] Tensor的属性123456789101112tensor = torch.rand(3,4)tensor.shape # 形状 torch.Size([3, 4])tensor.dtype # 数据类型 torch.float32tensor.device # 使用的设备 device(type='cpu')print(f&quot;Shape of tensor: {tensor.shape}&quot;)print(f&quot;Datatype of tensor: {tensor.dtype}&quot;)print(f&quot;Device tensor is stored on: {tensor.device}&quot;)Shape of tensor: Datatype of tensor: torch.float32Device tensor is stored on: cpu Tensor的操作Tensor的主要操作包含100种包含矩阵运算、切片等。具体的操作API点击这里。 常用的操作如下： 关于Tensor的操作 is_tensor(x)判断是否为Tensor 123&gt;&gt;&gt; x=torch.tensor([1,2,3])&gt;&gt;&gt; torch.is_tensor(x)True is_nonzero(x)判断单一元素的Tensor是否为0 12345678910111213141516&gt;&gt;&gt; torch.is_nonzero(torch.tensor([0.]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1.5]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([False]))False&gt;&gt;&gt; torch.is_nonzero(torch.tensor([3]))True&gt;&gt;&gt; torch.is_nonzero(torch.tensor([1, 3, 5]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with more than one value is ambiguous&gt;&gt;&gt; torch.is_nonzero(torch.tensor([]))Traceback (most recent call last):...RuntimeError: bool value of Tensor with no values is ambiguous nueml(x)统计张量里的元素数目 123456&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4, 5)&gt;&gt;&gt; torch.numel(a)120&gt;&gt;&gt; a = torch.zeros(4,4)&gt;&gt;&gt; torch.numel(a)16 创建Tensor操作 tensor(x)创建张量 from_numpy(a)也是创建张量，但是不同的是此方法的创建的tensor和array是共享内存的。 1234567&gt;&gt;&gt; a = numpy.array([1, 2, 3])&gt;&gt;&gt; t = torch.from_numpy(a)&gt;&gt;&gt; ttensor([ 1, 2, 3])&gt;&gt;&gt; t[0] = -1&gt;&gt;&gt; aarray([-1, 2, 3]) zeros() 创建全0矩阵 torch.zeros(size, , out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 主要参数： *size：形状可以是元组、列表、切片等。 requires_grad=False：是否要求梯度。 dtype=None:默认是None,因为set_default_tensor_type()函数可以设置默认的dtype()类型。 arange()和range()函数都是用于一维计数，配合for来使用，基本的功能也是继承numpy和python的基本语法。 arange-&gt;[start, end)，size=$\\lceil \\frac{end-start}{step} \\rceil$，并且start、end、step —&gt;&gt; int range-&gt;[start, end]，size=$\\lfloor \\frac{end-start}{step} \\rfloor+1$，并且start、end、step —&gt;&gt; float eye(n,m=None) 单位矩阵 full(size,fill_value ) 就是用某个数值来填充某个size的张量。同样的还有full_like() 索引、切片、旋转以及聚合的操作 cat(tensors, dim=0) 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; x = torch.randn(2, 3)&gt;&gt;&gt; xtensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 0)tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 1)tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; x1 = torch.randn(2, 3)&gt;&gt;&gt; x2 = torch.randn(2, 2)&gt;&gt;&gt; s = torch.cat((x1,x2),dim=1)&gt;&gt;&gt; stensor([[-0.5980, 0.2570, 1.1660, -0.0306, -1.0363], [ 0.2817, -0.1498, -0.6464, -0.3204, -1.6839]])# 这里dim=1上是不同的dim=0上是相同的，因此可以实现在dim=1上的切片，dim=0是用来对齐的。&gt;&gt;&gt; x3 = torch.randn(3, 2)&gt;&gt;&gt; s = torch.cat([x2,x3],dim=0)&gt;&gt;&gt; stensor([[-0.0306, -1.0363], [-0.3204, -1.6839], [-0.0858, 0.9804], [ 0.1920, -0.1728], [ 1.0318, -1.6507]])","link":"/2022/01/23/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%BF%90%E7%AE%97/"},{"title":"第一章绪论","text":"振动力学是力学专业的重要专业基础课，由此开始进入动力学的研究范畴，在航空航天、机械、土木等许多工程领域有着重要的应用背景。本文为第一章绪论，初步的介绍基本概念、学习目的、问题的提法、振动模型的建立以及系统的分类。 1.1 基本概念与学习目的 一般力学的对象主要是有限自由度系统的运动及其控制，有时它包含一个或多个无限自由度子系统。它包括运动稳定性理论、振动理论、动力系统理论、多体系统力学、机械动力学等。包括理论力学、振动力学、非线性力学。 固体力学是研究可变形固体在外界因素作用下所产生的应力、应变、位移和破坏等的力学分支。固体力学在力学中形成较早，应用也较广。包括材料力学、弹性力学、塑性力学、非线性介质力学。 流体力学是研究流体{液体和气体)的力学运动规律及其应用的学科。主要研究在各种力的作用下，流体本身的状态，以及流体和固体壁面,流体和流体间、流体与其他运动形态之间的相互作用的力学分支。包括流体力学、高等流体力学。 定义： 从广义上讲，如果表征一种运动的物理量作时而增大时而减小的反复变化，就可以称这种运动为振动 如果变化的物理量是一些机械量或力学量，例如物体的位移、速度、加速度、应力及应变等等，这种振动便称为机械振动 振动是自然界最普遍的现象之一 各种物理现象，诸如声、光、热等都包含振动 (1）心脏的搏动、耳膜和声带的振动，(2）桥梁和建筑物在风和地震作用下的振动,(3)飞机和轮船航行中的振动，（4）机床和刀具在加工时的振动 振动力学：借助数学、物理、实验和计算技术，探讨各种振动现象，阐明振动的基本规律，以便克服振动的消极因素，利用其积极因素，为合理解决各种振动问题提供理论依据。 学习的目的： 运用振动理论去创造和设计新型的振动设备、仪器及自动化装置 掌握振动的基本理论和分析方法，用以确定和限制振动对工程结构和机械产品的性能、寿命和安全的有害影响 1.2振动问题的提法 通常的研究对象被称作系统 它可以是一个零部件、一台机器、一个完整的工程结构 外部的激振力等因素被称作激励（输入） 系统发生的振动称为响应（输出） 振动的问题可以分为三类： 已知激励和系统，求响应（正问题） 动力响应分析，一般是建立微分方程，数值方法求解即可。 主要任务在于验算结构、产品等在工作时的动力响应（如变形、位移、应力等）是否满足预定的安全要求和其它要求 在产品设计阶段，对具体设计方案进行动力响应验算，若不符合要求再作修改，直到达到要求而最终确定设计方案，这一过程就是所谓的振动设计 这里比如响应中的反应设计的安全，加速度反应设计的舒适性特性。 高层建筑要有抗震要求，潜艇要有声学要求。 火箭-&gt;细长杆，尾端燃料推进器会给火箭本体造成振动（轴向、弯曲、扭振），从而影响卫星，因此火箭和推进器之间要加减震适配器。 第二类：已知和响应，求系统（第一个问题） 系统识别，系统辨识 求系统，主要是指获得对于系统的物理参数（如质量、刚数等）和系统关于振动的固有特性（如固有频率、主振型等）的认识 以估计物理参数为任务的叫做物理参数辨识，以估计系统振动固有特性为任务的叫做模态参数辨识或者试验模态分析 激励-&gt;卫星的姿态调整；响应-&gt;卫星的传感器（包括陀螺仪、端板上的加速度传感器） 机械臂本身的参数辨识 ; 空间机械臂抓取,输入(激励)为抓取前各个关节的力矩和加速度信息,输出(响应)为抓取后的力矩和加速度—&gt;&gt;得出被抓取的碎片的质量和惯量. 第三类：已知系统和响应，求激励（第二个逆问题） 环境预测 例如:为了避免产品在公路运输中的损坏，需要通过实地行车记录汽车振动和产品振动，以估计运输过程中是怎样的一种振动环境，运输过程对于产品是怎样的一种激励，这样才能有根据地为产品设计可靠的减震包装 对于火箭来说，系统的响应为传感器的输出，系统为火箭，反推激励-&gt;升空过程中的空气振动。 对于坦克来说，发射的炮弹为响应，坦克系统，反推地面环境对系统发射炮弹的激励。 相比之下，逆问题的求解要比正问题复杂，正问题建立ODE和PDE，再用数值方法求解即可。 1.3力学模型 振动系统的三要素：质量、刚度、阻尼 质量是感受惯性（包括转动惯量）的元件 刚度是感受弹性的元件 阻尼是耗能元件 描述振动系统的两类力学模型:（一般是建立数学模型） 连续系统模型（无限多自由度系统，分布参数系统） 结构参数（质量，刚度，阻尼等）在空间上连续分布 数学工具：偏微分方程 求解是将PDE离散化转化为ODE 离散系统模型（多自由度系统，单自由度系统） 结构参数为集中参量 数学工具：常微分方程 1.4振动及系统的分类按照微分方程的形式可以分为： 线性振动：描述其运动的方程为线性微分方程，相应的系统称为线性系统。线性系统的一个重要特性是线性叠加原理成立 非线性振动：描述其运动的方程为非线性微分方程，相应的系统称为非线性系统。对于非线性振动，线性叠加原理不成立 理论上，线性振动有统一的解决方法；而非线性振动就没有统一的方法。 按照激励的有无和性质可以分为： 固有振动：无激励时系统所有可能的运动集合（不是现实的振动，仅反映系统关于振动的固有属性) 自由振动：激励消失后系统所做的振动（现实的振动) 强迫振动：系统在外部激励作用下所做的振动 随机振动：系统在非确定性的随机激励下所做的振动，例如行驶在公路上的汽车的振动，激励无法使用函数来表示，只能用一个随机过程来表示 自激振动：系统受其自身运动诱发出来的激励作用而产生和维持的振动例如提琴发出的乐声，切削加工的高频振动，机翼的颤振等 参数振动：激励以系统本身的参数随时间变化的形式出现的振动，例如秋千被越荡越高。秋千受到的激励以摆长随时间变化的形式出现，而摆长的变化由人体的下蹲及站立造成。","link":"/2022/01/23/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BB%AA%E8%AE%BA/"},{"title":"Latex公式排版快速教程","text":"src=\"//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js\"> hljs.initHighlightingOnLoad(); 本文主要关注Latex在公式排版的技巧，并且配合Markdown更好的编辑公式。主要包含希腊字母、上下标、分式与根式、运算符、标注、箭头、括号与定界符、多行公式、大括号、矩阵以及实战书写几个公式。 因为hexo的公式排版和代码高亮有冲突，为了更好的显示公式只能牺牲代码显示，同时由于Hexo对于有些代码的显示有一定问题，有些代码还是不能很好的显示。 希腊字母输入方法：\\+字母的拼写 常用的希腊字母表 对于有大写的字母来说，直接将首字母大写即可得到大写的希腊字母，对于没有大写的字母如$\\alpha$和$\\beta$，如果首字母大写对应的是$\\Alpha$和$\\Beta$即AB。 对于变体字的输入，直接在前面加var即可。 上下标 一般来说，上下标直接使用^和_即可。 对于斜体的要加大括号，否则就会只对第一个有效。 1234$ a^2 , a_2 x^{y+z},p_{ij},p_ij$ a^2 , a_2, \\, x^{y+z},p_{ij},p_ij 英文字母只有在表示变量(或单一字符的函数名称，如f(r))时才可使用斜体，其余情况都应使用罗马体(直立体)。 1234567$ x_i 此时为斜体 x_{\\rm i} 此时为直立体roman x_{\\mathrm i} \\rm is short for \\mathrm x_{\\text i} \\text{e} ,\\text{i} 自然对数和虚数单位也要为直立体$ x_i, i=1,2...n\\\\ x_{\\rm i} ,i是input\\\\ x_{\\mathrm i},x_{\\text i}\\\\ \\text{A B},\\rm{AB}\\\\ \\text{e} 自然对数,\\text{i} 虚数单位 \\text{}和\\rm{}的区别是前者支持空格，后者不支持空格。 分式与根式\\frac(fraction,分数) 12345$ \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y} \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}$ 单个字符可以不用大括号，原理与上面相似。 如果感觉嵌套时的字符比较小的话，可以用\\dfrac{}{}. \\frac{1}{2}, \\frac 1 2 \\frac{1}{x+y}\\\\ \\frac{\\frac 1 x +1}{y+1},\\frac{\\dfrac 1 x +1}{y+1}\\sqrt[]{}(square root,平方根) 123$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z}$ \\sqrt 2, \\sqrt{x+y}, \\sqrt[3]{x+z} 对于非平方根的数在\\sqrt后加[]来自定义。 普通运算符12345678910$ +- \\times,\\cdot,\\div \\pm,\\mp &gt;&lt;,\\ge,\\le,\\gg,\\ll,\\ne,\\approx,\\equiv \\cap,\\cup,\\in,\\notin,\\subseteq,\\subsetneqq,\\subnsetneqq \\varnothing,\\forall,\\exists,\\nexists\\because,\\therefore \\mathbb R,\\R,\\Q,\\N,\\Z_+ \\mathcal F,\\mathscr F$ $\\pm$ ：\\pm(plus-mius 正负号) $\\mp$：\\mp(mius-plus 负正号) $\\ge$：\\ge(greater than or equal 大于等于) $\\le$：\\le(less than or equal 大于等于) $\\gg,\\ll$：\\gg,\\ll（远大于,远小于） $\\ne$：\\ne（not equal, 不等于） $\\approx$：\\approx(approximate, 约等于) $\\equiv$：\\equiv(equivalent, 恒等的) $\\cap,\\cup$：\\cap，\\cup（交集，并集） $\\in,\\notin$：\\in,\\notin（属于，不属于） $\\subseteq,\\subsetneqq,\\subsetneq$：\\subseteq,\\subsetneqq,\\subsetneq（子集，真子集） $\\supseteq,\\supsetneqq,\\supsetneq$：\\suqseteq,\\suqsetneqq,\\suqsetneq（与上面相反） $\\varnothing,\\forall$：\\varnothing（空集）,\\forall(与任意的) $\\exists,\\nexists$：\\exists,\\nexists（存在，不存在） $\\because,\\therefore$：\\because,\\therefore（因为，所以） $\\R,\\Q,\\N,\\Z$：\\R,\\Q,\\N,\\Z对于数集来说特有的字符，可以直接使用\\转义即可，但是除了数集以外的其他字符就无法使用了。完整写法为：\\mathbb R $\\mathcal F,\\mathscr F$：\\mathcal F,\\mathscr F（花体字符） 以下为上面字符的运行结果。 +-\\\\ \\times,\\cdot,\\div\\\\ \\pm,\\mp\\\\ >","link":"/2022/01/24/Latex/Latex%E5%85%AC%E5%BC%8F%E6%8E%92%E7%89%88%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B/"},{"title":"第二章单自由度系统振动_第一部分","text":"单自由度系统振动的第一部分，主要讲的是无阻尼自由振动、能量法、瑞利法以及等效刚度与质量。 无阻尼的自由振动令$x$为位移，以质量块静平衡位置为原点，$\\lambda$为静变形。受到初始扰动时，由牛顿第二定律，得： m\\ddot x(t) = mg - k(\\lambda+x(t))在静平衡时的位置：$mg = k\\lambda$ 则物体的振动或自由振动的微分方程为： m\\ddot x(t)+kx(t)=0令：$\\omega_0=\\sqrt \\frac{k}{m}$ 固有频率，单位：弧度/秒（rad/s) 则有微分方程为：$\\ddot x(t) + \\omega_0^2x(t)=0 \\Rightarrow$ 对应得特征方程为：$ms^2+k=0 \\Rightarrow$ 特征根：$s_{1,2}=\\pm i\\omega_0$ $s_1、s_2$都满足特征方程，因此通解可以写为 \\begin{align} x(t) &= A_1e^{s_1t}+A_2 e^{s_2t}\\\\ &=A_1e^{i\\omega t}+A_2 e^{-i\\omega t}\\\\ &= c_1 \\cos (\\omega_0t) +c_2 \\sin (\\omega_0t)\\\\ &= A \\sin (\\omega_0t+\\varphi) \\end{align}$c_1和c_2$为新常数，主要由初始条件来决定 振幅：$A=\\sqrt {(c_1^2+c_2^2)}$ 初相位：$\\varphi=tg^{-1} \\left (\\dfrac {c1}{c2} \\right )$ $\\omega_0$ ：系统固有的数值特征，与系统是否振动以及如何振动无关。 $A,\\varphi$：非系统固有数字特征，与系统所受激励和初始状态有关。 考虑系统在初始扰动下的自由振动，设$t=\\tau$的初始位移和初始速度为：$x(\\tau)=x_\\tau \\qquad \\dot x(\\tau)=\\dot x_\\tau$ 则令： c_1=b_1 \\cos(\\omega_0 \\tau)-b_2\\sin (\\omega_0\\tau)\\\\ c_2=b_1 \\sin(\\omega_0 \\tau)-b_2\\cos (\\omega_0\\tau)带入得：$b_1=x_\\tau \\quad b_2=\\dfrac{\\dot x_\\tau}{\\omega_0}$ 并且$\\tau$时刻后得自由振动的解为： x(t) = x_\\tau \\cos \\omega_0(t-\\tau) +\\frac{\\dot x_\\tau}{\\omega_0} \\sin \\omega_0(t-\\tau)\\\\带入零时刻的初始条件$x(0)=x_0 \\qquad \\dot x(0)=\\dot x_0$可得： x(t) = x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)=A\\sin(\\omega_0t+\\varphi)此时的振幅为$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}$，相位为$\\varphi=tg^{-1} \\dfrac{x_0\\omega_0}{\\dot x_0}$ 无阻尼的质量弹簧系统受到初始扰动后，其自由振动是以$\\omega_0$为振动顿率的简谐振动,并且永无休止。 初始条件的说明：初始条件是外界能量转入的一种方式， 有初始位移即转入了弹性势能。 有初始速度即转入了动能，用锤子敲击的脉冲就是输入了动能。 如图所示：可以得出， 弹簧的刚度为蓝色最大、黑色最小。 刚度越大、圆频率$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 越大，周期（$T=\\dfrac{2\\pi}{\\omega_0}$）越小。 由此得出圆频率的另一种计算方法： 由于在静止情况下$mg=k\\lambda$ 可得：$\\omega_0=\\sqrt{\\dfrac{k}{m}}=\\sqrt{\\dfrac{g}{\\lambda}}$ 对于不易得到m和k 的系统，若能测出静变形$\\lambda$，则用该式计算较为方便。 无阻尼振动的计算实例 首先，我们规定的原点一般为静平衡位置，这样可以时建模得到了微分方程为齐次的，在原长处建模时，微分方程为非齐次的。 m\\ddot x+kx=0\\\\ 如果以原长的位置进行建模：\\\\ m\\ddot x+k x=mg 由题可得振动的频率为：$\\omega_0=\\sqrt{\\dfrac{gk}{W}}=19.6\\,rad/s$ 重物匀速下降时处于静平衡位置，若将坐标原点取在绳被卡住瞬时重物所在位置，则t=0时有，$x_0=0\\quad \\dot x_0=v$ 于是带入振动方程： \\begin{align} x(t) &= x_0 \\cos \\omega_0(t) +\\frac{\\dot x_0}{\\omega_0} \\sin \\omega_0(t)\\\\ &=\\dfrac{v}{\\omega_0} \\sin(\\omega_0t)=12.8\\sin(19.6t) (cm) \\end{align} 求绳子的最大张力，一定时是绳子在最底部时的。绳中最大张力等于静张力与因为振动引起动的张力之和： T_{max}=T_s+kA=W+kA\\\\ =1.47\\times10^5+0.74\\times10^5=2.21\\times10^5 动张力几乎是静张力的一半 由于$kA=k\\dfrac{v}{\\omega_0}=v\\sqrt{km}$ 为了减少振动引起的动张力，应当降低升降系统的刚度。尽管这样可能会造成A过大舒适性下降，但是由于加速度减小，安全性得到保证。 首先，取平衡位置，以梁承受重物静平衡位置为坐标原点（就像相当于将重物平稳的放在上面产生的静变形为$\\lambda$） 由材料力学得：$\\lambda=\\dfrac{mgl^3}{48EJ}$ 自由振动频率：$\\omega_0=\\sqrt{\\dfrac{g}{\\lambda}}=\\sqrt {\\dfrac{48EJ}{ml^3}}$ 撞击时刻为零时刻，则t=0 时，有：$x_0=-\\lambda\\quad\\dot x_0=\\sqrt{2gh}$ 自由振动振幅：$A=\\sqrt{x_0^2+\\left(\\frac{\\dot x_0}{\\omega_0}\\right)^2}=\\sqrt{\\lambda^2+2h\\lambda}$ 梁的最大扰度：$\\lambda_{max}=A+\\lambda$ 由牛顿第二定律： I\\ddot \\theta(t)+k_\\theta \\theta(t)=0\\\\ \\ddot \\theta(t)+\\omega_0^2\\theta(t)=0 则扭振的固有频率为$\\omega_0=\\sqrt{\\dfrac{k_\\theta}{I}}$ 总结：由上例可看出，除坐标不同外，角振动与直线振动的数学描述完全相同。如果在弹簧质量系统中将m、k 称为广义质量及广义刚度，则弹簧质量系统的有关结论完全适用于角振动。以后不加特别声明时，弹簧质量系统是广义的。 从上两例还可看出，单自由度无阻尼系统总包含着惯性元件和弹性元件两种基本元件。 惯性元件是感受加速度的元件，它表现为系统的质量或转动惯量； 弹性元件是产生使系统恢复原来状态的恢复力的元件，它表现为具有刚度或扭转刚度的弹性体。 同一个系统中，若惯性增加，则使固有频率降低，而若刚度增加，则固有频率增大。 求复摆在平衡位置附近做微振动时的微分方程和固有频率。这里我们考虑的振动都是微振动（$\\sin \\theta \\approx \\theta$ )。 首先，由牛顿定律：$I_0\\ddot \\theta(t)+mga\\sin \\theta(t)=0$ 得出固有频率$\\omega_0=\\sqrt{\\dfrac{mga}{I_0}}$ 若已测出物体的固有频率，则可求出$\\omega_0$，再由移轴定理，可得物质绕质心的转动惯量：$I_c=I_0-ma^2$ 实验确定复杂形状物体的转动惯量的一个方法。 以静平衡位置为坐标原点建立坐标系，振动固有频率：$\\omega_0=\\sqrt{\\dfrac{K}{m}}=70rad/s$ 振动初始条件：$kx_0=mg\\times\\sin30° \\ \\Rightarrow x_0=-0.1cm$ 由题初始速度为$\\dot x_0=0$，则运动方程为$x(t)=-0.1\\cos(70t) cm$ 如果系统竖直放置，振动频率是否改变？不改变，因为质量是不变的，只有原长会改变。 能量法 对于不计阻尼即认为没有能量损失的单自由度系统，可利用能量守恒原理建立自由振动微分方程，或直接求出固有频率。 无阻尼系统为保守系统，其机械能守恒，即动能T 和势能V 之和保持不变，即：$T+V=const$ \\dfrac{d}{dt} (T+V)=0 当原点在静平衡位置的情况： 则总的势能为： V=-mgx+\\int_0^xk(\\lambda+x)\\,dx\\\\=-mgx+k\\lambda x+\\frac 1 2 k x^2 =\\frac 1 2 kx^2 则总的能量的为：$T+V=\\dfrac 1 2 k x^2+\\dfrac 1 2m \\dot x^2$ $\\dfrac{d}{dt} (T+V)=(m\\ddot x +kx)\\dot x=0 \\,\\Rightarrow \\, m\\ddot x(t)+kx(t)=0$ 能量法的步骤：(1)列方程，(2)求固有频率 如果将坐标原点不是取在系统的静平衡位置，而是取在弹簧为自由长时的位置，此时由能量之和的导数为零可得： $m\\ddot x \\dot x-mg\\dot x +kx \\dot x=0 \\, \\Rightarrow \\, m\\ddot x(t)+kx(t)=mg$ 设新的坐标$y=x-\\dfrac {mg} k =x- \\lambda \\ \\Rightarrow \\ m\\ddot y(t)+ky(t)=0$ 如果重力的影响仅是改变了惯性元件的静平衡位置，那么将坐标原点取在静平衡位置上，方程中就不会出现重力项。 由于$T+V=const$，则有$T_{max}= V_{max}\\Rightarrow\\frac 1 2m \\dot x_{max}^2=\\frac 1 2 k x_{max}^2$ 即有$\\dot x_{max}=\\omega_0x_{max}$，带入$x(t)= A \\sin (\\omega_0t+\\varphi) $，可得$\\omega_0=\\sqrt{\\dfrac{k}{m}}$ 对于转动：$\\dot \\theta_{max}=\\omega_0\\theta_{max}$ (1) 倒摆作微幅振动时的固有频率(2) 摆球$m=0.9kg$时，测得频率f为1.5HZ，$m=1.8kg$时，测得频率f为0.75HZ，问摆球质量为多少千克时恰使系统处于不稳定平衡状态？ 解法一：静平衡位置如左图，广义坐标为$\\theta$ 势能：由于是微振动，正弦遵循小角近似，但是余弦不遵循 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}-m g l(1-\\cos \\theta)\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}-m g l\\left(1-\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} \\theta^{2}-m g l \\theta^{2}\\right)=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 微分方程为：$T_{max}=U_{max} \\Rightarrow \\frac{1}{2} m l^{2} \\dot{\\theta}_{\\max }^{2}=\\dfrac{1}{2}\\left(k a^{2}-m g l\\right) \\theta_{\\max }^{2}$ 求固有频率：$\\dot \\theta_{max}=\\omega_0\\theta_{max} \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 这里我们将$ m l^{2}$视为等效质量，$\\left(k a^{2}-m g l\\right) $视为等效刚度。 解法二：静平衡位置如右图，广义坐标为$\\theta$ 势能：由于是微振动，这里用小角近似 \\begin{align} V&=2 \\times \\frac{1}{2}\\left(\\frac{1}{2} k\\right)(\\theta a)^{2}+m g l\\cos \\theta\\\\ &=\\frac{1}{2} k a^{2} \\theta^{2}+m g l\\left(1-2 \\sin ^{2} \\frac{\\theta}{2}\\right)\\\\ &=\\frac{1}{2}\\left(k a^{2} -m g l \\right)\\theta^{2}+mgl \\end{align} 动能：$T=\\dfrac{1}{2} I \\dot{\\theta}^{2}=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2}$ 由于$\\frac{d}{d t}(T+U)=0 \\Rightarrow\\ 2 m l^{2} \\dot{\\theta} \\ddot{\\theta}+2 \\theta\\left(k a^{2}-m g l\\right) \\dot{\\theta}=0$ 则有：$2 m l^{2} \\ddot{\\theta}+2\\left(k a^{2}-m g l\\right) \\theta=0 \\Rightarrow \\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 确定系统微振动的固有频率。 广义坐标：圆柱微转角$\\theta$，圆柱做一般运动， 由柯希尼定理，动能：$T=\\frac{1}{2}\\left(\\frac{3}{2} m R^{2}\\right) \\dot{\\theta}^{2}$ C点为瞬心 A点速度：$v_{A}=(R+a) \\dot{\\theta} \\ \\Rightarrow \\ x_{A}=(R+a) \\theta$ B点的速度：$v_{B}=(R-b) \\dot{\\theta}\\ \\Rightarrow \\ x_{B}=(R-b) \\theta$ 则势能为：$U=\\dfrac{1}{2}\\left(2 k_{1}\\right)(R+a)^{2} \\theta^{2}+\\dfrac{1}{2}\\left(2 k_{2}\\right)(R-b)^{2} \\theta^{2}$ 由于$T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{\\theta}_{\\max }=\\omega_{0} \\theta_{\\max }$ \\begin{align} \\omega_{0}^{2}&=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}\\\\ &=\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right] \\end{align}解得固有频率为：$\\omega_{0}=\\sqrt{\\dfrac{4}{3 m}\\left[k_{1}\\left(1+\\dfrac{a}{R}\\right)^{2}+k_{2}\\left(1-\\dfrac{b}{R}\\right)^{2}\\right]}$ 坐标原点设在静平衡位置，因为计算势能的时候预先压缩造成的重力势能和弹性势能一定会被约掉，得出其次动力学方程。 因此，广义的坐标：质量块的垂直位移x 动能： \\begin{align} T&=\\frac{1}{2} m \\dot{x}^{2}+\\dfrac{1}{2} M\\left(\\dfrac{1}{2} \\dot{x}\\right)^{2}+\\frac{1}{2}\\left(\\dfrac{1}{2} M R^{2}\\right)\\left(\\dfrac{\\dot{x}}{2 R}\\right)^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{1}{4} M+\\frac{1}{8} M\\right) \\dot{x}^{2}\\\\ &=\\frac{1}{2}\\left(m+\\frac{3}{8} M\\right) \\dot{x}^{2} \\end{align} 势能：$U=\\dfrac{1}{2} k_{2} x^{2}+\\dfrac{1}{2} k_{1}\\left(\\dfrac{1}{2} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{2}+\\dfrac{1}{4} k_{1}\\right) x^{2}$ 由能量守恒可知： $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max }$ 解得：$\\omega_{0}=\\sqrt{\\dfrac{2 k_{1}+8 k_{2}}{3 M+8 m}}$ 瑞利法利用能量法求解固有频率时，对于系统的动能的计算只考虑了惯性元件的动能，而忽略不计弹性元件的质量所具有的动能，因此算出的固有频率是实际值的上限。 这种简化方法在许多场合中都能满足要求，但有些工程问题中，弹性元件本身的质量因占系统总质量相当大的比例而不能忽略，否则算出的固有频率明显偏高。 当弹簧的质量的质量不是远小于小车的质量时，就无法忽略弹簧的质量，因此这里用等效的质量来分析。 系统最大的势能：$V_{\\max }=\\frac{1}{2} k x_{\\max }^{2}$ $T_{\\max }=U_{\\max } \\quad \\Rightarrow \\quad\\dot{x}_{\\max }=\\omega_{0} x_{\\max } \\quad \\Rightarrow \\quad \\omega_{0}=\\sqrt{\\dfrac{k}{m+m_{t}}}$ 若忽略 $m_t$ ，则$\\omega_0$增大，因此忽略弹簧动能所算出的固有频率是实际值的上限。 瑞利法求解等效的质量是通过积分来求解的。 等效质量与等效阻尼方法一：能量法求解 选定广义位移坐标后，将系统得动能、势能写成如下形式：$T=\\dfrac{1}{2} M_{e} \\dot{x}^{2} ,\\, V=\\dfrac{1}{2} K_{e} x^{2}$ 当 $\\dot x,x$分别取最大值时：$T \\rightarrow T_{\\max }， \\ V \\rightarrow V_{\\max }$ ，可以得出：$\\omega_{0}=\\sqrt{\\dfrac{K_{e}} {M_e}}$ $K_e$：简化系统的等效刚度；$M_e$：简化系统的等效质量。 等效的含义是指简化前后的系统的动能和势能分别相等。 主要步骤： 选定广义坐标 将动能和势能写成标准形式 根据系数写出等效刚度和等效阻尼 动能：$T=\\dfrac{1}{2} m l^{2} \\dot{\\theta}^{2} \\Rightarrow M_{e}=m l^{2}$ 势能：$V=\\frac{1}{2}\\left(k a^{2}-m g l\\right) \\theta^{2} \\Rightarrow K_{e}=k a^{2}-m g l$ 固有频率：$\\omega_{0}=\\sqrt{\\dfrac{k a^{2}-m g l}{m l^{2}}}$ 势能：$U=\\frac{1}{2}\\left[\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}\\right] \\theta^{2}$ 等效刚度：$K_{e}=\\left(2 k_{1}\\right)(R+a)^{2}+\\left(2 k_{2}\\right)(R-b)^{2}$ 则固有频率为：$\\omega_{0}^{2}=\\dfrac{2\\left[k_{1}(R+a)^{2}+k_{2}(R-b)^{2}\\right]}{3 m R^{2} / 2}$ 方法二：定义法 等效刚度：使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 等效质量：使系统在选定的坐标上产生单位加速度而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效质量。 使系统在选定的坐标上产生单位位移而需要在此坐标方向上施加的力，叫做系统在这个坐标上的等效刚度。 串联弹簧的刚度的倒数是原来各个弹簧刚度倒数的总和 并联弹簧的刚度是原来各个弹簧刚度的总和。 求：系统对于坐标x 的等效质量和等效刚度。 方法1：能量法 动能：$T=\\dfrac{1}{2} m_{1} \\dot{x}^{2}+\\dfrac{1}{2} m_{2}\\left(\\dfrac{l_{2}}{l_{1}} \\dot{x}\\right)^{2}=\\dfrac{1}{2}\\left(m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}\\right) \\dot{x}^{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 势能：$V=\\dfrac{1}{2} k_{1} x^{2}+\\dfrac{1}{2} k_{2}\\left(\\dfrac{l_{3}}{l_{1}} x\\right)^{2}=\\dfrac{1}{2}\\left(k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}\\right) x^{2}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 方法二：定义法 设使系统在x方向产生单位加速度需要施加力P，则在m1、m2上产生惯性力，对支座取矩： $P l_{1}=\\left(m_{1} \\cdot 1\\right) l_{1}+\\left(m_{2} \\cdot \\dfrac{l_{2}}{l_{1}}\\right) l_{2}$ 等效质量：$M_{e}=m_{1}+\\dfrac{l_{2}^{2}}{l_{1}^{2}} m_{2}$ 画虚线是夸张化的m，其实其位移非常的为微小，在零时刻产生了单位加速度$\\ddot x=1$，$m_1,m_2$在平衡位置静平衡位置：重力和弹簧预变形相互抵消，因此弹力可以忽略。 设使系统在x坐标上产生单位位移需要施加力P，则在k1、k2处将产生弹性恢复力，对支点取矩： $P l_{1}=\\left(k_{1} \\cdot 1\\right) l_{1}+\\left(k_{2} \\cdot \\dfrac{l_{3}}{l_{1}}\\right) l_{3}$ 等效刚度：$K_{e}=k_{1}+\\dfrac{l_{3}^{2}}{l_{1}^{2}} k_{2}$ 等效质量(惯性力)：动态求解(达朗贝尔原理)； 等效刚度(静力平衡：静态求解(列静力学方程)。","link":"/2022/01/27/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%8D%95%E8%87%AA%E7%94%B1%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%8C%AF%E5%8A%A8-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/"},{"title":"Latex期刊论文的排版","text":"本文主要针对与IEEE的一个Latex模板，主要从模板下载、语句解释、插入图片、插入公式、插入算法图、插入引用等方面来讲解如何使用模板。该教程属于简易教程，深入学习请看后续的详细教程。视频参考 Latex模板下载 模板下载:IEEE模板:http://www.ieee.org/publications_standards/publications/authors/author_templates.html 通用模板:https://www.overleaf.com/ 其他方法:百度,csdn等网页找 Latex的核心思想就是内容与格式分离 模板的基本语句解释 \\begin{document}是文件的开始，之前为导言区，可以加入各种各样的宏包。 \\begin{document}之后到\\begin{abstract}之前用来写作者信息，联系方式以及致谢等信息。 \\begin{IEEEkeywords} 后面写关键词。 \\section{Introduction} 之后为介绍综述部分。 \\subsection{name} 为子标题部分。 \\section{References Section} 参考文献部分。 \\begin{IEEEbiography} 开始作者生平部分。 插入图片 首先，导入宏包 \\usepackage{graphicx}。 其次，导入代码块，其中的后缀名可以去查看详细的教程。 最后，编辑图片的大小样式。 插入公式公式部分主要的内容参考之前的专门写公式那篇博客](https://houdezaiwu2019.github.io/2022/01/24/Latex/Latex公式排版快速教程/))。 首先，导入宏包 \\usepackage{amsmath,amsfonts} 其次，行间公式如图，文章终会自行标号，也可以自行标号\\tag{1.1}。 \\begin{equation} \\label{deqn_ex1} x = \\sum_{i=0}^{n} 2{i} Q. \\tag{1.1} \\end{equation} 最后，行内的公式的写法是在$ $之间直接写即可，如$x^2+y^2=0$ 插入参考文献实用办法插入参考文献 首先，引入宏包 \\usepackage[colorlinks,linkeolor-black,anchorcolor-black,citecolor-black]{hyperref }%用于调整多个参考文献的间距。直接用就好。 模板的插入方法，直接插入。 也可以自己使用BibTex格式的文件来插入，但是在实际编译的过程中要记得将BibTex文件也进行编译。 到百度上下载一个BibTex的文件。 引用BIb文件。 以下为BibTex文件的内容。 12345678@article{2021Exploiting,title={Exploiting Vector Attention and Contextual Prior for Ultrasound Image Segmentation},author={ Xu, L. and Gao, S. and Shi, L. and Wei, B. and He, Y. },journal={Neurocomputing},volume={454},number={1},year={2021},} 引用，BibTex也要编译，否则出现的是？，但是目前TexStduio我还没有找到在哪里编译BibTex文件。 插入算法图 首先，导入宏包 \\usepackage[ruled,linesnumbered]{algorithm2e}。 之后，导入算法块即可。 工具补充 补充好用网页:手写公式转latex https://editor.codecogs.com/ 手写符号，转latex表达 https://detexify.kirelabs.org/classify/html 截图看公式 https://mathpix.com/ 手写表格，转latex表达 https://www.tablesgenerator.com/","link":"/2022/01/25/Latex/Latex%E6%9C%9F%E5%88%8A%E8%AE%BA%E6%96%87%E7%9A%84%E6%8E%92%E7%89%88/"},{"title":"AlexNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); 本文首先详解AlexNet网络，计算每一层网络的维度并且整理了花数据集。之后，通过Pytorch对网络进行复现，主要从模型搭建、设置GPU、数据预处理、加载数据、配置损失函数和优化器、模型保存、模型训练验证与测试等方面进行实现。 AlexNet的详解AlexNet是2012年ISLVRC 2012 (lmageNet Large Scale Visual RecognitionChallenge）竞赛的冠军网络，分类准确率由传统的70%+提升到80%+。它是由Hinton和他的学生Alex Krizhevsky设计的。也是在那年之后，深度学习开始迅速发展。 AlexNet网络简介ISLVRC 2012训练集:1,281,167张已标注图片；验证集:50,000张已标注图片；测试集:100,000张未标注图片。 AlexNet的结构图 该网络的亮点在于: 首次利用GPU进行网络加速训练。 使用了ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数。 因为Sigmoid函数会出现梯度消失，梯度爆炸。 使用了LRN局部响应归一化。 在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。 过拟合：根本原因是特征维度过多，模型假设过于复杂，参数过多，训练数据过少，噪声过多，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。过度的拟合了训练数据，而没有考虑到泛化能力。 使用Dropout的方式在网络正向传播过程中随机失活一部分神经元。 回顾：经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1网络分层计算 第一层（Conv1）： 这里是运用了GPU的并行计算的功能，将96层分成了两部分进行计算。 通道数：input_channels = 3；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 11; stride = 4; padding = [1,2] 输入输出的尺寸数：input_size=[224,224,3]; output_size=[55,55,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(224-11+(1+2))}{4}+1=55 第二层（Maxpool1）：只是改变高度宽度，不改变深度。 通道数：input_channels = 96；output_channels = 48$\\times$2=96 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[55,55,96]; output_size=[27,27,96] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(55-3+0)}{2}+1=27 第三层（Conv2）： 通道数：input_channels = 96；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 5; stride = 1; padding = 2 输入输出的尺寸数：input_size=[27,27,96]; output_size=[27,27,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-5+4)}{1}+1=27 第四层（Maxpool2）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[27,27,256]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(27-3+0)}{2}+1=13 第五层（Conv3）： 通道数：input_channels = 256；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 384；output_channels = 192$\\times$2=384 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,256]; output_size=[13,13,384] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 384；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 1; padding = 1 输入输出的尺寸数：input_size=[13,13,384]; output_size=[13,13,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+2)}{1}+1=13 第六层（Conv4）： 通道数：input_channels = 256；output_channels = 128$\\times$2=256 卷积核参数：kernel_size = 3; stride = 2; padding = 0 输入输出的尺寸数：input_size=[13,13,256]; output_size=[6,6,256] N=\\dfrac{(W-F+2P)}{S}+1=\\dfrac{(13-3+0)}{2}+1=6 后三层接了三个全连接层，注意最后数据集有1000类，因此最后一个全连接层有1000个节点，如果我们的数据集有10类，最后的全连接层就10个节点。 layer_name kernel_size output_channels padding stride Conv1 11 96 [1,2] 4 Maxpool1 3 None 0 2 Conv2 5 256 [2,2] 1 Maxpool2 3 None 0 2 Conv3 3 384 [1,1] 1 Conv4 3 384 [1,1] 1 Conv5 3 256 [1,1] 1 Maxpool3 3 None 0 2 FC1 2048 None None None FC2 2048 None None None FC3 1000 None None None 数据集(flowers) （1）在data_set文件夹下创建新文件夹”flower_data” （2）点击链接下载花分类数据集 （3）解压数据集到flower_data文件夹下 （4）执行”split_data.py”脚本自动将数据集划分成训练集train和验证集val 1234├── flower_data ├── flower_photos（解压的数据集文件夹，3670个样本） ├── train（生成的训练集，3306个样本） └── val（生成的验证集，364个样本） AlexNet网络的pytorch实现模型的搭建 对于网络层比较多的结构来说，一般用在网络比较多的时候，且网络结构比较简单，没有跳跃连接等复杂的结构。 padding=tuple/int：如果tuple(1,2),代表上下方各补一行0，左右补两列0。但是，如果出现上述的计算出来的下一层的[H,W]不为0时，自动舍弃一行或一列零来满足最后结果为整数。 1nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2) 如果要左侧补一列，右侧补两列，上侧补一行，右侧补两行。要使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True): 减小使用内存，提高性能的参数。 self.modules()：返回一个迭代器，遍历网络中所有的模块； 关于初始化，目前版本的pytorch其实是可以自动进行初始化的。初始化时，对于卷积层使用恺明初始化，对于一般的全连接层使用正态分布初始化，偏差全部初始化为0。 1234567891011121314def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) 对于展开成为全连接层来说，保证第0位batch不变, start_dim=1$[batch\\ , channel\\ , weight\\ , height] \\rightarrow [batch\\ , num]$ 1x = torch.flatten(x, start_dim=1) # 也可以用view 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weight=False): super(AlexNet, self).__init__() # 卷积层合集 self.feature = nn.Sequential( # input [3,224,224] nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2), # output [48,55,55] # 如果出现上述的计算出来的下一层的[H,W]不为0时， # 自动舍弃一行零来满足最后结果为整数 # 或者使用nn.ZeroPad((1，2，1，2)) nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [48,27,27] nn.Conv2d(48, 128, kernel_size=5, padding=2), # output [128,27,27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,13,13] nn.Conv2d(128, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 192, kernel_size=3, padding=1), # output [192,13,13] nn.ReLU(inplace=True), nn.Conv2d(192, 128, kernel_size=3, padding=1), # output [128,13,13] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output [128,6,6] ) # 全连接层合集 self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(128*6*6, 2048), nn.ReLU(inplace=True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), nn.ReLU(inplace=True), nn.Linear(2048, num_classes), ) if init_weight: self._initialize_weights() # 一般情况下时自动进行初始化的 def _initialize_weights(self): for m in self.modules(): # module()返回一个迭代器 遍历一个类中所有的模块类 if isinstance(m, nn.Conv2d): # 参数1为对象(迭代器) 参数2为要作比较的对象 # 如果参数1对应的对象和参数2对应的类相同，返回True nn.init.kaiming_normal_(m.weight, mode='fan_out') # 对于卷积的参数使用恺明初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 对于全连接层，使用的正态分布初始化权重 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.constant_(m.bias, 0) def forward(self, x): x = self.feature(x) x = torch.flatten(x, start_dim=1) # [batch channel weight height] start_dim=1 # 就是保证第0位batch不变-&gt;[batch num] # 也可以用view x = self.classifier(x) return x 设置GPU设备1device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 数据预处理12345678910111213data_transform = { &quot;train&quot;: transforms.Compose([ transforms.RandomResizedCrop(224), # 随机截取大小为224的图片 transforms.RandomHorizontalFlip(), # 随机翻转 transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]), &quot;val&quot;: transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])} 这里我们将预处理部分分成“train”和”val”两部分，将其封装称为一个字典。 transforms.RandomResizedCrop(224)：随机截取一定大小的图片。 transforms.RandomHorizontalFlip()：对图片数据进行随机反转。 transforms.ToTensor()：将数据转化为Tensor，维度按照torch要求的排列$[batch\\ , channel\\ , weight\\ , height]$。 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))：将图片数据标准化。 加载数据12345678910# 获得绝对路径data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))# os.getcwd()获得当前位置的目录# ./.代表返回上一层目录 ../..代表返回上两层目录# 获得花的数据data_root = os.path.abspath(os.getcwd())image_path = data_root + &quot;/data_set/flower_data/&quot;train_dataset = datasets.ImageFolder(root=image_path + &quot;/train&quot;, transform=data_transform[&quot;train&quot;])# 求数据即得数据个数train_num = len(train_dataset) os.getcwd()：获得当前位置的目录。 ./.代表返回上一层目录； ../..代表返回上两层目录 os.path.join(os.getcwd(), “../..”)：代表返回上两层目录，其中join()的作用就是将内部路径进行合并，也可以进入当前目录的下的某个文件，join(os.getcwd(), “/xxx/xxx”) ImageFolder：用来以一定方式整理图片的类。 123456789# flower_list得到字典，但是得出的结果是反的flower_list = train_dataset.class_to_idx# 是的字典的val和key交换为位置的一种方法cla_dict = dict((val, key) for key, val in flower_list.items())# 将字典写入到Json文件中json_str = json.dumps(cla_dict, indent=4)with open('class_indices.json', 'w') as json_file: json_file.write(json_str) train_dataset.class_to_idx：得到类别和索引值的字典，此处预测得到的是索引值，想要得到花的名字就需要将key（名称）和value（索引值）交换位置。 json.dumps(cla_dict, indent=4)：将字典值写入到json文件中。 1234567{ &quot;0&quot;: &quot;daisy&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;} 数据的导入和加载12345678910batch_size = 32train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)val_dataset = datasets.ImageFolder(root=image_path + &quot;val&quot;, transform=data_transform[&quot;val&quot;])val_num = len(val_dataset)val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0) 这边和上一章相同，此处不在赘述。 损失函数的计算与优化器配置12345678net = AlexNet(num_classes=5, init_weight=True)net.to(device) # 启动GPUloss_function = torch.nn.CrossEntropyLoss()optimizer = optim.Adam(net.parameters(), lr=0.0002)save_path = '.AlexNet.pth'best_acc = 0.0 # 设置保存最高准确率所对应的参数 模型的训练与验证 net.train(),net.eval()：主要的作用是用来管理Dropout层和BN层，在训练的过程启用上述层，但是在预测的时候还是正常计算，不进行随机失活和BN操作。 训练过程 t1 = time.perf_counter()：用来记录训练的时间。 用来打印进度条的程序。其中，end=’’空字符。 123456# 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 以下是训练过程的代码实现。 123456789101112131415161718192021222324for epoch in range(15): net.train() # 主要针对的Dropout方法 running_loss = 0.0 t1 = time.perf_counter() for step, data in enumerate(train_loader, start=0): images, labels = data images, labels = images.to(device), labels.to(device) # 将梯度初始化为0 optimizer.zero_grad() outputs = net(images) loss = loss_function(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() # 打印训练的过程进度条 rate = (step + 1) / len(train_loader) a = &quot;*&quot; * int(rate * 50) b = &quot;.&quot; * int((1-rate) * 50) print(&quot;\\rtrain loss: {:^3.0f}%[{}-&gt;{}]{:.3f}&quot;.format(int(rate*100), a, b, loss), end='') # 这里end=''相当于是一个换行符 print() print(time.perf_counter()-t1) 验证过程1234567891011121314151617# 直接接在上一个for循环中net.eval()acc = 0.0with torch.no_grad(): for data_test in val_loader: test_images, test_labels = data_test test_images, test_labels = test_images.to(device), test_labels.to(device) outputs = net(test_images) predict_y = torch.max(outputs, dim=1)[1] print(predict_y == test_labels) acc += (predict_y == test_labels).sum().item() accurate_test = acc / val_num # 只保存最好的结果 if accurate_test &gt; best_acc: best_acc = accurate_test torch.save(net.state_dict(), save_path) print('[epoch %d] train_loss: %.3f test_accuracy: %3f' % (epoch + 1, running_loss/step, acc / val_num)) 模型测试导入数据1234567891011121314151617181920data_transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# load imageimg = Image.open(&quot;4.jpg&quot;)plt.imshow(img)# [N C H w]img = data_transform(img)# 增加一个维度img = torch.unsqueeze(img, dim=0)# 读取字典try: json_file = open('./class_indices.json', 'r') class_indict = json.load(json_file)except Exception as e: print(e) exit(-1) 导入模型12345678910111213141516# 建立模型model = AlexNet(num_classes=5)# load 权重model_weigh_path = &quot;.AlexNet.pth&quot;model.load_state_dict(torch.load(model_weigh_path))model.eval()with torch.no_grad(): # predict class output = torch.squeeze(model(img)) # 降低维度，将batch一维去掉 predict = torch.softmax(output, dim=0) predict_cla = torch.argmax(predict).numpy()print(class_indict[str(predict_cla)], predict[predict_cla].item())plt.show()","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/AlexNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"Pytorch入门教程及LeNet网络","text":"hljs.initHighlightingOnLoad(); 本篇为Pytorch入门教程，使用的网络为LeNet(1998)网络。主要从网络搭建、导入数据、定义损失函数与优化器、训练与验证模型、模型测试与保存方面进行展示。 建立LeNet网络模型123456789101112131415161718192021222324252627import torchimport torch.nn as nnimport torch.nn.functional as Fclass LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5) self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(32 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) # pytorch [batch, channel, height, width] def forward(self, x): #input(3,32,32) N=(32-5+0)/1+1=28 x = F.relu(self.conv1(x)) #output(16,28,28) N=28/2=14 x = self.pool1(x) #output(16,14,14) N=(14-5+0)/1+1=10 x = F.relu(self.conv2(x)) #output(32,10,10) N=10/2=5 x = self.pool2(x) #output(32,5,5) x = x.view(-1, 32*5*5) #output=32*5*5=800 x = F.relu(self.fc1(x)) #output=120 x = F.relu(self.fc2(x)) #output=84 out = F.relu((self.fc3(x)))#output=10 return out 经过卷积后的矩阵尺寸大小计算公式为： 其中输入图片的大小为$W\\times W$； Filter的大小为$F\\times F$，即kernel_size为F； 步长Stirde=S padding的像素数为P N=\\dfrac{(W-F+2P)}{S}+1以下我们进行模型的测试和调试： 12345678910111213141516# 模型的测试import torchX = torch.rand(size=(32, 3, 32, 32), dtype=torch.float32)model = LeNet()print(model)# 打印的结果如下：LeNet( (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (fc1): Linear(in_features=800, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 导入数据 这里我们使用的CIFAR-10数据集，一共由10类。 首先，下载数据集。 torchvision.datasets.xxx() 里面有我们需要很多数据集。 123456# 下载训练数据trainset = torchvision.datasets.CIFAR10( root=&quot;./data&quot;, #数据集下载的位置 train=True, #是否为训练集 transform=transforms,#图像处理函数 download=True) #是否下载 图像的处理函数集 1234transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) Compose([ ])函数的作用是将所有的处理函数合并、打包。 ToTensor()函数的作用是将图片数据转换为张量，维度转化为pytorch标准的维度，同时数据的范围由原来的$[0,255]\\rightarrow[0.0,1.0]$。 Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))的作用是将图片的张量数据进行标准化。 之后，导入数据集。 123456# 导入训练数据trainloader = utils.data.DataLoader( trainset, # 总的训练数据集 batch_size=50, # 一个batch里的样本数 shuffle=True, # 是否打乱顺序 num_workers=0) # 线程数 由于一次训练不可能将训练集所有的参数都选进来进行反向传播，因此我们把一次喂入数据的个数称为batch_size。 数据的测试，使用迭代器获得数据集中的图片和标签。 1234567891011121314151617181920test_data_iter = iter(test_loader)# 迭代器，用来获取test_image, test_label = test_data_iter.next()# 用来获取下一个参数# 显示函数def imshow(img): img = img / 2 + 0.5 # unnormalize 反标准化 npimg = img.numpy() # 转化为numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # 由于ToTensor()改变了数据的维度排列，转化为原来的维度排列 plt.show()# # get some random training imagesdataiter = iter(trainloader)images, labels = dataiter.next()# show imagesimshow(torchvision.utils.make_grid(images))# print labelsprint(' '.join('%5s' % classes[labels[j]] for j in range(4))) 定义损失函数12# 定义损失函数为交叉熵损失函数loss_function = nn.CrossEntropyLoss() 如图，在CrossEntropyLoss()里面已经包含了交叉熵的计算公式，因此就不在需要在网络里定义softmax()层了。 定义优化器这里使用的Adam() 优化器。 1234# 定义优化器（训练参数，学习率）optimizer = optim.Adam(net.parameters(), lr=0.01)# 可变学习率scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1) 训练模型1234567891011121314151617181920212223242526272829303132for epoch in range(5): # 一个epoch即对整个训练集进行一次训练,这里对训练集循5轮 running_loss = 0.0 # 训练误差初始化为0 for step, train_data in enumerate(trainloader, start=0): inputs, labels = train_data inputs, labels = inputs.to(device), labels.to(device) # 清除历史梯度,每一轮训练都要 optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) # 正向传播 loss = loss_function(outputs, labels) # 计算损失 loss.backward() # 反向传播 optimizer.step() # 优化器更新参数 # 打印训练结果 running_loss += loss.item() accuray = 0 test_image, test_label = test_image.to(device), test_label.to(device) if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 enumerate(trainloader, start=0)：返回的是数据集和对应的步数。 关于optimizer.zero_grad() 进行梯度的清零。 12345678910# 传统的方法for i, (image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2. backward optimizer.zero_grad() # reset gradient loss.backward() optimizer.step() 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； optimizer.zero_grad() 清空过往梯度； loss.backward() 反向传播，计算当前梯度； optimizer.step() 根据梯度更新网络参数 1234567891011121314151617# 梯度累加方法for i,(image, label) in enumerate(train_loader): # 1. input output pred = model(image) loss = criterion(pred, label) # 2.1 loss regularization loss = loss / accumulation_steps # 2.2 back propagation loss.backward() # 3. update parameters of net if (i+1) % accumulation_steps == 0: # optimizer the net optimizer.step() # update parameters of net optimizer.zero_grad() # reset gradient 获取 loss：输入图像和标签，通过infer计算得到预测值，计算损失函数； loss.backward() 反向传播，计算当前梯度； 多次循环步骤 1-2，不清空梯度，使梯度累加在已有梯度上； 梯度累加了一定次数后，先optimizer.step() 根据累计的梯度更新网络参数，然后optimizer.zero_grad() 清空过往梯度，为下一波梯度累加做准备； 总结来说：梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空，不断累加，累加一定次数后，根据累加的梯度更新网络参数，然后清空梯度，进行下一次循环。对于一些GPU内存不足的实验室，这是一个可以扩大batch_size的trick。 模型测试12345678910111213141516# 打印训练结果running_loss += loss.item()accuray = 0# 使用GPUtest_image, test_label = test_image.to(device), test_label.to(device)if step % 500 == 499: print('******************') with torch.no_grad(): # 代表以下的代码都是在torch.no_grad()下进行运算的 outputs = net(test_image) predit_y = torch.max(outputs, dim=1)[1] # _,predit_y = torch.max(outputs, dim=1) # max()返回的是两个维度，首先的最大值，之后是index accuray = (predit_y == test_label).sum().item() / test_label.shape[0] print('[%d, %5d] loss: %.3f test_accuray: %.3f' % (epoch + 1, step + 1, running_loss / 500, accuray)) running_loss = 0.0 with torch.no_grad():这里的with是一个上下文管理器，其中的作用是下面的代码都遵循torch.no_grad()。 其次，在预测过程中，不用进行梯度计算，用了反而内存不够，因此使用torch.no_grad()。 tensor.item()：用来获取tensor的数值。 保存模型12save_path = './LeNet.pth'torch.save(net.state_dict(), save_path) 模型测试 首先，对图片进行处理。 123456789101112# 数据预处理transform = transforms.Compose( [transforms.Resize((32, 32)), # 首先需resize成跟训练集图像一样的大小 transforms.ToTensor(), # 转换为torch的对的张量维度 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下im = Image.open('4.jpg')im = transform(im) # 转换成[C, H, W]im = torch.unsqueeze(im, dim=0) # 对数据增加一个新维度，# 因为tensor的维度是[batch, channel, height, width] torch.unsqueeze(im, dim=0)：对数据增加一个新维度，即加一个batch的维度。 之后，实例化网络 123# 实例化网络，加载训练好的模型参数net = LeNet()net.load_state_dict(torch.load('Lenet.pth')) 最后，预测类别 1234567# 预测classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')with torch.no_grad(): outputs = net(im) predict = torch.max(outputs, dim=1)[1].data.numpy()print(classes[int(predict)]) 这里，我们将outputs丢进torch.softmax() ，可得到属于每个类别的概率。 1234567predict = torch.softmax(outputs, dim=1)# dim=1的原因，是因为outputs为两维的，dim=0只有一个# outputs = tensor([[0.0000, 0.0000, 5.4191, 0.4988, 0.0000, 1.3599, 0.0000, 0.2233, 0.0000, 0.0000]])print(predict)# 输出:tensor([[0.0042, 0.0042, 0.9464, 0.0069, 0.0042, 0.0163, 0.0042, 0.0052, 0.0042, 0.0042]])","link":"/2022/01/28/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/Pytorch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8F%8ALeNet%E7%BD%91%E7%BB%9C/"},{"title":"GoogLeNet网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); GoogLeNet详解简介GoogLeNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task (分类任务)第一名，本文主要从模型的搭建以及pytorch实现上进行介绍。 网络中的亮点： 引入了Inception结构（融合不同尺度的特征信息) 使用1x1的卷积核进行降维以及映射处理 添加两个辅助分类器帮助训练 AlexNet和VGG都只有一个输出层，GoogLeNet有三个输出层(其中两个辅助分类层) 丢弃全连接层，使用平均池化层（大大减少模型参数) Inception结构 如图为原始的一种Inception结构； 主要的区别是之前的VGG主要采取串联的结构，增加模型的深度， Inception主要采取并行的结构，增加的是模型的宽度。 注意：每个分支所得的特征矩阵的高和宽必须是相同的。 如图为改进之后的网络图，这里1$\\times$1的卷积核的主要作用是用来降维的。 这里降维就是将深度降低，即channels数，通过减少深度，进而减少参数量，减少计算量。 辅助分类器(Auxiliary Classifier)The exact structure of the extra network on the side, including the auxiliary classifier, is as follows: An average pooling layer with 5x5 filter size and stride 3, resulting in an 4x4×512 outputfor the (4a), and 4×4×528 for the (4d) stage. $input_{size}=14,\\ output_{size}=\\dfrac{14-5+0}{3}+1=4$ A 1×1 convolution with 128 filters for dimension reduction and rectified linear activation.· A fully connected layer（全连接层） with 1024 units and rectified linear activation（RELU). A dropout layer with 70% ratio of dropped outputs. A linear layer with softmax loss as the classifier (predicting the same 1000 classes as themain classifier, but removed at inference time). 在3$\\times$3卷积之前要进行一个1$\\times$1卷积的降维处理。 上图为下面表格中对于的结构在网络中的位置。 如图，在实际的操作过程中，LocalRespNorm(LPN)层的作用不大，因此可以去掉。 如图相比之下发现，VGG的参数参数过多，是GoogLeNet的20倍。 但VGG的模型搭建简单，并且GoogLeNet辅助分类器的使用和修改比较麻烦，不容易调试，因此一般来说VGG的使用较多。 GoogLeNet的pytorch实现模型搭建因为GoogLeNet的一些结构块的代码复用比较多，因此这里首先创建几个模板文件，以方便之后模型的搭建。 基本卷积块12345678910class BasicCon2vd(nn.Module): def __init__(self, in_channels, out_channels, **kwargs): super(BasicCon2vd, self).__init__() self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, **kwargs) self.relu = nn.ReLU(inplace=True) def forward(self, x): x = self.conv(x) x = self.relu(x) return x 由于卷积层都是伴随着ReLU激活函数来使用的，因此首先建立将二者合并的模板。 通过使用模板搭建的方式，使得网络得结构一目了然，很清晰。 Inception模板的搭建 1234567891011121314151617181920212223242526272829class Inception(nn.Module): def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj): super(Inception, self).__init__() self.branch1 = BasicCon2vd(in_channels, ch1x1, kernel_size=1) self.branch2 = nn.Sequential( BasicCon2vd(in_channels, ch3x3red, kernel_size=1), BasicCon2vd(ch3x3red, ch3x3, kernel_size=3, padding=1) # 将padding=1 使得branch的输入和输出是相同的 ) self.branch3 = nn.Sequential( BasicCon2vd(in_channels, ch5x5red, kernel_size=1), BasicCon2vd(ch5x5red, ch5x5, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) self.branch4 = nn.Sequential( nn.MaxPool2d(kernel_size=3, stride=1, padding=1), BasicCon2vd(in_channels, pool_proj, kernel_size=5, padding=2) # 将padding=2 使得branch的输入和输出是相同的 ) def forward(self, x): branch1 = self.branch1(x) branch2 = self.branch2(x) branch3 = self.branch3(x) branch4 = self.branch4(x) output = [branch1, branch2, branch3, branch4] return torch.cat(output, 1) # 在维度1上面进行叠加和整合, 即在channel上进行拼接 通过不同的padding参数，保证每个branch的输入和输出总是相同的。 最后，在维度dim=1上面进行叠加和整合, 即在channel上进行拼接。 辅助分类器的搭建123456789101112131415161718192021222324252627class InceptionAux(nn.Module): def __init__(self, in_channels, num_classes): super(InceptionAux, self).__init__() self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3) self.conv = BasicConv2d(in_channels, 128, kernel_size=1) # output[batch, 128, 4, 4] self.fc1 = nn.Linear(2048, 1024) self.fc2 = nn.Linear(1024, num_classes) def forward(self, x): # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 x = self.averagePool(x) # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4 x = self.conv(x) # N x 128 x 4 x 4 x = torch.flatten(x, 1) # [batch channel width height] 1 代表在1的维度下进行展平 x = F.dropout(x, 0.5, training=self.training) # self.training model.train()模式下为true 在model.eval()下为False # N x 2048 x = F.relu(self.fc1(x), inplace=True) x = F.dropout(x, 0.5, training=self.training) # N x 1024 x = self.fc2(x) # N x num_classes return x 开始时，在平均池化下采样和卷积之前，一个辅助分类器与第二个辅助分类器的深度是不同的。 dropout层的随机概率p=0.7，但是实际的效果不一定好，因此我们将调整为p=0.5。 当我们实例化个模型model后，可以通过model.train()和model.eval()来控制模型的状态。在model.train()模式下self.training=True，在model.eval()模式下self.training=False GoogLeNet搭建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class GoogLeNet(nn.Module): def __init__(self, num_classes=1000, aux_logits=True, init_weight = False): super(GoogLeNet, self).__init__() self.aux_logits = aux_logits self.conv1 = BasicCon2vd(3, 64, kernel_size=7, stride=7, padding=3) # 计算默认为下取整 该层的作用是将H,W缩小为原来的一半 self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True) # ceil_mode=True时 取整方式变为了上取整 self.conv2 = BasicCon2vd(64, 64, kernel_size=1) self.conv3 = BasicCon2vd(64, 192, kernel_size=3, padding=1) self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32) self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64) self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64) self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64) self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64) self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128) self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True) self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128) self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128) if self.aux_logits: self.aux1 = InceptionAux(512, num_classes) self.aux2 = InceptionAux(528, num_classes) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # (1, 1) 这里的(1, 1) &lt;=&gt; (width, Height) 无论输入是多少 输出都为1*1 self.dropout = nn.Dropout(p=0.4) self.fc = nn.Linear(1024, num_classes) if init_weight: self._initialize_weights() def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) def forward(self, x): # N x 3 x 224 x 224 x = self.conv1(x) # N x 64 x 112 x 112 x = self.maxpool1(x) # N x 64 x 56 x 56 x = self.conv2(x) # N x 64 x 56 x 56 x = self.conv3(x) # N x 192 x 56 x 56 x = self.maxpool2(x) # N x 192 x 28 x 28 x = self.inception3a(x) # N x 256 x 28 x 28 x = self.inception3b(x) # N x 480 x 28 x 28 x = self.maxpool3(x) # N x 480 x 14 x 14 x = self.inception4a(x) # N x 512 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux1 = self.aux1(x) x = self.inception4b(x) # N x 512 x 14 x 14 x = self.inception4c(x) # N x 512 x 14 x 14 x = self.inception4d(x) # N x 528 x 14 x 14 if self.training and self.aux_logits: # eval model lose this layer aux2 = self.aux2(x) x = self.inception4e(x) # N x 832 x 14 x 14 x = self.maxpool4(x) # N x 832 x 7 x 7 x = self.inception5a(x) # N x 832 x 7 x 7 x = self.inception5b(x) # N x 1024 x 7 x 7 x = self.avgpool(x) # N x 1024 x 1 x 1 x = torch.flatten(x, 1) # N x 1024 x = self.dropout(x) x = self.fc(x) # N x 1000 (num_classes) if self.training and self.aux_logits: # eval model lose this layer return x, aux2, aux1 return x self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)：ceil_mode=True时 取整方式变为了上取整。 nn.AdaptiveAvgPool2d((1, 1)) ：自适应的池化下采样操作，其中输入参数为一个元组，大小为目标输出的[H,w]值。 模型的训练但部分还是和之前的模型相似的，以下为不同的部分。 1234net = GoogLeNet(num_classes=5, aux_logits=True, init_weights=True) net.to(device) loss_function = nn.CrossEntropyLoss() optimizer = optim.Adam(net.parameters(), lr=0.0003) 首先是定义的模型为GoogLeNet与原来不同。 123456789101112131415for step, data in enumerate(train_bar): images, labels = data optimizer.zero_grad() logits, aux_logits2, aux_logits1 = net(images.to(device)) loss0 = loss_function(logits, labels.to(device)) loss1 = loss_function(aux_logits1, labels.to(device)) loss2 = loss_function(aux_logits2, labels.to(device)) loss = loss0 + loss1 * 0.3 + loss2 * 0.3 loss.backward() optimizer.step() # print statistics running_loss += loss.item() train_bar.desc = &quot;train epoch[{}/{}] loss:{:.3f}&quot;.format(epoch + 1, epochs, loss) 其次是治理的损失函数用三个，训练时分别辅助分类器进行计算，之后再将计算得到的辅助分类器的值进行加权处理。 在训练是，会去计算各种辅助分类器的输出，计算损失函数，之后在验证和测试过程中，就不会再去计算辅助分类器了。 模型测试1234567# create modelmodel = GoogLeNet(num_classes=5, aux_logits=False).to(device)# load model weightsweights_path = &quot;./googleNet.pth&quot;assert os.path.exists(weights_path), &quot;file: '{}' dose not exist.&quot;.format(weights_path)missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device), strict=False) 这里，我们在训练过程中是保存了辅助分类器的参数的，但是在测试时，没有定义辅助分类器，因此将strict=False，默认为True，此时model.load_state_dict() 会返回两个结果，unexpected_keys保留的是之前辅助分类器的层。 最好的结果达到了86%左右。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"},{"title":"VGG网络详解与Pytorch实现","text":"hljs.initHighlightingOnLoad(); VGG网络详解简述VGG在2014年由牛津大学著名研究组VGG (Visual GeometryGroup)提出，斩获该年ImageNet竞赛中Localization Task (定位任务)第一名和Classification Task (分类任务)第二名。本文从模型的搭建与pytorch的实现进行具体的介绍。 VGG网络的几种配置 一般使用的时候，多用D网络。 网络中的亮点: 通过堆叠多个3x3的卷积核来替代大尺度卷积核——(减少所需参数) 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核，代替后拥有相同的感受野。 CNN的感受野在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野(receptive field)。通俗的解释是，输出feature map上的一个单元对应输入层上的区域大小。 感受野的计算公式： F(i)=(F(i+1)-1)\\times Stride+K_{size} $F(i)$为第i层感受野，$Stride$为第i层的步距，$K_{size}$为卷积核或采样核尺寸。 Pool1：Size=2$\\times$2，Stride=2；Conv1：size=3$\\times$3，Stride=2 Feature map：$F=1$ Pool1：$F=(1-1)\\times2+2=2$ Conv1：$F=(2-1)\\times2+3=5$ 验证两个3$\\times$3的卷积核可以代替一个7$\\times$7(Stride=1): Feature map：$F=1$ Conv3$\\times$3(3)：$F=(1-1)\\times1+3=3$ Conv3$\\times$3(2)：$F=(3-1)\\times1+3=5$ Conv3$\\times$3(1)：$F=(5-1)\\times1+3=7$ 论文中提到，可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核。使用7x7卷积核所需参数，与堆叠三个3x3卷积核所需参数(假设输入输出channel为C) $7\\times7\\times C \\times C = 49C^2$ $3\\times3\\times C \\times C+3\\times3\\times C \\times C+3\\times3\\times C \\times C=27C^2$ 卷积层的作用是用来提取特征，全连接层的作用的用来分类。 VGG的pytorch实现模型搭建123456cfgs = { 'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], 'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], 'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],} 配置VGG的模型list，里面的数字代表Conv层的channel数，“M”代表Maxpool层。 其中cfg为一个dict的数据，Key为不同VGG的类型，Value为list即不同的VGG网络的配置参数。 卷积层的实现12345678910111213def make_features(cfg: list): layers = [] in_channels = 3 for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) layers += [conv2d, nn.ReLU(True)] # 每个卷积函数跟ReLU激活函数都是绑定在一起的。 in_channels = v # 下一层的输入为本层的输出 return nn.Sequential(*layers) 该代码是用来读取配置文件的，由于输入为一张图片，因此输入的in_channels=3。 nn.Sequential(layers)*：实例化非关键字参数实现的。 全连接层的实现12345678910111213self.classifier = nn.Sequential( # 第一个全连接层 nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), # 第二个全连接层 nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), # 第三个全连接层 nn.Linear(2048, class_num) ) 全部的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738class VGG(nn.Module): def __init__(self, features, class_num=1000, init_weights=False): super(VGG, self).__init__() self.features = features self.classifier = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(512*7*7, 2048), nn.ReLU(True), nn.Dropout(p=0.5), nn.Linear(2048, 2048), # 原论文为4096，为了加快速度我们设置为2048 nn.ReLU(True), nn.Linear(2048, class_num) ) if init_weights: self._initialize_weights() def forward(self, x): # N x 3 x 224 x 224 x = self.features(x) # N x 512 x 7 x 7 # 展平操作，和之前相似 x = torch.flatten(x, start_dim=1) # N x 512*7*7 x = self.classifier(x) return x def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') nn.init.xavier_uniform_(m.weight) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) # nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 模型的实例化123456789def vgg(model_name=&quot;vgg16&quot;, **kwargs): try: cfg = cfgs[model_name] # 得出配置列表参数 except: print(&quot;Warning: model number {} not in cfgs dict!&quot;.format(model_name)) exit(-1) model = VGG(make_features(cfg), **kwargs) return model \\*kwargs*：代表可变字典长度的参数。 模型的训练训练的过程，基本和ALexNet相同。这里由于VGG网络的参数多，训练所需要的数据大，而现实过程中我们的参数不足，因此需要迁移学习的方法来解决比较好。","link":"/2022/01/30/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"}],"tags":[{"name":"Typora","slug":"Typora","link":"/tags/Typora/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"机械振动","slug":"机械振动","link":"/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"},{"name":"Latex","slug":"Latex","link":"/tags/Latex/"},{"name":"图像分类","slug":"图像分类","link":"/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"}],"categories":[{"name":"Typora","slug":"Typora","link":"/categories/Typora/"},{"name":"PyTorch教程与源码讲解","slug":"PyTorch教程与源码讲解","link":"/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"},{"name":"振动力学","slug":"振动力学","link":"/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"},{"name":"Latex","slug":"Latex","link":"/categories/Latex/"},{"name":"图像分类网络及Pytorch实现","slug":"图像分类网络及Pytorch实现","link":"/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"}]}