<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>DeepLab Vx语义分割网络及代码实现 - houdezaiwu&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="czt"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="czt"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="hljs.initHighlightingOnLoad();  本文主要理论部分分别介绍了DeepLab v1、DeepLab v2、DeepLab v3模型的主要架构，解决的主要问题如空间不变性和下采样丢失信息等，以及为了解决文中提到的问题采取的手段。在代码实现部分，Pytorch主要是进行了是基于FCN网络来修改的。在backbone部分可以选择resnet和mobilenet v3，本"><meta property="og:type" content="blog"><meta property="og:title" content="DeepLab Vx语义分割网络及代码实现"><meta property="og:url" content="http://example.com/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/DeepLab-Vx%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><meta property="og:site_name" content="houdezaiwu&#039;s blog"><meta property="og:description" content="hljs.initHighlightingOnLoad();  本文主要理论部分分别介绍了DeepLab v1、DeepLab v2、DeepLab v3模型的主要架构，解决的主要问题如空间不变性和下采样丢失信息等，以及为了解决文中提到的问题采取的手段。在代码实现部分，Pytorch主要是进行了是基于FCN网络来修改的。在backbone部分可以选择resnet和mobilenet v3，本"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/20220626114021.png"><meta property="article:published_time" content="2022-07-07T14:22:32.000Z"><meta property="article:modified_time" content="2022-07-07T14:31:12.898Z"><meta property="article:author" content="czt"><meta property="article:tag" content="Pytorch"><meta property="article:tag" content="语义分割"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/20220626114021.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/DeepLab-Vx%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},"headline":"DeepLab Vx语义分割网络及代码实现","image":["https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/20220626114021.png"],"datePublished":"2022-07-07T14:22:32.000Z","dateModified":"2022-07-07T14:31:12.898Z","author":{"@type":"Person","name":"czt"},"publisher":{"@type":"Organization","name":"houdezaiwu's blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"hljs.initHighlightingOnLoad();  本文主要理论部分分别介绍了DeepLab v1、DeepLab v2、DeepLab v3模型的主要架构，解决的主要问题如空间不变性和下采样丢失信息等，以及为了解决文中提到的问题采取的手段。在代码实现部分，Pytorch主要是进行了是基于FCN网络来修改的。在backbone部分可以选择resnet和mobilenet v3，本"}</script><link rel="canonical" href="http://example.com/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/DeepLab-Vx%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="stylesheet" href="/css/prism-coy-without-shadows.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/20220626114021.png" alt="DeepLab Vx语义分割网络及代码实现"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-07-07T14:22:32.000Z" title="2022/7/7 下午10:22:32">2022-07-07</time>发表</span><span class="level-item"><time dateTime="2022-07-07T14:31:12.898Z" title="2022/7/7 下午10:31:12">2022-07-07</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">语义分割及Pytorch实现</a></span><span class="level-item">41 分钟读完 (大约6222个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">DeepLab Vx语义分割网络及代码实现</h1><div class="content"><link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">

<!-- hexo-inject:begin --><!-- hexo-inject:end --><script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<p>本文主要理论部分分别介绍了<strong>DeepLab v1、DeepLab v2、DeepLab v3</strong>模型的主要架构，解决的主要问题<strong>如空间不变性和下采样丢失信息</strong>等，以及为了解决文中提到的问题采取的手段。在代码实现部分，Pytorch主要是进行了是基于FCN网络来修改的。在<code>backbone</code>部分可以选择resnet和mobilenet v3，本文主要讲解的是resent部分。在ASPP部分，是基于FCNHead的框架来搭建的。</p>
<span id="more"></span>
<h2 id="DeepLab-V1"><a href="#DeepLab-V1" class="headerlink" title="DeepLab V1"></a><strong>DeepLab V1</strong></h2><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220705202948298.png" alt=""></p>
<h3 id="主要的问题"><a href="#主要的问题" class="headerlink" title="主要的问题"></a><strong>主要的问题</strong></h3><p>首先，文章总结了当前情况下语义分割存在的问题，其中主要包括<strong>下采样操作会造成分辨率的下降</strong>，其次就是无法保证空间不变性，因为在分类网络中，一般都是要满足空间不变性的，就是图片旋转平移变化之后其预测的结果是不变的，但是<strong>对于语义分割而言，不可以出现空间不变性。</strong></p>
<p>对于上述的问题，本文给出的解决方案是使用<strong>膨胀卷积</strong>来保证又足够的分辨率，其次就是使用<strong>Fully-connected CRF(Conditional Random Field)</strong>，但是这个在早期的语义分割里面使用较多，但是在v3开始就不在使用了。</p>
<hr>
<h3 id="网络的优势"><a href="#网络的优势" class="headerlink" title="网络的优势"></a><strong>网络的优势</strong></h3><ul>
<li>速度更快，论文中说是因为采用了膨胀卷积的原因，但fully-connected CRFs很耗时；</li>
<li>准确率更高，相比之前最好的网络提升了7.2个点；</li>
<li>模型结构简单，主要由DCNNs (Deep Convolutional Nerual Networcks) 和CRFs联级构成。</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220705204942442.png" alt=""></p>
<blockquote>
<p>这里面常见的结构又以下几种，包括<strong>MSC、CRF、LargeFOV</strong>单个结构，但本文我们仅仅讲<strong>MSC、LargeFOV.</strong></p>
</blockquote>
<hr>
<h3 id="Large-FOV"><a href="#Large-FOV" class="headerlink" title="Large FOV"></a><strong>Large FOV</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220705205401389.png" alt=""></p>
<ul>
<li>在保证Mean IoU不下降的前提下，去加快模型的训练速度。</li>
<li>网络的backbone也是当是效果最好的VGG16网络。</li>
<li>这里也是使用了全连接FC层化为卷积的操作，使用的是<code>kernel_size=7x7,channels=4096</code>的卷积网络。但是这样这样做为成为本文的一个计算的瓶颈。于是如下表所示，会有一个对卷积核进行下采样得到<code>kernel_size=4x4</code>的情况。<ul>
<li>当我们这里的<code>kernel_size=4</code>之后，会将对应的感受野原来的一半，于是就会出现<code>Mean_IoU</code>降低的情况，同时其读取速度和占用的内存都会升高。</li>
<li>之后，通过提高膨胀系数<code>input_stride=8</code>，于是就会出现感受野恢复到原来情况。</li>
<li>最后，继续将卷积核的尺寸下降到<code>kernel_size=4</code>，其中膨胀系数上升到<code>input_stride=12</code>，同时卷积核个数下降到<code>channels=1024</code>，最后得到的运算速度又运算速度和<code>Mean_IoU</code>都有所上升。</li>
</ul>
</li>
<li><strong>于是LargeFOV 就等价于一个卷积核为<code>kernel_size=3</code>，膨胀系数为12的卷积。</strong></li>
</ul>
<p>最后的配置图如下图：</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/Snipaste_2022-07-06_09-29-13.jpg" alt=""></p>
<p>这里的backbone为VGG网络，但是有部分也是进行了修改：</p>
<ul>
<li>第一个Maxpool，将原来的<code>kernel_size=2-&gt;3</code>。</li>
<li>其中前三个下采样操作的倍率为8倍。</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706095555408.png" alt=""></p>
<hr>
<h3 id="MSc-Multi-Scale"><a href="#MSc-Multi-Scale" class="headerlink" title="MSc(Multi-Scale)"></a><strong>MSc(Multi-Scale)</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706095737812.png" alt=""></p>
<p>其实就是融合多个尺度上的数据，其实这里原论文的作者不是很推荐，作者比较推荐去使用CRF。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706100051905.png" alt=""></p>
<p>这里是将原图尺度和前面4个maxpool尺度进行融合，最后提高间级都转化为<code>28x28xnum_class</code>.</p>
<h2 id="DeepLab-v2"><a href="#DeepLab-v2" class="headerlink" title="DeepLab v2"></a><strong>DeepLab v2</strong></h2><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706102610889.png" alt=""></p>
<p>相比于v1其主要的提升在于其换了backbone，2016年分类领域的重要作品resent出世，其效果力压VGG，于是好多问题的backbone就投向了resnet，其次就是其引入了aspp结构。</p>
<hr>
<h3 id="主要的问题-1"><a href="#主要的问题-1" class="headerlink" title="主要的问题"></a><strong>主要的问题</strong></h3><p>这里其实和之前的v1大致相同，基本的问题有三个：</p>
<ul>
<li>分辨率会被降低，(主要是由于下采样<code>stride&gt;1</code>的层导致的)；</li>
<li>目标的多尺度问题；</li>
<li>DCNNs的不变性(invarience)会降低定位的精度。</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706103612439.png" alt=""></p>
<p>在v1的基础上增加了多尺度的问题。</p>
<hr>
<h3 id="对应的解决方法"><a href="#对应的解决方法" class="headerlink" title="对应的解决方法"></a><strong>对应的解决方法</strong></h3><ul>
<li><p><strong>针对分辨率被降低的问题</strong>，一般就是将最后的几个Maxpooling层的<strong>stride设置成1</strong>(如果是通过卷积下采样的，比如resnet，同样将<strong>stride设置成1</strong>即可)，<strong>配合使用膨胀卷积。</strong></p>
<blockquote>
<p><strong>就是和前面一样，将下采样的卷积层的stride=1，配合膨胀卷积来使用。</strong></p>
</blockquote>
</li>
<li><p><strong>针对目标多尺度的问题，</strong>最容易想到的就是将<strong>图像缩放到多个尺度分别通过网络进行推理，最后将多个结果进行融合即可</strong>。这样做虽然有用但是计算量太大了。为了解决这个问题，<strong>DeepLab V2中提出了ASPP模块(atrous spatial pyramid pooling)。</strong></p>
</li>
<li><p><strong>针对DCNNs不变性导致定位精度降低的问题，</strong>和DeepLab V1差不多还是<strong>通过CRFs解决</strong>，不过这里用的是fully connected <strong>pairwise</strong> CRF，相比V1里的fully connected CRF要更高效点。</p>
</li>
</ul>
<hr>
<h3 id="网络的优势-1"><a href="#网络的优势-1" class="headerlink" title="网络的优势"></a><strong>网络的优势</strong></h3><ul>
<li>运算速度会更快；</li>
<li>其准确率会更高，并且在当是state-of-art；</li>
<li>模型的结构简单，但是还是原来的DCNNs+CRF的联级。</li>
</ul>
<hr>
<h3 id="ASPP-atrous-spatial-pyramid-pooling"><a href="#ASPP-atrous-spatial-pyramid-pooling" class="headerlink" title="ASPP(atrous spatial pyramid pooling)"></a><strong>ASPP(atrous spatial pyramid pooling)</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706105725625.png" alt=""></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706105750447.png" alt=""></p>
<p>如上图所示，是将图片经过不同的膨胀卷积得到不同尺度的特征，之后将不同尺度的特征进行并联。</p>
<p>这里有两种ASPP结构，和LargeFOV相比的结构如下表所示。</p>
<ul>
<li><p>ASPP-S对应的膨胀系数为 $r=\{2,4,8,12\}$ ；</p>
</li>
<li><p>ASPP-L对应的膨胀系数为 $r=\{6,12,18,24\}$；</p>
</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706111159949.png" alt=""></p>
<p>需要注意的是，上图的backbone是针对一般的VGG16的，在resnet为backbone的网络中，其只有一个3x3的膨胀卷积，没有后面那两个全连接层。</p>
<hr>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a><strong>消融实验</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706111825171.png" alt=""></p>
<ul>
<li>上图的主要的方法包括，<strong>MSC代表多尺度操作</strong>、<strong>COCO代表是否进行预训练操作</strong>、<strong>Aug代表是否进行数据增强</strong>、<strong>LargeFOV</strong>、<strong>ASPP</strong>、<strong>CRF是主要来解决空间不变性的方法</strong>。</li>
<li>MSc中将原来的图像变成<code>scale=&#123;0.5,0.75,1&#125;</code>，之后的融合操作就去上述三个输出里面的最大值，相比原来提升了两个点。</li>
<li>COCO就是将其在COCO数据集上进行预训练操作，相比之前提升了两个点。</li>
<li>Aug就是对数据进行增强操作，其实就是对数据进行0.5-1.5倍的缩放。</li>
<li>LargeFOV对最后的结果的提升不是很明显。</li>
<li>ASPP和CRF对最后的提升有1.5个点左右。相比之下CRF的提升就不是很明显了，但是在v1中是可以提上4个点左右。</li>
<li>将VGG16换成resnet101大概可以提升3个点。</li>
</ul>
<hr>
<h3 id="学习策略的设计"><a href="#学习策略的设计" class="headerlink" title="学习策略的设计"></a><strong>学习策略的设计</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706134308503.png" alt=""></p>
<p>这里提高更改学习率的策略就可以提高3个点的提升。</p>
<script type="math/tex; mode=display">
learing\_rate=lr\times(1-\frac{iter}{max\_iter})^{power}</script><blockquote>
<p>作者的炼丹能力太强了。</p>
</blockquote>
<hr>
<h3 id="网络的结构"><a href="#网络的结构" class="headerlink" title="网络的结构"></a><strong>网络的结构</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220706134924781.png" alt=""></p>
<p>这里和FCN其实很像，<code>large3</code>之前基本上照抄的resnet-101，后面就重新修改的网络，将膨胀卷积加入到网络之中了。</p>
<p>如右图所示，其主要的<code>layer3,layer4</code>主要的变化是取消了下采样，换成了对应的膨胀卷积，其中在<code>layer3</code>里面得到膨胀系数为2，在<code>layer4</code>里面的膨胀系数为4，前面没有膨胀卷积，因此不会出现gridding effect的现象。</p>
<p>下面接一个ASPP操作的，将其输入到四个带偏置的卷积，其输出的维度就是分类的个数。</p>
<blockquote>
<p>我估计这里的膨胀卷积应该会有padding，要不然不会出现输入和输出一样的尺寸的情况。</p>
</blockquote>
<h2 id="DeepLab-V3"><a href="#DeepLab-V3" class="headerlink" title="DeepLab V3"></a><strong>DeepLab V3</strong></h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707090044668.png" alt=""></p>
<ul>
<li>引入了<strong>Multi-grid</strong>的思想，之前在v2里面<strong>膨胀系数</strong>都是随意进行实现的，在v3中为了避免出现<strong>gridding effect</strong>这里重新设计了膨胀系数。</li>
<li>改进之前的ASPP结构。</li>
<li>移除了CRF结构，因为CPF结构在v2里面有时候就效果非常提升不如在v1结构中明显了。</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707090638450.png" alt=""></p>
<p>以上分别是如何获取多尺度信息的方法：</p>
<ul>
<li>第一种是将图片缩放到不同的结构类型，分别进行的特征提取后再进行融合merge。</li>
<li>第二种是将适用encoder-decoder架构，这种架构的代表网络是U-Net，先进行下采样，然后上采样的时候不断融合之前的信息。</li>
<li>第三种是先进行下采样，之后提高膨胀卷积来恢复到原来的大小，改架构的代表就是DeepLab v1。</li>
<li>第四种是引入ASPP架构来获取多尺度信息融合的能力，该架构的代表是DeepLab v2。</li>
</ul>
<h3 id="DeepLab-v3的两种结构"><a href="#DeepLab-v3的两种结构" class="headerlink" title="DeepLab v3的两种结构"></a><strong>DeepLab v3的两种结构</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707091722453.png" alt=""></p>
<p>其实本文构建了两个模型，但是最后github代码复现比较多的还是ASPP的模型，up猜想ASPP比较消耗内存，可能由于当是的内存不多才用了第一个模型。</p>
<p>下面来分别看两个模型：</p>
<ul>
<li><p>cascaded model中前面的4个层对应的就是ResNet结构中的<code>layer1,layer2,layer3,layer4</code></p>
<blockquote>
<p><strong>由于<code>layer1</code>是没有进行下采样的，进行下采样的是<code>layer1</code>之前的maxpool层，于是其图中标注的通道数有问题。</strong></p>
</blockquote>
<ul>
<li>其次就是，由于当是显卡内存的问题，其之前在训练是将下采样率为16，验证的时候设置为8，来节约缓存开销，增大训练过程中的<code>batch_size</code>。</li>
<li>这里的膨胀系数有特定的计算公式$膨胀系数=rate \times multi_grid$ </li>
<li>后面的几个层<code>block5,6,7</code>在结构上和<code>block4</code>是相同的，都是残差块拼接的结构，就是膨胀系数不同而已。</li>
</ul>
</li>
<li><p>ASPP model 这个模型乍一看是其实和之前的DeepLab v2很类似，但是其在ASPP模块的结构上面进行了调整。</p>
<ul>
<li>这里一共有5个分支，分别是<strong>Conv1x1、Conv3x3_rate=6、Conv3x3_rate=12、Conv3x3_rate=18、全局pooling</strong>。最后提高一个Concat拼接和一个Conv1x1。</li>
<li>如下图所示为二者的对比图，其中对应v3来说，当其下采样率为8时，对应的膨胀系数要翻倍。</li>
</ul>
</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707095226034.png" alt=""></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707095244183.png" alt=""></p>
<p>相比之下，v2的ASPP结构就显得很简陋。</p>
<h3 id="Multi-grid"><a href="#Multi-grid" class="headerlink" title="Multi-grid"></a><strong>Multi-grid</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707100037969.png" alt=""></p>
<p>这里由上面可知，<code>block5,6,7</code>的结构和之前一样，都是三个卷积相连的残差结构，于是就有<strong>Multi-Grid</strong>的参数有三个，这三个的膨胀系数计算的公式为：$膨胀系数=rate \times multi_grid$ 。</p>
<p>对于cascade model 主要采用的是$(1,2,1)$的Multi-grid，此时效果最好。</p>
<p>对于ASPP model 主要采用的是$(1,2,4)$的Multi-grid，此时效果最好。</p>
<h3 id="消融实验-1"><a href="#消融实验-1" class="headerlink" title="消融实验"></a><strong>消融实验</strong></h3><p><strong>cascaded model</strong></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707101425019.png" alt=""></p>
<p>MS对应的放大的倍率，$sclaes=\{0.5,0.75,1.0,1.25,1.5,1.75\}$，这里使用MS之后可以提高0.8个百分点。</p>
<p>OS其实是<code>out_stride</code>就是下采样率的大小，将在显存允许的情况下，将16倍变成8倍就科研提高1.5个百分点。</p>
<p>Flip即为延水平方向反转的操作，可以提高0.4个点。</p>
<p><strong>ASPP model</strong></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707102415607.png" alt=""></p>
<p>OS=8提高了1.3个百分点，MS提高了1个百分点，Flip提高了1个百分点，COCO数据集上的进行预训练操作，可以提高3百分点。</p>
<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a><strong>训练细节</strong></h3><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707105652022.png" alt=""></p>
<p>如上图所示，相比DeepLab v2-CRF ,DeepLab v3的在训练的效果上提升的了6个百分点，在消融实验中，仅仅实验MS+改进的ASPP其实也不至于就提升6个点，于是就是在训练的过程进行了一些tick。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707105315543.png" alt=""></p>
<blockquote>
<p><strong>crop_size</strong>：代表的是输入到网络中的大小，如果图片大于crop_size就将其进行随机的剪裁操作。</p>
</blockquote>
<ul>
<li><p>增大crop_size就会可以提高9个百分点。</p>
</li>
<li><p><strong>训练的时候还原回到原来的尺度之后再来计算损失</strong>，在DeepLab v2中是真实的标签也进行缩放，先计算损失然后再进行上采样。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707111906836.png" alt=""></p>
<p>这样做的原因时但是的算例不足，这样做的可以加快计算速度。</p>
<p>如果还原到原来到尺寸之后再来计算损失，就会比原来提高1.2个百分点。</p>
</li>
<li><p>fine-tuning (微调) 这里就是在训练的过程中选择性的冻结某些层。本文在训练的过程中，选择性的冻结BN层就会达到很好的效果，提升1.3个百分点。</p>
</li>
</ul>
<h3 id="Pytorch-官方实现的DeepLab-v3"><a href="#Pytorch-官方实现的DeepLab-v3" class="headerlink" title="Pytorch 官方实现的DeepLab v3"></a><strong>Pytorch 官方实现的DeepLab v3</strong></h3><ul>
<li>Pytorch的代码是没有使用Multi-Grid的。</li>
<li>多了一个FCNHead辅助训练分支，可以选择不使用。</li>
<li>无论是训练还是验证output_stride都使用的8。</li>
<li>ASPP中三个膨胀卷积分支的膨胀系数是12,24,36。</li>
</ul>
<p>以下是这个DeepLab v3的网络图，这里我们从细节的地方来对其进行分析。</p>
<p><img src="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/raw/75f81bff3f2ca53866ece59042ad0a473f2fb930/pytorch_segmentation/deeplab_v3/deeplabv3_resnet50.png" alt="deeplabv3_resnet50_pytorch"></p>
<p>前面的三层已经下采样了8倍了，因此这里不是很需要再次进行下采样了，<strong>原论文是下采样16倍，因此其在<code>layer3</code>出还是需要再次进行下采样操作。</strong>因此在<code>layer3,4</code>处就将<code>stride=1</code>不进行下采样操作。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707113625503.png" alt=""></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707114133967.png" alt=""></p>
<p><code>backbone</code>出来以后就进入ASPP层，出来之后我们进入一个类似于FCN Head的结构将<code>channel=num_class</code>，最后进行双线性插值上采样输出。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707114459421.png" alt=""></p>
<hr>
<h2 id="DeepLab-v3的pytorch代码实现"><a href="#DeepLab-v3的pytorch代码实现" class="headerlink" title="DeepLab v3的pytorch代码实现"></a><strong>DeepLab v3的pytorch代码实现</strong></h2><p>本项目主要来自于pytorch官方的源码：<a target="_blank" rel="noopener" href="https://github.com/pytorch/vision/tree/main/torchvision/models/segmentation">https://github.com/pytorch/vision/tree/main/torchvision/models/segmentation</a></p>
<h3 id="环境的配置"><a href="#环境的配置" class="headerlink" title="环境的配置"></a><strong>环境的配置</strong></h3><ul>
<li>Python3.6/3.7/3.8</li>
<li>Pytorch1.10</li>
<li>Ubuntu或Centos(Windows暂不支持多GPU训练)</li>
<li>最好使用GPU训练</li>
<li>详细环境配置见<code>requirements.txt</code></li>
</ul>
<h3 id="文件的结构"><a href="#文件的结构" class="headerlink" title="文件的结构"></a><strong>文件的结构</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">├── src: 模型的backbone以及DeepLabv3的搭建</span><br><span class="line">├── train_utils: 训练、验证以及多GPU训练相关模块</span><br><span class="line">├── my_dataset.py: 自定义dataset用于读取VOC数据集</span><br><span class="line">├── train.py: 以deeplabv3_resnet50为例进行训练</span><br><span class="line">├── train_multi_GPU.py: 针对使用多GPU的用户使用</span><br><span class="line">├── predict.py: 简易的预测脚本，使用训练好的权重进行预测测试</span><br><span class="line">├── validation.py: 利用训练好的权重验证/测试数据的mIoU等指标，并生成record_mAP.txt文件</span><br><span class="line">└── pascal_voc_classes.json: pascal_voc标签文件</span><br></pre></td></tr></table></figure>
<h3 id="预训练权重的下载"><a href="#预训练权重的下载" class="headerlink" title="预训练权重的下载"></a><strong>预训练权重的下载</strong></h3><ul>
<li>注意：官方提供的预训练权重是在COCO上预训练得到的，训练时只针对和PASCAL VOC相同的类别进行了训练，所以类别数是21(包括背景)</li>
<li>deeplabv3_resnet50: <a target="_blank" rel="noopener" href="https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth">https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth</a></li>
<li>deeplabv3_resnet101: <a target="_blank" rel="noopener" href="https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth">https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth</a></li>
<li>deeplabv3_mobilenetv3_large_coco: <a target="_blank" rel="noopener" href="https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth">https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth</a></li>
<li>注意，下载的预训练权重记得要重命名，比如在train.py中读取的是<code>deeplabv3_resnet50_coco.pth</code>文件， 不是<code>deeplabv3_resnet50_coco-cd0a2569.pth</code></li>
</ul>
<p>其他的大部分和之前的FCN类似，比如如何构建数据集、混淆矩阵、以及如何进行训练和评估等，本文主要讲解和之前不一样的部分，例如模型的搭建、学习率更新策略的设计等。</p>
<h3 id="学习率更新策略的实现"><a href="#学习率更新策略的实现" class="headerlink" title="学习率更新策略的实现"></a><strong>学习率更新策略的实现</strong></h3><p>下面是创建学习率更新算法的主要代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_lr_scheduler</span>(<span class="params">optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">                        num_step: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        epochs: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        warmup=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        warmup_epochs=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        warmup_factor=<span class="number">1e-3</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_step &gt; <span class="number">0</span> <span class="keyword">and</span> epochs &gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> warmup <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        warmup_epochs = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        根据step数返回一个学习率倍率因子，</span></span><br><span class="line"><span class="string">        注意在训练开始之前，pytorch会提前调用一次lr_scheduler.step()方法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> warmup <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">and</span> x &lt;= (warmup_epochs * num_step):</span><br><span class="line">            alpha = <span class="built_in">float</span>(x) / (warmup_epochs * num_step)</span><br><span class="line">            <span class="comment"># warmup过程中lr倍率因子从warmup_factor -&gt; 1</span></span><br><span class="line">            <span class="keyword">return</span> warmup_factor * (<span class="number">1</span> - alpha) + alpha</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># warmup后lr倍率因子从1 -&gt; 0</span></span><br><span class="line">            <span class="comment"># 参考deeplab_v2: Learning rate policy</span></span><br><span class="line">            <span class="keyword">return</span> (<span class="number">1</span> - (x - warmup_epochs * num_step) / ((epochs - warmup_epochs) * num_step)) ** <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=f)</span><br></pre></td></tr></table></figure>
<h4 id="输入的参数"><a href="#输入的参数" class="headerlink" title="输入的参数"></a><strong>输入的参数</strong></h4><ul>
<li><code>num_step</code>：每个epoch里面有多少步；</li>
<li><code>epoch</code>：这个训练一共有多少循环epoch；</li>
<li><code>warmup=True</code>：是否需要进行热身训练，一般情况下都是为True的；</li>
<li><code>warmup_epochs=1</code>：热身训练持续的多少个循环epoch，默认是1；</li>
<li><code>warmup_factor=1e-3</code>：在热身阶段就是将学习率从<code>warmup_factor</code>逐渐递增到1的一个过程。</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707161111491.png" alt=""></p>
<h4 id="内置实现函数"><a href="#内置实现函数" class="headerlink" title="内置实现函数"></a><strong>内置实现函数</strong></h4><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707160013566.png" alt=""></p>
<p>开始的时候，默认情况是进行<code>warmup</code>的，于是将学习率从<code>warmup_factor</code>逐渐递增到1，到第二个epoch之后就是按照DeepLab v2里给出的策略进行训练。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707161035378.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建学习率更新策略，这里是每个step更新一次(不是每个epoch)</span></span><br><span class="line">lr_scheduler = create_lr_scheduler(optimizer, <span class="built_in">len</span>(train_loader), args.epochs, warmup=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率变化的可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">lr_list = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_loader)):</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]</span><br><span class="line">        lr_list.append(lr)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(lr_list)), lr_list)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="模型的创建"><a href="#模型的创建" class="headerlink" title="模型的创建"></a><strong>模型的创建</strong></h3><h4 id="整体模型的搭建"><a href="#整体模型的搭建" class="headerlink" title="整体模型的搭建"></a><strong>整体模型的搭建</strong></h4><p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707162342104.png" alt=""></p>
<p>上面为创建模型的主要代码，其中大部分和之前的FCN很像，我猜想可能是开发模型的那些人想要让代码复用性更好，方便模型和框架上的统一才这样做的。其中就比如DeepLab v3中本来就没有用辅助分类器，但是这个模型就加了辅助分类器。</p>
<p>这里的导入预训练的部分其实就是和之前的效果一样。</p>
<ul>
<li><p>先导入在COCO数据集上预先训练好的模型权重。</p>
</li>
<li><p>之后删去分类的部分，因为其对应的类别肯能和自己的任务不同。</p>
</li>
<li><p>最后就剩余权重导入到模型中去。</p>
</li>
</ul>
<hr>
<p>下面我们进入第一步创建deeplabv3_resnet模型的代码，该代码主要在<code>deeplabv3_model.py</code>的文件下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deeplabv3_resnet50</span>(<span class="params">aux, num_classes=<span class="number">21</span>, pretrain_backbone=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="comment"># &#x27;resnet50_imagenet&#x27;: &#x27;https://download.pytorch.org/models/resnet50-0676ba61.pth&#x27;</span></span><br><span class="line">    <span class="comment"># &#x27;deeplabv3_resnet50_coco&#x27;: &#x27;https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth&#x27;</span></span><br><span class="line">    backbone = resnet50(replace_stride_with_dilation=[<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pretrain_backbone:</span><br><span class="line">        <span class="comment"># 载入resnet50 backbone预训练权重</span></span><br><span class="line">        backbone.load_state_dict(torch.load(<span class="string">&quot;resnet50.pth&quot;</span>, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    out_inplanes = <span class="number">2048</span></span><br><span class="line">    aux_inplanes = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line">    return_layers = &#123;<span class="string">&#x27;layer4&#x27;</span>: <span class="string">&#x27;out&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> aux:</span><br><span class="line">        return_layers[<span class="string">&#x27;layer3&#x27;</span>] = <span class="string">&#x27;aux&#x27;</span></span><br><span class="line">    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)</span><br><span class="line"></span><br><span class="line">    aux_classifier = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># why using aux: https://github.com/pytorch/vision/issues/4292</span></span><br><span class="line">    <span class="keyword">if</span> aux:</span><br><span class="line">        aux_classifier = FCNHead(aux_inplanes, num_classes)</span><br><span class="line"></span><br><span class="line">    classifier = DeepLabHead(out_inplanes, num_classes)</span><br><span class="line"></span><br><span class="line">    model = DeepLabV3(backbone, classifier, aux_classifier)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果不想适应之前的coco数据集的预训练模型，可以自己导入resnet-50在imagenet数据集上的数据来进行训练。</p>
</li>
<li><p>之后将就是重构<code>backbone</code>，将没有用到的模块删去。</p>
</li>
<li><p>然后使用DeepLabHead模块来构建辅助分类器和主分类器。</p>
<blockquote>
<p><strong>ASPP结构也是包含在DeepLabHead的结构里面的。</strong></p>
</blockquote>
</li>
<li><p>最后将分类器、辅助分类器、backbone来一同构建DeepLab V3大模型。</p>
</li>
</ul>
<p>这里的是实现的过程和之前的FCN网络相同，其具体实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepLabV3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;aux_classifier&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, backbone, classifier, aux_classifier=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DeepLabV3, self).__init__()</span><br><span class="line">        self.backbone = backbone</span><br><span class="line">        self.classifier = classifier</span><br><span class="line">        self.aux_classifier = aux_classifier</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, Tensor]:</span></span><br><span class="line">        input_shape = x.shape[-<span class="number">2</span>:]</span><br><span class="line">        <span class="comment"># contract: features is a dict of tensors</span></span><br><span class="line">        features = self.backbone(x)</span><br><span class="line"></span><br><span class="line">        result = OrderedDict()</span><br><span class="line">        x = features[<span class="string">&quot;out&quot;</span>]</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="comment"># 使用双线性插值还原回原图尺度</span></span><br><span class="line">        x = F.interpolate(x, size=input_shape, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line">        result[<span class="string">&quot;out&quot;</span>] = x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.aux_classifier <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = features[<span class="string">&quot;aux&quot;</span>]</span><br><span class="line">            x = self.aux_classifier(x)</span><br><span class="line">            <span class="comment"># 使用双线性插值还原回原图尺度</span></span><br><span class="line">            x = F.interpolate(x, size=input_shape, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line">            result[<span class="string">&quot;aux&quot;</span>] = x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>这里使用<code>mobilenetv3</code>来实现的代码和<code>resnet</code>略微不同，这里不再细讲。</p>
<blockquote>
<p>之前论文的作者讲过，转置卷积和双线性插值的效果相同，但是插值的计算速度快。</p>
</blockquote>
<hr>
<p>由于前面的部分之前已经有所介绍了，现在我们直接跳入到DeepLabHead结构中。</p>
<p>这里的DeepLabHead层的结构是直接继承自<code>nn.Sequential</code>的。</p>
<blockquote>
<p><strong>在Sequential中他写了相应的forward函数，我们如果不需要重写的话，就可以只写相应的层，不去重写对应的forward函数。</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepLabHead</span>(<span class="params">nn.Sequential</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, num_classes: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>(DeepLabHead, self).__init__(</span><br><span class="line">            ASPP(in_channels, [<span class="number">12</span>, <span class="number">24</span>, <span class="number">36</span>]),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, num_classes, <span class="number">1</span>)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>这个结构就是按照之前的给出的结构来直接搭建的，并且这个类是不需要重写前向传递函数的。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707114459421.png" alt=""></p>
<ul>
<li>首先将<code>backbone</code>里面的信息输入到ASPP里面进行多尺度融合；</li>
<li>然后将其输出输入到一个Conv3x3的网络进行信息提取；</li>
<li>之后通过一个Conv1x1的卷积，其实是作用和全连接层类似，将通道数变成和类别数一样；</li>
<li>最后将输出进行二维插值还原到原来的尺寸。</li>
</ul>
<h4 id="ASPP结构的实现"><a href="#ASPP结构的实现" class="headerlink" title="ASPP结构的实现"></a><strong>ASPP结构的实现</strong></h4><p>下面我们来对ASPP的实现进行分析。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707095244183.png" alt=""></p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707171829199.png" alt=""></p>
<p>这里的输入参数为输入通道的通道数<code>in_channels</code>和膨胀系数<code>atrous_rates</code>。</p>
<p>后面建立第一个分支Conv1x1模块的部分。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707172436407.png" alt=""></p>
<p>然后分别来构建其余的几个带有膨胀系数的Conv3x3的块，这里首先<code>atrous_rates</code>列表化，然后遍历每个系数，来创建不同的<code>ASPPConv</code>块。其实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ASPPConv</span>(<span class="params">nn.Sequential</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>, dilation: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>(ASPPConv, self).__init__(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, <span class="number">3</span>, padding=dilation, dilation=dilation, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>最后再加入一个全局的池化层，其代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ASPPPooling</span>(<span class="params">nn.Sequential</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>(ASPPPooling, self).__init__(</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707173216159.png" alt=""></p>
<p>这里将上述创建好的几个并联的模块放到<code>nn.ModuleList</code>中，再创建一个映射层来融合上面五个通道中的输出。</p>
<p><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/semantic_segmentation/image-20220707173725982.png" alt=""></p>
<p>最后，实现前向传播函数，其中遍历上述<code>nn.ModuleList</code>里面的所有的模块，计算x通过上面五个结构之后的输出，将输出concatenate后导入到信息融合层中处理得到最后的输出。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>DeepLab Vx语义分割网络及代码实现</p><p><a href="http://example.com/2022/07/07/语义分割及Pytorch实现/DeepLab-Vx语义分割网络及代码实现/">http://example.com/2022/07/07/语义分割及Pytorch实现/DeepLab-Vx语义分割网络及代码实现/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>czt</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-07-07</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-07-07</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Pytorch/">Pytorch</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">语义分割</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/07/07/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/LR-ASPP%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">LR-ASPP语义分割网络及代码实现</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/07/05/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/FCN%E7%BD%91%E7%BB%9C%E8%AF%A6%E7%BB%86%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><span class="level-item">FCN网络详细代码实现</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/hexoimg/202201222202112.jpg" alt="厚德载物"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">厚德载物</p><p class="is-size-6 is-block">实事求是，敢为人先</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 湖北 武汉</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">104</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">39</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://paperswithcode.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">paperwithcode</span></span><span class="level-right"><span class="level-item tag">paperswithcode.com</span></span></a></li><li><a class="level is-mobile" href="https://scholar.google.com.hk/?hl=zh-CN" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">google_scholar</span></span><span class="level-right"><span class="level-item tag">scholar.google.com.hk</span></span></a></li><li><a class="level is-mobile" href="https://arxiv.org/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">arxiv</span></span><span class="level-right"><span class="level-item tag">arxiv.org</span></span></a></li><li><a class="level is-mobile" href="https://leetcode-cn.com/problemset/algorithms/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leetcode</span></span><span class="level-right"><span class="level-item tag">leetcode-cn.com</span></span></a></li><li><a class="level is-mobile" href="https://mathf.itewqq.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">mathf</span></span><span class="level-right"><span class="level-item tag">mathf.itewqq.cn</span></span></a></li><li><a class="level is-mobile" href="https://qwerty.kaiyi.cool/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">qwerty</span></span><span class="level-right"><span class="level-item tag">qwerty.kaiyi.cool</span></span></a></li><li><a class="level is-mobile" href="https://www.overleaf.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">overleaf</span></span><span class="level-right"><span class="level-item tag">www.overleaf.com</span></span></a></li><li><a class="level is-mobile" href="http://www.pipioj.online/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">pipioj</span></span><span class="level-right"><span class="level-item tag">www.pipioj.online</span></span></a></li><li><a class="level is-mobile" href="https://monumental-tarsier-a544f3.netlify.app" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">hugocvofczt</span></span><span class="level-right"><span class="level-item tag">monumental-tarsier-a544f3.netlify.app</span></span></a></li><li><a class="level is-mobile" href="https://app.netlify.com/sites/monumental-tarsier-a544f3/overview" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">netlify</span></span><span class="level-right"><span class="level-item tag">app.netlify.com</span></span></a></li><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">十二月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">八月 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">七月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">三月 2022</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">二月 2022</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">一月 2022</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ANSYS/"><span class="tag">ANSYS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-learning/"><span class="tag">Deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Finite-Element-Analysis/"><span class="tag">Finite Element Analysis</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%E5%AE%9E%E6%88%98/"><span class="tag">GAN实战</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-Adversarial-Networks/"><span class="tag">Generative Adversarial Networks</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IEEE%E6%8A%95%E7%A8%BF/"><span class="tag">IEEE投稿</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-learning/"><span class="tag">Machine learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Networks/"><span class="tag">Neural Networks</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SLAM/"><span class="tag">SLAM</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Typora/"><span class="tag">Typora</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/auto-encoder/"><span class="tag">auto-encoder</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/c/"><span class="tag">c++</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/control-theory/"><span class="tag">control theory</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/latex/"><span class="tag">latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/object-detection/"><span class="tag">object detection</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/opencv/"><span class="tag">opencv</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/point-cloud/"><span class="tag">point cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"><span class="tag">图像分类</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tag">图神经网络</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="tag">控制理论</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"><span class="tag">无监督学习</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E5%88%86%E6%9E%90/"><span class="tag">有限元分析</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E6%8C%AF%E5%8A%A8/"><span class="tag">机械振动</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"><span class="tag">生成模型</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="tag">目标检测</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94/"><span class="tag">科研</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><span class="tag">自注意力机制</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"><span class="tag">论文写作</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"><span class="tag">语义分割</span><span class="tag">6</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#DeepLab-V1"><span class="level-left"><span class="level-item">1</span><span class="level-item">DeepLab V1</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#主要的问题"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">主要的问题</span></span></a></li><li><a class="level is-mobile" href="#网络的优势"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">网络的优势</span></span></a></li><li><a class="level is-mobile" href="#Large-FOV"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Large FOV</span></span></a></li><li><a class="level is-mobile" href="#MSc-Multi-Scale"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">MSc(Multi-Scale)</span></span></a></li></ul></li><li><a class="level is-mobile" href="#DeepLab-v2"><span class="level-left"><span class="level-item">2</span><span class="level-item">DeepLab v2</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#主要的问题-1"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">主要的问题</span></span></a></li><li><a class="level is-mobile" href="#对应的解决方法"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">对应的解决方法</span></span></a></li><li><a class="level is-mobile" href="#网络的优势-1"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">网络的优势</span></span></a></li><li><a class="level is-mobile" href="#ASPP-atrous-spatial-pyramid-pooling"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">ASPP(atrous spatial pyramid pooling)</span></span></a></li><li><a class="level is-mobile" href="#消融实验"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">消融实验</span></span></a></li><li><a class="level is-mobile" href="#学习策略的设计"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">学习策略的设计</span></span></a></li><li><a class="level is-mobile" href="#网络的结构"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">网络的结构</span></span></a></li></ul></li><li><a class="level is-mobile" href="#DeepLab-V3"><span class="level-left"><span class="level-item">3</span><span class="level-item">DeepLab V3</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#概述"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">概述</span></span></a></li><li><a class="level is-mobile" href="#DeepLab-v3的两种结构"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">DeepLab v3的两种结构</span></span></a></li><li><a class="level is-mobile" href="#Multi-grid"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">Multi-grid</span></span></a></li><li><a class="level is-mobile" href="#消融实验-1"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">消融实验</span></span></a></li><li><a class="level is-mobile" href="#训练细节"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">训练细节</span></span></a></li><li><a class="level is-mobile" href="#Pytorch-官方实现的DeepLab-v3"><span class="level-left"><span class="level-item">3.6</span><span class="level-item">Pytorch 官方实现的DeepLab v3</span></span></a></li></ul></li><li><a class="level is-mobile" href="#DeepLab-v3的pytorch代码实现"><span class="level-left"><span class="level-item">4</span><span class="level-item">DeepLab v3的pytorch代码实现</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#环境的配置"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">环境的配置</span></span></a></li><li><a class="level is-mobile" href="#文件的结构"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">文件的结构</span></span></a></li><li><a class="level is-mobile" href="#预训练权重的下载"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">预训练权重的下载</span></span></a></li><li><a class="level is-mobile" href="#学习率更新策略的实现"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">学习率更新策略的实现</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#输入的参数"><span class="level-left"><span class="level-item">4.4.1</span><span class="level-item">输入的参数</span></span></a></li><li><a class="level is-mobile" href="#内置实现函数"><span class="level-left"><span class="level-item">4.4.2</span><span class="level-item">内置实现函数</span></span></a></li></ul></li><li><a class="level is-mobile" href="#模型的创建"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">模型的创建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#整体模型的搭建"><span class="level-left"><span class="level-item">4.5.1</span><span class="level-item">整体模型的搭建</span></span></a></li><li><a class="level is-mobile" href="#ASPP结构的实现"><span class="level-left"><span class="level-item">4.5.2</span><span class="level-item">ASPP结构的实现</span></span></a></li></ul></li></ul></li></ul></div></div><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Finite-Element-Analysis/"><span class="level-start"><span class="level-item">Finite Element Analysis</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Generative-Adversarial-Networks/"><span class="level-start"><span class="level-item">Generative Adversarial Networks</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Latex/"><span class="level-start"><span class="level-item">Latex</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Point-Cloud/"><span class="level-start"><span class="level-item">Point Cloud</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/PyTorch%E6%95%99%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%AE%B2%E8%A7%A3/"><span class="level-start"><span class="level-item">PyTorch教程与源码讲解</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/SLAM/"><span class="level-start"><span class="level-item">SLAM</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/Typora/"><span class="level-start"><span class="level-item">Typora</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/auto-encoder/"><span class="level-start"><span class="level-item">auto-encoder</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/opencv/"><span class="level-start"><span class="level-item">opencv</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">图像分类网络及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">图神经网络</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8C%AF%E5%8A%A8%E5%8A%9B%E5%AD%A6/"><span class="level-start"><span class="level-item">振动力学</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/"><span class="level-start"><span class="level-item">机器学习基石</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="level-start"><span class="level-item">现代控制理论</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Epytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">目标检测与pytorch实现</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E7%A0%94%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">科研入门笔记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%92%8CTransformer/"><span class="level-start"><span class="level-item">自注意力机制和Transformer</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item">语义分割及Pytorch实现</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">高级机器学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2022/12/31/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="ConvNeXt网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-12-31T14:16:44.000Z">2022-12-31</time></p><p class="title"><a href="/2022/12/31/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">ConvNeXt网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/12/26/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/"><img src="https://cdn.jsdelivr.net/gh/houdezaiwu2019/image-bed/pytorch/202201271155098.png" alt="VIT网络详解与Pytorch实现"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-12-26T01:38:13.000Z">2022-12-26</time></p><p class="title"><a href="/2022/12/26/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/VIT%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E4%B8%8EPytorch%E5%AE%9E%E7%8E%B0/">VIT网络详解与Pytorch实现</a></p><p class="categories"><a href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C%E5%8F%8APytorch%E5%AE%9E%E7%8E%B0/">图像分类网络及Pytorch实现</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-3/"><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/FEM/APDL.jpg" alt="APDL Learning 3"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-10-19T08:21:53.000Z">2022-10-19</time></p><p class="title"><a href="/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-3/">APDL Learning 3</a></p><p class="categories"><a href="/categories/Finite-Element-Analysis/">Finite Element Analysis</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-2/"><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/FEM/APDL.jpg" alt="APDL Learning 2"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-10-19T08:03:23.000Z">2022-10-19</time></p><p class="title"><a href="/2022/10/19/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-2/">APDL Learning 2</a></p><p class="categories"><a href="/categories/Finite-Element-Analysis/">Finite Element Analysis</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/09/30/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-1/"><img src="https://fastly.jsdelivr.net/gh/houdezaiwu2019/image-bed/FEM/APDL.jpg" alt="APDL Learning 1"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-09-30T07:22:07.000Z">2022-09-30</time></p><p class="title"><a href="/2022/09/30/%E6%9C%89%E9%99%90%E5%85%83%E6%96%B9%E6%B3%95/APDL-learning-1/">APDL Learning 1</a></p><p class="categories"><a href="/categories/Finite-Element-Analysis/">Finite Element Analysis</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="houdezaiwu&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 czt</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>